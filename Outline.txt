Outline



1. Motivation.
2.1 Why we need generalization. Sclability, Robustness, humanlike intelligence, 
2.2 Motivation for Graph Neural networks. Rich representation, Relational reasoning, transferability, 
2. Problem Statement
   - MDP formulation.
   - Objective- maximum reward and optimal policy.
3. Background. 
   - Graphs
   - GNNs, GCN, GAT, GNN-RNN.
   - PPO.
4. Related Work.
5. Approach
5.1 Graph topology
   -Full Mesh: Every node is connected to every other node, ideal for dense interaction environments.
   -Proximity-based Graph: Nodes are connected based on spatial or conceptual proximity, useful for local interaction scenarios.
   -Predicate-based Graph: Connections are formed based on specific conditions or predicates, fitting for rule-based interactions.

5.2 Suitability of Graph Topology for Different Games
1. Pong - Full mesh or proximity based, Why? because of constant interactions between all the objects.
2. Freeway - Proximity based, only necessary to know nearby objects like cars to make an action
3. Pacman - Predicate based, because position of ghost ,pellets wall etc interactions are useful.
4. Breakout - Predicate based, capture dynamic interactions
   

5.3Suitability of GNN Architecture for Different Games
1. Pong - GCN or GAT, they can capture relational dependencies in the game.
2. Freeway - GCN or GAT, they can capture relational dependencies in the game.
3. Pacman - GCN+RNN, temporal nature and strategy making for timing of using powerups and evading the ghosts.
4. Breakout - GCN+RNN, temporal nature and strategy for maximising bricks broken will help rnn.

5.4 Edge Encoding for Different Games

5.5 Training procedure
1. COnvert to graph for the state. 
2. Pass to gnn or gnn-rnn.
3. optimise using ppo.
5.6 Evaluation Procedure
Testing the model in a variety of game scenarios, possibly unseen during training, to gauge its adaptability and performance.
5.7 Evaluation Metrics
Win Rate: The percentage of games won by the AI agent.
Score: Numerical score achieved, reflecting the agent's efficiency or skill.
8. Conclusion.
9. References.
