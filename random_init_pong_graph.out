--------------------- Slurm Task Prolog ------------------------
Job ID: 8046088
Job name: pong_supervised_gnn
Host: cn-406
Date: Mon Jul 15 09:51:16 CEST 2024
User: rishabh.bhatia
Slurm account: rleap
Slurm partition: rleap_gpu_24gb
Work dir: 
------------------
Node usage:
JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
8044499 rleap_gpu exp7_log markus.f  R   19:46:40      1 cn-406
8044498 rleap_gpu exp6_mic markus.f  R   19:46:44      1 cn-406
8046088 rleap_gpu pong_sup rishabh.  R       0:00      1 cn-406
8045911 rleap_gpu   tunnel rishabh.  R      50:59      1 cn-406
8044553 rleap_gpu train.sl samuel.s  R   17:24:22      1 cn-406
8044552 rleap_gpu train.sl samuel.s  R   17:24:34      1 cn-406
------------------
Show launch script with:
sacct -B -j 
------------------
--------------------- Slurm Task Prolog ------------------------
wandb: Currently logged in as: rishabh-bhatia (rwth-ml). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.1
wandb: Run data is saved locally in /work/rleap1/rishabh.bhatia/Master-Thesis-GNN/wandb/run-20240715_095124-x45naqwb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-snowball-198
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rwth-ml/gnn_atari_pong
wandb: üöÄ View run at https://wandb.ai/rwth-ml/gnn_atari_pong/runs/x45naqwb
wandb: Currently logged in as: rishabh-bhatia (rwth-ml). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: rishabh-bhatia (rwth-ml). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: rishabh-bhatia (rwth-ml). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: rishabh-bhatia (rwth-ml). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: rishabh-bhatia (rwth-ml). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: rishabh-bhatia (rwth-ml). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: rishabh-bhatia (rwth-ml). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: rishabh-bhatia (rwth-ml). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.1
wandb: Run data is saved locally in /work/rleap1/rishabh.bhatia/Master-Thesis-GNN/wandb/run-20240715_095134-45w12jzr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-flower-199
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rwth-ml/gnn_atari_pong
wandb: üöÄ View run at https://wandb.ai/rwth-ml/gnn_atari_pong/runs/45w12jzr
/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.[0m
  logger.warn(
wandb: wandb version 0.17.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.1
wandb: Run data is saved locally in /work/rleap1/rishabh.bhatia/Master-Thesis-GNN/wandb/run-20240715_095134-i10usw8h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-hill-206
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rwth-ml/gnn_atari_pong
wandb: üöÄ View run at https://wandb.ai/rwth-ml/gnn_atari_pong/runs/i10usw8h
wandb: wandb version 0.17.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.1
wandb: Run data is saved locally in /work/rleap1/rishabh.bhatia/Master-Thesis-GNN/wandb/run-20240715_095134-o94negpd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-dawn-200
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rwth-ml/gnn_atari_pong
wandb: üöÄ View run at https://wandb.ai/rwth-ml/gnn_atari_pong/runs/o94negpd
wandb: wandb version 0.17.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.1
wandb: Run data is saved locally in /work/rleap1/rishabh.bhatia/Master-Thesis-GNN/wandb/run-20240715_095134-ltqp2gco
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-shape-204
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rwth-ml/gnn_atari_pong
wandb: üöÄ View run at https://wandb.ai/rwth-ml/gnn_atari_pong/runs/ltqp2gco
wandb: wandb version 0.17.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.1
wandb: Run data is saved locally in /work/rleap1/rishabh.bhatia/Master-Thesis-GNN/wandb/run-20240715_095134-9kol8qs5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-cosmos-201
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rwth-ml/gnn_atari_pong
wandb: üöÄ View run at https://wandb.ai/rwth-ml/gnn_atari_pong/runs/9kol8qs5
/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.[0m
  logger.warn(
/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.[0m
  logger.warn(
/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.[0m
  logger.warn(
/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.[0m
  logger.warn(
wandb: wandb version 0.17.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.1
wandb: Run data is saved locally in /work/rleap1/rishabh.bhatia/Master-Thesis-GNN/wandb/run-20240715_095134-x1ia9af8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-thunder-201
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rwth-ml/gnn_atari_pong
wandb: üöÄ View run at https://wandb.ai/rwth-ml/gnn_atari_pong/runs/x1ia9af8
wandb: wandb version 0.17.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.1
wandb: Run data is saved locally in /work/rleap1/rishabh.bhatia/Master-Thesis-GNN/wandb/run-20240715_095134-2r246zsy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-water-203
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rwth-ml/gnn_atari_pong
wandb: üöÄ View run at https://wandb.ai/rwth-ml/gnn_atari_pong/runs/2r246zsy
/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.[0m
  logger.warn(
/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.[0m
  logger.warn(
wandb: wandb version 0.17.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.1
wandb: Run data is saved locally in /work/rleap1/rishabh.bhatia/Master-Thesis-GNN/wandb/run-20240715_095134-r1k39m17
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-fog-205
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rwth-ml/gnn_atari_pong
wandb: üöÄ View run at https://wandb.ai/rwth-ml/gnn_atari_pong/runs/r1k39m17
/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.[0m
  logger.warn(
/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:414: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f66f338dc30> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f66f111c070>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
Using cpu device
time to encode step size is: 0.007112026214599609
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 808      |
|    ep_rew_mean     | -56.9    |
| time/              |          |
|    fps             | 840      |
|    iterations      | 1        |
|    time_elapsed    | 19       |
|    total_timesteps | 16384    |
---------------------------------
time to encode step size is: 0.03161263465881348
time to encode step size is: 0.007004737854003906
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 842          |
|    ep_rew_mean          | -55.6        |
| time/                   |              |
|    fps                  | 226          |
|    iterations           | 2            |
|    time_elapsed         | 144          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0053831693 |
|    clip_fraction        | 0.0332       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.09        |
|    explained_variance   | 0.0231       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.995        |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.000977    |
|    value_loss           | 2.71         |
------------------------------------------
time to encode step size is: 0.02959418296813965
time to encode step size is: 0.0035202503204345703
time to encode step size is: 0.003098011016845703
time to encode step size is: 0.0033905506134033203
time to encode step size is: 0.0031452178955078125
time to encode step size is: 0.0030982494354248047
Eval num_timesteps=40000, episode_reward=13.50 +/- 27.74
Episode length: 1816.20 +/- 456.88
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 1.82e+03     |
|    mean_reward          | 13.5         |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0073204204 |
|    clip_fraction        | 0.0749       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.08        |
|    explained_variance   | 0.735        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.41         |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00573     |
|    value_loss           | 3.94         |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 906      |
|    ep_rew_mean     | -50.2    |
| time/              |          |
|    fps             | 162      |
|    iterations      | 3        |
|    time_elapsed    | 302      |
|    total_timesteps | 49152    |
---------------------------------
time to encode step size is: 0.029566049575805664
time to encode step size is: 0.03149724006652832
time to encode step size is: 0.00710606575012207
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 974         |
|    ep_rew_mean          | -46.7       |
| time/                   |             |
|    fps                  | 154         |
|    iterations           | 4           |
|    time_elapsed         | 424         |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.009164967 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | 0.77        |
|    learning_rate        | 0.0003      |
|    loss                 | 2.27        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00908    |
|    value_loss           | 4.9         |
-----------------------------------------
time to encode step size is: 0.04585766792297363
time to encode step size is: 0.007039785385131836
Num timesteps: 80000
Best mean reward: -inf - Last mean reward per episode: -33.45
Saving new best model at 81706 timesteps
Saving new best model to ./logs/Pong-GNN-training/best_model.zip
time to encode step size is: 0.0034797191619873047
time to encode step size is: 0.0031614303588867188
time to encode step size is: 0.003517627716064453
time to encode step size is: 0.0031397342681884766
time to encode step size is: 0.0032112598419189453
time to encode step size is: 0.0031685829162597656
time to encode step size is: 0.003170490264892578
Eval num_timesteps=80000, episode_reward=52.00 +/- 9.26
Episode length: 3000.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3e+03       |
|    mean_reward          | 52          |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.011457549 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.06       |
|    explained_variance   | 0.729       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.5         |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00835    |
|    value_loss           | 4.78        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.07e+03 |
|    ep_rew_mean     | -36.9    |
| time/              |          |
|    fps             | 135      |
|    iterations      | 5        |
|    time_elapsed    | 604      |
|    total_timesteps | 81920    |
---------------------------------
time to encode step size is: 0.0302278995513916
time to encode step size is: 0.04288983345031738
time to encode step size is: 0.006977081298828125
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.18e+03    |
|    ep_rew_mean          | -28.6       |
| time/                   |             |
|    fps                  | 135         |
|    iterations           | 6           |
|    time_elapsed         | 726         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.013417112 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.06       |
|    explained_variance   | 0.673       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.58        |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.004      |
|    value_loss           | 3.17        |
-----------------------------------------
time to encode step size is: 0.029142379760742188
time to encode step size is: 0.006803035736083984
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.27e+03   |
|    ep_rew_mean          | -18.1      |
| time/                   |            |
|    fps                  | 134        |
|    iterations           | 7          |
|    time_elapsed         | 853        |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.01153573 |
|    clip_fraction        | 0.147      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.05      |
|    explained_variance   | 0.74       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.33       |
|    n_updates            | 60         |
|    policy_gradient_loss | -2.73e-05  |
|    value_loss           | 2.78       |
----------------------------------------
time to encode step size is: 0.030124425888061523
time to encode step size is: 0.0031621456146240234
time to encode step size is: 0.0031898021697998047
time to encode step size is: 0.0031642913818359375
time to encode step size is: 0.0032472610473632812
time to encode step size is: 0.005363941192626953
time to encode step size is: 0.003247976303100586
time to encode step size is: 0.0031642913818359375
Eval num_timesteps=120000, episode_reward=54.00 +/- 22.37
Episode length: 2623.00 +/- 754.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.62e+03    |
|    mean_reward          | 54          |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.013794273 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.05       |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.623       |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00223    |
|    value_loss           | 1.94        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.36e+03 |
|    ep_rew_mean     | -9.9     |
| time/              |          |
|    fps             | 127      |
|    iterations      | 8        |
|    time_elapsed    | 1025     |
|    total_timesteps | 131072   |
---------------------------------
time to encode step size is: 0.02884840965270996
time to encode step size is: 0.034775495529174805
time to encode step size is: 0.007090330123901367
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.42e+03    |
|    ep_rew_mean          | -4.56       |
| time/                   |             |
|    fps                  | 128         |
|    iterations           | 9           |
|    time_elapsed         | 1151        |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.013800398 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.03       |
|    explained_variance   | 0.792       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.612       |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00144    |
|    value_loss           | 1.92        |
-----------------------------------------
time to encode step size is: 0.028551816940307617
time to encode step size is: 0.007113456726074219
Num timesteps: 160000
Best mean reward: -33.45 - Last mean reward per episode: 16.48
Saving new best model at 188731 timesteps
Saving new best model to ./logs/Pong-GNN-training/best_model.zip
time to encode step size is: 0.0032494068145751953
time to encode step size is: 0.003326416015625
time to encode step size is: 0.003251314163208008
time to encode step size is: 0.003217935562133789
time to encode step size is: 0.0031969547271728516
time to encode step size is: 0.003183126449584961
time to encode step size is: 0.003206014633178711
Eval num_timesteps=160000, episode_reward=68.60 +/- 16.56
Episode length: 3000.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3e+03       |
|    mean_reward          | 68.6        |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.013481021 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.03       |
|    explained_variance   | 0.758       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.726       |
|    n_updates            | 90          |
|    policy_gradient_loss | 0.000517    |
|    value_loss           | 2.11        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.49e+03 |
|    ep_rew_mean     | 3.94     |
| time/              |          |
|    fps             | 122      |
|    iterations      | 10       |
|    time_elapsed    | 1333     |
|    total_timesteps | 163840   |
---------------------------------
time to encode step size is: 0.04207205772399902
time to encode step size is: 0.006979703903198242
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.59e+03    |
|    ep_rew_mean          | 13.6        |
| time/                   |             |
|    fps                  | 123         |
|    iterations           | 11          |
|    time_elapsed         | 1461        |
|    total_timesteps      | 180224      |
| train/                  |             |
|    approx_kl            | 0.014101955 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.02       |
|    explained_variance   | 0.774       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.15        |
|    n_updates            | 100         |
|    policy_gradient_loss | 0.00025     |
|    value_loss           | 2.19        |
-----------------------------------------
time to encode step size is: 0.028237342834472656
time to encode step size is: 0.028688907623291016
time to encode step size is: 0.007334709167480469
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.7e+03     |
|    ep_rew_mean          | 25.6        |
| time/                   |             |
|    fps                  | 124         |
|    iterations           | 12          |
|    time_elapsed         | 1584        |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.013574412 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.334       |
|    n_updates            | 110         |
|    policy_gradient_loss | 0.00128     |
|    value_loss           | 1.35        |
-----------------------------------------
time to encode step size is: 0.04119300842285156
time to encode step size is: 0.0032570362091064453
time to encode step size is: 0.003177165985107422
time to encode step size is: 0.003184795379638672
time to encode step size is: 0.0033774375915527344
time to encode step size is: 0.004475116729736328
time to encode step size is: 0.0032346248626708984
time to encode step size is: 0.003206968307495117
Eval num_timesteps=200000, episode_reward=54.50 +/- 24.43
Episode length: 2614.40 +/- 771.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.61e+03   |
|    mean_reward          | 54.5       |
| time/                   |            |
|    total_timesteps      | 200000     |
| train/                  |            |
|    approx_kl            | 0.01246912 |
|    clip_fraction        | 0.152      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | 0.793      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.803      |
|    n_updates            | 120        |
|    policy_gradient_loss | 0.000972   |
|    value_loss           | 1.77       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.82e+03 |
|    ep_rew_mean     | 38.6     |
| time/              |          |
|    fps             | 120      |
|    iterations      | 13       |
|    time_elapsed    | 1767     |
|    total_timesteps | 212992   |
---------------------------------
time to encode step size is: 0.02904057502746582
time to encode step size is: 0.02939748764038086
time to encode step size is: 0.006959438323974609
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.91e+03    |
|    ep_rew_mean          | 48.3        |
| time/                   |             |
|    fps                  | 121         |
|    iterations           | 14          |
|    time_elapsed         | 1893        |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.012884771 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.393       |
|    n_updates            | 130         |
|    policy_gradient_loss | 0.00156     |
|    value_loss           | 1.69        |
-----------------------------------------
time to encode step size is: 0.028713464736938477
time to encode step size is: 0.007109403610229492
Num timesteps: 240000
Best mean reward: 16.48 - Last mean reward per episode: 71.39
Saving new best model at 299492 timesteps
Saving new best model to ./logs/Pong-GNN-training/best_model.zip
time to encode step size is: 0.003246784210205078
time to encode step size is: 0.0032186508178710938
time to encode step size is: 0.0031747817993164062
time to encode step size is: 0.0032181739807128906
time to encode step size is: 0.0031642913818359375
time to encode step size is: 0.0032281875610351562
Eval num_timesteps=240000, episode_reward=61.60 +/- 19.76
Episode length: 2728.00 +/- 544.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.73e+03    |
|    mean_reward          | 61.6        |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.012658235 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.98       |
|    explained_variance   | 0.762       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.155       |
|    n_updates            | 140         |
|    policy_gradient_loss | 0.000376    |
|    value_loss           | 1.37        |
-----------------------------------------
time to encode step size is: 0.007258176803588867
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 55.7     |
| time/              |          |
|    fps             | 118      |
|    iterations      | 15       |
|    time_elapsed    | 2072     |
|    total_timesteps | 245760   |
---------------------------------
time to encode step size is: 0.029461383819580078
time to encode step size is: 0.007071971893310547
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.08e+03     |
|    ep_rew_mean          | 65.9         |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 16           |
|    time_elapsed         | 2199         |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0118178595 |
|    clip_fraction        | 0.141        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.988       |
|    explained_variance   | 0.778        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.972        |
|    n_updates            | 150          |
|    policy_gradient_loss | 0.00103      |
|    value_loss           | 1.53         |
------------------------------------------
time to encode step size is: 0.028383255004882812
time to encode step size is: 0.0070765018463134766
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.13e+03    |
|    ep_rew_mean          | 76.3        |
| time/                   |             |
|    fps                  | 119         |
|    iterations           | 17          |
|    time_elapsed         | 2325        |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.013113974 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.987      |
|    explained_variance   | 0.819       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19        |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.000988   |
|    value_loss           | 1.84        |
-----------------------------------------
time to encode step size is: 0.029677629470825195
time to encode step size is: 0.0041081905364990234
time to encode step size is: 0.003369569778442383
time to encode step size is: 0.0031113624572753906
time to encode step size is: 0.0035157203674316406
time to encode step size is: 0.003196239471435547
time to encode step size is: 0.0031185150146484375
time to encode step size is: 0.0032401084899902344
Eval num_timesteps=280000, episode_reward=71.30 +/- 20.07
Episode length: 2713.60 +/- 572.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.71e+03    |
|    mean_reward          | 71.3        |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.014106903 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | 0.797       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.46        |
|    n_updates            | 170         |
|    policy_gradient_loss | 0.00035     |
|    value_loss           | 1.72        |
-----------------------------------------
New best mean reward!
time to encode step size is: 0.006890535354614258
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.15e+03 |
|    ep_rew_mean     | 80.1     |
| time/              |          |
|    fps             | 117      |
|    iterations      | 18       |
|    time_elapsed    | 2500     |
|    total_timesteps | 294912   |
---------------------------------
time to encode step size is: 0.04137420654296875
time to encode step size is: 0.007023811340332031
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.18e+03    |
|    ep_rew_mean          | 80.8        |
| time/                   |             |
|    fps                  | 118         |
|    iterations           | 19          |
|    time_elapsed         | 2625        |
|    total_timesteps      | 311296      |
| train/                  |             |
|    approx_kl            | 0.015562158 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.996      |
|    explained_variance   | 0.768       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.358       |
|    n_updates            | 180         |
|    policy_gradient_loss | 0.0023      |
|    value_loss           | 1.81        |
-----------------------------------------
time to encode step size is: 0.02950739860534668
time to encode step size is: 0.0076732635498046875
Num timesteps: 320000
Best mean reward: 71.39 - Last mean reward per episode: 80.92
Saving new best model at 401770 timesteps
Saving new best model to ./logs/Pong-GNN-training/best_model.zip
time to encode step size is: 0.0031540393829345703
time to encode step size is: 0.0031468868255615234
time to encode step size is: 0.003133058547973633
time to encode step size is: 0.003118753433227539
time to encode step size is: 0.0031931400299072266
time to encode step size is: 0.003133535385131836
time to encode step size is: 0.003197193145751953
Eval num_timesteps=320000, episode_reward=70.00 +/- 32.11
Episode length: 2753.60 +/- 492.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.75e+03    |
|    mean_reward          | 70          |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.016045164 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.984      |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.724       |
|    n_updates            | 190         |
|    policy_gradient_loss | 0.00129     |
|    value_loss           | 1.48        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.19e+03 |
|    ep_rew_mean     | 83.2     |
| time/              |          |
|    fps             | 116      |
|    iterations      | 20       |
|    time_elapsed    | 2801     |
|    total_timesteps | 327680   |
---------------------------------
time to encode step size is: 0.029677867889404297
time to encode step size is: 0.009148597717285156
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.19e+03   |
|    ep_rew_mean          | 84.2       |
| time/                   |            |
|    fps                  | 117        |
|    iterations           | 21         |
|    time_elapsed         | 2928       |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.01726258 |
|    clip_fraction        | 0.169      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.967     |
|    explained_variance   | 0.836      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.248      |
|    n_updates            | 200        |
|    policy_gradient_loss | 0.0076     |
|    value_loss           | 1.1        |
----------------------------------------
time to encode step size is: 0.02919936180114746
time to encode step size is: 0.0423588752746582
time to encode step size is: 0.007236003875732422
time to encode step size is: 0.0031456947326660156
time to encode step size is: 0.003241300582885742
time to encode step size is: 0.003162384033203125
time to encode step size is: 0.0031702518463134766
time to encode step size is: 0.0032384395599365234
Eval num_timesteps=360000, episode_reward=72.00 +/- 20.26
Episode length: 2325.00 +/- 836.86
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.32e+03    |
|    mean_reward          | 72          |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.015506599 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.993      |
|    explained_variance   | 0.86        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.357       |
|    n_updates            | 210         |
|    policy_gradient_loss | 0.00409     |
|    value_loss           | 1.33        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.19e+03 |
|    ep_rew_mean     | 85.2     |
| time/              |          |
|    fps             | 116      |
|    iterations      | 22       |
|    time_elapsed    | 3090     |
|    total_timesteps | 360448   |
---------------------------------
time to encode step size is: 0.02918386459350586
time to encode step size is: 0.042588233947753906
time to encode step size is: 0.007160186767578125
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.19e+03    |
|    ep_rew_mean          | 86.1        |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 23          |
|    time_elapsed         | 3214        |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.015637105 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.983      |
|    explained_variance   | 0.822       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.37        |
|    n_updates            | 220         |
|    policy_gradient_loss | 0.000589    |
|    value_loss           | 1.44        |
-----------------------------------------
time to encode step size is: 0.028873920440673828
time to encode step size is: 0.007054567337036133
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.17e+03    |
|    ep_rew_mean          | 86.9        |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 24          |
|    time_elapsed         | 3347        |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.014817722 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.977      |
|    explained_variance   | 0.807       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.72        |
|    n_updates            | 230         |
|    policy_gradient_loss | 0.00225     |
|    value_loss           | 1.35        |
-----------------------------------------
time to encode step size is: 0.028627395629882812
Num timesteps: 400000
Best mean reward: 80.92 - Last mean reward per episode: 81.75
Saving new best model at 512178 timesteps
Saving new best model to ./logs/Pong-GNN-training/best_model.zip
time to encode step size is: 0.0031871795654296875
time to encode step size is: 0.00324249267578125
time to encode step size is: 0.0031604766845703125
time to encode step size is: 0.003253459930419922
time to encode step size is: 0.0031774044036865234
time to encode step size is: 0.0033054351806640625
time to encode step size is: 0.006356239318847656
Eval num_timesteps=400000, episode_reward=64.20 +/- 12.87
Episode length: 2791.80 +/- 416.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.79e+03   |
|    mean_reward          | 64.2       |
| time/                   |            |
|    total_timesteps      | 400000     |
| train/                  |            |
|    approx_kl            | 0.01751231 |
|    clip_fraction        | 0.158      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.956     |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.642      |
|    n_updates            | 240        |
|    policy_gradient_loss | 0.00212    |
|    value_loss           | 1.38       |
----------------------------------------
time to encode step size is: 0.007080078125
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.16e+03 |
|    ep_rew_mean     | 85.9     |
| time/              |          |
|    fps             | 115      |
|    iterations      | 25       |
|    time_elapsed    | 3531     |
|    total_timesteps | 409600   |
---------------------------------
time to encode step size is: 0.04601645469665527
time to encode step size is: 0.007038593292236328
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.15e+03    |
|    ep_rew_mean          | 85.2        |
| time/                   |             |
|    fps                  | 116         |
|    iterations           | 26          |
|    time_elapsed         | 3661        |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.017495498 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.962      |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.342       |
|    n_updates            | 250         |
|    policy_gradient_loss | 0.000697    |
|    value_loss           | 1.62        |
-----------------------------------------
time to encode step size is: 0.028903484344482422
time to encode step size is: 0.0069849491119384766
time to encode step size is: 0.0031480789184570312
time to encode step size is: 0.003210783004760742
time to encode step size is: 0.003379344940185547
time to encode step size is: 0.0031061172485351562
time to encode step size is: 0.003968477249145508
time to encode step size is: 0.0030994415283203125
time to encode step size is: 0.0031168460845947266
time to encode step size is: 0.0031158924102783203
Eval num_timesteps=440000, episode_reward=55.40 +/- 16.07
Episode length: 3000.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3e+03       |
|    mean_reward          | 55.4        |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.015082475 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.957      |
|    explained_variance   | 0.819       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.421       |
|    n_updates            | 260         |
|    policy_gradient_loss | 0.00449     |
|    value_loss           | 1.63        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.17e+03 |
|    ep_rew_mean     | 84.9     |
| time/              |          |
|    fps             | 115      |
|    iterations      | 27       |
|    time_elapsed    | 3841     |
|    total_timesteps | 442368   |
---------------------------------
time to encode step size is: 0.02882671356201172
time to encode step size is: 0.007174015045166016
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.17e+03   |
|    ep_rew_mean          | 84.1       |
| time/                   |            |
|    fps                  | 115        |
|    iterations           | 28         |
|    time_elapsed         | 3966       |
|    total_timesteps      | 458752     |
| train/                  |            |
|    approx_kl            | 0.01619279 |
|    clip_fraction        | 0.168      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.961     |
|    explained_variance   | 0.804      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.3        |
|    n_updates            | 270        |
|    policy_gradient_loss | 0.00254    |
|    value_loss           | 1.63       |
----------------------------------------
time to encode step size is: 0.029459476470947266
time to encode step size is: 0.011825084686279297
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.21e+03    |
|    ep_rew_mean          | 84.2        |
| time/                   |             |
|    fps                  | 116         |
|    iterations           | 29          |
|    time_elapsed         | 4088        |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.016907003 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.973      |
|    explained_variance   | 0.788       |
|    learning_rate        | 0.0003      |
|    loss                 | 1           |
|    n_updates            | 280         |
|    policy_gradient_loss | 0.00305     |
|    value_loss           | 1.72        |
-----------------------------------------
time to encode step size is: 0.041643619537353516
time to encode step size is: 0.006931781768798828
Num timesteps: 480000
Best mean reward: 81.75 - Last mean reward per episode: 79.91
time to encode step size is: 0.0031456947326660156
time to encode step size is: 0.003382444381713867
time to encode step size is: 0.003140687942504883
time to encode step size is: 0.0033676624298095703
time to encode step size is: 0.003204345703125
time to encode step size is: 0.0033981800079345703
time to encode step size is: 0.0031280517578125
Eval num_timesteps=480000, episode_reward=42.50 +/- 7.78
Episode length: 3000.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3e+03       |
|    mean_reward          | 42.5        |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.015240728 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.984      |
|    explained_variance   | 0.732       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.431       |
|    n_updates            | 290         |
|    policy_gradient_loss | 0.00368     |
|    value_loss           | 1.9         |
-----------------------------------------
time to encode step size is: 0.006934642791748047
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.21e+03 |
|    ep_rew_mean     | 80.8     |
| time/              |          |
|    fps             | 115      |
|    iterations      | 30       |
|    time_elapsed    | 4273     |
|    total_timesteps | 491520   |
---------------------------------
time to encode step size is: 0.041536808013916016
time to encode step size is: 0.007048845291137695
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.21e+03   |
|    ep_rew_mean          | 79.4       |
| time/                   |            |
|    fps                  | 115        |
|    iterations           | 31         |
|    time_elapsed         | 4400       |
|    total_timesteps      | 507904     |
| train/                  |            |
|    approx_kl            | 0.01527089 |
|    clip_fraction        | 0.165      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.997     |
|    explained_variance   | 0.774      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.267      |
|    n_updates            | 300        |
|    policy_gradient_loss | 0.00201    |
|    value_loss           | 1.95       |
----------------------------------------
time to encode step size is: 0.02990412712097168
time to encode step size is: 0.0069806575775146484
time to encode step size is: 0.0033638477325439453
time to encode step size is: 0.0031425952911376953
time to encode step size is: 0.003381967544555664
time to encode step size is: 0.003237009048461914
time to encode step size is: 0.003470897674560547
time to encode step size is: 0.003123760223388672
time to encode step size is: 0.003202199935913086
Eval num_timesteps=520000, episode_reward=50.70 +/- 14.65
Episode length: 3000.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3e+03       |
|    mean_reward          | 50.7        |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.015397964 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.982      |
|    explained_variance   | 0.796       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.34        |
|    n_updates            | 310         |
|    policy_gradient_loss | 0.00182     |
|    value_loss           | 1.99        |
-----------------------------------------
time to encode step size is: 0.0071756839752197266
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.18e+03 |
|    ep_rew_mean     | 78.7     |
| time/              |          |
|    fps             | 114      |
|    iterations      | 32       |
|    time_elapsed    | 4581     |
|    total_timesteps | 524288   |
---------------------------------
time to encode step size is: 0.02858138084411621
time to encode step size is: 0.0069446563720703125
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.16e+03    |
|    ep_rew_mean          | 76.1        |
| time/                   |             |
|    fps                  | 114         |
|    iterations           | 33          |
|    time_elapsed         | 4702        |
|    total_timesteps      | 540672      |
| train/                  |             |
|    approx_kl            | 0.014362548 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.979      |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.12        |
|    n_updates            | 320         |
|    policy_gradient_loss | 0.00122     |
|    value_loss           | 2.09        |
-----------------------------------------
time to encode step size is: 0.029963970184326172
time to encode step size is: 0.00718998908996582
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.12e+03    |
|    ep_rew_mean          | 74.9        |
| time/                   |             |
|    fps                  | 115         |
|    iterations           | 34          |
|    time_elapsed         | 4824        |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.015178192 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.974      |
|    explained_variance   | 0.799       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.347       |
|    n_updates            | 330         |
|    policy_gradient_loss | 0.00138     |
|    value_loss           | 1.65        |
-----------------------------------------
time to encode step size is: 0.0304105281829834
time to encode step size is: 0.006747245788574219
Num timesteps: 560000
Best mean reward: 81.75 - Last mean reward per episode: 69.05
time to encode step size is: 0.003186941146850586
time to encode step size is: 0.0031566619873046875
time to encode step size is: 0.0031609535217285156
time to encode step size is: 0.0031845569610595703
time to encode step size is: 0.003139019012451172
time to encode step size is: 0.0031392574310302734
Eval num_timesteps=560000, episode_reward=49.00 +/- 18.31
Episode length: 2572.40 +/- 855.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.57e+03   |
|    mean_reward          | 49         |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.01430208 |
|    clip_fraction        | 0.175      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.969     |
|    explained_variance   | 0.808      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.459      |
|    n_updates            | 340        |
|    policy_gradient_loss | 0.00251    |
|    value_loss           | 1.82       |
----------------------------------------
time to encode step size is: 0.006899118423461914
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.11e+03 |
|    ep_rew_mean     | 75.3     |
| time/              |          |
|    fps             | 114      |
|    iterations      | 35       |
|    time_elapsed    | 4993     |
|    total_timesteps | 573440   |
---------------------------------
time to encode step size is: 0.042050838470458984
time to encode step size is: 0.006842851638793945
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.14e+03    |
|    ep_rew_mean          | 74.6        |
| time/                   |             |
|    fps                  | 115         |
|    iterations           | 36          |
|    time_elapsed         | 5122        |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.015479144 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.955      |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.452       |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00105    |
|    value_loss           | 1.71        |
-----------------------------------------
time to encode step size is: 0.04232025146484375
time to encode step size is: 0.007078886032104492
time to encode step size is: 0.0031828880310058594
time to encode step size is: 0.003570079803466797
time to encode step size is: 0.003180980682373047
time to encode step size is: 0.0032014846801757812
time to encode step size is: 0.003251314163208008
time to encode step size is: 0.0032989978790283203
time to encode step size is: 0.0031850337982177734
Eval num_timesteps=600000, episode_reward=70.90 +/- 28.00
Episode length: 3000.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3e+03       |
|    mean_reward          | 70.9        |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.014678455 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.932      |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.307       |
|    n_updates            | 360         |
|    policy_gradient_loss | 0.000748    |
|    value_loss           | 1.53        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.13e+03 |
|    ep_rew_mean     | 75       |
| time/              |          |
|    fps             | 114      |
|    iterations      | 37       |
|    time_elapsed    | 5307     |
|    total_timesteps | 606208   |
---------------------------------
time to encode step size is: 0.029490947723388672
time to encode step size is: 0.03011941909790039
time to encode step size is: 0.007029294967651367
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.17e+03   |
|    ep_rew_mean          | 72.4       |
| time/                   |            |
|    fps                  | 114        |
|    iterations           | 38         |
|    time_elapsed         | 5433       |
|    total_timesteps      | 622592     |
| train/                  |            |
|    approx_kl            | 0.01531257 |
|    clip_fraction        | 0.152      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.934     |
|    explained_variance   | 0.749      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.855      |
|    n_updates            | 370        |
|    policy_gradient_loss | 0.00348    |
|    value_loss           | 2.03       |
----------------------------------------
time to encode step size is: 0.028726816177368164
time to encode step size is: 0.007274150848388672
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.17e+03    |
|    ep_rew_mean          | 71.5        |
| time/                   |             |
|    fps                  | 115         |
|    iterations           | 39          |
|    time_elapsed         | 5555        |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.014919564 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.912      |
|    explained_variance   | 0.749       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.38        |
|    n_updates            | 380         |
|    policy_gradient_loss | 0.00323     |
|    value_loss           | 1.69        |
-----------------------------------------
time to encode step size is: 0.02896857261657715
Num timesteps: 640000
Best mean reward: 81.75 - Last mean reward per episode: 66.33
time to encode step size is: 0.0041348934173583984
time to encode step size is: 0.003103494644165039
time to encode step size is: 0.003117084503173828
time to encode step size is: 0.003108501434326172
time to encode step size is: 0.003124237060546875
time to encode step size is: 0.003174304962158203
time to encode step size is: 0.003116607666015625
time to encode step size is: 0.003192424774169922
Eval num_timesteps=640000, episode_reward=38.60 +/- 7.55
Episode length: 3000.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3e+03       |
|    mean_reward          | 38.6        |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.014503734 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.915      |
|    explained_variance   | 0.8         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.559       |
|    n_updates            | 390         |
|    policy_gradient_loss | 0.00237     |
|    value_loss           | 1.74        |
-----------------------------------------
time to encode step size is: 0.007108926773071289
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.14e+03 |
|    ep_rew_mean     | 71.5     |
| time/              |          |
|    fps             | 114      |
|    iterations      | 40       |
|    time_elapsed    | 5738     |
|    total_timesteps | 655360   |
---------------------------------
time to encode step size is: 0.042075395584106445
time to encode step size is: 0.007147312164306641
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.14e+03    |
|    ep_rew_mean          | 72.1        |
| time/                   |             |
|    fps                  | 114         |
|    iterations           | 41          |
|    time_elapsed         | 5866        |
|    total_timesteps      | 671744      |
| train/                  |             |
|    approx_kl            | 0.015058677 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.916      |
|    explained_variance   | 0.798       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.841       |
|    n_updates            | 400         |
|    policy_gradient_loss | 0.00238     |
|    value_loss           | 1.68        |
-----------------------------------------
time to encode step size is: 0.02846384048461914
time to encode step size is: 0.012240409851074219
time to encode step size is: 0.003137350082397461
time to encode step size is: 0.0032243728637695312
time to encode step size is: 0.0031862258911132812
time to encode step size is: 0.00318145751953125
time to encode step size is: 0.003228425979614258
time to encode step size is: 0.003163576126098633
time to encode step size is: 0.0032896995544433594
Eval num_timesteps=680000, episode_reward=41.20 +/- 12.59
Episode length: 3000.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3e+03       |
|    mean_reward          | 41.2        |
| time/                   |             |
|    total_timesteps      | 680000      |
| train/                  |             |
|    approx_kl            | 0.014801532 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.915      |
|    explained_variance   | 0.818       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.636       |
|    n_updates            | 410         |
|    policy_gradient_loss | 0.00377     |
|    value_loss           | 1.87        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.1e+03  |
|    ep_rew_mean     | 70.9     |
| time/              |          |
|    fps             | 113      |
|    iterations      | 42       |
|    time_elapsed    | 6056     |
|    total_timesteps | 688128   |
---------------------------------
time to encode step size is: 0.028745174407958984
time to encode step size is: 0.02845144271850586
time to encode step size is: 0.008006572723388672
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.1e+03     |
|    ep_rew_mean          | 71          |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 43          |
|    time_elapsed         | 6183        |
|    total_timesteps      | 704512      |
| train/                  |             |
|    approx_kl            | 0.017915674 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.9        |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07        |
|    n_updates            | 420         |
|    policy_gradient_loss | 0.00167     |
|    value_loss           | 2.61        |
-----------------------------------------
time to encode step size is: 0.02933478355407715
time to encode step size is: 0.0071125030517578125
Num timesteps: 720000
Best mean reward: 81.75 - Last mean reward per episode: 64.73
time to encode step size is: 0.003173828125
time to encode step size is: 0.0032165050506591797
time to encode step size is: 0.0032062530517578125
time to encode step size is: 0.003195524215698242
time to encode step size is: 0.0031900405883789062
time to encode step size is: 0.003267049789428711
time to encode step size is: 0.0032944679260253906
Eval num_timesteps=720000, episode_reward=72.50 +/- 24.08
Episode length: 3000.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 3e+03        |
|    mean_reward          | 72.5         |
| time/                   |              |
|    total_timesteps      | 720000       |
| train/                  |              |
|    approx_kl            | 0.0148098925 |
|    clip_fraction        | 0.162        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.893       |
|    explained_variance   | 0.786        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.39         |
|    n_updates            | 430          |
|    policy_gradient_loss | 0.00571      |
|    value_loss           | 2.59         |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.12e+03 |
|    ep_rew_mean     | 69       |
| time/              |          |
|    fps             | 113      |
|    iterations      | 44       |
|    time_elapsed    | 6361     |
|    total_timesteps | 720896   |
---------------------------------
time to encode step size is: 0.028549671173095703
time to encode step size is: 0.007605791091918945
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.13e+03    |
|    ep_rew_mean          | 69.5        |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 45          |
|    time_elapsed         | 6488        |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.015018234 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.877      |
|    explained_variance   | 0.79        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.932       |
|    n_updates            | 440         |
|    policy_gradient_loss | 0.000319    |
|    value_loss           | 1.84        |
-----------------------------------------
time to encode step size is: 0.028316497802734375
time to encode step size is: 0.02919316291809082
time to encode step size is: 0.007173299789428711
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.16e+03    |
|    ep_rew_mean          | 70.7        |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 46          |
|    time_elapsed         | 6614        |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.015737837 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.868      |
|    explained_variance   | 0.749       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.633       |
|    n_updates            | 450         |
|    policy_gradient_loss | 0.00321     |
|    value_loss           | 1.73        |
-----------------------------------------
time to encode step size is: 0.02944326400756836
time to encode step size is: 0.003119230270385742
time to encode step size is: 0.004000186920166016
time to encode step size is: 0.003201723098754883
time to encode step size is: 0.0031375885009765625
time to encode step size is: 0.0031151771545410156
time to encode step size is: 0.003108978271484375
time to encode step size is: 0.0031380653381347656
time to encode step size is: 0.0031659603118896484
Eval num_timesteps=760000, episode_reward=52.60 +/- 5.68
Episode length: 3000.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 3e+03        |
|    mean_reward          | 52.6         |
| time/                   |              |
|    total_timesteps      | 760000       |
| train/                  |              |
|    approx_kl            | 0.0145511255 |
|    clip_fraction        | 0.15         |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.853       |
|    explained_variance   | 0.822        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.251        |
|    n_updates            | 460          |
|    policy_gradient_loss | 0.00281      |
|    value_loss           | 1.64         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.18e+03 |
|    ep_rew_mean     | 70.2     |
| time/              |          |
|    fps             | 113      |
|    iterations      | 47       |
|    time_elapsed    | 6796     |
|    total_timesteps | 770048   |
---------------------------------
time to encode step size is: 0.041280508041381836
time to encode step size is: 0.028736591339111328
time to encode step size is: 0.006871938705444336
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.22e+03    |
|    ep_rew_mean          | 69.9        |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 48          |
|    time_elapsed         | 6923        |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.016670901 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.855      |
|    explained_variance   | 0.7         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.34        |
|    n_updates            | 470         |
|    policy_gradient_loss | 0.0035      |
|    value_loss           | 1.97        |
-----------------------------------------
time to encode step size is: 0.04279303550720215
time to encode step size is: 0.007051229476928711
Num timesteps: 800000
Best mean reward: 81.75 - Last mean reward per episode: 66.08
time to encode step size is: 0.003114938735961914
time to encode step size is: 0.0031328201293945312
time to encode step size is: 0.003227710723876953
time to encode step size is: 0.003136157989501953
time to encode step size is: 0.0032694339752197266
time to encode step size is: 0.0031354427337646484
Eval num_timesteps=800000, episode_reward=83.20 +/- 20.12
Episode length: 2629.40 +/- 741.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.63e+03    |
|    mean_reward          | 83.2        |
| time/                   |             |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.016694192 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.869      |
|    explained_variance   | 0.784       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01        |
|    n_updates            | 480         |
|    policy_gradient_loss | 0.00496     |
|    value_loss           | 2.08        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.24e+03 |
|    ep_rew_mean     | 69.8     |
| time/              |          |
|    fps             | 113      |
|    iterations      | 49       |
|    time_elapsed    | 7097     |
|    total_timesteps | 802816   |
---------------------------------
time to encode step size is: 0.04462099075317383
time to encode step size is: 0.006804227828979492
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.21e+03    |
|    ep_rew_mean          | 69.8        |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 50          |
|    time_elapsed         | 7225        |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.017871544 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.842      |
|    explained_variance   | 0.803       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.839       |
|    n_updates            | 490         |
|    policy_gradient_loss | 0.00593     |
|    value_loss           | 1.87        |
-----------------------------------------
time to encode step size is: 0.028842449188232422
time to encode step size is: 0.04168224334716797
time to encode step size is: 0.007089853286743164
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.2e+03     |
|    ep_rew_mean          | 70.3        |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 51          |
|    time_elapsed         | 7355        |
|    total_timesteps      | 835584      |
| train/                  |             |
|    approx_kl            | 0.017586265 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.838      |
|    explained_variance   | 0.818       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.311       |
|    n_updates            | 500         |
|    policy_gradient_loss | 0.00556     |
|    value_loss           | 1.73        |
-----------------------------------------
time to encode step size is: 0.028905868530273438
time to encode step size is: 0.0033605098724365234
time to encode step size is: 0.003156900405883789
time to encode step size is: 0.003348112106323242
time to encode step size is: 0.003193378448486328
time to encode step size is: 0.0035257339477539062
time to encode step size is: 0.0031893253326416016
Eval num_timesteps=840000, episode_reward=73.90 +/- 23.72
Episode length: 2390.80 +/- 824.29
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.39e+03    |
|    mean_reward          | 73.9        |
| time/                   |             |
|    total_timesteps      | 840000      |
| train/                  |             |
|    approx_kl            | 0.015557861 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.844      |
|    explained_variance   | 0.802       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.845       |
|    n_updates            | 510         |
|    policy_gradient_loss | 0.0059      |
|    value_loss           | 2.65        |
-----------------------------------------
time to encode step size is: 0.006815910339355469
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.18e+03 |
|    ep_rew_mean     | 70.4     |
| time/              |          |
|    fps             | 113      |
|    iterations      | 52       |
|    time_elapsed    | 7524     |
|    total_timesteps | 851968   |
---------------------------------
time to encode step size is: 0.029717445373535156
time to encode step size is: 0.007796764373779297
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.21e+03    |
|    ep_rew_mean          | 69.9        |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 53          |
|    time_elapsed         | 7645        |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.016305014 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.851      |
|    explained_variance   | 0.785       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.413       |
|    n_updates            | 520         |
|    policy_gradient_loss | 0.0083      |
|    value_loss           | 1.99        |
-----------------------------------------
time to encode step size is: 0.041588544845581055
time to encode step size is: 0.006754159927368164
Num timesteps: 880000
Best mean reward: 81.75 - Last mean reward per episode: 72.58
time to encode step size is: 0.003136157989501953
time to encode step size is: 0.004510164260864258
time to encode step size is: 0.0031158924102783203
time to encode step size is: 0.00321197509765625
time to encode step size is: 0.003787994384765625
time to encode step size is: 0.0032088756561279297
time to encode step size is: 0.0032579898834228516
Eval num_timesteps=880000, episode_reward=67.70 +/- 28.97
Episode length: 3000.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3e+03       |
|    mean_reward          | 67.7        |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.022064433 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.867      |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.521       |
|    n_updates            | 530         |
|    policy_gradient_loss | 0.0063      |
|    value_loss           | 1.79        |
-----------------------------------------
time to encode step size is: 0.00711512565612793
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.2e+03  |
|    ep_rew_mean     | 71.2     |
| time/              |          |
|    fps             | 113      |
|    iterations      | 54       |
|    time_elapsed    | 7826     |
|    total_timesteps | 884736   |
---------------------------------
time to encode step size is: 0.02912282943725586
time to encode step size is: 0.007032871246337891
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.21e+03    |
|    ep_rew_mean          | 71.9        |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 55          |
|    time_elapsed         | 7949        |
|    total_timesteps      | 901120      |
| train/                  |             |
|    approx_kl            | 0.020809012 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.87       |
|    explained_variance   | 0.768       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.331       |
|    n_updates            | 540         |
|    policy_gradient_loss | 0.0106      |
|    value_loss           | 1.56        |
-----------------------------------------
time to encode step size is: 0.028421878814697266
time to encode step size is: 0.007110118865966797
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2.21e+03 |
|    ep_rew_mean          | 74.2     |
| time/                   |          |
|    fps                  | 113      |
|    iterations           | 56       |
|    time_elapsed         | 8072     |
|    total_timesteps      | 917504   |
| train/                  |          |
|    approx_kl            | 0.01813  |
|    clip_fraction        | 0.183    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.877   |
|    explained_variance   | 0.808    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.782    |
|    n_updates            | 550      |
|    policy_gradient_loss | 0.00777  |
|    value_loss           | 1.84     |
--------------------------------------
time to encode step size is: 0.02850937843322754
time to encode step size is: 0.0068721771240234375
time to encode step size is: 0.003119230270385742
time to encode step size is: 0.0031316280364990234
time to encode step size is: 0.0031473636627197266
time to encode step size is: 0.003117799758911133
time to encode step size is: 0.003130674362182617
Eval num_timesteps=920000, episode_reward=80.00 +/- 20.20
Episode length: 2239.40 +/- 942.30
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.24e+03   |
|    mean_reward          | 80         |
| time/                   |            |
|    total_timesteps      | 920000     |
| train/                  |            |
|    approx_kl            | 0.01702753 |
|    clip_fraction        | 0.175      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.893     |
|    explained_variance   | 0.793      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.33       |
|    n_updates            | 560        |
|    policy_gradient_loss | 0.00636    |
|    value_loss           | 1.64       |
----------------------------------------
time to encode step size is: 0.006895542144775391
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.25e+03 |
|    ep_rew_mean     | 75.5     |
| time/              |          |
|    fps             | 113      |
|    iterations      | 57       |
|    time_elapsed    | 8238     |
|    total_timesteps | 933888   |
---------------------------------
time to encode step size is: 0.02869105339050293
time to encode step size is: 0.006997585296630859
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.24e+03    |
|    ep_rew_mean          | 76.2        |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 58          |
|    time_elapsed         | 8367        |
|    total_timesteps      | 950272      |
| train/                  |             |
|    approx_kl            | 0.019644126 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.89       |
|    explained_variance   | 0.779       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.312       |
|    n_updates            | 570         |
|    policy_gradient_loss | 0.00782     |
|    value_loss           | 2.06        |
-----------------------------------------
time to encode step size is: 0.030857563018798828
time to encode step size is: 0.0068721771240234375
Num timesteps: 960000
Best mean reward: 81.75 - Last mean reward per episode: 75.77
time to encode step size is: 0.003121614456176758
time to encode step size is: 0.0034029483795166016
time to encode step size is: 0.0031113624572753906
time to encode step size is: 0.0033555030822753906
time to encode step size is: 0.003963947296142578
time to encode step size is: 0.0034542083740234375
time to encode step size is: 0.0031387805938720703
Eval num_timesteps=960000, episode_reward=62.60 +/- 15.94
Episode length: 3000.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3e+03       |
|    mean_reward          | 62.6        |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.024073921 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.907      |
|    explained_variance   | 0.758       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.28        |
|    n_updates            | 580         |
|    policy_gradient_loss | 0.00962     |
|    value_loss           | 2.63        |
-----------------------------------------
time to encode step size is: 0.007004499435424805
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.21e+03 |
|    ep_rew_mean     | 74.5     |
| time/              |          |
|    fps             | 113      |
|    iterations      | 59       |
|    time_elapsed    | 8546     |
|    total_timesteps | 966656   |
---------------------------------
time to encode step size is: 0.028501033782958984
time to encode step size is: 0.007238626480102539
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.17e+03    |
|    ep_rew_mean          | 75.1        |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 60          |
|    time_elapsed         | 8673        |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.016201131 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.927      |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.588       |
|    n_updates            | 590         |
|    policy_gradient_loss | 0.00586     |
|    value_loss           | 2.25        |
-----------------------------------------
time to encode step size is: 0.028747081756591797
time to encode step size is: 0.006819486618041992
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.09e+03    |
|    ep_rew_mean          | 75.2        |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 61          |
|    time_elapsed         | 8795        |
|    total_timesteps      | 999424      |
| train/                  |             |
|    approx_kl            | 0.015843142 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.932      |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.3         |
|    n_updates            | 600         |
|    policy_gradient_loss | 0.00454     |
|    value_loss           | 2.31        |
-----------------------------------------
time to encode step size is: 0.02872753143310547
time to encode step size is: 0.003211498260498047
time to encode step size is: 0.005369424819946289
time to encode step size is: 0.0031435489654541016
time to encode step size is: 0.003147125244140625
time to encode step size is: 0.003133535385131836
time to encode step size is: 0.003121614456176758
time to encode step size is: 0.003141164779663086
Eval num_timesteps=1000000, episode_reward=71.20 +/- 35.27
Episode length: 2687.20 +/- 625.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.69e+03    |
|    mean_reward          | 71.2        |
| time/                   |             |
|    total_timesteps      | 1000000     |
| train/                  |             |
|    approx_kl            | 0.018068865 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.953      |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.634       |
|    n_updates            | 610         |
|    policy_gradient_loss | 0.00557     |
|    value_loss           | 2.48        |
-----------------------------------------
time to encode step size is: 0.007091045379638672
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.09e+03 |
|    ep_rew_mean     | 74.1     |
| time/              |          |
|    fps             | 113      |
|    iterations      | 62       |
|    time_elapsed    | 8972     |
|    total_timesteps | 1015808  |
---------------------------------
time to encode step size is: 0.029090166091918945
time to encode step size is: 0.0071103572845458984
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.07e+03    |
|    ep_rew_mean          | 73.3        |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 63          |
|    time_elapsed         | 9102        |
|    total_timesteps      | 1032192     |
| train/                  |             |
|    approx_kl            | 0.015447461 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.953      |
|    explained_variance   | 0.795       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.879       |
|    n_updates            | 620         |
|    policy_gradient_loss | 0.00519     |
|    value_loss           | 1.94        |
-----------------------------------------
time to encode step size is: 0.028574466705322266
time to encode step size is: 0.006860494613647461
Num timesteps: 1040000
Best mean reward: 81.75 - Last mean reward per episode: 71.65
time to encode step size is: 0.0032083988189697266
time to encode step size is: 0.0031232833862304688
time to encode step size is: 0.0031321048736572266
time to encode step size is: 0.0031349658966064453
time to encode step size is: 0.0031380653381347656
time to encode step size is: 0.003292083740234375
time to encode step size is: 0.0032515525817871094
Eval num_timesteps=1040000, episode_reward=78.90 +/- 27.08
Episode length: 3000.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3e+03       |
|    mean_reward          | 78.9        |
| time/                   |             |
|    total_timesteps      | 1040000     |
| train/                  |             |
|    approx_kl            | 0.015756264 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.951      |
|    explained_variance   | 0.788       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.49        |
|    n_updates            | 630         |
|    policy_gradient_loss | 0.00471     |
|    value_loss           | 2.9         |
-----------------------------------------
time to encode step size is: 0.006927490234375
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.08e+03 |
|    ep_rew_mean     | 73.5     |
| time/              |          |
|    fps             | 112      |
|    iterations      | 64       |
|    time_elapsed    | 9285     |
|    total_timesteps | 1048576  |
---------------------------------
time to encode step size is: 0.028482675552368164
time to encode step size is: 0.006906032562255859
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.07e+03    |
|    ep_rew_mean          | 73.3        |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 65          |
|    time_elapsed         | 9418        |
|    total_timesteps      | 1064960     |
| train/                  |             |
|    approx_kl            | 0.016313648 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.981      |
|    explained_variance   | 0.741       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.618       |
|    n_updates            | 640         |
|    policy_gradient_loss | 0.00713     |
|    value_loss           | 3.3         |
-----------------------------------------
time to encode step size is: 0.02845907211303711
time to encode step size is: 0.00902414321899414
time to encode step size is: 0.0032122135162353516
time to encode step size is: 0.003153562545776367
time to encode step size is: 0.0031375885009765625
time to encode step size is: 0.003161191940307617
time to encode step size is: 0.003127574920654297
time to encode step size is: 0.0032181739807128906
time to encode step size is: 0.003238677978515625
time to encode step size is: 0.0031938552856445312
Eval num_timesteps=1080000, episode_reward=33.70 +/- 4.48
Episode length: 3000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3e+03      |
|    mean_reward          | 33.7       |
| time/                   |            |
|    total_timesteps      | 1080000    |
| train/                  |            |
|    approx_kl            | 0.01506961 |
|    clip_fraction        | 0.182      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.973     |
|    explained_variance   | 0.775      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.73       |
|    n_updates            | 650        |
|    policy_gradient_loss | 0.00595    |
|    value_loss           | 2.57       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.07e+03 |
|    ep_rew_mean     | 69       |
| time/              |          |
|    fps             | 112      |
|    iterations      | 66       |
|    time_elapsed    | 9596     |
|    total_timesteps | 1081344  |
---------------------------------
time to encode step size is: 0.15427279472351074
time to encode step size is: 0.007107257843017578
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | 66.3        |
| time/                   |             |
|    fps                  | 112         |
|    iterations           | 67          |
|    time_elapsed         | 9720        |
|    total_timesteps      | 1097728     |
| train/                  |             |
|    approx_kl            | 0.016135294 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.982      |
|    explained_variance   | 0.768       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.62        |
|    n_updates            | 660         |
|    policy_gradient_loss | 0.00216     |
|    value_loss           | 3.48        |
-----------------------------------------
time to encode step size is: 0.03466391563415527
time to encode step size is: 0.006917715072631836
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | 65.1        |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 68          |
|    time_elapsed         | 9843        |
|    total_timesteps      | 1114112     |
| train/                  |             |
|    approx_kl            | 0.016264379 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.966      |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.64        |
|    n_updates            | 670         |
|    policy_gradient_loss | 0.00382     |
|    value_loss           | 3.24        |
-----------------------------------------
time to encode step size is: 0.02861166000366211
time to encode step size is: 0.006920814514160156
Num timesteps: 1120000
Best mean reward: 81.75 - Last mean reward per episode: 63.78
time to encode step size is: 0.003229379653930664
time to encode step size is: 0.003133058547973633
time to encode step size is: 0.0031783580780029297
time to encode step size is: 0.0031692981719970703
time to encode step size is: 0.0033919811248779297
time to encode step size is: 0.0031232833862304688
time to encode step size is: 0.0031671524047851562
Eval num_timesteps=1120000, episode_reward=48.10 +/- 19.04
Episode length: 2890.20 +/- 219.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.89e+03    |
|    mean_reward          | 48.1        |
| time/                   |             |
|    total_timesteps      | 1120000     |
| train/                  |             |
|    approx_kl            | 0.016775765 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.976      |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.4         |
|    n_updates            | 680         |
|    policy_gradient_loss | 0.00626     |
|    value_loss           | 2.93        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.03e+03 |
|    ep_rew_mean     | 64.6     |
| time/              |          |
|    fps             | 112      |
|    iterations      | 69       |
|    time_elapsed    | 10022    |
|    total_timesteps | 1130496  |
---------------------------------
time to encode step size is: 0.0293276309967041
time to encode step size is: 0.029161691665649414
time to encode step size is: 0.007074117660522461
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.03e+03    |
|    ep_rew_mean          | 64.8        |
| time/                   |             |
|    fps                  | 112         |
|    iterations           | 70          |
|    time_elapsed         | 10152       |
|    total_timesteps      | 1146880     |
| train/                  |             |
|    approx_kl            | 0.013929516 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.972      |
|    explained_variance   | 0.798       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.901       |
|    n_updates            | 690         |
|    policy_gradient_loss | 0.00662     |
|    value_loss           | 2.75        |
-----------------------------------------
time to encode step size is: 0.03682065010070801
time to encode step size is: 0.007117509841918945
time to encode step size is: 0.003161191940307617
time to encode step size is: 0.003130197525024414
time to encode step size is: 0.0031876564025878906
time to encode step size is: 0.0031549930572509766
time to encode step size is: 0.0031960010528564453
time to encode step size is: 0.0033006668090820312
time to encode step size is: 0.003138303756713867
Eval num_timesteps=1160000, episode_reward=37.60 +/- 6.66
Episode length: 3000.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3e+03       |
|    mean_reward          | 37.6        |
| time/                   |             |
|    total_timesteps      | 1160000     |
| train/                  |             |
|    approx_kl            | 0.017506067 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.976      |
|    explained_variance   | 0.752       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02        |
|    n_updates            | 700         |
|    policy_gradient_loss | 0.00867     |
|    value_loss           | 3.57        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.04e+03 |
|    ep_rew_mean     | 63.6     |
| time/              |          |
|    fps             | 112      |
|    iterations      | 71       |
|    time_elapsed    | 10332    |
|    total_timesteps | 1163264  |
---------------------------------
time to encode step size is: 0.029020071029663086
time to encode step size is: 0.04154491424560547
time to encode step size is: 0.0070002079010009766
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.03e+03    |
|    ep_rew_mean          | 63.8        |
| time/                   |             |
|    fps                  | 112         |
|    iterations           | 72          |
|    time_elapsed         | 10460       |
|    total_timesteps      | 1179648     |
| train/                  |             |
|    approx_kl            | 0.020264689 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.948      |
|    explained_variance   | 0.759       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.93        |
|    n_updates            | 710         |
|    policy_gradient_loss | 0.0101      |
|    value_loss           | 3.42        |
-----------------------------------------
time to encode step size is: 0.05375528335571289
time to encode step size is: 0.006964683532714844
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.09e+03    |
|    ep_rew_mean          | 61.9        |
| time/                   |             |
|    fps                  | 113         |
|    iterations           | 73          |
|    time_elapsed         | 10584       |
|    total_timesteps      | 1196032     |
| train/                  |             |
|    approx_kl            | 0.021446073 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.985      |
|    explained_variance   | 0.804       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.32        |
|    n_updates            | 720         |
|    policy_gradient_loss | 0.0106      |
|    value_loss           | 2.54        |
-----------------------------------------
slurmstepd-cn-406: error: *** JOB 8046088 ON cn-406 CANCELLED AT 2024-07-15T12:50:06 ***
--------------------- Slurm Task Epilog ------------------------
Job ID: 8046088
Time: Mon Jul 15 12:50:06 CEST 2024
Elapsed Time: 02:58:50
Billing per second for TRES: billing=640,cpu=32,mem=32G,node=1
Show resource usage with e.g.:
sacct -j 8046088 -o Elapsed,TotalCPU,UserCPU,SystemCPU,MaxRSS,ReqTRES%60,MaxDiskRead,MaxDiskWrite
--------------------- Slurm Task Epilog ------------------------
