
Using cpu device
/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:414: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7fa08f912ef0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f9f2eb76ad0>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
-----------------------------
| time/              |      |
|    fps             | 1119 |
|    iterations      | 1    |
|    time_elapsed    | 7    |
|    total_timesteps | 8192 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3e+03       |
|    ep_rew_mean          | -1.49e+03   |
| time/                   |             |
|    fps                  | 367         |
|    iterations           | 2           |
|    time_elapsed         | 44          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.007575615 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | -3.6e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0344      |
|    n_updates            | 10          |
|    policy_gradient_loss | 0.00066     |
|    value_loss           | 2.35        |
-----------------------------------------
Traceback (most recent call last):
  File "/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/work/rleap1/rishabh.bhatia/Master-Thesis-GNN/games/freeway/run_supervised_cnn.py", line 93, in <module>
    model.learn(total_timesteps=1000000, callback=[training_callback, eval_callback])
  File "/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 315, in learn
    return super().learn(
  File "/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 313, in learn
    self.train()
  File "/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 279, in train
    loss.backward()
  File "/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/work/rleap1/rishabh.bhatia/miniconda3/envs/train/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt