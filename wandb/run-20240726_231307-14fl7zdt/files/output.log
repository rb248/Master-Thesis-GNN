Using cpu device
----------------------------
| time/              |     |
|    fps             | 194 |
|    iterations      | 1   |
|    time_elapsed    | 0   |
|    total_timesteps | 128 |
----------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.
  logger.warn(
-------------------------------------------
| time/                   |               |
|    fps                  | 55            |
|    iterations           | 2             |
|    time_elapsed         | 4             |
|    total_timesteps      | 256           |
| train/                  |               |
|    approx_kl            | 0.00011743419 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.00455       |
|    learning_rate        | 0.0003        |
|    loss                 | 6.48          |
|    n_updates            | 10            |
|    policy_gradient_loss | -1.67e-05     |
|    value_loss           | 27            |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 52           |
|    iterations           | 3            |
|    time_elapsed         | 7            |
|    total_timesteps      | 384          |
| train/                  |              |
|    approx_kl            | 0.0027488503 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.00346      |
|    learning_rate        | 0.0003       |
|    loss                 | 17.9         |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00235     |
|    value_loss           | 41.6         |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 50          |
|    iterations           | 4           |
|    time_elapsed         | 10          |
|    total_timesteps      | 512         |
| train/                  |             |
|    approx_kl            | 0.010086294 |
|    clip_fraction        | 0.0141      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 0.000632    |
|    learning_rate        | 0.0003      |
|    loss                 | 18          |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00935    |
|    value_loss           | 41          |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 48         |
|    iterations           | 5          |
|    time_elapsed         | 13         |
|    total_timesteps      | 640        |
| train/                  |            |
|    approx_kl            | 0.01609142 |
|    clip_fraction        | 0.0938     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.08      |
|    explained_variance   | -0.000543  |
|    learning_rate        | 0.0003     |
|    loss                 | 16.9       |
|    n_updates            | 40         |
|    policy_gradient_loss | -0.0139    |
|    value_loss           | 39.1       |
----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 47           |
|    iterations           | 6            |
|    time_elapsed         | 16           |
|    total_timesteps      | 768          |
| train/                  |              |
|    approx_kl            | 6.226404e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.07        |
|    explained_variance   | 7.74e-05     |
|    learning_rate        | 0.0003       |
|    loss                 | 16.9         |
|    n_updates            | 50           |
|    policy_gradient_loss | 0.000749     |
|    value_loss           | 38.6         |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 7           |
|    time_elapsed         | 19          |
|    total_timesteps      | 896         |
| train/                  |             |
|    approx_kl            | 0.009016858 |
|    clip_fraction        | 0.0125      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.08       |
|    explained_variance   | -0.000401   |
|    learning_rate        | 0.0003      |
|    loss                 | 17.4        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00648    |
|    value_loss           | 38.1        |
-----------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 1000
Best mean reward: -inf - Last mean reward per episode: -805.61
Saving new best model at 113000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 45           |
|    iterations           | 8            |
|    time_elapsed         | 22           |
|    total_timesteps      | 1024         |
| train/                  |              |
|    approx_kl            | 0.0055648377 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.09        |
|    explained_variance   | -5.6e-05     |
|    learning_rate        | 0.0003       |
|    loss                 | 16.9         |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00421     |
|    value_loss           | 37.3         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 43          |
|    iterations           | 9           |
|    time_elapsed         | 26          |
|    total_timesteps      | 1152        |
| train/                  |             |
|    approx_kl            | 0.018446188 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 0.0369      |
|    learning_rate        | 0.0003      |
|    loss                 | 12.3        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.017      |
|    value_loss           | 27.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 609         |
|    ep_rew_mean          | -290        |
| time/                   |             |
|    fps                  | 44          |
|    iterations           | 10          |
|    time_elapsed         | 28          |
|    total_timesteps      | 1280        |
| train/                  |             |
|    approx_kl            | 0.017108975 |
|    clip_fraction        | 0.0563      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | -0.000252   |
|    learning_rate        | 0.0003      |
|    loss                 | 15.7        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0138     |
|    value_loss           | 35.7        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 609        |
|    ep_rew_mean          | -290       |
| time/                   |            |
|    fps                  | 44         |
|    iterations           | 11         |
|    time_elapsed         | 31         |
|    total_timesteps      | 1408       |
| train/                  |            |
|    approx_kl            | 0.01208475 |
|    clip_fraction        | 0.102      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.00103   |
|    learning_rate        | 0.0003     |
|    loss                 | 70.9       |
|    n_updates            | 100        |
|    policy_gradient_loss | -0.00647   |
|    value_loss           | 99.3       |
----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 480           |
|    ep_rew_mean          | -220          |
| time/                   |               |
|    fps                  | 43            |
|    iterations           | 12            |
|    time_elapsed         | 35            |
|    total_timesteps      | 1536          |
| train/                  |               |
|    approx_kl            | 0.00045848778 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.01         |
|    explained_variance   | 1.59e-05      |
|    learning_rate        | 0.0003        |
|    loss                 | 18.2          |
|    n_updates            | 110           |
|    policy_gradient_loss | 0.000261      |
|    value_loss           | 36            |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 480         |
|    ep_rew_mean          | -220        |
| time/                   |             |
|    fps                  | 43          |
|    iterations           | 13          |
|    time_elapsed         | 38          |
|    total_timesteps      | 1664        |
| train/                  |             |
|    approx_kl            | 0.010209437 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.935      |
|    explained_variance   | -0.00322    |
|    learning_rate        | 0.0003      |
|    loss                 | 60.7        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0177     |
|    value_loss           | 108         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 416          |
|    ep_rew_mean          | -186         |
| time/                   |              |
|    fps                  | 43           |
|    iterations           | 14           |
|    time_elapsed         | 41           |
|    total_timesteps      | 1792         |
| train/                  |              |
|    approx_kl            | 0.0005630017 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.951       |
|    explained_variance   | -1.43e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 16.4         |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00208     |
|    value_loss           | 34.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 416          |
|    ep_rew_mean          | -186         |
| time/                   |              |
|    fps                  | 42           |
|    iterations           | 15           |
|    time_elapsed         | 45           |
|    total_timesteps      | 1920         |
| train/                  |              |
|    approx_kl            | 0.0010642689 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.904       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 28.1         |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00101     |
|    value_loss           | 56.3         |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 2000
Best mean reward: -805.61 - Last mean reward per episode: -756.20
Saving new best model at 113666 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 416           |
|    ep_rew_mean          | -186          |
| time/                   |               |
|    fps                  | 41            |
|    iterations           | 16            |
|    time_elapsed         | 49            |
|    total_timesteps      | 2048          |
| train/                  |               |
|    approx_kl            | 0.00013516471 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.907        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 15.3          |
|    n_updates            | 150           |
|    policy_gradient_loss | 0.00072       |
|    value_loss           | 32.5          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 416          |
|    ep_rew_mean          | -186         |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 17           |
|    time_elapsed         | 53           |
|    total_timesteps      | 2176         |
| train/                  |              |
|    approx_kl            | 0.0018189866 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.908       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 14.9         |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00527     |
|    value_loss           | 31.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 416          |
|    ep_rew_mean          | -186         |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 18           |
|    time_elapsed         | 57           |
|    total_timesteps      | 2304         |
| train/                  |              |
|    approx_kl            | 0.0005885097 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.89        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 14.3         |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.000817    |
|    value_loss           | 31           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 474           |
|    ep_rew_mean          | -211          |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 19            |
|    time_elapsed         | 61            |
|    total_timesteps      | 2432          |
| train/                  |               |
|    approx_kl            | 0.00036013033 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.892        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 14.6          |
|    n_updates            | 180           |
|    policy_gradient_loss | -0.000434     |
|    value_loss           | 30.3          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 474          |
|    ep_rew_mean          | -211         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 20           |
|    time_elapsed         | 65           |
|    total_timesteps      | 2560         |
| train/                  |              |
|    approx_kl            | 0.0049753063 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.878       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 73.2         |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.00229     |
|    value_loss           | 170          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 382          |
|    ep_rew_mean          | -162         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 21           |
|    time_elapsed         | 69           |
|    total_timesteps      | 2688         |
| train/                  |              |
|    approx_kl            | 0.0030882335 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.796       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 15.5         |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00228     |
|    value_loss           | 31.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 350           |
|    ep_rew_mean          | -145          |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 22            |
|    time_elapsed         | 71            |
|    total_timesteps      | 2816          |
| train/                  |               |
|    approx_kl            | 0.00019491557 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.809        |
|    explained_variance   | -0.000174     |
|    learning_rate        | 0.0003        |
|    loss                 | 103           |
|    n_updates            | 210           |
|    policy_gradient_loss | -0.00215      |
|    value_loss           | 224           |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 325         |
|    ep_rew_mean          | -130        |
| time/                   |             |
|    fps                  | 39          |
|    iterations           | 23          |
|    time_elapsed         | 74          |
|    total_timesteps      | 2944        |
| train/                  |             |
|    approx_kl            | 0.012310868 |
|    clip_fraction        | 0.043       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.739      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 86.3        |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00858    |
|    value_loss           | 170         |
-----------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 3000
Best mean reward: -756.20 - Last mean reward per episode: -674.07
Saving new best model at 114987 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 299          |
|    ep_rew_mean          | -117         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 24           |
|    time_elapsed         | 79           |
|    total_timesteps      | 3072         |
| train/                  |              |
|    approx_kl            | 0.0037307367 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.613       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 132          |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.00131     |
|    value_loss           | 236          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 263          |
|    ep_rew_mean          | -99.9        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 25           |
|    time_elapsed         | 82           |
|    total_timesteps      | 3200         |
| train/                  |              |
|    approx_kl            | 0.0036682659 |
|    clip_fraction        | 0.0227       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.553       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 71.2         |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00382     |
|    value_loss           | 113          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 236          |
|    ep_rew_mean          | -85.8        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 26           |
|    time_elapsed         | 85           |
|    total_timesteps      | 3328         |
| train/                  |              |
|    approx_kl            | 0.0023620664 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.611       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 88.8         |
|    n_updates            | 250          |
|    policy_gradient_loss | 0.00185      |
|    value_loss           | 192          |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 236        |
|    ep_rew_mean          | -85.8      |
| time/                   |            |
|    fps                  | 38         |
|    iterations           | 27         |
|    time_elapsed         | 88         |
|    total_timesteps      | 3456       |
| train/                  |            |
|    approx_kl            | 0.02777753 |
|    clip_fraction        | 0.114      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.725     |
|    explained_variance   | -2.52e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 127        |
|    n_updates            | 260        |
|    policy_gradient_loss | 0.00208    |
|    value_loss           | 235        |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 236          |
|    ep_rew_mean          | -85.8        |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 28           |
|    time_elapsed         | 94           |
|    total_timesteps      | 3584         |
| train/                  |              |
|    approx_kl            | 0.0006211633 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.821       |
|    explained_variance   | 0.00339      |
|    learning_rate        | 0.0003       |
|    loss                 | 13.6         |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.00102     |
|    value_loss           | 33.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 247          |
|    ep_rew_mean          | -90.1        |
| time/                   |              |
|    fps                  | 36           |
|    iterations           | 29           |
|    time_elapsed         | 100          |
|    total_timesteps      | 3712         |
| train/                  |              |
|    approx_kl            | 0.0006447155 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.828       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 13           |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.00117     |
|    value_loss           | 30.6         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 247         |
|    ep_rew_mean          | -90.1       |
| time/                   |             |
|    fps                  | 36          |
|    iterations           | 30          |
|    time_elapsed         | 105         |
|    total_timesteps      | 3840        |
| train/                  |             |
|    approx_kl            | 0.002124181 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.836      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 124         |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.000369   |
|    value_loss           | 232         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 244         |
|    ep_rew_mean          | -88.7       |
| time/                   |             |
|    fps                  | 36          |
|    iterations           | 31          |
|    time_elapsed         | 108         |
|    total_timesteps      | 3968        |
| train/                  |             |
|    approx_kl            | 0.002128895 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.779      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 16.4        |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.000688   |
|    value_loss           | 34          |
-----------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 4000
Best mean reward: -674.07 - Last mean reward per episode: -595.78
Saving new best model at 115979 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 225         |
|    ep_rew_mean          | -79         |
| time/                   |             |
|    fps                  | 36          |
|    iterations           | 32          |
|    time_elapsed         | 112         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.014006032 |
|    clip_fraction        | 0.075       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.695      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 42.8        |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0032     |
|    value_loss           | 108         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 220          |
|    ep_rew_mean          | -76.6        |
| time/                   |              |
|    fps                  | 36           |
|    iterations           | 33           |
|    time_elapsed         | 115          |
|    total_timesteps      | 4224         |
| train/                  |              |
|    approx_kl            | 0.0059693325 |
|    clip_fraction        | 0.0461       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.695       |
|    explained_variance   | -0.0166      |
|    learning_rate        | 0.0003       |
|    loss                 | 105          |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00464     |
|    value_loss           | 224          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 215          |
|    ep_rew_mean          | -74.7        |
| time/                   |              |
|    fps                  | 36           |
|    iterations           | 34           |
|    time_elapsed         | 117          |
|    total_timesteps      | 4352         |
| train/                  |              |
|    approx_kl            | 0.0020110332 |
|    clip_fraction        | 0.00703      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.766       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 37.6         |
|    n_updates            | 330          |
|    policy_gradient_loss | -0.00188     |
|    value_loss           | 96.4         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 208         |
|    ep_rew_mean          | -70.9       |
| time/                   |             |
|    fps                  | 37          |
|    iterations           | 35          |
|    time_elapsed         | 121         |
|    total_timesteps      | 4480        |
| train/                  |             |
|    approx_kl            | 0.005191645 |
|    clip_fraction        | 0.0875      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.835      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 42.1        |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00909    |
|    value_loss           | 96.5        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 198         |
|    ep_rew_mean          | -66.2       |
| time/                   |             |
|    fps                  | 37          |
|    iterations           | 36          |
|    time_elapsed         | 124         |
|    total_timesteps      | 4608        |
| train/                  |             |
|    approx_kl            | 0.030988745 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.713      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 79.8        |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.0051     |
|    value_loss           | 157         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 189         |
|    ep_rew_mean          | -61.2       |
| time/                   |             |
|    fps                  | 37          |
|    iterations           | 37          |
|    time_elapsed         | 127         |
|    total_timesteps      | 4736        |
| train/                  |             |
|    approx_kl            | 0.004014421 |
|    clip_fraction        | 0.0219      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.676      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 81.8        |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.00156    |
|    value_loss           | 167         |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 189           |
|    ep_rew_mean          | -61.2         |
| time/                   |               |
|    fps                  | 37            |
|    iterations           | 38            |
|    time_elapsed         | 129           |
|    total_timesteps      | 4864          |
| train/                  |               |
|    approx_kl            | 0.00012915069 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.712        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 73.5          |
|    n_updates            | 370           |
|    policy_gradient_loss | -3.15e-05     |
|    value_loss           | 186           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 190           |
|    ep_rew_mean          | -61.9         |
| time/                   |               |
|    fps                  | 37            |
|    iterations           | 39            |
|    time_elapsed         | 133           |
|    total_timesteps      | 4992          |
| train/                  |               |
|    approx_kl            | 1.2897886e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.715        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 18.1          |
|    n_updates            | 380           |
|    policy_gradient_loss | -6.67e-05     |
|    value_loss           | 49.6          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 5000
Best mean reward: -595.78 - Last mean reward per episode: -517.26
Saving new best model at 116938 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
Eval num_timesteps=5000, episode_reward=2.60 +/- 9.77
Episode length: 66.80 +/- 7.65
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 66.8        |
|    mean_reward          | 2.6         |
| time/                   |             |
|    total_timesteps      | 5000        |
| train/                  |             |
|    approx_kl            | 0.031667255 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.785      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 51.4        |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.00597    |
|    value_loss           | 82.3        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | -60      |
| time/              |          |
|    fps             | 37       |
|    iterations      | 40       |
|    time_elapsed    | 138      |
|    total_timesteps | 5120     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 182          |
|    ep_rew_mean          | -58          |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 41           |
|    time_elapsed         | 141          |
|    total_timesteps      | 5248         |
| train/                  |              |
|    approx_kl            | 0.0045119366 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.832       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 60.8         |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00296     |
|    value_loss           | 88.3         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 177         |
|    ep_rew_mean          | -55.9       |
| time/                   |             |
|    fps                  | 37          |
|    iterations           | 42          |
|    time_elapsed         | 144         |
|    total_timesteps      | 5376        |
| train/                  |             |
|    approx_kl            | 0.019160371 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.727      |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 42.5        |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0102     |
|    value_loss           | 97.2        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 173          |
|    ep_rew_mean          | -53.8        |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 43           |
|    time_elapsed         | 147          |
|    total_timesteps      | 5504         |
| train/                  |              |
|    approx_kl            | 0.0020121937 |
|    clip_fraction        | 0.0391       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.729       |
|    explained_variance   | -3.58e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 73.3         |
|    n_updates            | 420          |
|    policy_gradient_loss | -0.000463    |
|    value_loss           | 150          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 168         |
|    ep_rew_mean          | -50.9       |
| time/                   |             |
|    fps                  | 37          |
|    iterations           | 44          |
|    time_elapsed         | 149         |
|    total_timesteps      | 5632        |
| train/                  |             |
|    approx_kl            | 0.007847348 |
|    clip_fraction        | 0.0164      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.683      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 59.1        |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00504    |
|    value_loss           | 135         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 165          |
|    ep_rew_mean          | -49.5        |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 45           |
|    time_elapsed         | 153          |
|    total_timesteps      | 5760         |
| train/                  |              |
|    approx_kl            | 0.0045273765 |
|    clip_fraction        | 0.0273       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.55        |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 84.1         |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00228     |
|    value_loss           | 172          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 163          |
|    ep_rew_mean          | -48.3        |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 46           |
|    time_elapsed         | 156          |
|    total_timesteps      | 5888         |
| train/                  |              |
|    approx_kl            | 0.0004363982 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.516       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 49.1         |
|    n_updates            | 450          |
|    policy_gradient_loss | -0.000985    |
|    value_loss           | 89.3         |
------------------------------------------
Num timesteps: 6000
Best mean reward: -517.26 - Last mean reward per episode: -427.59
Saving new best model at 118035 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 165          |
|    ep_rew_mean          | -49.5        |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 47           |
|    time_elapsed         | 159          |
|    total_timesteps      | 6016         |
| train/                  |              |
|    approx_kl            | 0.0003494313 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.482       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 41.7         |
|    n_updates            | 460          |
|    policy_gradient_loss | -0.000391    |
|    value_loss           | 76.5         |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 160         |
|    ep_rew_mean          | -46.9       |
| time/                   |             |
|    fps                  | 37          |
|    iterations           | 48          |
|    time_elapsed         | 163         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.012971112 |
|    clip_fraction        | 0.0656      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.416      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 43          |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00401    |
|    value_loss           | 94.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 155          |
|    ep_rew_mean          | -44.6        |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 49           |
|    time_elapsed         | 165          |
|    total_timesteps      | 6272         |
| train/                  |              |
|    approx_kl            | 0.0002915943 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.333       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 89.5         |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.00147     |
|    value_loss           | 155          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 152          |
|    ep_rew_mean          | -43.5        |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 50           |
|    time_elapsed         | 168          |
|    total_timesteps      | 6400         |
| train/                  |              |
|    approx_kl            | 7.392373e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.321       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 80.2         |
|    n_updates            | 490          |
|    policy_gradient_loss | 4.51e-06     |
|    value_loss           | 145          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 149          |
|    ep_rew_mean          | -42.2        |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 51           |
|    time_elapsed         | 171          |
|    total_timesteps      | 6528         |
| train/                  |              |
|    approx_kl            | 0.0001377156 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.318       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 38           |
|    n_updates            | 500          |
|    policy_gradient_loss | -0.000344    |
|    value_loss           | 92.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 148          |
|    ep_rew_mean          | -41.5        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 52           |
|    time_elapsed         | 174          |
|    total_timesteps      | 6656         |
| train/                  |              |
|    approx_kl            | 0.0001971717 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.302       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 72.2         |
|    n_updates            | 510          |
|    policy_gradient_loss | 0.000226     |
|    value_loss           | 145          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 148          |
|    ep_rew_mean          | -41.8        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 53           |
|    time_elapsed         | 177          |
|    total_timesteps      | 6784         |
| train/                  |              |
|    approx_kl            | 0.0007907003 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.311       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 31.5         |
|    n_updates            | 520          |
|    policy_gradient_loss | -0.00302     |
|    value_loss           | 90.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 148          |
|    ep_rew_mean          | -41.5        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 54           |
|    time_elapsed         | 180          |
|    total_timesteps      | 6912         |
| train/                  |              |
|    approx_kl            | 0.0034714136 |
|    clip_fraction        | 0.0187       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.3         |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 31.4         |
|    n_updates            | 530          |
|    policy_gradient_loss | -0.00369     |
|    value_loss           | 87.6         |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 7000
Best mean reward: -427.59 - Last mean reward per episode: -374.33
Saving new best model at 119216 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 146           |
|    ep_rew_mean          | -40.9         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 55            |
|    time_elapsed         | 184           |
|    total_timesteps      | 7040          |
| train/                  |               |
|    approx_kl            | 0.00085513014 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.248        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 58.4          |
|    n_updates            | 540           |
|    policy_gradient_loss | -0.00195      |
|    value_loss           | 89.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 144          |
|    ep_rew_mean          | -39.5        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 56           |
|    time_elapsed         | 187          |
|    total_timesteps      | 7168         |
| train/                  |              |
|    approx_kl            | 4.834868e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.241       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 51.9         |
|    n_updates            | 550          |
|    policy_gradient_loss | 0.000312     |
|    value_loss           | 99.3         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 141           |
|    ep_rew_mean          | -38.1         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 57            |
|    time_elapsed         | 190           |
|    total_timesteps      | 7296          |
| train/                  |               |
|    approx_kl            | 0.00025320658 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.245        |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 108           |
|    n_updates            | 560           |
|    policy_gradient_loss | -0.00146      |
|    value_loss           | 204           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 139           |
|    ep_rew_mean          | -36.7         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 58            |
|    time_elapsed         | 193           |
|    total_timesteps      | 7424          |
| train/                  |               |
|    approx_kl            | 0.00028708437 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.26         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 87.7          |
|    n_updates            | 570           |
|    policy_gradient_loss | -0.000605     |
|    value_loss           | 154           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 138          |
|    ep_rew_mean          | -36.5        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 59           |
|    time_elapsed         | 196          |
|    total_timesteps      | 7552         |
| train/                  |              |
|    approx_kl            | 7.107854e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.268       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 114          |
|    n_updates            | 580          |
|    policy_gradient_loss | 0.000283     |
|    value_loss           | 253          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 136          |
|    ep_rew_mean          | -35.4        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 60           |
|    time_elapsed         | 199          |
|    total_timesteps      | 7680         |
| train/                  |              |
|    approx_kl            | 0.0016054795 |
|    clip_fraction        | 0.0109       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.284       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 40.2         |
|    n_updates            | 590          |
|    policy_gradient_loss | -0.00259     |
|    value_loss           | 87.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 133           |
|    ep_rew_mean          | -34.2         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 61            |
|    time_elapsed         | 202           |
|    total_timesteps      | 7808          |
| train/                  |               |
|    approx_kl            | 0.00021453295 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.315        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 71.5          |
|    n_updates            | 600           |
|    policy_gradient_loss | -0.000783     |
|    value_loss           | 136           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 132          |
|    ep_rew_mean          | -33.7        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 62           |
|    time_elapsed         | 205          |
|    total_timesteps      | 7936         |
| train/                  |              |
|    approx_kl            | 6.453134e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.32        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 63.4         |
|    n_updates            | 610          |
|    policy_gradient_loss | -4.05e-05    |
|    value_loss           | 129          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 8000
Best mean reward: -374.33 - Last mean reward per episode: -282.53
Saving new best model at 120226 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 131           |
|    ep_rew_mean          | -33           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 63            |
|    time_elapsed         | 207           |
|    total_timesteps      | 8064          |
| train/                  |               |
|    approx_kl            | 4.7544017e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.316        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 39.2          |
|    n_updates            | 620           |
|    policy_gradient_loss | -2.07e-05     |
|    value_loss           | 85.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 128           |
|    ep_rew_mean          | -31.8         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 64            |
|    time_elapsed         | 210           |
|    total_timesteps      | 8192          |
| train/                  |               |
|    approx_kl            | 0.00017259503 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.321        |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 68.5          |
|    n_updates            | 630           |
|    policy_gradient_loss | -0.000541     |
|    value_loss           | 132           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 127          |
|    ep_rew_mean          | -30.8        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 65           |
|    time_elapsed         | 213          |
|    total_timesteps      | 8320         |
| train/                  |              |
|    approx_kl            | 9.182701e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.336       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 79.7         |
|    n_updates            | 640          |
|    policy_gradient_loss | -8.3e-05     |
|    value_loss           | 165          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 125         |
|    ep_rew_mean          | -30         |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 66          |
|    time_elapsed         | 217         |
|    total_timesteps      | 8448        |
| train/                  |             |
|    approx_kl            | 0.000103008 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.339      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 87.2        |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.000515   |
|    value_loss           | 206         |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 124           |
|    ep_rew_mean          | -29.7         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 67            |
|    time_elapsed         | 220           |
|    total_timesteps      | 8576          |
| train/                  |               |
|    approx_kl            | 0.00053571817 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.334        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 42.1          |
|    n_updates            | 660           |
|    policy_gradient_loss | -0.00121      |
|    value_loss           | 88.7          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 123          |
|    ep_rew_mean          | -28.4        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 68           |
|    time_elapsed         | 223          |
|    total_timesteps      | 8704         |
| train/                  |              |
|    approx_kl            | 4.524365e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.317       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 29.9         |
|    n_updates            | 670          |
|    policy_gradient_loss | -0.000143    |
|    value_loss           | 63           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 122           |
|    ep_rew_mean          | -27.6         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 69            |
|    time_elapsed         | 227           |
|    total_timesteps      | 8832          |
| train/                  |               |
|    approx_kl            | 2.2519846e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.307        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 165           |
|    n_updates            | 680           |
|    policy_gradient_loss | -0.000257     |
|    value_loss           | 257           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 122           |
|    ep_rew_mean          | -27.6         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 70            |
|    time_elapsed         | 231           |
|    total_timesteps      | 8960          |
| train/                  |               |
|    approx_kl            | 0.00082367286 |
|    clip_fraction        | 0.00625       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.329        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 87.1          |
|    n_updates            | 690           |
|    policy_gradient_loss | -0.00191      |
|    value_loss           | 185           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 9000
Best mean reward: -282.53 - Last mean reward per episode: -190.07
Saving new best model at 121234 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 121          |
|    ep_rew_mean          | -27.2        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 71           |
|    time_elapsed         | 235          |
|    total_timesteps      | 9088         |
| train/                  |              |
|    approx_kl            | 9.827083e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.331       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 23           |
|    n_updates            | 700          |
|    policy_gradient_loss | 0.000134     |
|    value_loss           | 57.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 120          |
|    ep_rew_mean          | -26.6        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 72           |
|    time_elapsed         | 238          |
|    total_timesteps      | 9216         |
| train/                  |              |
|    approx_kl            | 9.932509e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.322       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 47.4         |
|    n_updates            | 710          |
|    policy_gradient_loss | -0.000287    |
|    value_loss           | 101          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 120          |
|    ep_rew_mean          | -26.6        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 73           |
|    time_elapsed         | 241          |
|    total_timesteps      | 9344         |
| train/                  |              |
|    approx_kl            | 8.239411e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.308       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 63.6         |
|    n_updates            | 720          |
|    policy_gradient_loss | 1.68e-05     |
|    value_loss           | 107          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 120          |
|    ep_rew_mean          | -26.9        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 74           |
|    time_elapsed         | 245          |
|    total_timesteps      | 9472         |
| train/                  |              |
|    approx_kl            | 6.504683e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.311       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 21.7         |
|    n_updates            | 730          |
|    policy_gradient_loss | -0.00049     |
|    value_loss           | 52.9         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 119           |
|    ep_rew_mean          | -26.3         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 75            |
|    time_elapsed         | 248           |
|    total_timesteps      | 9600          |
| train/                  |               |
|    approx_kl            | 1.9218307e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.316        |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 72.5          |
|    n_updates            | 740           |
|    policy_gradient_loss | -0.000204     |
|    value_loss           | 151           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 119          |
|    ep_rew_mean          | -26.3        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 76           |
|    time_elapsed         | 251          |
|    total_timesteps      | 9728         |
| train/                  |              |
|    approx_kl            | 0.0037264167 |
|    clip_fraction        | 0.0187       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.337       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 45.7         |
|    n_updates            | 750          |
|    policy_gradient_loss | -0.00256     |
|    value_loss           | 103          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 120           |
|    ep_rew_mean          | -26.9         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 77            |
|    time_elapsed         | 255           |
|    total_timesteps      | 9856          |
| train/                  |               |
|    approx_kl            | 0.00085603725 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.406        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 26.8          |
|    n_updates            | 760           |
|    policy_gradient_loss | -0.000863     |
|    value_loss           | 57.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 120          |
|    ep_rew_mean          | -26.9        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 78           |
|    time_elapsed         | 258          |
|    total_timesteps      | 9984         |
| train/                  |              |
|    approx_kl            | 0.0056888657 |
|    clip_fraction        | 0.0344       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.378       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 58.2         |
|    n_updates            | 770          |
|    policy_gradient_loss | -0.00348     |
|    value_loss           | 108          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 10000
Best mean reward: -190.07 - Last mean reward per episode: -91.94
Saving new best model at 122268 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
Eval num_timesteps=10000, episode_reward=3.80 +/- 6.00
Episode length: 64.40 +/- 5.54
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 64.4         |
|    mean_reward          | 3.8          |
| time/                   |              |
|    total_timesteps      | 10000        |
| train/                  |              |
|    approx_kl            | 0.0009233523 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.306       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 37.7         |
|    n_updates            | 780          |
|    policy_gradient_loss | -0.00203     |
|    value_loss           | 72.4         |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 119      |
|    ep_rew_mean     | -26.5    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 79       |
|    time_elapsed    | 262      |
|    total_timesteps | 10112    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 119          |
|    ep_rew_mean          | -26.2        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 80           |
|    time_elapsed         | 265          |
|    total_timesteps      | 10240        |
| train/                  |              |
|    approx_kl            | 0.0013001272 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.269       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 52.7         |
|    n_updates            | 790          |
|    policy_gradient_loss | -0.00256     |
|    value_loss           | 121          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 118           |
|    ep_rew_mean          | -25.8         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 81            |
|    time_elapsed         | 268           |
|    total_timesteps      | 10368         |
| train/                  |               |
|    approx_kl            | 0.00018603262 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.239        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 36.3          |
|    n_updates            | 800           |
|    policy_gradient_loss | -0.00124      |
|    value_loss           | 81.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 117           |
|    ep_rew_mean          | -25.2         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 82            |
|    time_elapsed         | 271           |
|    total_timesteps      | 10496         |
| train/                  |               |
|    approx_kl            | 0.00022000121 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.235        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 51.8          |
|    n_updates            | 810           |
|    policy_gradient_loss | -0.000861     |
|    value_loss           | 124           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 116           |
|    ep_rew_mean          | -24.9         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 83            |
|    time_elapsed         | 274           |
|    total_timesteps      | 10624         |
| train/                  |               |
|    approx_kl            | 5.1195733e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.213        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 67.7          |
|    n_updates            | 820           |
|    policy_gradient_loss | 0.000452      |
|    value_loss           | 158           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 115          |
|    ep_rew_mean          | -24.7        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 84           |
|    time_elapsed         | 277          |
|    total_timesteps      | 10752        |
| train/                  |              |
|    approx_kl            | 0.0009278101 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.227       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 54.6         |
|    n_updates            | 830          |
|    policy_gradient_loss | -0.00253     |
|    value_loss           | 118          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 115           |
|    ep_rew_mean          | -24.4         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 85            |
|    time_elapsed         | 280           |
|    total_timesteps      | 10880         |
| train/                  |               |
|    approx_kl            | 0.00063244393 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.244        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 44.4          |
|    n_updates            | 840           |
|    policy_gradient_loss | -0.000497     |
|    value_loss           | 73.5          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 11000
Best mean reward: -91.94 - Last mean reward per episode: -11.38
Saving new best model at 123561 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 114           |
|    ep_rew_mean          | -23.9         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 86            |
|    time_elapsed         | 283           |
|    total_timesteps      | 11008         |
| train/                  |               |
|    approx_kl            | 2.3895875e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.214        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 50.1          |
|    n_updates            | 850           |
|    policy_gradient_loss | 0.000536      |
|    value_loss           | 108           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 114          |
|    ep_rew_mean          | -23.9        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 87           |
|    time_elapsed         | 286          |
|    total_timesteps      | 11136        |
| train/                  |              |
|    approx_kl            | 2.594199e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.219       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 56.5         |
|    n_updates            | 860          |
|    policy_gradient_loss | -0.000106    |
|    value_loss           | 108          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 114           |
|    ep_rew_mean          | -24.1         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 88            |
|    time_elapsed         | 290           |
|    total_timesteps      | 11264         |
| train/                  |               |
|    approx_kl            | 1.2726523e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.224        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 27.7          |
|    n_updates            | 870           |
|    policy_gradient_loss | 8.03e-05      |
|    value_loss           | 56.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 114           |
|    ep_rew_mean          | -24.1         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 89            |
|    time_elapsed         | 294           |
|    total_timesteps      | 11392         |
| train/                  |               |
|    approx_kl            | 0.00019445643 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.219        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 71.7          |
|    n_updates            | 880           |
|    policy_gradient_loss | -0.00086      |
|    value_loss           | 142           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 114           |
|    ep_rew_mean          | -24.1         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 90            |
|    time_elapsed         | 297           |
|    total_timesteps      | 11520         |
| train/                  |               |
|    approx_kl            | 4.9720053e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.206        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 26.4          |
|    n_updates            | 890           |
|    policy_gradient_loss | -0.000188     |
|    value_loss           | 56.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 114           |
|    ep_rew_mean          | -24.1         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 91            |
|    time_elapsed         | 301           |
|    total_timesteps      | 11648         |
| train/                  |               |
|    approx_kl            | 3.3732504e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.204        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 21.1          |
|    n_updates            | 900           |
|    policy_gradient_loss | -3.99e-05     |
|    value_loss           | 49.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 114           |
|    ep_rew_mean          | -24.1         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 92            |
|    time_elapsed         | 304           |
|    total_timesteps      | 11776         |
| train/                  |               |
|    approx_kl            | 1.2805685e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.206        |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 19.7          |
|    n_updates            | 910           |
|    policy_gradient_loss | 2.08e-05      |
|    value_loss           | 46            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 114           |
|    ep_rew_mean          | -24.1         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 93            |
|    time_elapsed         | 307           |
|    total_timesteps      | 11904         |
| train/                  |               |
|    approx_kl            | 3.4122728e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.203        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 17.9          |
|    n_updates            | 920           |
|    policy_gradient_loss | -0.000384     |
|    value_loss           | 43.3          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 12000
Best mean reward: -11.38 - Last mean reward per episode: -11.71
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 114         |
|    ep_rew_mean          | -24.1       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 94          |
|    time_elapsed         | 311         |
|    total_timesteps      | 12032       |
| train/                  |             |
|    approx_kl            | 8.61939e-06 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.198      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 16.9        |
|    n_updates            | 930         |
|    policy_gradient_loss | -6.52e-05   |
|    value_loss           | 40.9        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 114           |
|    ep_rew_mean          | -24.1         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 95            |
|    time_elapsed         | 314           |
|    total_timesteps      | 12160         |
| train/                  |               |
|    approx_kl            | 4.4992194e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.197        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 15            |
|    n_updates            | 940           |
|    policy_gradient_loss | -7.24e-05     |
|    value_loss           | 38.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 123           |
|    ep_rew_mean          | -28.9         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 96            |
|    time_elapsed         | 317           |
|    total_timesteps      | 12288         |
| train/                  |               |
|    approx_kl            | 2.0163134e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.199        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 13.9          |
|    n_updates            | 950           |
|    policy_gradient_loss | 1.45e-05      |
|    value_loss           | 35.3          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 123          |
|    ep_rew_mean          | -28.7        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 97           |
|    time_elapsed         | 320          |
|    total_timesteps      | 12416        |
| train/                  |              |
|    approx_kl            | 6.930949e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.195       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 7.18         |
|    n_updates            | 960          |
|    policy_gradient_loss | -0.000615    |
|    value_loss           | 22.9         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 112           |
|    ep_rew_mean          | -22.9         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 98            |
|    time_elapsed         | 324           |
|    total_timesteps      | 12544         |
| train/                  |               |
|    approx_kl            | 0.00023033237 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.183        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 74.3          |
|    n_updates            | 970           |
|    policy_gradient_loss | -0.00103      |
|    value_loss           | 217           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 111           |
|    ep_rew_mean          | -22.4         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 99            |
|    time_elapsed         | 327           |
|    total_timesteps      | 12672         |
| train/                  |               |
|    approx_kl            | 3.5667792e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.17         |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 181           |
|    n_updates            | 980           |
|    policy_gradient_loss | -0.000449     |
|    value_loss           | 283           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 103          |
|    ep_rew_mean          | -18.4        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 100          |
|    time_elapsed         | 330          |
|    total_timesteps      | 12800        |
| train/                  |              |
|    approx_kl            | 0.0026218342 |
|    clip_fraction        | 0.0305       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.192       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 39.1         |
|    n_updates            | 990          |
|    policy_gradient_loss | -0.00583     |
|    value_loss           | 96.1         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 103           |
|    ep_rew_mean          | -18.4         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 101           |
|    time_elapsed         | 334           |
|    total_timesteps      | 12928         |
| train/                  |               |
|    approx_kl            | 0.00017411681 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.193        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 88.9          |
|    n_updates            | 1000          |
|    policy_gradient_loss | -0.000593     |
|    value_loss           | 157           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 13000
Best mean reward: -11.38 - Last mean reward per episode: -15.36
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 104           |
|    ep_rew_mean          | -18.6         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 102           |
|    time_elapsed         | 337           |
|    total_timesteps      | 13056         |
| train/                  |               |
|    approx_kl            | 2.9671937e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.185        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 19.5          |
|    n_updates            | 1010          |
|    policy_gradient_loss | -0.000454     |
|    value_loss           | 41.1          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 103          |
|    ep_rew_mean          | -18.2        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 103          |
|    time_elapsed         | 340          |
|    total_timesteps      | 13184        |
| train/                  |              |
|    approx_kl            | 7.524155e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.18        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 42.2         |
|    n_updates            | 1020         |
|    policy_gradient_loss | -4.79e-05    |
|    value_loss           | 93.4         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 102         |
|    ep_rew_mean          | -17.9       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 104         |
|    time_elapsed         | 343         |
|    total_timesteps      | 13312       |
| train/                  |             |
|    approx_kl            | 0.002990256 |
|    clip_fraction        | 0.0195      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.153      |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 54.7        |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.00296    |
|    value_loss           | 113         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 102          |
|    ep_rew_mean          | -17.8        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 105          |
|    time_elapsed         | 346          |
|    total_timesteps      | 13440        |
| train/                  |              |
|    approx_kl            | 0.0008157552 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.119       |
|    explained_variance   | 1.79e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 82.4         |
|    n_updates            | 1040         |
|    policy_gradient_loss | 0.000114     |
|    value_loss           | 180          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 102           |
|    ep_rew_mean          | -17.9         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 106           |
|    time_elapsed         | 350           |
|    total_timesteps      | 13568         |
| train/                  |               |
|    approx_kl            | 5.9930608e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.108        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 136           |
|    n_updates            | 1050          |
|    policy_gradient_loss | -0.000167     |
|    value_loss           | 271           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 103           |
|    ep_rew_mean          | -18.2         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 107           |
|    time_elapsed         | 354           |
|    total_timesteps      | 13696         |
| train/                  |               |
|    approx_kl            | 3.8403086e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.105        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 36.1          |
|    n_updates            | 1060          |
|    policy_gradient_loss | -1.74e-05     |
|    value_loss           | 92.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 98            |
|    ep_rew_mean          | -16           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 108           |
|    time_elapsed         | 357           |
|    total_timesteps      | 13824         |
| train/                  |               |
|    approx_kl            | 6.7495275e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.101        |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 45.9          |
|    n_updates            | 1070          |
|    policy_gradient_loss | 3.86e-05      |
|    value_loss           | 91            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 97.9          |
|    ep_rew_mean          | -15.8         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 109           |
|    time_elapsed         | 359           |
|    total_timesteps      | 13952         |
| train/                  |               |
|    approx_kl            | 0.00035246415 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.107        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 57.7          |
|    n_updates            | 1080          |
|    policy_gradient_loss | -0.000352     |
|    value_loss           | 133           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 14000
Best mean reward: -11.38 - Last mean reward per episode: -13.62
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 96.6          |
|    ep_rew_mean          | -15.2         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 110           |
|    time_elapsed         | 362           |
|    total_timesteps      | 14080         |
| train/                  |               |
|    approx_kl            | 3.4247525e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.116        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 75.2          |
|    n_updates            | 1090          |
|    policy_gradient_loss | 2.47e-06      |
|    value_loss           | 256           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 96.6         |
|    ep_rew_mean          | -15.2        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 111          |
|    time_elapsed         | 365          |
|    total_timesteps      | 14208        |
| train/                  |              |
|    approx_kl            | 9.155832e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.112       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 68.2         |
|    n_updates            | 1100         |
|    policy_gradient_loss | -0.000512    |
|    value_loss           | 147          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 97.5          |
|    ep_rew_mean          | -15.7         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 112           |
|    time_elapsed         | 368           |
|    total_timesteps      | 14336         |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.107        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 19.6          |
|    n_updates            | 1110          |
|    policy_gradient_loss | -1.49e-08     |
|    value_loss           | 45.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 97.4          |
|    ep_rew_mean          | -15.7         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 113           |
|    time_elapsed         | 371           |
|    total_timesteps      | 14464         |
| train/                  |               |
|    approx_kl            | 2.0517502e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.106        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 46.1          |
|    n_updates            | 1120          |
|    policy_gradient_loss | -0.000198     |
|    value_loss           | 138           |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 97.8        |
|    ep_rew_mean          | -16         |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 114         |
|    time_elapsed         | 374         |
|    total_timesteps      | 14592       |
| train/                  |             |
|    approx_kl            | 5.82356e-06 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.104      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 64.5        |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.000223   |
|    value_loss           | 134         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 96           |
|    ep_rew_mean          | -15.1        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 115          |
|    time_elapsed         | 377          |
|    total_timesteps      | 14720        |
| train/                  |              |
|    approx_kl            | 0.0012342976 |
|    clip_fraction        | 0.0125       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.119       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 27.4         |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.00647     |
|    value_loss           | 85.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 95.1          |
|    ep_rew_mean          | -14.6         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 116           |
|    time_elapsed         | 379           |
|    total_timesteps      | 14848         |
| train/                  |               |
|    approx_kl            | 2.2253953e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.133        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 42.2          |
|    n_updates            | 1150          |
|    policy_gradient_loss | 1.85e-05      |
|    value_loss           | 129           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 95.1          |
|    ep_rew_mean          | -14.5         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 117           |
|    time_elapsed         | 383           |
|    total_timesteps      | 14976         |
| train/                  |               |
|    approx_kl            | 7.7765435e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.134        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 87.5          |
|    n_updates            | 1160          |
|    policy_gradient_loss | -1.65e-06     |
|    value_loss           | 172           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 15000
Best mean reward: -11.38 - Last mean reward per episode: -14.20
Eval num_timesteps=15000, episode_reward=-8.90 +/- 15.30
Episode length: 77.80 +/- 30.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 77.8         |
|    mean_reward          | -8.9         |
| time/                   |              |
|    total_timesteps      | 15000        |
| train/                  |              |
|    approx_kl            | 4.355656e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.131       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 33.4         |
|    n_updates            | 1170         |
|    policy_gradient_loss | -0.000325    |
|    value_loss           | 86.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 95       |
|    ep_rew_mean     | -14.6    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 118      |
|    time_elapsed    | 388      |
|    total_timesteps | 15104    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 95           |
|    ep_rew_mean          | -14.5        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 119          |
|    time_elapsed         | 390          |
|    total_timesteps      | 15232        |
| train/                  |              |
|    approx_kl            | 0.0010359823 |
|    clip_fraction        | 0.00625      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.117       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 58.9         |
|    n_updates            | 1180         |
|    policy_gradient_loss | -0.00218     |
|    value_loss           | 79.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.5          |
|    ep_rew_mean          | -14.4         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 120           |
|    time_elapsed         | 393           |
|    total_timesteps      | 15360         |
| train/                  |               |
|    approx_kl            | 1.5515368e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.101        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 138           |
|    n_updates            | 1190          |
|    policy_gradient_loss | 0.00047       |
|    value_loss           | 227           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 92.6          |
|    ep_rew_mean          | -13.4         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 121           |
|    time_elapsed         | 395           |
|    total_timesteps      | 15488         |
| train/                  |               |
|    approx_kl            | 0.00030272687 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0964       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 68.1          |
|    n_updates            | 1200          |
|    policy_gradient_loss | -0.00147      |
|    value_loss           | 120           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 92.7         |
|    ep_rew_mean          | -13.4        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 122          |
|    time_elapsed         | 398          |
|    total_timesteps      | 15616        |
| train/                  |              |
|    approx_kl            | 2.477225e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0878      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 60.8         |
|    n_updates            | 1210         |
|    policy_gradient_loss | -0.000128    |
|    value_loss           | 117          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 92.6         |
|    ep_rew_mean          | -13.2        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 123          |
|    time_elapsed         | 400          |
|    total_timesteps      | 15744        |
| train/                  |              |
|    approx_kl            | 0.0011934582 |
|    clip_fraction        | 0.00625      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0961      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 58.1         |
|    n_updates            | 1220         |
|    policy_gradient_loss | -0.00447     |
|    value_loss           | 115          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 92.6          |
|    ep_rew_mean          | -13.1         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 124           |
|    time_elapsed         | 403           |
|    total_timesteps      | 15872         |
| train/                  |               |
|    approx_kl            | 0.00010890281 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.121        |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 84.3          |
|    n_updates            | 1230          |
|    policy_gradient_loss | -0.00119      |
|    value_loss           | 195           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 16000
Best mean reward: -11.38 - Last mean reward per episode: -11.95
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 92.7         |
|    ep_rew_mean          | -13.2        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 125          |
|    time_elapsed         | 406          |
|    total_timesteps      | 16000        |
| train/                  |              |
|    approx_kl            | 0.0007657544 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.133       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 65.5         |
|    n_updates            | 1240         |
|    policy_gradient_loss | -0.0014      |
|    value_loss           | 131          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 92.3          |
|    ep_rew_mean          | -12.9         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 126           |
|    time_elapsed         | 409           |
|    total_timesteps      | 16128         |
| train/                  |               |
|    approx_kl            | 0.00026927888 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.145        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 25.8          |
|    n_updates            | 1250          |
|    policy_gradient_loss | -0.000767     |
|    value_loss           | 68.5          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 92.5         |
|    ep_rew_mean          | -13          |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 127          |
|    time_elapsed         | 412          |
|    total_timesteps      | 16256        |
| train/                  |              |
|    approx_kl            | 0.0002544811 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.157       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 30.7         |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.000684    |
|    value_loss           | 66.9         |
------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 92.3           |
|    ep_rew_mean          | -12.9          |
| time/                   |                |
|    fps                  | 39             |
|    iterations           | 128            |
|    time_elapsed         | 415            |
|    total_timesteps      | 16384          |
| train/                  |                |
|    approx_kl            | 0.000119810924 |
|    clip_fraction        | 0              |
|    clip_range           | 0.2            |
|    entropy_loss         | -0.174         |
|    explained_variance   | 0              |
|    learning_rate        | 0.0003         |
|    loss                 | 46.9           |
|    n_updates            | 1270           |
|    policy_gradient_loss | 7.46e-05       |
|    value_loss           | 71.6           |
--------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 92.3          |
|    ep_rew_mean          | -12.9         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 129           |
|    time_elapsed         | 418           |
|    total_timesteps      | 16512         |
| train/                  |               |
|    approx_kl            | 0.00015031546 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.182        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 44.1          |
|    n_updates            | 1280          |
|    policy_gradient_loss | -0.000776     |
|    value_loss           | 79.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 93.5          |
|    ep_rew_mean          | -13.7         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 130           |
|    time_elapsed         | 421           |
|    total_timesteps      | 16640         |
| train/                  |               |
|    approx_kl            | 0.00042871898 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.205        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 21.5          |
|    n_updates            | 1290          |
|    policy_gradient_loss | -0.00336      |
|    value_loss           | 46.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 93.9          |
|    ep_rew_mean          | -13.8         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 131           |
|    time_elapsed         | 424           |
|    total_timesteps      | 16768         |
| train/                  |               |
|    approx_kl            | 3.5939738e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.22         |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 53.7          |
|    n_updates            | 1300          |
|    policy_gradient_loss | 7.2e-05       |
|    value_loss           | 123           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 93.8          |
|    ep_rew_mean          | -14           |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 132           |
|    time_elapsed         | 426           |
|    total_timesteps      | 16896         |
| train/                  |               |
|    approx_kl            | 0.00037285686 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.224        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 54.9          |
|    n_updates            | 1310          |
|    policy_gradient_loss | -0.00153      |
|    value_loss           | 117           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 17000
Best mean reward: -11.38 - Last mean reward per episode: -13.81
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 93.5          |
|    ep_rew_mean          | -13.9         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 133           |
|    time_elapsed         | 429           |
|    total_timesteps      | 17024         |
| train/                  |               |
|    approx_kl            | 5.6219753e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.246        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 40.5          |
|    n_updates            | 1320          |
|    policy_gradient_loss | 0.000801      |
|    value_loss           | 79.1          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 93.3         |
|    ep_rew_mean          | -13.6        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 134          |
|    time_elapsed         | 432          |
|    total_timesteps      | 17152        |
| train/                  |              |
|    approx_kl            | 0.0002902262 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.231       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 54.7         |
|    n_updates            | 1330         |
|    policy_gradient_loss | -0.000802    |
|    value_loss           | 109          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 94.1        |
|    ep_rew_mean          | -13.9       |
| time/                   |             |
|    fps                  | 39          |
|    iterations           | 135         |
|    time_elapsed         | 436         |
|    total_timesteps      | 17280       |
| train/                  |             |
|    approx_kl            | 0.003405414 |
|    clip_fraction        | 0.0187      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.194      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 90.8        |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.00338    |
|    value_loss           | 179         |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.1          |
|    ep_rew_mean          | -14           |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 136           |
|    time_elapsed         | 438           |
|    total_timesteps      | 17408         |
| train/                  |               |
|    approx_kl            | 0.00027394667 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.166        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 75.8          |
|    n_updates            | 1350          |
|    policy_gradient_loss | -0.000168     |
|    value_loss           | 117           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 93.8          |
|    ep_rew_mean          | -13.7         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 137           |
|    time_elapsed         | 441           |
|    total_timesteps      | 17536         |
| train/                  |               |
|    approx_kl            | 0.00021724962 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.186        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 53.6          |
|    n_updates            | 1360          |
|    policy_gradient_loss | -0.000222     |
|    value_loss           | 106           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 93.9          |
|    ep_rew_mean          | -13.7         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 138           |
|    time_elapsed         | 443           |
|    total_timesteps      | 17664         |
| train/                  |               |
|    approx_kl            | 4.7505833e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.198        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 47.2          |
|    n_updates            | 1370          |
|    policy_gradient_loss | -0.000256     |
|    value_loss           | 139           |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 94.1        |
|    ep_rew_mean          | -13.9       |
| time/                   |             |
|    fps                  | 39          |
|    iterations           | 139         |
|    time_elapsed         | 447         |
|    total_timesteps      | 17792       |
| train/                  |             |
|    approx_kl            | 0.002403786 |
|    clip_fraction        | 0.0125      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.189      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 37.7        |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.00204    |
|    value_loss           | 110         |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.7          |
|    ep_rew_mean          | -14.4         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 140           |
|    time_elapsed         | 450           |
|    total_timesteps      | 17920         |
| train/                  |               |
|    approx_kl            | 5.8442354e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.155        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 34.1          |
|    n_updates            | 1390          |
|    policy_gradient_loss | 0.000796      |
|    value_loss           | 85.7          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 18000
Best mean reward: -11.38 - Last mean reward per episode: -14.42
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 94.7         |
|    ep_rew_mean          | -14.3        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 141          |
|    time_elapsed         | 453          |
|    total_timesteps      | 18048        |
| train/                  |              |
|    approx_kl            | 0.0008083293 |
|    clip_fraction        | 0.00625      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.167       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 55.7         |
|    n_updates            | 1400         |
|    policy_gradient_loss | -0.00251     |
|    value_loss           | 110          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 95.2          |
|    ep_rew_mean          | -14.4         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 142           |
|    time_elapsed         | 457           |
|    total_timesteps      | 18176         |
| train/                  |               |
|    approx_kl            | 0.00021399185 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.197        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 45.6          |
|    n_updates            | 1410          |
|    policy_gradient_loss | -5.69e-05     |
|    value_loss           | 78.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 95.3          |
|    ep_rew_mean          | -14.6         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 143           |
|    time_elapsed         | 461           |
|    total_timesteps      | 18304         |
| train/                  |               |
|    approx_kl            | 1.8142164e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.203        |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 112           |
|    n_updates            | 1420          |
|    policy_gradient_loss | -2.25e-05     |
|    value_loss           | 196           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 95.7          |
|    ep_rew_mean          | -14.9         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 144           |
|    time_elapsed         | 464           |
|    total_timesteps      | 18432         |
| train/                  |               |
|    approx_kl            | 9.2891045e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.195        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 50.3          |
|    n_updates            | 1430          |
|    policy_gradient_loss | -0.00042      |
|    value_loss           | 114           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.7          |
|    ep_rew_mean          | -14.6         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 145           |
|    time_elapsed         | 467           |
|    total_timesteps      | 18560         |
| train/                  |               |
|    approx_kl            | 0.00028799195 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.177        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 94.8          |
|    n_updates            | 1440          |
|    policy_gradient_loss | -0.00129      |
|    value_loss           | 201           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 94.7         |
|    ep_rew_mean          | -14.5        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 146          |
|    time_elapsed         | 470          |
|    total_timesteps      | 18688        |
| train/                  |              |
|    approx_kl            | 0.0017339177 |
|    clip_fraction        | 0.0187       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.143       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 39.1         |
|    n_updates            | 1450         |
|    policy_gradient_loss | -0.000988    |
|    value_loss           | 99.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 93.4         |
|    ep_rew_mean          | -13.7        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 147          |
|    time_elapsed         | 473          |
|    total_timesteps      | 18816        |
| train/                  |              |
|    approx_kl            | 3.057858e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.129       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 65.3         |
|    n_updates            | 1460         |
|    policy_gradient_loss | -6.98e-05    |
|    value_loss           | 161          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 93.2         |
|    ep_rew_mean          | -13.6        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 148          |
|    time_elapsed         | 476          |
|    total_timesteps      | 18944        |
| train/                  |              |
|    approx_kl            | 4.114071e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.124       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 62.4         |
|    n_updates            | 1470         |
|    policy_gradient_loss | -0.000151    |
|    value_loss           | 158          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 19000
Best mean reward: -11.38 - Last mean reward per episode: -12.70
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 93.4         |
|    ep_rew_mean          | -13.6        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 149          |
|    time_elapsed         | 479          |
|    total_timesteps      | 19072        |
| train/                  |              |
|    approx_kl            | 4.824251e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.132       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 72.5         |
|    n_updates            | 1480         |
|    policy_gradient_loss | 0.000173     |
|    value_loss           | 107          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 91.5         |
|    ep_rew_mean          | -12.8        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 150          |
|    time_elapsed         | 482          |
|    total_timesteps      | 19200        |
| train/                  |              |
|    approx_kl            | 9.075273e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.13        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 62.7         |
|    n_updates            | 1490         |
|    policy_gradient_loss | -0.000207    |
|    value_loss           | 140          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 91.2          |
|    ep_rew_mean          | -12.5         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 151           |
|    time_elapsed         | 485           |
|    total_timesteps      | 19328         |
| train/                  |               |
|    approx_kl            | 0.00036436366 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.125        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 50.2          |
|    n_updates            | 1500          |
|    policy_gradient_loss | -0.000676     |
|    value_loss           | 99.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 91.4          |
|    ep_rew_mean          | -12.6         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 152           |
|    time_elapsed         | 488           |
|    total_timesteps      | 19456         |
| train/                  |               |
|    approx_kl            | 0.00012166286 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.107        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 55.3          |
|    n_updates            | 1510          |
|    policy_gradient_loss | 0.00064       |
|    value_loss           | 129           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 91.2         |
|    ep_rew_mean          | -12.5        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 153          |
|    time_elapsed         | 491          |
|    total_timesteps      | 19584        |
| train/                  |              |
|    approx_kl            | 8.009374e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.105       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 31.6         |
|    n_updates            | 1520         |
|    policy_gradient_loss | -1.79e-05    |
|    value_loss           | 69.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 91.4         |
|    ep_rew_mean          | -12.7        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 154          |
|    time_elapsed         | 493          |
|    total_timesteps      | 19712        |
| train/                  |              |
|    approx_kl            | 4.342757e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.104       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 43.6         |
|    n_updates            | 1530         |
|    policy_gradient_loss | 5.29e-05     |
|    value_loss           | 87.3         |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 92         |
|    ep_rew_mean          | -13        |
| time/                   |            |
|    fps                  | 39         |
|    iterations           | 155        |
|    time_elapsed         | 496        |
|    total_timesteps      | 19840      |
| train/                  |            |
|    approx_kl            | 0.00347644 |
|    clip_fraction        | 0.0109     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.136     |
|    explained_variance   | -1.19e-07  |
|    learning_rate        | 0.0003     |
|    loss                 | 48.8       |
|    n_updates            | 1540       |
|    policy_gradient_loss | -0.00583   |
|    value_loss           | 91         |
----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 91.7          |
|    ep_rew_mean          | -12.6         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 156           |
|    time_elapsed         | 499           |
|    total_timesteps      | 19968         |
| train/                  |               |
|    approx_kl            | 0.00025140448 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.179        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 36.1          |
|    n_updates            | 1550          |
|    policy_gradient_loss | -0.000421     |
|    value_loss           | 75            |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 20000
Best mean reward: -11.38 - Last mean reward per episode: -12.24
Eval num_timesteps=20000, episode_reward=-5.10 +/- 15.54
Episode length: 78.20 +/- 25.03
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 78.2          |
|    mean_reward          | -5.1          |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 1.6303267e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.189        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 97.6          |
|    n_updates            | 1560          |
|    policy_gradient_loss | 0.000132      |
|    value_loss           | 173           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 91.2     |
|    ep_rew_mean     | -12.4    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 157      |
|    time_elapsed    | 504      |
|    total_timesteps | 20096    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 91.2          |
|    ep_rew_mean          | -12.4         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 158           |
|    time_elapsed         | 507           |
|    total_timesteps      | 20224         |
| train/                  |               |
|    approx_kl            | 3.1143427e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.189        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 24            |
|    n_updates            | 1570          |
|    policy_gradient_loss | -3.73e-05     |
|    value_loss           | 69.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 90           |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 159          |
|    time_elapsed         | 509          |
|    total_timesteps      | 20352        |
| train/                  |              |
|    approx_kl            | 0.0008254666 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.178       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 41.2         |
|    n_updates            | 1580         |
|    policy_gradient_loss | -0.000593    |
|    value_loss           | 92.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80.6         |
|    ep_rew_mean          | -6.91        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 160          |
|    time_elapsed         | 512          |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 0.0011236863 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.15        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 47.7         |
|    n_updates            | 1590         |
|    policy_gradient_loss | -0.00186     |
|    value_loss           | 90           |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80.5        |
|    ep_rew_mean          | -7.07       |
| time/                   |             |
|    fps                  | 39          |
|    iterations           | 161         |
|    time_elapsed         | 515         |
|    total_timesteps      | 20608       |
| train/                  |             |
|    approx_kl            | 0.006443643 |
|    clip_fraction        | 0.0367      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.101      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 50.6        |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.00433    |
|    value_loss           | 88.3        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 80.4          |
|    ep_rew_mean          | -6.98         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 162           |
|    time_elapsed         | 517           |
|    total_timesteps      | 20736         |
| train/                  |               |
|    approx_kl            | 7.1525574e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0794       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 36.5          |
|    n_updates            | 1610          |
|    policy_gradient_loss | 2.19e-09      |
|    value_loss           | 68.2          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -6.51     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 163       |
|    time_elapsed         | 520       |
|    total_timesteps      | 20864     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0773   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 106       |
|    n_updates            | 1620      |
|    policy_gradient_loss | 1.4e-10   |
|    value_loss           | 170       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.8         |
|    ep_rew_mean          | -5.53        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 164          |
|    time_elapsed         | 522          |
|    total_timesteps      | 20992        |
| train/                  |              |
|    approx_kl            | 6.844895e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0746      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 55           |
|    n_updates            | 1630         |
|    policy_gradient_loss | -0.000271    |
|    value_loss           | 122          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 21000
Best mean reward: -11.38 - Last mean reward per episode: -5.92
Saving new best model at 134154 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 78           |
|    ep_rew_mean          | -5.61        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 165          |
|    time_elapsed         | 525          |
|    total_timesteps      | 21120        |
| train/                  |              |
|    approx_kl            | 0.0002367585 |
|    clip_fraction        | 0.00156      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.061       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 48.4         |
|    n_updates            | 1640         |
|    policy_gradient_loss | -0.000816    |
|    value_loss           | 120          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 78.1         |
|    ep_rew_mean          | -5.87        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 166          |
|    time_elapsed         | 529          |
|    total_timesteps      | 21248        |
| train/                  |              |
|    approx_kl            | 0.0003410466 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0518      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 54.1         |
|    n_updates            | 1650         |
|    policy_gradient_loss | -0.001       |
|    value_loss           | 111          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.6          |
|    ep_rew_mean          | -5.5          |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 167           |
|    time_elapsed         | 532           |
|    total_timesteps      | 21376         |
| train/                  |               |
|    approx_kl            | 2.3841858e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.044        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 49.4          |
|    n_updates            | 1660          |
|    policy_gradient_loss | 1.35e-09      |
|    value_loss           | 85.7          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.7      |
|    ep_rew_mean          | -5.04     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 168       |
|    time_elapsed         | 535       |
|    total_timesteps      | 21504     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0427   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 78.3      |
|    n_updates            | 1670      |
|    policy_gradient_loss | -3.59e-09 |
|    value_loss           | 181       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76.8          |
|    ep_rew_mean          | -5.01         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 169           |
|    time_elapsed         | 538           |
|    total_timesteps      | 21632         |
| train/                  |               |
|    approx_kl            | 7.2233845e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0448       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 29.9          |
|    n_updates            | 1680          |
|    policy_gradient_loss | -0.000161     |
|    value_loss           | 77.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76.6          |
|    ep_rew_mean          | -5.11         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 170           |
|    time_elapsed         | 541           |
|    total_timesteps      | 21760         |
| train/                  |               |
|    approx_kl            | 0.00021395553 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0508       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 48.2          |
|    n_updates            | 1690          |
|    policy_gradient_loss | 0.000238      |
|    value_loss           | 114           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.3         |
|    ep_rew_mean          | -5.35        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 171          |
|    time_elapsed         | 544          |
|    total_timesteps      | 21888        |
| train/                  |              |
|    approx_kl            | 9.033829e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.053       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 41.8         |
|    n_updates            | 1700         |
|    policy_gradient_loss | 2.12e-05     |
|    value_loss           | 79.8         |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 22000
Best mean reward: -5.92 - Last mean reward per episode: -4.87
Saving new best model at 135187 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.7      |
|    ep_rew_mean          | -4.54     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 172       |
|    time_elapsed         | 547       |
|    total_timesteps      | 22016     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.053    |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 52.4      |
|    n_updates            | 1710      |
|    policy_gradient_loss | -1.58e-09 |
|    value_loss           | 109       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.2      |
|    ep_rew_mean          | -4.71     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 173       |
|    time_elapsed         | 550       |
|    total_timesteps      | 22144     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0535   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.1      |
|    n_updates            | 1720      |
|    policy_gradient_loss | -1.16e-09 |
|    value_loss           | 83.7      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.2     |
|    ep_rew_mean          | -4.71    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 174      |
|    time_elapsed         | 554      |
|    total_timesteps      | 22272    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0542  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 36.7     |
|    n_updates            | 1730     |
|    policy_gradient_loss | -1.4e-09 |
|    value_loss           | 96.2     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.9          |
|    ep_rew_mean          | -5.33         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 175           |
|    time_elapsed         | 558           |
|    total_timesteps      | 22400         |
| train/                  |               |
|    approx_kl            | 1.5804544e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0548       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 26.7          |
|    n_updates            | 1740          |
|    policy_gradient_loss | -0.0001       |
|    value_loss           | 59.2          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 78           |
|    ep_rew_mean          | -5.03        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 176          |
|    time_elapsed         | 562          |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0009166454 |
|    clip_fraction        | 0.00313      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0573      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 78.6         |
|    n_updates            | 1750         |
|    policy_gradient_loss | -0.00131     |
|    value_loss           | 147          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 78.2         |
|    ep_rew_mean          | -4.97        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 177          |
|    time_elapsed         | 565          |
|    total_timesteps      | 22656        |
| train/                  |              |
|    approx_kl            | 3.119139e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0569      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 95.9         |
|    n_updates            | 1760         |
|    policy_gradient_loss | 0.000118     |
|    value_loss           | 246          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.9      |
|    ep_rew_mean          | -4.66     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 178       |
|    time_elapsed         | 569       |
|    total_timesteps      | 22784     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0561   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.7      |
|    n_updates            | 1770      |
|    policy_gradient_loss | -6.52e-10 |
|    value_loss           | 119       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.9          |
|    ep_rew_mean          | -4.67         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 179           |
|    time_elapsed         | 572           |
|    total_timesteps      | 22912         |
| train/                  |               |
|    approx_kl            | 3.5031699e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0559       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 114           |
|    n_updates            | 1780          |
|    policy_gradient_loss | -7.68e-05     |
|    value_loss           | 186           |
-------------------------------------------
Num timesteps: 23000
Best mean reward: -4.87 - Last mean reward per episode: -4.86
Saving new best model at 136165 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.5         |
|    ep_rew_mean          | -4.36        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 180          |
|    time_elapsed         | 575          |
|    total_timesteps      | 23040        |
| train/                  |              |
|    approx_kl            | 0.0004636282 |
|    clip_fraction        | 0.00313      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.06        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 36.5         |
|    n_updates            | 1790         |
|    policy_gradient_loss | -0.0013      |
|    value_loss           | 76           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.6          |
|    ep_rew_mean          | -4.3          |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 181           |
|    time_elapsed         | 578           |
|    total_timesteps      | 23168         |
| train/                  |               |
|    approx_kl            | 9.8799355e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0701       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 84.5          |
|    n_updates            | 1800          |
|    policy_gradient_loss | 0.00054       |
|    value_loss           | 179           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.9          |
|    ep_rew_mean          | -4.45         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 182           |
|    time_elapsed         | 581           |
|    total_timesteps      | 23296         |
| train/                  |               |
|    approx_kl            | 0.00016100286 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0647       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 37.1          |
|    n_updates            | 1810          |
|    policy_gradient_loss | -0.000564     |
|    value_loss           | 105           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.9          |
|    ep_rew_mean          | -4.45         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 183           |
|    time_elapsed         | 583           |
|    total_timesteps      | 23424         |
| train/                  |               |
|    approx_kl            | 0.00044745067 |
|    clip_fraction        | 0.00234       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0613       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 37.3          |
|    n_updates            | 1820          |
|    policy_gradient_loss | -0.00131      |
|    value_loss           | 74.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 78.7         |
|    ep_rew_mean          | -4.56        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 184          |
|    time_elapsed         | 587          |
|    total_timesteps      | 23552        |
| train/                  |              |
|    approx_kl            | 9.852182e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0724      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 32.3         |
|    n_updates            | 1830         |
|    policy_gradient_loss | 0.000885     |
|    value_loss           | 67           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 78.7          |
|    ep_rew_mean          | -4.66         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 185           |
|    time_elapsed         | 590           |
|    total_timesteps      | 23680         |
| train/                  |               |
|    approx_kl            | 1.1473894e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0732       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 61.1          |
|    n_updates            | 1840          |
|    policy_gradient_loss | -1.89e-05     |
|    value_loss           | 140           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 78.8          |
|    ep_rew_mean          | -4.58         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 186           |
|    time_elapsed         | 593           |
|    total_timesteps      | 23808         |
| train/                  |               |
|    approx_kl            | 2.5657006e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0714       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 37            |
|    n_updates            | 1850          |
|    policy_gradient_loss | -0.000182     |
|    value_loss           | 97.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.9         |
|    ep_rew_mean          | -4.13        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 187          |
|    time_elapsed         | 596          |
|    total_timesteps      | 23936        |
| train/                  |              |
|    approx_kl            | 9.040348e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0685      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 50.7         |
|    n_updates            | 1860         |
|    policy_gradient_loss | -0.000159    |
|    value_loss           | 144          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 24000
Best mean reward: -4.86 - Last mean reward per episode: -2.86
Saving new best model at 137191 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77           |
|    ep_rew_mean          | -3.73        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 188          |
|    time_elapsed         | 599          |
|    total_timesteps      | 24064        |
| train/                  |              |
|    approx_kl            | 0.0010756925 |
|    clip_fraction        | 0.00703      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0583      |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 36.8         |
|    n_updates            | 1870         |
|    policy_gradient_loss | -0.00138     |
|    value_loss           | 70.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.3          |
|    ep_rew_mean          | -2.83         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 189           |
|    time_elapsed         | 602           |
|    total_timesteps      | 24192         |
| train/                  |               |
|    approx_kl            | 0.00043665664 |
|    clip_fraction        | 0.00234       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0539       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 32.9          |
|    n_updates            | 1880          |
|    policy_gradient_loss | -0.0014       |
|    value_loss           | 71.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75            |
|    ep_rew_mean          | -2.67         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 190           |
|    time_elapsed         | 605           |
|    total_timesteps      | 24320         |
| train/                  |               |
|    approx_kl            | 5.8449805e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0644       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 38.5          |
|    n_updates            | 1890          |
|    policy_gradient_loss | 0.000292      |
|    value_loss           | 76.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.7          |
|    ep_rew_mean          | -2.53         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 191           |
|    time_elapsed         | 608           |
|    total_timesteps      | 24448         |
| train/                  |               |
|    approx_kl            | 5.9604645e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0569       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 46.2          |
|    n_updates            | 1900          |
|    policy_gradient_loss | 1.82e-09      |
|    value_loss           | 83.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.8          |
|    ep_rew_mean          | -2.59         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 192           |
|    time_elapsed         | 610           |
|    total_timesteps      | 24576         |
| train/                  |               |
|    approx_kl            | 0.00019793026 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0573       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 46.6          |
|    n_updates            | 1910          |
|    policy_gradient_loss | -0.000389     |
|    value_loss           | 87.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.3          |
|    ep_rew_mean          | -2.35         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 193           |
|    time_elapsed         | 613           |
|    total_timesteps      | 24704         |
| train/                  |               |
|    approx_kl            | 0.00038505113 |
|    clip_fraction        | 0.00313       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0661       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 59.1          |
|    n_updates            | 1920          |
|    policy_gradient_loss | -0.00329      |
|    value_loss           | 149           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 74.6         |
|    ep_rew_mean          | -2.42        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 194          |
|    time_elapsed         | 616          |
|    total_timesteps      | 24832        |
| train/                  |              |
|    approx_kl            | 3.418699e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0752      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 30.1         |
|    n_updates            | 1930         |
|    policy_gradient_loss | 0.000103     |
|    value_loss           | 67.9         |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.3     |
|    ep_rew_mean          | -2.25    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 195      |
|    time_elapsed         | 620      |
|    total_timesteps      | 24960    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.077   |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 33.3     |
|    n_updates            | 1940     |
|    policy_gradient_loss | 1.63e-09 |
|    value_loss           | 102      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 25000
Best mean reward: -2.86 - Last mean reward per episode: -1.95
Saving new best model at 138155 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
Eval num_timesteps=25000, episode_reward=-10.80 +/- 18.90
Episode length: 89.60 +/- 35.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 89.6         |
|    mean_reward          | -10.8        |
| time/                   |              |
|    total_timesteps      | 25000        |
| train/                  |              |
|    approx_kl            | 8.471124e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.074       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 47.9         |
|    n_updates            | 1950         |
|    policy_gradient_loss | -0.00038     |
|    value_loss           | 100          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 74.3     |
|    ep_rew_mean     | -2.25    |
| time/              |          |
|    fps             | 40       |
|    iterations      | 196      |
|    time_elapsed    | 625      |
|    total_timesteps | 25088    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.7          |
|    ep_rew_mean          | -2.25         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 197           |
|    time_elapsed         | 629           |
|    total_timesteps      | 25216         |
| train/                  |               |
|    approx_kl            | 1.4487654e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.066        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 33.3          |
|    n_updates            | 1960          |
|    policy_gradient_loss | -1.33e-05     |
|    value_loss           | 70            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 74.1         |
|    ep_rew_mean          | -1.74        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 198          |
|    time_elapsed         | 633          |
|    total_timesteps      | 25344        |
| train/                  |              |
|    approx_kl            | 0.0004283078 |
|    clip_fraction        | 0.00156      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0598      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 92.4         |
|    n_updates            | 1970         |
|    policy_gradient_loss | -0.00102     |
|    value_loss           | 176          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.1          |
|    ep_rew_mean          | -1.74         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 199           |
|    time_elapsed         | 636           |
|    total_timesteps      | 25472         |
| train/                  |               |
|    approx_kl            | 3.9808452e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0499       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 75.9          |
|    n_updates            | 1980          |
|    policy_gradient_loss | 8.01e-05      |
|    value_loss           | 140           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.8          |
|    ep_rew_mean          | -2.02         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 200           |
|    time_elapsed         | 639           |
|    total_timesteps      | 25600         |
| train/                  |               |
|    approx_kl            | 2.1881424e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0482       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 34.5          |
|    n_updates            | 1990          |
|    policy_gradient_loss | -7e-05        |
|    value_loss           | 71.3          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 74.3        |
|    ep_rew_mean          | -1.96       |
| time/                   |             |
|    fps                  | 40          |
|    iterations           | 201         |
|    time_elapsed         | 641         |
|    total_timesteps      | 25728       |
| train/                  |             |
|    approx_kl            | 8.96398e-07 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0475     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 38.7        |
|    n_updates            | 2000        |
|    policy_gradient_loss | -2.24e-05   |
|    value_loss           | 91.1        |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.6     |
|    ep_rew_mean          | -2.21    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 202      |
|    time_elapsed         | 645      |
|    total_timesteps      | 25856    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0472  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 30.5     |
|    n_updates            | 2010     |
|    policy_gradient_loss | 1.4e-10  |
|    value_loss           | 79.6     |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 74.1         |
|    ep_rew_mean          | -2.13        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 203          |
|    time_elapsed         | 647          |
|    total_timesteps      | 25984        |
| train/                  |              |
|    approx_kl            | 9.313226e-09 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0477      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 31.5         |
|    n_updates            | 2020         |
|    policy_gradient_loss | 2.56e-06     |
|    value_loss           | 65.2         |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 26000
Best mean reward: -1.95 - Last mean reward per episode: -2.67
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74        |
|    ep_rew_mean          | -1.92     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 204       |
|    time_elapsed         | 651       |
|    total_timesteps      | 26112     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0478   |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 44.5      |
|    n_updates            | 2030      |
|    policy_gradient_loss | -1.16e-10 |
|    value_loss           | 79.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75       |
|    ep_rew_mean          | -2.51    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 205      |
|    time_elapsed         | 654      |
|    total_timesteps      | 26240    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0478  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 74.8     |
|    n_updates            | 2040     |
|    policy_gradient_loss | 4.42e-09 |
|    value_loss           | 134      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75        |
|    ep_rew_mean          | -2.5      |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 206       |
|    time_elapsed         | 657       |
|    total_timesteps      | 26368     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0479   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 60.2      |
|    n_updates            | 2050      |
|    policy_gradient_loss | -5.75e-09 |
|    value_loss           | 114       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.8      |
|    ep_rew_mean          | -2.59     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 207       |
|    time_elapsed         | 660       |
|    total_timesteps      | 26496     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0483   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 46.9      |
|    n_updates            | 2060      |
|    policy_gradient_loss | 3.86e-09  |
|    value_loss           | 80.3      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.3          |
|    ep_rew_mean          | -2.27         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 208           |
|    time_elapsed         | 663           |
|    total_timesteps      | 26624         |
| train/                  |               |
|    approx_kl            | 8.6018816e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0493       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 42.5          |
|    n_updates            | 2070          |
|    policy_gradient_loss | -0.000279     |
|    value_loss           | 77            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.8          |
|    ep_rew_mean          | -2.52         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 209           |
|    time_elapsed         | 666           |
|    total_timesteps      | 26752         |
| train/                  |               |
|    approx_kl            | 0.00021285191 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.052        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 68.9          |
|    n_updates            | 2080          |
|    policy_gradient_loss | -0.000425     |
|    value_loss           | 155           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.6          |
|    ep_rew_mean          | -2.42         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 210           |
|    time_elapsed         | 669           |
|    total_timesteps      | 26880         |
| train/                  |               |
|    approx_kl            | 1.0858756e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0467       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 32.1          |
|    n_updates            | 2090          |
|    policy_gradient_loss | 0.00114       |
|    value_loss           | 66.8          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 27000
Best mean reward: -1.95 - Last mean reward per episode: -2.71
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.2          |
|    ep_rew_mean          | -2.83         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 211           |
|    time_elapsed         | 672           |
|    total_timesteps      | 27008         |
| train/                  |               |
|    approx_kl            | 2.9802322e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0476       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 41.2          |
|    n_updates            | 2100          |
|    policy_gradient_loss | -1.12e-09     |
|    value_loss           | 82.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 74.8         |
|    ep_rew_mean          | -2.62        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 212          |
|    time_elapsed         | 675          |
|    total_timesteps      | 27136        |
| train/                  |              |
|    approx_kl            | 6.388547e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0502      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 34.4         |
|    n_updates            | 2110         |
|    policy_gradient_loss | -0.000698    |
|    value_loss           | 83.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.6          |
|    ep_rew_mean          | -2.5          |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 213           |
|    time_elapsed         | 677           |
|    total_timesteps      | 27264         |
| train/                  |               |
|    approx_kl            | 2.3896806e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0529       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 44.9          |
|    n_updates            | 2120          |
|    policy_gradient_loss | -6.68e-05     |
|    value_loss           | 89.3          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 74.4         |
|    ep_rew_mean          | -2.42        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 214          |
|    time_elapsed         | 680          |
|    total_timesteps      | 27392        |
| train/                  |              |
|    approx_kl            | 0.0004152474 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0461      |
|    explained_variance   | 1.79e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 52.1         |
|    n_updates            | 2130         |
|    policy_gradient_loss | -0.00113     |
|    value_loss           | 87           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.5          |
|    ep_rew_mean          | -2.63         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 215           |
|    time_elapsed         | 683           |
|    total_timesteps      | 27520         |
| train/                  |               |
|    approx_kl            | 0.00012417743 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0382       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 47.3          |
|    n_updates            | 2140          |
|    policy_gradient_loss | -0.000272     |
|    value_loss           | 89.5          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 74.5         |
|    ep_rew_mean          | -2.62        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 216          |
|    time_elapsed         | 686          |
|    total_timesteps      | 27648        |
| train/                  |              |
|    approx_kl            | 6.872602e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0344      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 31.5         |
|    n_updates            | 2150         |
|    policy_gradient_loss | -0.000411    |
|    value_loss           | 90.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.4          |
|    ep_rew_mean          | -2.6          |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 217           |
|    time_elapsed         | 689           |
|    total_timesteps      | 27776         |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0306       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 43.7          |
|    n_updates            | 2160          |
|    policy_gradient_loss | -1.16e-09     |
|    value_loss           | 84.9          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.7     |
|    ep_rew_mean          | -2.75    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 218      |
|    time_elapsed         | 692      |
|    total_timesteps      | 27904    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0299  |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 38.9     |
|    n_updates            | 2170     |
|    policy_gradient_loss | 1.16e-11 |
|    value_loss           | 82.6     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 28000
Best mean reward: -1.95 - Last mean reward per episode: -3.15
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.6      |
|    ep_rew_mean          | -2.58     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 219       |
|    time_elapsed         | 694       |
|    total_timesteps      | 28032     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0301   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.9      |
|    n_updates            | 2180      |
|    policy_gradient_loss | -4.12e-09 |
|    value_loss           | 68.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.9     |
|    ep_rew_mean          | -2.46    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 220      |
|    time_elapsed         | 697      |
|    total_timesteps      | 28160    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0303  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 74.7     |
|    n_updates            | 2190     |
|    policy_gradient_loss | 2.7e-09  |
|    value_loss           | 124      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.5      |
|    ep_rew_mean          | -2.73     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 221       |
|    time_elapsed         | 700       |
|    total_timesteps      | 28288     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0306   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 58.2      |
|    n_updates            | 2200      |
|    policy_gradient_loss | -5.24e-09 |
|    value_loss           | 111       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.5          |
|    ep_rew_mean          | -2.75         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 222           |
|    time_elapsed         | 703           |
|    total_timesteps      | 28416         |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0307       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 45.6          |
|    n_updates            | 2210          |
|    policy_gradient_loss | -1.41e-06     |
|    value_loss           | 104           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 74.9         |
|    ep_rew_mean          | -3.03        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 223          |
|    time_elapsed         | 706          |
|    total_timesteps      | 28544        |
| train/                  |              |
|    approx_kl            | 5.401671e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0307      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 33.7         |
|    n_updates            | 2220         |
|    policy_gradient_loss | -1.32e-06    |
|    value_loss           | 70           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 74.9         |
|    ep_rew_mean          | -3.04        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 224          |
|    time_elapsed         | 709          |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 0.0007904116 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0275      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 33.9         |
|    n_updates            | 2230         |
|    policy_gradient_loss | -0.00126     |
|    value_loss           | 90           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 74.7         |
|    ep_rew_mean          | -2.87        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 225          |
|    time_elapsed         | 712          |
|    total_timesteps      | 28800        |
| train/                  |              |
|    approx_kl            | 5.956879e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0215      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 62.1         |
|    n_updates            | 2240         |
|    policy_gradient_loss | -0.000185    |
|    value_loss           | 124          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 75           |
|    ep_rew_mean          | -3.2         |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 226          |
|    time_elapsed         | 715          |
|    total_timesteps      | 28928        |
| train/                  |              |
|    approx_kl            | 9.387592e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0194      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 56.8         |
|    n_updates            | 2250         |
|    policy_gradient_loss | -0.000464    |
|    value_loss           | 127          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 29000
Best mean reward: -1.95 - Last mean reward per episode: -3.38
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -2.99     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 227       |
|    time_elapsed         | 719       |
|    total_timesteps      | 29056     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.017    |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 43.3      |
|    n_updates            | 2260      |
|    policy_gradient_loss | -9.97e-09 |
|    value_loss           | 115       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -2.99     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 228       |
|    time_elapsed         | 722       |
|    total_timesteps      | 29184     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0164   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 93.9      |
|    n_updates            | 2270      |
|    policy_gradient_loss | -2.05e-09 |
|    value_loss           | 188       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.3     |
|    ep_rew_mean          | -3.63    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 229      |
|    time_elapsed         | 725      |
|    total_timesteps      | 29312    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0164  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 32.3     |
|    n_updates            | 2280     |
|    policy_gradient_loss | 3.12e-09 |
|    value_loss           | 66.3     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.4      |
|    ep_rew_mean          | -3.48     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 230       |
|    time_elapsed         | 728       |
|    total_timesteps      | 29440     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0164   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 28.6      |
|    n_updates            | 2290      |
|    policy_gradient_loss | -2.33e-10 |
|    value_loss           | 77.7      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.4     |
|    ep_rew_mean          | -3.58    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 231      |
|    time_elapsed         | 731      |
|    total_timesteps      | 29568    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0166  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 85.1     |
|    n_updates            | 2300     |
|    policy_gradient_loss | 6.54e-09 |
|    value_loss           | 150      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.4     |
|    ep_rew_mean          | -3.62    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 232      |
|    time_elapsed         | 734      |
|    total_timesteps      | 29696    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0167  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 44.5     |
|    n_updates            | 2310     |
|    policy_gradient_loss | 3.63e-09 |
|    value_loss           | 78.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.9      |
|    ep_rew_mean          | -2.66     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 233       |
|    time_elapsed         | 736       |
|    total_timesteps      | 29824     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0168   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.3      |
|    n_updates            | 2320      |
|    policy_gradient_loss | -3.31e-09 |
|    value_loss           | 78.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.5      |
|    ep_rew_mean          | -2.85     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 234       |
|    time_elapsed         | 739       |
|    total_timesteps      | 29952     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0169   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.4      |
|    n_updates            | 2330      |
|    policy_gradient_loss | -5.45e-09 |
|    value_loss           | 77.2      |
---------------------------------------
Num timesteps: 30000
Best mean reward: -1.95 - Last mean reward per episode: -3.76
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=30000, episode_reward=-71.10 +/- 144.23
Episode length: 214.20 +/- 291.98
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 214       |
|    mean_reward          | -71.1     |
| time/                   |           |
|    total_timesteps      | 30000     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0171   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.2      |
|    n_updates            | 2340      |
|    policy_gradient_loss | -1.54e-09 |
|    value_loss           | 77.2      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 73.4     |
|    ep_rew_mean     | -2.88    |
| time/              |          |
|    fps             | 40       |
|    iterations      | 235      |
|    time_elapsed    | 748      |
|    total_timesteps | 30080    |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.7      |
|    ep_rew_mean          | -3.33     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 236       |
|    time_elapsed         | 751       |
|    total_timesteps      | 30208     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0173   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.2      |
|    n_updates            | 2350      |
|    policy_gradient_loss | -8.85e-10 |
|    value_loss           | 75.6      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 74           |
|    ep_rew_mean          | -3.48        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 237          |
|    time_elapsed         | 754          |
|    total_timesteps      | 30336        |
| train/                  |              |
|    approx_kl            | 0.0004990683 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0202      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 41.7         |
|    n_updates            | 2360         |
|    policy_gradient_loss | -0.00103     |
|    value_loss           | 78.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.2          |
|    ep_rew_mean          | -3.68         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 238           |
|    time_elapsed         | 757           |
|    total_timesteps      | 30464         |
| train/                  |               |
|    approx_kl            | 0.00060238736 |
|    clip_fraction        | 0.00469       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0256       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 27.6          |
|    n_updates            | 2370          |
|    policy_gradient_loss | -0.00603      |
|    value_loss           | 66.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.4          |
|    ep_rew_mean          | -4.1          |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 239           |
|    time_elapsed         | 760           |
|    total_timesteps      | 30592         |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0301       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 31.8          |
|    n_updates            | 2380          |
|    policy_gradient_loss | -2.82e-09     |
|    value_loss           | 86.1          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.6      |
|    ep_rew_mean          | -3.98     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 240       |
|    time_elapsed         | 763       |
|    total_timesteps      | 30720     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0313   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.9      |
|    n_updates            | 2390      |
|    policy_gradient_loss | -1.96e-09 |
|    value_loss           | 82        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.7      |
|    ep_rew_mean          | -3.92     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 241       |
|    time_elapsed         | 767       |
|    total_timesteps      | 30848     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0319   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 68.5      |
|    n_updates            | 2400      |
|    policy_gradient_loss | -1.82e-09 |
|    value_loss           | 143       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.8     |
|    ep_rew_mean          | -3.62    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 242      |
|    time_elapsed         | 770      |
|    total_timesteps      | 30976    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0325  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 64.4     |
|    n_updates            | 2410     |
|    policy_gradient_loss | 1.47e-09 |
|    value_loss           | 117      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 31000
Best mean reward: -1.95 - Last mean reward per episode: -7.80
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.1     |
|    ep_rew_mean          | -3.87    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 243      |
|    time_elapsed         | 774      |
|    total_timesteps      | 31104    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0331  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 77.6     |
|    n_updates            | 2420     |
|    policy_gradient_loss | 5.26e-09 |
|    value_loss           | 120      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.1      |
|    ep_rew_mean          | -4.14     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 244       |
|    time_elapsed         | 777       |
|    total_timesteps      | 31232     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0335   |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 41.3      |
|    n_updates            | 2430      |
|    policy_gradient_loss | -1.54e-09 |
|    value_loss           | 70        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.7      |
|    ep_rew_mean          | -4.47     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 245       |
|    time_elapsed         | 779       |
|    total_timesteps      | 31360     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0337   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 54.1      |
|    n_updates            | 2440      |
|    policy_gradient_loss | -1.77e-09 |
|    value_loss           | 92        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.6      |
|    ep_rew_mean          | -4.3      |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 246       |
|    time_elapsed         | 782       |
|    total_timesteps      | 31488     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0341   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37        |
|    n_updates            | 2450      |
|    policy_gradient_loss | -1.63e-09 |
|    value_loss           | 68.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.6      |
|    ep_rew_mean          | -4.21     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 247       |
|    time_elapsed         | 785       |
|    total_timesteps      | 31616     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0344   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 64.3      |
|    n_updates            | 2460      |
|    policy_gradient_loss | -1.72e-09 |
|    value_loss           | 125       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.8     |
|    ep_rew_mean          | -4.31    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 248      |
|    time_elapsed         | 788      |
|    total_timesteps      | 31744    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0346  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 77.4     |
|    n_updates            | 2470     |
|    policy_gradient_loss | 1.96e-09 |
|    value_loss           | 127      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.9          |
|    ep_rew_mean          | -4.83         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 249           |
|    time_elapsed         | 791           |
|    total_timesteps      | 31872         |
| train/                  |               |
|    approx_kl            | 0.00023083948 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0334       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 37.6          |
|    n_updates            | 2480          |
|    policy_gradient_loss | -0.000769     |
|    value_loss           | 83.8          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 32000
Best mean reward: -1.95 - Last mean reward per episode: -8.55
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.3          |
|    ep_rew_mean          | -4.47         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 250           |
|    time_elapsed         | 795           |
|    total_timesteps      | 32000         |
| train/                  |               |
|    approx_kl            | 1.4812686e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.03         |
|    explained_variance   | 1.79e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 43.5          |
|    n_updates            | 2490          |
|    policy_gradient_loss | 0.000178      |
|    value_loss           | 73.8          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -4.71     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 251       |
|    time_elapsed         | 798       |
|    total_timesteps      | 32128     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0297   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 66.5      |
|    n_updates            | 2500      |
|    policy_gradient_loss | 8.22e-09  |
|    value_loss           | 120       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.9      |
|    ep_rew_mean          | -4.95     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 252       |
|    time_elapsed         | 800       |
|    total_timesteps      | 32256     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0298   |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 26.2      |
|    n_updates            | 2510      |
|    policy_gradient_loss | -9.97e-09 |
|    value_loss           | 70.1      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.4     |
|    ep_rew_mean          | -4.68    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 253      |
|    time_elapsed         | 803      |
|    total_timesteps      | 32384    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0299  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 56.3     |
|    n_updates            | 2520     |
|    policy_gradient_loss | 2.78e-09 |
|    value_loss           | 85.7     |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 75.4         |
|    ep_rew_mean          | -4.91        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 254          |
|    time_elapsed         | 807          |
|    total_timesteps      | 32512        |
| train/                  |              |
|    approx_kl            | 0.0031001177 |
|    clip_fraction        | 0.0102       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0388      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 34.2         |
|    n_updates            | 2530         |
|    policy_gradient_loss | -0.00494     |
|    value_loss           | 88.7         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 75.3         |
|    ep_rew_mean          | -4.96        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 255          |
|    time_elapsed         | 812          |
|    total_timesteps      | 32640        |
| train/                  |              |
|    approx_kl            | 5.662441e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0513      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 30.9         |
|    n_updates            | 2540         |
|    policy_gradient_loss | 5.12e-10     |
|    value_loss           | 83.1         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 75.4         |
|    ep_rew_mean          | -5.19        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 256          |
|    time_elapsed         | 815          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 4.189089e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.053       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 41.5         |
|    n_updates            | 2550         |
|    policy_gradient_loss | -4.03e-05    |
|    value_loss           | 85.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.4          |
|    ep_rew_mean          | -5.19         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 257           |
|    time_elapsed         | 818           |
|    total_timesteps      | 32896         |
| train/                  |               |
|    approx_kl            | 1.2630131e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0505       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 25.2          |
|    n_updates            | 2560          |
|    policy_gradient_loss | -0.000153     |
|    value_loss           | 67.9          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 33000
Best mean reward: -1.95 - Last mean reward per episode: -9.05
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77        |
|    ep_rew_mean          | -6.08     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 258       |
|    time_elapsed         | 821       |
|    total_timesteps      | 33024     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0489   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 28.4      |
|    n_updates            | 2570      |
|    policy_gradient_loss | 7.91e-08  |
|    value_loss           | 60.7      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76            |
|    ep_rew_mean          | -5.69         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 259           |
|    time_elapsed         | 825           |
|    total_timesteps      | 33152         |
| train/                  |               |
|    approx_kl            | 0.00011867331 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0476       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 56.4          |
|    n_updates            | 2580          |
|    policy_gradient_loss | -0.000507     |
|    value_loss           | 121           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 75.9         |
|    ep_rew_mean          | -5.47        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 260          |
|    time_elapsed         | 828          |
|    total_timesteps      | 33280        |
| train/                  |              |
|    approx_kl            | 9.905035e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0432      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 41.8         |
|    n_updates            | 2590         |
|    policy_gradient_loss | -0.000191    |
|    value_loss           | 86.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 75.8         |
|    ep_rew_mean          | -5.38        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 261          |
|    time_elapsed         | 830          |
|    total_timesteps      | 33408        |
| train/                  |              |
|    approx_kl            | 0.0009023715 |
|    clip_fraction        | 0.00313      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0414      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 109          |
|    n_updates            | 2600         |
|    policy_gradient_loss | -0.000354    |
|    value_loss           | 146          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 75.7         |
|    ep_rew_mean          | -5.37        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 262          |
|    time_elapsed         | 833          |
|    total_timesteps      | 33536        |
| train/                  |              |
|    approx_kl            | 0.0014105965 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0618      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 46.8         |
|    n_updates            | 2610         |
|    policy_gradient_loss | -0.000946    |
|    value_loss           | 84.2         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.6          |
|    ep_rew_mean          | -5.08         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 263           |
|    time_elapsed         | 835           |
|    total_timesteps      | 33664         |
| train/                  |               |
|    approx_kl            | 0.00035032025 |
|    clip_fraction        | 0.00156       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0704       |
|    explained_variance   | 1.79e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 42.3          |
|    n_updates            | 2620          |
|    policy_gradient_loss | -0.000516     |
|    value_loss           | 84.7          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 74.8         |
|    ep_rew_mean          | -5.12        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 264          |
|    time_elapsed         | 838          |
|    total_timesteps      | 33792        |
| train/                  |              |
|    approx_kl            | 0.0014509046 |
|    clip_fraction        | 0.0102       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0458      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 41.3         |
|    n_updates            | 2630         |
|    policy_gradient_loss | -0.0016      |
|    value_loss           | 89.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.8          |
|    ep_rew_mean          | -5.12         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 265           |
|    time_elapsed         | 841           |
|    total_timesteps      | 33920         |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0374       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 58.9          |
|    n_updates            | 2640          |
|    policy_gradient_loss | 1.56e-09      |
|    value_loss           | 117           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 34000
Best mean reward: -1.95 - Last mean reward per episode: -8.89
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.5     |
|    ep_rew_mean          | -5.34    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 266      |
|    time_elapsed         | 843      |
|    total_timesteps      | 34048    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0366  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 35.9     |
|    n_updates            | 2650     |
|    policy_gradient_loss | 1.07e-09 |
|    value_loss           | 70.4     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.6          |
|    ep_rew_mean          | -5.59         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 267           |
|    time_elapsed         | 846           |
|    total_timesteps      | 34176         |
| train/                  |               |
|    approx_kl            | 2.4348963e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0362       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 75.7          |
|    n_updates            | 2660          |
|    policy_gradient_loss | 4.59e-05      |
|    value_loss           | 114           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 75.1         |
|    ep_rew_mean          | -5.27        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 268          |
|    time_elapsed         | 849          |
|    total_timesteps      | 34304        |
| train/                  |              |
|    approx_kl            | 0.0007271576 |
|    clip_fraction        | 0.00313      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0323      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 31           |
|    n_updates            | 2670         |
|    policy_gradient_loss | -0.00109     |
|    value_loss           | 78.3         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.1          |
|    ep_rew_mean          | -5.27         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 269           |
|    time_elapsed         | 853           |
|    total_timesteps      | 34432         |
| train/                  |               |
|    approx_kl            | 4.1163526e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0269       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 57.9          |
|    n_updates            | 2680          |
|    policy_gradient_loss | -9.22e-05     |
|    value_loss           | 106           |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 77          |
|    ep_rew_mean          | -6.1        |
| time/                   |             |
|    fps                  | 40          |
|    iterations           | 270         |
|    time_elapsed         | 857         |
|    total_timesteps      | 34560       |
| train/                  |             |
|    approx_kl            | 8.04197e-06 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0256     |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 30.7        |
|    n_updates            | 2690        |
|    policy_gradient_loss | -0.00011    |
|    value_loss           | 62.3        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76.7          |
|    ep_rew_mean          | -5.94         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 271           |
|    time_elapsed         | 860           |
|    total_timesteps      | 34688         |
| train/                  |               |
|    approx_kl            | 8.4131025e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0249       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 54.7          |
|    n_updates            | 2700          |
|    policy_gradient_loss | -9.84e-05     |
|    value_loss           | 109           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76.7          |
|    ep_rew_mean          | -5.94         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 272           |
|    time_elapsed         | 863           |
|    total_timesteps      | 34816         |
| train/                  |               |
|    approx_kl            | 3.6639627e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0234       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 44.8          |
|    n_updates            | 2710          |
|    policy_gradient_loss | -0.000223     |
|    value_loss           | 90.3          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 76.8         |
|    ep_rew_mean          | -5.88        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 273          |
|    time_elapsed         | 867          |
|    total_timesteps      | 34944        |
| train/                  |              |
|    approx_kl            | 0.0013389569 |
|    clip_fraction        | 0.00391      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0272      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 43.7         |
|    n_updates            | 2720         |
|    policy_gradient_loss | -0.00194     |
|    value_loss           | 94.1         |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 35000
Best mean reward: -1.95 - Last mean reward per episode: -9.14
Eval num_timesteps=35000, episode_reward=-4.80 +/- 4.84
Episode length: 77.60 +/- 16.13
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 77.6         |
|    mean_reward          | -4.8         |
| time/                   |              |
|    total_timesteps      | 35000        |
| train/                  |              |
|    approx_kl            | 7.068599e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0385      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 52.7         |
|    n_updates            | 2730         |
|    policy_gradient_loss | 0.000155     |
|    value_loss           | 96.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 76.8     |
|    ep_rew_mean     | -5.88    |
| time/              |          |
|    fps             | 40       |
|    iterations      | 274      |
|    time_elapsed    | 872      |
|    total_timesteps | 35072    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77           |
|    ep_rew_mean          | -5.99        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 275          |
|    time_elapsed         | 875          |
|    total_timesteps      | 35200        |
| train/                  |              |
|    approx_kl            | 6.329268e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.04        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 36.3         |
|    n_updates            | 2740         |
|    policy_gradient_loss | -9.82e-05    |
|    value_loss           | 78.2         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.3      |
|    ep_rew_mean          | -6.07     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 276       |
|    time_elapsed         | 878       |
|    total_timesteps      | 35328     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.041    |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 31.3      |
|    n_updates            | 2750      |
|    policy_gradient_loss | -1.44e-09 |
|    value_loss           | 70.2      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.3         |
|    ep_rew_mean          | -5.87        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 277          |
|    time_elapsed         | 882          |
|    total_timesteps      | 35456        |
| train/                  |              |
|    approx_kl            | 0.0014674747 |
|    clip_fraction        | 0.00391      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0443      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 55.1         |
|    n_updates            | 2760         |
|    policy_gradient_loss | -0.00164     |
|    value_loss           | 149          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.9         |
|    ep_rew_mean          | -6.17        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 278          |
|    time_elapsed         | 885          |
|    total_timesteps      | 35584        |
| train/                  |              |
|    approx_kl            | 2.682209e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0513      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 105          |
|    n_updates            | 2770         |
|    policy_gradient_loss | 3.59e-09     |
|    value_loss           | 178          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.7          |
|    ep_rew_mean          | -5.96         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 279           |
|    time_elapsed         | 888           |
|    total_timesteps      | 35712         |
| train/                  |               |
|    approx_kl            | 4.8568472e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0551       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 72            |
|    n_updates            | 2780          |
|    policy_gradient_loss | -0.000358     |
|    value_loss           | 111           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.6         |
|    ep_rew_mean          | -5.89        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 280          |
|    time_elapsed         | 890          |
|    total_timesteps      | 35840        |
| train/                  |              |
|    approx_kl            | 4.058471e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0601      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 56.3         |
|    n_updates            | 2790         |
|    policy_gradient_loss | -8.84e-05    |
|    value_loss           | 144          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.6          |
|    ep_rew_mean          | -5.8          |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 281           |
|    time_elapsed         | 893           |
|    total_timesteps      | 35968         |
| train/                  |               |
|    approx_kl            | 1.7713755e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0617       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 68.9          |
|    n_updates            | 2800          |
|    policy_gradient_loss | -0.000127     |
|    value_loss           | 132           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 36000
Best mean reward: -1.95 - Last mean reward per episode: -9.53
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 78.4          |
|    ep_rew_mean          | -6.18         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 282           |
|    time_elapsed         | 897           |
|    total_timesteps      | 36096         |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0582       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 54.9          |
|    n_updates            | 2810          |
|    policy_gradient_loss | 4.47e-09      |
|    value_loss           | 122           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 78.1         |
|    ep_rew_mean          | -5.96        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 283          |
|    time_elapsed         | 900          |
|    total_timesteps      | 36224        |
| train/                  |              |
|    approx_kl            | 0.0010736557 |
|    clip_fraction        | 0.00937      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0678      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 59.3         |
|    n_updates            | 2820         |
|    policy_gradient_loss | -0.00111     |
|    value_loss           | 98.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.9         |
|    ep_rew_mean          | -5.77        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 284          |
|    time_elapsed         | 903          |
|    total_timesteps      | 36352        |
| train/                  |              |
|    approx_kl            | 7.979106e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0751      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 97.9         |
|    n_updates            | 2830         |
|    policy_gradient_loss | 2.81e-05     |
|    value_loss           | 183          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.6         |
|    ep_rew_mean          | -5.71        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 285          |
|    time_elapsed         | 906          |
|    total_timesteps      | 36480        |
| train/                  |              |
|    approx_kl            | 4.877802e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0758      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 62.9         |
|    n_updates            | 2840         |
|    policy_gradient_loss | -2.82e-05    |
|    value_loss           | 121          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.8         |
|    ep_rew_mean          | -5.7         |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 286          |
|    time_elapsed         | 908          |
|    total_timesteps      | 36608        |
| train/                  |              |
|    approx_kl            | 9.144656e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0728      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 33.6         |
|    n_updates            | 2850         |
|    policy_gradient_loss | -0.000115    |
|    value_loss           | 85.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.5         |
|    ep_rew_mean          | -5.67        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 287          |
|    time_elapsed         | 911          |
|    total_timesteps      | 36736        |
| train/                  |              |
|    approx_kl            | 7.484108e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.07        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 86           |
|    n_updates            | 2860         |
|    policy_gradient_loss | -8.21e-05    |
|    value_loss           | 164          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.6          |
|    ep_rew_mean          | -5.99         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 288           |
|    time_elapsed         | 914           |
|    total_timesteps      | 36864         |
| train/                  |               |
|    approx_kl            | 0.00048682932 |
|    clip_fraction        | 0.00313       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0626       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 31.8          |
|    n_updates            | 2870          |
|    policy_gradient_loss | -0.00104      |
|    value_loss           | 81.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76.7          |
|    ep_rew_mean          | -5.33         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 289           |
|    time_elapsed         | 917           |
|    total_timesteps      | 36992         |
| train/                  |               |
|    approx_kl            | 0.00028804876 |
|    clip_fraction        | 0.00313       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0614       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 42.6          |
|    n_updates            | 2880          |
|    policy_gradient_loss | -0.000894     |
|    value_loss           | 83.5          |
-------------------------------------------
Num timesteps: 37000
Best mean reward: -1.95 - Last mean reward per episode: -8.78
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 76.6         |
|    ep_rew_mean          | -5.49        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 290          |
|    time_elapsed         | 921          |
|    total_timesteps      | 37120        |
| train/                  |              |
|    approx_kl            | 6.854534e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0716      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 69.3         |
|    n_updates            | 2890         |
|    policy_gradient_loss | -1.63e-10    |
|    value_loss           | 144          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76.5          |
|    ep_rew_mean          | -5.36         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 291           |
|    time_elapsed         | 924           |
|    total_timesteps      | 37248         |
| train/                  |               |
|    approx_kl            | 0.00014266884 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0704       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 50.3          |
|    n_updates            | 2900          |
|    policy_gradient_loss | -0.0002       |
|    value_loss           | 91            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 76.4         |
|    ep_rew_mean          | -5.22        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 292          |
|    time_elapsed         | 928          |
|    total_timesteps      | 37376        |
| train/                  |              |
|    approx_kl            | 0.0006513153 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0548      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 45.8         |
|    n_updates            | 2910         |
|    policy_gradient_loss | -0.000775    |
|    value_loss           | 99.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76.7          |
|    ep_rew_mean          | -5.37         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 293           |
|    time_elapsed         | 930           |
|    total_timesteps      | 37504         |
| train/                  |               |
|    approx_kl            | 0.00036488054 |
|    clip_fraction        | 0.00313       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0439       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 65            |
|    n_updates            | 2920          |
|    policy_gradient_loss | -0.000819     |
|    value_loss           | 126           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 76.5         |
|    ep_rew_mean          | -5.16        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 294          |
|    time_elapsed         | 933          |
|    total_timesteps      | 37632        |
| train/                  |              |
|    approx_kl            | 0.0012432281 |
|    clip_fraction        | 0.00391      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0467      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 38.9         |
|    n_updates            | 2930         |
|    policy_gradient_loss | -0.00148     |
|    value_loss           | 93.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76.5          |
|    ep_rew_mean          | -5.06         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 295           |
|    time_elapsed         | 936           |
|    total_timesteps      | 37760         |
| train/                  |               |
|    approx_kl            | 0.00016018702 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.066        |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 63.1          |
|    n_updates            | 2940          |
|    policy_gradient_loss | 7.29e-05      |
|    value_loss           | 123           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76.3          |
|    ep_rew_mean          | -4.96         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 296           |
|    time_elapsed         | 939           |
|    total_timesteps      | 37888         |
| train/                  |               |
|    approx_kl            | 2.3841858e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0725       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 69.1          |
|    n_updates            | 2950          |
|    policy_gradient_loss | -4.24e-09     |
|    value_loss           | 126           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 38000
Best mean reward: -1.95 - Last mean reward per episode: -5.01
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 76.1         |
|    ep_rew_mean          | -4.87        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 297          |
|    time_elapsed         | 941          |
|    total_timesteps      | 38016        |
| train/                  |              |
|    approx_kl            | 0.0007502418 |
|    clip_fraction        | 0.00234      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0697      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 43.3         |
|    n_updates            | 2960         |
|    policy_gradient_loss | -0.000909    |
|    value_loss           | 92           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76.1          |
|    ep_rew_mean          | -4.77         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 298           |
|    time_elapsed         | 944           |
|    total_timesteps      | 38144         |
| train/                  |               |
|    approx_kl            | 0.00011741789 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0554       |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 46.6          |
|    n_updates            | 2970          |
|    policy_gradient_loss | -0.000125     |
|    value_loss           | 93.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76            |
|    ep_rew_mean          | -4.61         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 299           |
|    time_elapsed         | 947           |
|    total_timesteps      | 38272         |
| train/                  |               |
|    approx_kl            | 3.2660086e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0504       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 53.8          |
|    n_updates            | 2980          |
|    policy_gradient_loss | -7.94e-05     |
|    value_loss           | 101           |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.5     |
|    ep_rew_mean          | -4.95    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 300      |
|    time_elapsed         | 950      |
|    total_timesteps      | 38400    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0485  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 73.7     |
|    n_updates            | 2990     |
|    policy_gradient_loss | -3.1e-09 |
|    value_loss           | 123      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76.2          |
|    ep_rew_mean          | -4.89         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 301           |
|    time_elapsed         | 953           |
|    total_timesteps      | 38528         |
| train/                  |               |
|    approx_kl            | 2.0874664e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0474       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 60.7          |
|    n_updates            | 3000          |
|    policy_gradient_loss | -0.00014      |
|    value_loss           | 102           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 76.1         |
|    ep_rew_mean          | -4.93        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 302          |
|    time_elapsed         | 955          |
|    total_timesteps      | 38656        |
| train/                  |              |
|    approx_kl            | 0.0011960259 |
|    clip_fraction        | 0.0109       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0375      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 53.8         |
|    n_updates            | 3010         |
|    policy_gradient_loss | -0.00206     |
|    value_loss           | 94.2         |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.2     |
|    ep_rew_mean          | -4.42    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 303      |
|    time_elapsed         | 958      |
|    total_timesteps      | 38784    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0316  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 43.7     |
|    n_updates            | 3020     |
|    policy_gradient_loss | 4.61e-09 |
|    value_loss           | 91       |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 74.6        |
|    ep_rew_mean          | -3.99       |
| time/                   |             |
|    fps                  | 40          |
|    iterations           | 304         |
|    time_elapsed         | 960         |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 5.44684e-05 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0303     |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 66.5        |
|    n_updates            | 3030        |
|    policy_gradient_loss | -0.000299   |
|    value_loss           | 116         |
-----------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 39000
Best mean reward: -1.95 - Last mean reward per episode: -3.74
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.8     |
|    ep_rew_mean          | -4.12    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 305      |
|    time_elapsed         | 963      |
|    total_timesteps      | 39040    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0283  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 57.7     |
|    n_updates            | 3040     |
|    policy_gradient_loss | 6.98e-10 |
|    value_loss           | 152      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.8     |
|    ep_rew_mean          | -4.2     |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 306      |
|    time_elapsed         | 966      |
|    total_timesteps      | 39168    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0281  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 47.5     |
|    n_updates            | 3050     |
|    policy_gradient_loss | 1.63e-09 |
|    value_loss           | 90.4     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75            |
|    ep_rew_mean          | -4.29         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 307           |
|    time_elapsed         | 969           |
|    total_timesteps      | 39296         |
| train/                  |               |
|    approx_kl            | 1.4947727e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0283       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 32.5          |
|    n_updates            | 3060          |
|    policy_gradient_loss | -1.52e-07     |
|    value_loss           | 70.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.3          |
|    ep_rew_mean          | -3.96         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 308           |
|    time_elapsed         | 972           |
|    total_timesteps      | 39424         |
| train/                  |               |
|    approx_kl            | 0.00019491091 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0254       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 51.4          |
|    n_updates            | 3070          |
|    policy_gradient_loss | -0.00056      |
|    value_loss           | 92.6          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.8     |
|    ep_rew_mean          | -4.32    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 309      |
|    time_elapsed         | 974      |
|    total_timesteps      | 39552    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0223  |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 36.7     |
|    n_updates            | 3080     |
|    policy_gradient_loss | 1.98e-09 |
|    value_loss           | 83.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.3     |
|    ep_rew_mean          | -4.05    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 310      |
|    time_elapsed         | 977      |
|    total_timesteps      | 39680    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0219  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 28.1     |
|    n_updates            | 3090     |
|    policy_gradient_loss | 1.44e-09 |
|    value_loss           | 69.7     |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 74.3        |
|    ep_rew_mean          | -3.85       |
| time/                   |             |
|    fps                  | 40          |
|    iterations           | 311         |
|    time_elapsed         | 980         |
|    total_timesteps      | 39808       |
| train/                  |             |
|    approx_kl            | 0.001578093 |
|    clip_fraction        | 0.00469     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0285     |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 56.5        |
|    n_updates            | 3100        |
|    policy_gradient_loss | -0.00128    |
|    value_loss           | 90.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 74.1         |
|    ep_rew_mean          | -3.73        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 312          |
|    time_elapsed         | 983          |
|    total_timesteps      | 39936        |
| train/                  |              |
|    approx_kl            | 2.035033e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0369      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 78.3         |
|    n_updates            | 3110         |
|    policy_gradient_loss | 0.000383     |
|    value_loss           | 169          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 40000
Best mean reward: -1.95 - Last mean reward per episode: -2.85
Eval num_timesteps=40000, episode_reward=2.80 +/- 8.59
Episode length: 66.40 +/- 7.84
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 66.4     |
|    mean_reward          | 2.8      |
| time/                   |          |
|    total_timesteps      | 40000    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0366  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 44.5     |
|    n_updates            | 3120     |
|    policy_gradient_loss | 1.54e-09 |
|    value_loss           | 91.6     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 73.9     |
|    ep_rew_mean     | -3.65    |
| time/              |          |
|    fps             | 40       |
|    iterations      | 313      |
|    time_elapsed    | 988      |
|    total_timesteps | 40064    |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.8     |
|    ep_rew_mean          | -3.52    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 314      |
|    time_elapsed         | 991      |
|    total_timesteps      | 40192    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.037   |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 41.9     |
|    n_updates            | 3130     |
|    policy_gradient_loss | 2.79e-10 |
|    value_loss           | 88.4     |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 72.8         |
|    ep_rew_mean          | -3.08        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 315          |
|    time_elapsed         | 994          |
|    total_timesteps      | 40320        |
| train/                  |              |
|    approx_kl            | 6.848015e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.037       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 56.8         |
|    n_updates            | 3140         |
|    policy_gradient_loss | -3.35e-05    |
|    value_loss           | 122          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.9      |
|    ep_rew_mean          | -3.17     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 316       |
|    time_elapsed         | 996       |
|    total_timesteps      | 40448     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0354   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.2      |
|    n_updates            | 3150      |
|    policy_gradient_loss | -8.34e-09 |
|    value_loss           | 70.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.8     |
|    ep_rew_mean          | -3.12    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 317      |
|    time_elapsed         | 999      |
|    total_timesteps      | 40576    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0351  |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 55.6     |
|    n_updates            | 3160     |
|    policy_gradient_loss | 3.35e-09 |
|    value_loss           | 89.7     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 73            |
|    ep_rew_mean          | -3.19         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 318           |
|    time_elapsed         | 1002          |
|    total_timesteps      | 40704         |
| train/                  |               |
|    approx_kl            | 2.1527521e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0347       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 63.7          |
|    n_updates            | 3170          |
|    policy_gradient_loss | -0.000261     |
|    value_loss           | 161           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 73.4          |
|    ep_rew_mean          | -3.31         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 319           |
|    time_elapsed         | 1005          |
|    total_timesteps      | 40832         |
| train/                  |               |
|    approx_kl            | 2.5299843e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0327       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 27.2          |
|    n_updates            | 3180          |
|    policy_gradient_loss | -0.000123     |
|    value_loss           | 68.6          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.7      |
|    ep_rew_mean          | -3.44     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 320       |
|    time_elapsed         | 1008      |
|    total_timesteps      | 40960     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0317   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 60        |
|    n_updates            | 3190      |
|    policy_gradient_loss | -1.4e-10  |
|    value_loss           | 125       |
---------------------------------------
Num timesteps: 41000
Best mean reward: -1.95 - Last mean reward per episode: -3.26
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.1      |
|    ep_rew_mean          | -3.65     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 321       |
|    time_elapsed         | 1011      |
|    total_timesteps      | 41088     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0318   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 32.5      |
|    n_updates            | 3200      |
|    policy_gradient_loss | 1.13e-08  |
|    value_loss           | 68.4      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.1     |
|    ep_rew_mean          | -3.75    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 322      |
|    time_elapsed         | 1014     |
|    total_timesteps      | 41216    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.032   |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 48.5     |
|    n_updates            | 3210     |
|    policy_gradient_loss | 2.56e-09 |
|    value_loss           | 87.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74       |
|    ep_rew_mean          | -3.52    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 323      |
|    time_elapsed         | 1017     |
|    total_timesteps      | 41344    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0322  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 37.4     |
|    n_updates            | 3220     |
|    policy_gradient_loss | 2.63e-09 |
|    value_loss           | 68.2     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.9     |
|    ep_rew_mean          | -3.44    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 324      |
|    time_elapsed         | 1020     |
|    total_timesteps      | 41472    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0325  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 60.3     |
|    n_updates            | 3230     |
|    policy_gradient_loss | 3.96e-09 |
|    value_loss           | 148      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74            |
|    ep_rew_mean          | -3.49         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 325           |
|    time_elapsed         | 1024          |
|    total_timesteps      | 41600         |
| train/                  |               |
|    approx_kl            | 1.2033619e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0325       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 58.4          |
|    n_updates            | 3240          |
|    policy_gradient_loss | -1.33e-05     |
|    value_loss           | 132           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.1      |
|    ep_rew_mean          | -2.73     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 326       |
|    time_elapsed         | 1026      |
|    total_timesteps      | 41728     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0306   |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 54.3      |
|    n_updates            | 3250      |
|    policy_gradient_loss | -5.91e-09 |
|    value_loss           | 90.2      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 71.7          |
|    ep_rew_mean          | -2.56         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 327           |
|    time_elapsed         | 1029          |
|    total_timesteps      | 41856         |
| train/                  |               |
|    approx_kl            | 0.00038359128 |
|    clip_fraction        | 0.00313       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0262       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 50.3          |
|    n_updates            | 3260          |
|    policy_gradient_loss | -0.000943     |
|    value_loss           | 86.7          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 71.7         |
|    ep_rew_mean          | -2.54        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 328          |
|    time_elapsed         | 1031         |
|    total_timesteps      | 41984        |
| train/                  |              |
|    approx_kl            | 0.0001479648 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.021       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 54.6         |
|    n_updates            | 3270         |
|    policy_gradient_loss | -0.000526    |
|    value_loss           | 85.5         |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 42000
Best mean reward: -1.95 - Last mean reward per episode: -1.99
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.6      |
|    ep_rew_mean          | -2.42     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 329       |
|    time_elapsed         | 1034      |
|    total_timesteps      | 42112     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0184   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.7      |
|    n_updates            | 3280      |
|    policy_gradient_loss | -3.38e-09 |
|    value_loss           | 83.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71        |
|    ep_rew_mean          | -2.08     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 330       |
|    time_elapsed         | 1037      |
|    total_timesteps      | 42240     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.018    |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 86.4      |
|    n_updates            | 3290      |
|    policy_gradient_loss | -3.89e-09 |
|    value_loss           | 148       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.4      |
|    ep_rew_mean          | -1.78     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 331       |
|    time_elapsed         | 1040      |
|    total_timesteps      | 42368     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0181   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35        |
|    n_updates            | 3300      |
|    policy_gradient_loss | -7.01e-09 |
|    value_loss           | 78.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 69.7      |
|    ep_rew_mean          | -1.67     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 332       |
|    time_elapsed         | 1043      |
|    total_timesteps      | 42496     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0182   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 50.1      |
|    n_updates            | 3310      |
|    policy_gradient_loss | 4.14e-09  |
|    value_loss           | 108       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 69.8      |
|    ep_rew_mean          | -1.7      |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 333       |
|    time_elapsed         | 1046      |
|    total_timesteps      | 42624     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0184   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39        |
|    n_updates            | 3320      |
|    policy_gradient_loss | -6.54e-09 |
|    value_loss           | 77.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 69.7      |
|    ep_rew_mean          | -1.66     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 334       |
|    time_elapsed         | 1049      |
|    total_timesteps      | 42752     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0186   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.7      |
|    n_updates            | 3330      |
|    policy_gradient_loss | -1.91e-09 |
|    value_loss           | 77.9      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 69.8         |
|    ep_rew_mean          | -1.79        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 335          |
|    time_elapsed         | 1052         |
|    total_timesteps      | 42880        |
| train/                  |              |
|    approx_kl            | 0.0009383424 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0201      |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 75.8         |
|    n_updates            | 3340         |
|    policy_gradient_loss | -0.00207     |
|    value_loss           | 114          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 43000
Best mean reward: -1.95 - Last mean reward per episode: -1.70
Saving new best model at 158283 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 70.2          |
|    ep_rew_mean          | -1.91         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 336           |
|    time_elapsed         | 1056          |
|    total_timesteps      | 43008         |
| train/                  |               |
|    approx_kl            | 6.9942325e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0218       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 34.4          |
|    n_updates            | 3350          |
|    policy_gradient_loss | 4.84e-05      |
|    value_loss           | 78.2          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 70.3     |
|    ep_rew_mean          | -1.94    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 337      |
|    time_elapsed         | 1059     |
|    total_timesteps      | 43136    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0218  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 99.8     |
|    n_updates            | 3360     |
|    policy_gradient_loss | 2.33e-09 |
|    value_loss           | 154      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71        |
|    ep_rew_mean          | -2.17     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 338       |
|    time_elapsed         | 1062      |
|    total_timesteps      | 43264     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0219   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 25.9      |
|    n_updates            | 3370      |
|    policy_gradient_loss | -7.22e-10 |
|    value_loss           | 66.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 70.8     |
|    ep_rew_mean          | -2.21    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 339      |
|    time_elapsed         | 1065     |
|    total_timesteps      | 43392    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0219  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 31.3     |
|    n_updates            | 3380     |
|    policy_gradient_loss | 2.61e-09 |
|    value_loss           | 95.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.2      |
|    ep_rew_mean          | -2.5      |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 340       |
|    time_elapsed         | 1068      |
|    total_timesteps      | 43520     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.022    |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 58.3      |
|    n_updates            | 3390      |
|    policy_gradient_loss | -9.31e-10 |
|    value_loss           | 119       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 71.9     |
|    ep_rew_mean          | -2.85    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 341      |
|    time_elapsed         | 1071     |
|    total_timesteps      | 43648    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0222  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 34.1     |
|    n_updates            | 3400     |
|    policy_gradient_loss | 7.26e-09 |
|    value_loss           | 67.6     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 71.7     |
|    ep_rew_mean          | -2.73    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 342      |
|    time_elapsed         | 1074     |
|    total_timesteps      | 43776    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0224  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 46.3     |
|    n_updates            | 3410     |
|    policy_gradient_loss | 8.85e-10 |
|    value_loss           | 81       |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.2     |
|    ep_rew_mean          | -3.1     |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 343      |
|    time_elapsed         | 1077     |
|    total_timesteps      | 43904    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0226  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 31.4     |
|    n_updates            | 3420     |
|    policy_gradient_loss | 4.28e-09 |
|    value_loss           | 68.5     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 44000
Best mean reward: -1.70 - Last mean reward per episode: -3.29
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.9     |
|    ep_rew_mean          | -3.46    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 344      |
|    time_elapsed         | 1080     |
|    total_timesteps      | 44032    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0227  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 38.9     |
|    n_updates            | 3430     |
|    policy_gradient_loss | 5.12e-09 |
|    value_loss           | 104      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 73            |
|    ep_rew_mean          | -3.48         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 345           |
|    time_elapsed         | 1083          |
|    total_timesteps      | 44160         |
| train/                  |               |
|    approx_kl            | 0.00047859084 |
|    clip_fraction        | 0.00234       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0256       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 31.4          |
|    n_updates            | 3440          |
|    policy_gradient_loss | -0.00208      |
|    value_loss           | 81.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 73.6          |
|    ep_rew_mean          | -3.81         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 346           |
|    time_elapsed         | 1086          |
|    total_timesteps      | 44288         |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.032        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 27.1          |
|    n_updates            | 3450          |
|    policy_gradient_loss | -6.24e-09     |
|    value_loss           | 70.2          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74       |
|    ep_rew_mean          | -4.19    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 347      |
|    time_elapsed         | 1088     |
|    total_timesteps      | 44416    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0335  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 31.7     |
|    n_updates            | 3460     |
|    policy_gradient_loss | 4.19e-10 |
|    value_loss           | 68.5     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74            |
|    ep_rew_mean          | -4.19         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 348           |
|    time_elapsed         | 1091          |
|    total_timesteps      | 44544         |
| train/                  |               |
|    approx_kl            | 0.00059011206 |
|    clip_fraction        | 0.00391       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0303       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 64.6          |
|    n_updates            | 3470          |
|    policy_gradient_loss | -0.00112      |
|    value_loss           | 99.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 73.9          |
|    ep_rew_mean          | -4.16         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 349           |
|    time_elapsed         | 1094          |
|    total_timesteps      | 44672         |
| train/                  |               |
|    approx_kl            | 4.0818006e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0252       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 31.9          |
|    n_updates            | 3480          |
|    policy_gradient_loss | -0.000289     |
|    value_loss           | 71.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.5          |
|    ep_rew_mean          | -4.46         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 350           |
|    time_elapsed         | 1097          |
|    total_timesteps      | 44800         |
| train/                  |               |
|    approx_kl            | 4.9499795e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.024        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 59.8          |
|    n_updates            | 3490          |
|    policy_gradient_loss | 1.9e-05       |
|    value_loss           | 107           |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.1     |
|    ep_rew_mean          | -4.64    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 351      |
|    time_elapsed         | 1101     |
|    total_timesteps      | 44928    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0242  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 77.4     |
|    n_updates            | 3500     |
|    policy_gradient_loss | 4.28e-09 |
|    value_loss           | 134      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 45000
Best mean reward: -1.70 - Last mean reward per episode: -4.59
Eval num_timesteps=45000, episode_reward=-24.90 +/- 24.95
Episode length: 117.80 +/- 54.39
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 118       |
|    mean_reward          | -24.9     |
| time/                   |           |
|    total_timesteps      | 45000     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0245   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 58.3      |
|    n_updates            | 3510      |
|    policy_gradient_loss | 2.84e-09  |
|    value_loss           | 106       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 74.9     |
|    ep_rew_mean     | -4.55    |
| time/              |          |
|    fps             | 40       |
|    iterations      | 352      |
|    time_elapsed    | 1107     |
|    total_timesteps | 45056    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.9          |
|    ep_rew_mean          | -4.55         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 353           |
|    time_elapsed         | 1110          |
|    total_timesteps      | 45184         |
| train/                  |               |
|    approx_kl            | 2.2961758e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0244       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 44.3          |
|    n_updates            | 3520          |
|    policy_gradient_loss | -4.04e-05     |
|    value_loss           | 79.5          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.3      |
|    ep_rew_mean          | -5.38     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 354       |
|    time_elapsed         | 1113      |
|    total_timesteps      | 45312     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0238   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 18.6      |
|    n_updates            | 3530      |
|    policy_gradient_loss | -4.12e-08 |
|    value_loss           | 49.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.5      |
|    ep_rew_mean          | -5.34     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 355       |
|    time_elapsed         | 1116      |
|    total_timesteps      | 45440     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0237   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 52.1      |
|    n_updates            | 3540      |
|    policy_gradient_loss | -2.28e-09 |
|    value_loss           | 112       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.7      |
|    ep_rew_mean          | -6.04     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 356       |
|    time_elapsed         | 1119      |
|    total_timesteps      | 45568     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0239   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 42.3      |
|    n_updates            | 3550      |
|    policy_gradient_loss | 2.84e-09  |
|    value_loss           | 123       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.4      |
|    ep_rew_mean          | -6.39     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 357       |
|    time_elapsed         | 1122      |
|    total_timesteps      | 45696     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.024    |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 48.1      |
|    n_updates            | 3560      |
|    policy_gradient_loss | -3.24e-09 |
|    value_loss           | 72.3      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 78.5        |
|    ep_rew_mean          | -6.35       |
| time/                   |             |
|    fps                  | 40          |
|    iterations           | 358         |
|    time_elapsed         | 1125        |
|    total_timesteps      | 45824       |
| train/                  |             |
|    approx_kl            | 0.004371163 |
|    clip_fraction        | 0.00781     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0308     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 30.6        |
|    n_updates            | 3570        |
|    policy_gradient_loss | -0.00255    |
|    value_loss           | 80.3        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 78.8          |
|    ep_rew_mean          | -6.29         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 359           |
|    time_elapsed         | 1129          |
|    total_timesteps      | 45952         |
| train/                  |               |
|    approx_kl            | 1.1622906e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.047        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 91.5          |
|    n_updates            | 3580          |
|    policy_gradient_loss | -3.63e-09     |
|    value_loss           | 144           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 46000
Best mean reward: -1.70 - Last mean reward per episode: -7.00
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 78.6          |
|    ep_rew_mean          | -6            |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 360           |
|    time_elapsed         | 1132          |
|    total_timesteps      | 46080         |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0511       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 94.9          |
|    n_updates            | 3590          |
|    policy_gradient_loss | -1.86e-09     |
|    value_loss           | 264           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 78.7          |
|    ep_rew_mean          | -6.04         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 361           |
|    time_elapsed         | 1136          |
|    total_timesteps      | 46208         |
| train/                  |               |
|    approx_kl            | 3.5664532e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0497       |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 88.9          |
|    n_updates            | 3600          |
|    policy_gradient_loss | -0.00022      |
|    value_loss           | 193           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 78.9          |
|    ep_rew_mean          | -6.16         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 362           |
|    time_elapsed         | 1140          |
|    total_timesteps      | 46336         |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0461       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 43.2          |
|    n_updates            | 3610          |
|    policy_gradient_loss | -6.98e-09     |
|    value_loss           | 112           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 79.3          |
|    ep_rew_mean          | -6.35         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 363           |
|    time_elapsed         | 1143          |
|    total_timesteps      | 46464         |
| train/                  |               |
|    approx_kl            | 1.9334257e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0451       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 84.8          |
|    n_updates            | 3620          |
|    policy_gradient_loss | -3.81e-05     |
|    value_loss           | 187           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 79.6          |
|    ep_rew_mean          | -6.5          |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 364           |
|    time_elapsed         | 1146          |
|    total_timesteps      | 46592         |
| train/                  |               |
|    approx_kl            | 1.7695129e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0445       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 62.8          |
|    n_updates            | 3630          |
|    policy_gradient_loss | 2.1e-06       |
|    value_loss           | 132           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 79.6         |
|    ep_rew_mean          | -6.5         |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 365          |
|    time_elapsed         | 1149         |
|    total_timesteps      | 46720        |
| train/                  |              |
|    approx_kl            | 0.0010106401 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0478      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 62.8         |
|    n_updates            | 3640         |
|    policy_gradient_loss | -0.00377     |
|    value_loss           | 80.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 81.1          |
|    ep_rew_mean          | -7.16         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 366           |
|    time_elapsed         | 1153          |
|    total_timesteps      | 46848         |
| train/                  |               |
|    approx_kl            | 4.8135407e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0524       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 17.7          |
|    n_updates            | 3650          |
|    policy_gradient_loss | -3.29e-05     |
|    value_loss           | 41.2          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.1      |
|    ep_rew_mean          | -7.16     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 367       |
|    time_elapsed         | 1156      |
|    total_timesteps      | 46976     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0535   |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 121       |
|    n_updates            | 3660      |
|    policy_gradient_loss | -6.45e-09 |
|    value_loss           | 228       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 47000
Best mean reward: -1.70 - Last mean reward per episode: -8.05
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 82.5         |
|    ep_rew_mean          | -7.75        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 368          |
|    time_elapsed         | 1160         |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 2.773013e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0534      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 21.8         |
|    n_updates            | 3670         |
|    policy_gradient_loss | -5.09e-05    |
|    value_loss           | 45.9         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 82.6          |
|    ep_rew_mean          | -7.89         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 369           |
|    time_elapsed         | 1163          |
|    total_timesteps      | 47232         |
| train/                  |               |
|    approx_kl            | 1.8426217e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0518       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 60.9          |
|    n_updates            | 3680          |
|    policy_gradient_loss | -0.000236     |
|    value_loss           | 179           |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.6     |
|    ep_rew_mean          | -8.29    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 370      |
|    time_elapsed         | 1167     |
|    total_timesteps      | 47360    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0503  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 37.8     |
|    n_updates            | 3690     |
|    policy_gradient_loss | -1.3e-09 |
|    value_loss           | 92.2     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 83.4          |
|    ep_rew_mean          | -8.11         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 371           |
|    time_elapsed         | 1170          |
|    total_timesteps      | 47488         |
| train/                  |               |
|    approx_kl            | 1.5692785e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0502       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 119           |
|    n_updates            | 3700          |
|    policy_gradient_loss | -6.03e-06     |
|    value_loss           | 222           |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.1     |
|    ep_rew_mean          | -7.93    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 372      |
|    time_elapsed         | 1172     |
|    total_timesteps      | 47616    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0499  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 76.8     |
|    n_updates            | 3710     |
|    policy_gradient_loss | 3.06e-09 |
|    value_loss           | 172      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 84.3          |
|    ep_rew_mean          | -8.46         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 373           |
|    time_elapsed         | 1175          |
|    total_timesteps      | 47744         |
| train/                  |               |
|    approx_kl            | 0.00015071966 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0481       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 52.7          |
|    n_updates            | 3720          |
|    policy_gradient_loss | -0.000285     |
|    value_loss           | 85.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 83.9          |
|    ep_rew_mean          | -8.27         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 374           |
|    time_elapsed         | 1178          |
|    total_timesteps      | 47872         |
| train/                  |               |
|    approx_kl            | 6.8083405e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0433       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 47.7          |
|    n_updates            | 3730          |
|    policy_gradient_loss | -7.34e-05     |
|    value_loss           | 128           |
-------------------------------------------
Num timesteps: 48000
Best mean reward: -1.70 - Last mean reward per episode: -9.51
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 83.8          |
|    ep_rew_mean          | -8.11         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 375           |
|    time_elapsed         | 1181          |
|    total_timesteps      | 48000         |
| train/                  |               |
|    approx_kl            | 7.9065096e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0389       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 50.4          |
|    n_updates            | 3740          |
|    policy_gradient_loss | -0.000294     |
|    value_loss           | 90.4          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 84           |
|    ep_rew_mean          | -8.19        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 376          |
|    time_elapsed         | 1184         |
|    total_timesteps      | 48128        |
| train/                  |              |
|    approx_kl            | 3.040256e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0353      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 107          |
|    n_updates            | 3750         |
|    policy_gradient_loss | -0.000286    |
|    value_loss           | 181          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 84.8          |
|    ep_rew_mean          | -8.81         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 377           |
|    time_elapsed         | 1187          |
|    total_timesteps      | 48256         |
| train/                  |               |
|    approx_kl            | 3.5862904e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0327       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 43.7          |
|    n_updates            | 3760          |
|    policy_gradient_loss | -0.000284     |
|    value_loss           | 135           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.8      |
|    ep_rew_mean          | -8.71     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 378       |
|    time_elapsed         | 1190      |
|    total_timesteps      | 48384     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0308   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.8      |
|    n_updates            | 3770      |
|    policy_gradient_loss | -1.16e-09 |
|    value_loss           | 85.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.9      |
|    ep_rew_mean          | -9.06     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 379       |
|    time_elapsed         | 1194      |
|    total_timesteps      | 48512     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0308   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 62.8      |
|    n_updates            | 3780      |
|    policy_gradient_loss | -3.68e-09 |
|    value_loss           | 134       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.2     |
|    ep_rew_mean          | -8.99    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 380      |
|    time_elapsed         | 1198     |
|    total_timesteps      | 48640    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0313  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 85.9     |
|    n_updates            | 3790     |
|    policy_gradient_loss | 2.42e-09 |
|    value_loss           | 186      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 86.7          |
|    ep_rew_mean          | -9.24         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 381           |
|    time_elapsed         | 1202          |
|    total_timesteps      | 48768         |
| train/                  |               |
|    approx_kl            | 6.6150445e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0328       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 85.7          |
|    n_updates            | 3800          |
|    policy_gradient_loss | -0.00112      |
|    value_loss           | 209           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 85.6          |
|    ep_rew_mean          | -8.51         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 382           |
|    time_elapsed         | 1205          |
|    total_timesteps      | 48896         |
| train/                  |               |
|    approx_kl            | 2.6889145e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0346       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 43            |
|    n_updates            | 3810          |
|    policy_gradient_loss | -2.18e-05     |
|    value_loss           | 82.5          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 49000
Best mean reward: -1.70 - Last mean reward per episode: -9.61
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.1     |
|    ep_rew_mean          | -8.75    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 383      |
|    time_elapsed         | 1208     |
|    total_timesteps      | 49024    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0317  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 115      |
|    n_updates            | 3820     |
|    policy_gradient_loss | 1.54e-09 |
|    value_loss           | 247      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.4      |
|    ep_rew_mean          | -8.88     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 384       |
|    time_elapsed         | 1211      |
|    total_timesteps      | 49152     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0312   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.4      |
|    n_updates            | 3830      |
|    policy_gradient_loss | -2.79e-09 |
|    value_loss           | 84.8      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 86.4         |
|    ep_rew_mean          | -8.88        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 385          |
|    time_elapsed         | 1214         |
|    total_timesteps      | 49280        |
| train/                  |              |
|    approx_kl            | 5.820766e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0315      |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 38.5         |
|    n_updates            | 3840         |
|    policy_gradient_loss | -4.62e-08    |
|    value_loss           | 82.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 88.1          |
|    ep_rew_mean          | -9.54         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 386           |
|    time_elapsed         | 1217          |
|    total_timesteps      | 49408         |
| train/                  |               |
|    approx_kl            | 1.2809411e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.032        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 20.7          |
|    n_updates            | 3850          |
|    policy_gradient_loss | -0.000167     |
|    value_loss           | 44            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 87.8         |
|    ep_rew_mean          | -9.53        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 387          |
|    time_elapsed         | 1221         |
|    total_timesteps      | 49536        |
| train/                  |              |
|    approx_kl            | 7.486669e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0321      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 131          |
|    n_updates            | 3860         |
|    policy_gradient_loss | -0.00018     |
|    value_loss           | 189          |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.6     |
|    ep_rew_mean          | -9.21    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 388      |
|    time_elapsed         | 1224     |
|    total_timesteps      | 49664    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0287  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 92.5     |
|    n_updates            | 3870     |
|    policy_gradient_loss | 2.65e-09 |
|    value_loss           | 178      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 88.6     |
|    ep_rew_mean          | -9.62    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 389      |
|    time_elapsed         | 1229     |
|    total_timesteps      | 49792    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0279  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 109      |
|    n_updates            | 3880     |
|    policy_gradient_loss | 4.89e-09 |
|    value_loss           | 174      |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 87.9         |
|    ep_rew_mean          | -9.25        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 390          |
|    time_elapsed         | 1233         |
|    total_timesteps      | 49920        |
| train/                  |              |
|    approx_kl            | 0.0003333278 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0267      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 115          |
|    n_updates            | 3890         |
|    policy_gradient_loss | -0.000211    |
|    value_loss           | 186          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 50000
Best mean reward: -1.70 - Last mean reward per episode: -10.42
Eval num_timesteps=50000, episode_reward=-5.80 +/- 8.16
Episode length: 71.60 +/- 16.32
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 71.6          |
|    mean_reward          | -5.8          |
| time/                   |               |
|    total_timesteps      | 50000         |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0211       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 85.9          |
|    n_updates            | 3900          |
|    policy_gradient_loss | 9.64e-09      |
|    value_loss           | 154           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 87.7     |
|    ep_rew_mean     | -9.14    |
| time/              |          |
|    fps             | 40       |
|    iterations      | 391      |
|    time_elapsed    | 1237     |
|    total_timesteps | 50048    |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.8      |
|    ep_rew_mean          | -9.18     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 392       |
|    time_elapsed         | 1240      |
|    total_timesteps      | 50176     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0198   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45.9      |
|    n_updates            | 3910      |
|    policy_gradient_loss | -7.92e-10 |
|    value_loss           | 84.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.3     |
|    ep_rew_mean          | -8.96    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 393      |
|    time_elapsed         | 1243     |
|    total_timesteps      | 50304    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0197  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 128      |
|    n_updates            | 3920     |
|    policy_gradient_loss | 5.17e-09 |
|    value_loss           | 234      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.1      |
|    ep_rew_mean          | -8.86     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 394       |
|    time_elapsed         | 1245      |
|    total_timesteps      | 50432     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0198   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 97        |
|    n_updates            | 3930      |
|    policy_gradient_loss | -4.84e-09 |
|    value_loss           | 174       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.6      |
|    ep_rew_mean          | -9.1      |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 395       |
|    time_elapsed         | 1248      |
|    total_timesteps      | 50560     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0199   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 72.9      |
|    n_updates            | 3940      |
|    policy_gradient_loss | -3.68e-09 |
|    value_loss           | 127       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.8      |
|    ep_rew_mean          | -9.18     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 396       |
|    time_elapsed         | 1251      |
|    total_timesteps      | 50688     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0202   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 60        |
|    n_updates            | 3950      |
|    policy_gradient_loss | -2.75e-09 |
|    value_loss           | 116       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.8      |
|    ep_rew_mean          | -9.21     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 397       |
|    time_elapsed         | 1254      |
|    total_timesteps      | 50816     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0202   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.7      |
|    n_updates            | 3960      |
|    policy_gradient_loss | -4.35e-09 |
|    value_loss           | 77.3      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 87.9         |
|    ep_rew_mean          | -9.16        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 398          |
|    time_elapsed         | 1257         |
|    total_timesteps      | 50944        |
| train/                  |              |
|    approx_kl            | 0.0027784659 |
|    clip_fraction        | 0.00625      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0239      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 45.1         |
|    n_updates            | 3970         |
|    policy_gradient_loss | -0.00273     |
|    value_loss           | 92.5         |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 51000
Best mean reward: -1.70 - Last mean reward per episode: -11.34
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 88.9          |
|    ep_rew_mean          | -9.74         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 399           |
|    time_elapsed         | 1260          |
|    total_timesteps      | 51072         |
| train/                  |               |
|    approx_kl            | 6.9509726e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0242       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 88.3          |
|    n_updates            | 3980          |
|    policy_gradient_loss | -0.000246     |
|    value_loss           | 133           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89        |
|    ep_rew_mean          | -9.82     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 400       |
|    time_elapsed         | 1264      |
|    total_timesteps      | 51200     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.023    |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 108       |
|    n_updates            | 3990      |
|    policy_gradient_loss | -2.33e-09 |
|    value_loss           | 167       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.1      |
|    ep_rew_mean          | -9.73     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 401       |
|    time_elapsed         | 1267      |
|    total_timesteps      | 51328     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0229   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 71.2      |
|    n_updates            | 4000      |
|    policy_gradient_loss | -6.47e-09 |
|    value_loss           | 124       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.2      |
|    ep_rew_mean          | -9.81     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 402       |
|    time_elapsed         | 1270      |
|    total_timesteps      | 51456     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0231   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 50        |
|    n_updates            | 4010      |
|    policy_gradient_loss | -4.1e-09  |
|    value_loss           | 125       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.2     |
|    ep_rew_mean          | -9.78    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 403      |
|    time_elapsed         | 1272     |
|    total_timesteps      | 51584    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0233  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 95.4     |
|    n_updates            | 4020     |
|    policy_gradient_loss | 1.93e-09 |
|    value_loss           | 188      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.6      |
|    ep_rew_mean          | -9.98     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 404       |
|    time_elapsed         | 1275      |
|    total_timesteps      | 51712     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0233   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 43.3      |
|    n_updates            | 4030      |
|    policy_gradient_loss | -3.26e-09 |
|    value_loss           | 81.4      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.8     |
|    ep_rew_mean          | -10.1    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 405      |
|    time_elapsed         | 1278     |
|    total_timesteps      | 51840    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0235  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 75.1     |
|    n_updates            | 4040     |
|    policy_gradient_loss | 4.66e-11 |
|    value_loss           | 162      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.9      |
|    ep_rew_mean          | -9.76     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 406       |
|    time_elapsed         | 1281      |
|    total_timesteps      | 51968     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0236   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.1      |
|    n_updates            | 4050      |
|    policy_gradient_loss | -4.66e-09 |
|    value_loss           | 81.7      |
---------------------------------------
Num timesteps: 52000
Best mean reward: -1.70 - Last mean reward per episode: -9.87
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 88.9     |
|    ep_rew_mean          | -9.76    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 407      |
|    time_elapsed         | 1284     |
|    total_timesteps      | 52096    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0237  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 120      |
|    n_updates            | 4060     |
|    policy_gradient_loss | 9.55e-10 |
|    value_loss           | 199      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 88.8     |
|    ep_rew_mean          | -9.78    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 408      |
|    time_elapsed         | 1287     |
|    total_timesteps      | 52224    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0237  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 23.2     |
|    n_updates            | 4070     |
|    policy_gradient_loss | 4.19e-09 |
|    value_loss           | 49.6     |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 88.6         |
|    ep_rew_mean          | -9.69        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 409          |
|    time_elapsed         | 1290         |
|    total_timesteps      | 52352        |
| train/                  |              |
|    approx_kl            | 5.580019e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0235      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 122          |
|    n_updates            | 4080         |
|    policy_gradient_loss | -8.66e-05    |
|    value_loss           | 172          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 87.9        |
|    ep_rew_mean          | -9.35       |
| time/                   |             |
|    fps                  | 40          |
|    iterations           | 410         |
|    time_elapsed         | 1293        |
|    total_timesteps      | 52480       |
| train/                  |             |
|    approx_kl            | 0.001065149 |
|    clip_fraction        | 0.00937     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0251     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 34.5        |
|    n_updates            | 4090        |
|    policy_gradient_loss | -0.00186    |
|    value_loss           | 81          |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.8     |
|    ep_rew_mean          | -9.21    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 411      |
|    time_elapsed         | 1295     |
|    total_timesteps      | 52608    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0269  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.6     |
|    n_updates            | 4100     |
|    policy_gradient_loss | 7.4e-09  |
|    value_loss           | 123      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.5      |
|    ep_rew_mean          | -8.65     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 412       |
|    time_elapsed         | 1298      |
|    total_timesteps      | 52736     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.027    |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 90.7      |
|    n_updates            | 4110      |
|    policy_gradient_loss | -7.22e-10 |
|    value_loss           | 164       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.4      |
|    ep_rew_mean          | -8.38     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 413       |
|    time_elapsed         | 1301      |
|    total_timesteps      | 52864     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0272   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.7      |
|    n_updates            | 4120      |
|    policy_gradient_loss | -8.15e-10 |
|    value_loss           | 141       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.8     |
|    ep_rew_mean          | -8       |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 414      |
|    time_elapsed         | 1304     |
|    total_timesteps      | 52992    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0275  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 111      |
|    n_updates            | 4130     |
|    policy_gradient_loss | 2.65e-09 |
|    value_loss           | 171      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 53000
Best mean reward: -1.70 - Last mean reward per episode: -8.51
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.4      |
|    ep_rew_mean          | -7.78     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 415       |
|    time_elapsed         | 1307      |
|    total_timesteps      | 53120     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.028    |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 76.2      |
|    n_updates            | 4140      |
|    policy_gradient_loss | -3.68e-09 |
|    value_loss           | 147       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.8     |
|    ep_rew_mean          | -7.53    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 416      |
|    time_elapsed         | 1310     |
|    total_timesteps      | 53248    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0285  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 45.7     |
|    n_updates            | 4150     |
|    policy_gradient_loss | 1.16e-09 |
|    value_loss           | 107      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 85.3          |
|    ep_rew_mean          | -7.78         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 417           |
|    time_elapsed         | 1314          |
|    total_timesteps      | 53376         |
| train/                  |               |
|    approx_kl            | 2.3148954e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0286       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 105           |
|    n_updates            | 4160          |
|    policy_gradient_loss | -0.000163     |
|    value_loss           | 185           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 85.3          |
|    ep_rew_mean          | -7.78         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 418           |
|    time_elapsed         | 1317          |
|    total_timesteps      | 53504         |
| train/                  |               |
|    approx_kl            | 1.0639895e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0271       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 45.7          |
|    n_updates            | 4170          |
|    policy_gradient_loss | -0.000104     |
|    value_loss           | 79.1          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.7     |
|    ep_rew_mean          | -7.83    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 419      |
|    time_elapsed         | 1321     |
|    total_timesteps      | 53632    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0261  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 24.4     |
|    n_updates            | 4180     |
|    policy_gradient_loss | 5.34e-08 |
|    value_loss           | 54.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.2     |
|    ep_rew_mean          | -7.29    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 420      |
|    time_elapsed         | 1325     |
|    total_timesteps      | 53760    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.026   |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 89.7     |
|    n_updates            | 4190     |
|    policy_gradient_loss | 1.61e-09 |
|    value_loss           | 172      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.3     |
|    ep_rew_mean          | -7.34    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 421      |
|    time_elapsed         | 1328     |
|    total_timesteps      | 53888    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0264  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 116      |
|    n_updates            | 4200     |
|    policy_gradient_loss | 2.33e-09 |
|    value_loss           | 225      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 54000
Best mean reward: -1.70 - Last mean reward per episode: -7.01
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 84.5          |
|    ep_rew_mean          | -6.96         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 422           |
|    time_elapsed         | 1331          |
|    total_timesteps      | 54016         |
| train/                  |               |
|    approx_kl            | 0.00068163266 |
|    clip_fraction        | 0.00391       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0292       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 26.3          |
|    n_updates            | 4210          |
|    policy_gradient_loss | -0.00249      |
|    value_loss           | 74            |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 83.9        |
|    ep_rew_mean          | -6.66       |
| time/                   |             |
|    fps                  | 40          |
|    iterations           | 423         |
|    time_elapsed         | 1334        |
|    total_timesteps      | 54144       |
| train/                  |             |
|    approx_kl            | 6.02426e-06 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.033      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 83.1        |
|    n_updates            | 4220        |
|    policy_gradient_loss | -2.71e-05   |
|    value_loss           | 142         |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.9     |
|    ep_rew_mean          | -6.66    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 424      |
|    time_elapsed         | 1338     |
|    total_timesteps      | 54272    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0312  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 32.6     |
|    n_updates            | 4230     |
|    policy_gradient_loss | 1.02e-08 |
|    value_loss           | 75.2     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.9      |
|    ep_rew_mean          | -6.66     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 425       |
|    time_elapsed         | 1342      |
|    total_timesteps      | 54400     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0307   |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 21.4      |
|    n_updates            | 4240      |
|    policy_gradient_loss | -3.68e-09 |
|    value_loss           | 49.7      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.9     |
|    ep_rew_mean          | -6.66    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 426      |
|    time_elapsed         | 1347     |
|    total_timesteps      | 54528    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0307  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 19.4     |
|    n_updates            | 4250     |
|    policy_gradient_loss | 4.01e-08 |
|    value_loss           | 46.6     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 83.9          |
|    ep_rew_mean          | -6.66         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 427           |
|    time_elapsed         | 1351          |
|    total_timesteps      | 54656         |
| train/                  |               |
|    approx_kl            | 4.8920978e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0301       |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 22.3          |
|    n_updates            | 4260          |
|    policy_gradient_loss | -0.00034      |
|    value_loss           | 46.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 83.9          |
|    ep_rew_mean          | -6.66         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 428           |
|    time_elapsed         | 1355          |
|    total_timesteps      | 54784         |
| train/                  |               |
|    approx_kl            | 4.4730958e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0283       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 21.8          |
|    n_updates            | 4270          |
|    policy_gradient_loss | -0.000171     |
|    value_loss           | 46.8          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.9     |
|    ep_rew_mean          | -6.66    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 429      |
|    time_elapsed         | 1359     |
|    total_timesteps      | 54912    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0273  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 21.5     |
|    n_updates            | 4280     |
|    policy_gradient_loss | 3.08e-08 |
|    value_loss           | 46.1     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 55000
Best mean reward: -1.70 - Last mean reward per episode: -7.30
Eval num_timesteps=55000, episode_reward=-5.50 +/- 5.97
Episode length: 71.00 +/- 11.93
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 71            |
|    mean_reward          | -5.5          |
| time/                   |               |
|    total_timesteps      | 55000         |
| train/                  |               |
|    approx_kl            | 5.3942204e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0278       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 20.8          |
|    n_updates            | 4290          |
|    policy_gradient_loss | -0.000915     |
|    value_loss           | 45.1          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 83.9     |
|    ep_rew_mean     | -6.66    |
| time/              |          |
|    fps             | 40       |
|    iterations      | 430      |
|    time_elapsed    | 1365     |
|    total_timesteps | 55040    |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.8     |
|    ep_rew_mean          | -6.5     |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 431      |
|    time_elapsed         | 1369     |
|    total_timesteps      | 55168    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0301  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 20.5     |
|    n_updates            | 4300     |
|    policy_gradient_loss | 2.1e-10  |
|    value_loss           | 43.7     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 84            |
|    ep_rew_mean          | -6.88         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 432           |
|    time_elapsed         | 1372          |
|    total_timesteps      | 55296         |
| train/                  |               |
|    approx_kl            | 0.00029517757 |
|    clip_fraction        | 0.00234       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0291       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 111           |
|    n_updates            | 4310          |
|    policy_gradient_loss | -0.000343     |
|    value_loss           | 197           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 83.8         |
|    ep_rew_mean          | -7.08        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 433          |
|    time_elapsed         | 1375         |
|    total_timesteps      | 55424        |
| train/                  |              |
|    approx_kl            | 3.082119e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0252      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 72.7         |
|    n_updates            | 4320         |
|    policy_gradient_loss | -0.000119    |
|    value_loss           | 137          |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.9     |
|    ep_rew_mean          | -6.75    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 434      |
|    time_elapsed         | 1378     |
|    total_timesteps      | 55552    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0232  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 86.3     |
|    n_updates            | 4330     |
|    policy_gradient_loss | 2.84e-09 |
|    value_loss           | 179      |
--------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 82.6           |
|    ep_rew_mean          | -6.49          |
| time/                   |                |
|    fps                  | 40             |
|    iterations           | 435            |
|    time_elapsed         | 1380           |
|    total_timesteps      | 55680          |
| train/                  |                |
|    approx_kl            | 0.000107347965 |
|    clip_fraction        | 0              |
|    clip_range           | 0.2            |
|    entropy_loss         | -0.0239        |
|    explained_variance   | 0              |
|    learning_rate        | 0.0003         |
|    loss                 | 56.2           |
|    n_updates            | 4340           |
|    policy_gradient_loss | -0.0012        |
|    value_loss           | 129            |
--------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 82.4          |
|    ep_rew_mean          | -6.42         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 436           |
|    time_elapsed         | 1384          |
|    total_timesteps      | 55808         |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.028        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 70            |
|    n_updates            | 4350          |
|    policy_gradient_loss | 1.09e-09      |
|    value_loss           | 170           |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.6     |
|    ep_rew_mean          | -5.2     |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 437      |
|    time_elapsed         | 1387     |
|    total_timesteps      | 55936    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0293  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 37.5     |
|    n_updates            | 4360     |
|    policy_gradient_loss | 2.28e-09 |
|    value_loss           | 83.1     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 56000
Best mean reward: -1.70 - Last mean reward per episode: -4.71
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.5     |
|    ep_rew_mean          | -4.97    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 438      |
|    time_elapsed         | 1389     |
|    total_timesteps      | 56064    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0296  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 138      |
|    n_updates            | 4370     |
|    policy_gradient_loss | 6.8e-09  |
|    value_loss           | 205      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.5      |
|    ep_rew_mean          | -4.58     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 439       |
|    time_elapsed         | 1392      |
|    total_timesteps      | 56192     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0298   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 130       |
|    n_updates            | 4380      |
|    policy_gradient_loss | 6.17e-10  |
|    value_loss           | 222       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 79            |
|    ep_rew_mean          | -4.88         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 440           |
|    time_elapsed         | 1395          |
|    total_timesteps      | 56320         |
| train/                  |               |
|    approx_kl            | 1.1073425e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0299       |
|    explained_variance   | 1.79e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 30.9          |
|    n_updates            | 4390          |
|    policy_gradient_loss | -4.1e-06      |
|    value_loss           | 84.8          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.6     |
|    ep_rew_mean          | -4.41    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 441      |
|    time_elapsed         | 1398     |
|    total_timesteps      | 56448    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0306  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 65.9     |
|    n_updates            | 4400     |
|    policy_gradient_loss | 6.98e-11 |
|    value_loss           | 116      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.6     |
|    ep_rew_mean          | -4.31    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 442      |
|    time_elapsed         | 1400     |
|    total_timesteps      | 56576    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0314  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 68.3     |
|    n_updates            | 4410     |
|    policy_gradient_loss | 6.1e-09  |
|    value_loss           | 149      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.9      |
|    ep_rew_mean          | -4.43     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 443       |
|    time_elapsed         | 1404      |
|    total_timesteps      | 56704     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.032    |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 48.4      |
|    n_updates            | 4420      |
|    policy_gradient_loss | -2.75e-09 |
|    value_loss           | 126       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.7         |
|    ep_rew_mean          | -4.34        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 444          |
|    time_elapsed         | 1407         |
|    total_timesteps      | 56832        |
| train/                  |              |
|    approx_kl            | 6.164145e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.032       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 113          |
|    n_updates            | 4430         |
|    policy_gradient_loss | -8.17e-05    |
|    value_loss           | 163          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76.9          |
|    ep_rew_mean          | -4.07         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 445           |
|    time_elapsed         | 1409          |
|    total_timesteps      | 56960         |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0267       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 67            |
|    n_updates            | 4440          |
|    policy_gradient_loss | 4.66e-09      |
|    value_loss           | 117           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 57000
Best mean reward: -1.70 - Last mean reward per episode: -3.26
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.8          |
|    ep_rew_mean          | -3.81         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 446           |
|    time_elapsed         | 1412          |
|    total_timesteps      | 57088         |
| train/                  |               |
|    approx_kl            | 5.8101956e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0246       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 68.9          |
|    n_updates            | 4450          |
|    policy_gradient_loss | -0.000307     |
|    value_loss           | 114           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -3.38     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 447       |
|    time_elapsed         | 1414      |
|    total_timesteps      | 57216     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0226   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 71.6      |
|    n_updates            | 4460      |
|    policy_gradient_loss | -6.05e-10 |
|    value_loss           | 111       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.2     |
|    ep_rew_mean          | -3.62    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 448      |
|    time_elapsed         | 1417     |
|    total_timesteps      | 57344    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0222  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 70       |
|    n_updates            | 4470     |
|    policy_gradient_loss | 3.77e-09 |
|    value_loss           | 198      |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 74.9        |
|    ep_rew_mean          | -3.33       |
| time/                   |             |
|    fps                  | 40          |
|    iterations           | 449         |
|    time_elapsed         | 1420        |
|    total_timesteps      | 57472       |
| train/                  |             |
|    approx_kl            | 0.000387643 |
|    clip_fraction        | 0.00313     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0205     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 39.3        |
|    n_updates            | 4480        |
|    policy_gradient_loss | -0.000899   |
|    value_loss           | 106         |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.7     |
|    ep_rew_mean          | -2.46    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 450      |
|    time_elapsed         | 1423     |
|    total_timesteps      | 57600    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0183  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 104      |
|    n_updates            | 4490     |
|    policy_gradient_loss | 2.7e-09  |
|    value_loss           | 182      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.7     |
|    ep_rew_mean          | -2.54    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 451      |
|    time_elapsed         | 1425     |
|    total_timesteps      | 57728    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0181  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.3     |
|    n_updates            | 4500     |
|    policy_gradient_loss | 5.17e-09 |
|    value_loss           | 95.5     |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 72.7         |
|    ep_rew_mean          | -2.56        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 452          |
|    time_elapsed         | 1428         |
|    total_timesteps      | 57856        |
| train/                  |              |
|    approx_kl            | 0.0026122332 |
|    clip_fraction        | 0.00781      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0216      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 46.2         |
|    n_updates            | 4510         |
|    policy_gradient_loss | -0.000732    |
|    value_loss           | 90.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 71.8         |
|    ep_rew_mean          | -2.08        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 453          |
|    time_elapsed         | 1432         |
|    total_timesteps      | 57984        |
| train/                  |              |
|    approx_kl            | 2.682209e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0304      |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 52           |
|    n_updates            | 4520         |
|    policy_gradient_loss | 4.19e-10     |
|    value_loss           | 155          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 58000
Best mean reward: -1.70 - Last mean reward per episode: -2.32
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 71.8         |
|    ep_rew_mean          | -2.08        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 454          |
|    time_elapsed         | 1436         |
|    total_timesteps      | 58112        |
| train/                  |              |
|    approx_kl            | 9.164214e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0325      |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 65.6         |
|    n_updates            | 4530         |
|    policy_gradient_loss | 4.34e-05     |
|    value_loss           | 162          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 71.8          |
|    ep_rew_mean          | -2.08         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 455           |
|    time_elapsed         | 1439          |
|    total_timesteps      | 58240         |
| train/                  |               |
|    approx_kl            | 3.2708049e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0321       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 25.8          |
|    n_updates            | 4540          |
|    policy_gradient_loss | -3.8e-05      |
|    value_loss           | 55.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 71.8         |
|    ep_rew_mean          | -2.08        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 456          |
|    time_elapsed         | 1443         |
|    total_timesteps      | 58368        |
| train/                  |              |
|    approx_kl            | 7.636845e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0316      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 25.3         |
|    n_updates            | 4550         |
|    policy_gradient_loss | 1.94e-06     |
|    value_loss           | 54.9         |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 71.8     |
|    ep_rew_mean          | -2.08    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 457      |
|    time_elapsed         | 1446     |
|    total_timesteps      | 58496    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0317  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 24.5     |
|    n_updates            | 4560     |
|    policy_gradient_loss | 3.86e-08 |
|    value_loss           | 53.2     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 71.8     |
|    ep_rew_mean          | -2.08    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 458      |
|    time_elapsed         | 1450     |
|    total_timesteps      | 58624    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0318  |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 22.5     |
|    n_updates            | 4570     |
|    policy_gradient_loss | 1.36e-08 |
|    value_loss           | 50.7     |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 79.9         |
|    ep_rew_mean          | -6.13        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 459          |
|    time_elapsed         | 1454         |
|    total_timesteps      | 58752        |
| train/                  |              |
|    approx_kl            | 5.489681e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0315      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 21.6         |
|    n_updates            | 4580         |
|    policy_gradient_loss | -6.4e-05     |
|    value_loss           | 48.8         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.8      |
|    ep_rew_mean          | -6.09     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 460       |
|    time_elapsed         | 1457      |
|    total_timesteps      | 58880     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0307   |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 28.7      |
|    n_updates            | 4590      |
|    policy_gradient_loss | 3.31e-09  |
|    value_loss           | 81.2      |
---------------------------------------
Num timesteps: 59000
Best mean reward: -1.70 - Last mean reward per episode: -6.80
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.2     |
|    ep_rew_mean          | -6.3     |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 461      |
|    time_elapsed         | 1460     |
|    total_timesteps      | 59008    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0308  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 43.4     |
|    n_updates            | 4600     |
|    policy_gradient_loss | 9.69e-09 |
|    value_loss           | 80.7     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80       |
|    ep_rew_mean          | -6.47    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 462      |
|    time_elapsed         | 1463     |
|    total_timesteps      | 59136    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0315  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 44       |
|    n_updates            | 4610     |
|    policy_gradient_loss | 2.51e-09 |
|    value_loss           | 105      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80        |
|    ep_rew_mean          | -6.47     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 463       |
|    time_elapsed         | 1467      |
|    total_timesteps      | 59264     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0325   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 70.1      |
|    n_updates            | 4620      |
|    policy_gradient_loss | -1.4e-10  |
|    value_loss           | 154       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.2      |
|    ep_rew_mean          | -6.62     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 464       |
|    time_elapsed         | 1469      |
|    total_timesteps      | 59392     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0329   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 50.1      |
|    n_updates            | 4630      |
|    policy_gradient_loss | 1.09e-08  |
|    value_loss           | 116       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 80            |
|    ep_rew_mean          | -6.29         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 465           |
|    time_elapsed         | 1472          |
|    total_timesteps      | 59520         |
| train/                  |               |
|    approx_kl            | 9.0823974e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0323       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 34.2          |
|    n_updates            | 4640          |
|    policy_gradient_loss | -0.000261     |
|    value_loss           | 78.9          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.2     |
|    ep_rew_mean          | -6.38    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 466      |
|    time_elapsed         | 1475     |
|    total_timesteps      | 59648    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0298  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 114      |
|    n_updates            | 4650     |
|    policy_gradient_loss | 2.37e-09 |
|    value_loss           | 203      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 80.2          |
|    ep_rew_mean          | -6.4          |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 467           |
|    time_elapsed         | 1478          |
|    total_timesteps      | 59776         |
| train/                  |               |
|    approx_kl            | 0.00097539695 |
|    clip_fraction        | 0.00625       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0257       |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 76.6          |
|    n_updates            | 4660          |
|    policy_gradient_loss | -0.000852     |
|    value_loss           | 128           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 79.5          |
|    ep_rew_mean          | -6.08         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 468           |
|    time_elapsed         | 1481          |
|    total_timesteps      | 59904         |
| train/                  |               |
|    approx_kl            | 0.00019980175 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0198       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 45.8          |
|    n_updates            | 4670          |
|    policy_gradient_loss | -0.000589     |
|    value_loss           | 78.6          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 60000
Best mean reward: -1.70 - Last mean reward per episode: -6.54
Eval num_timesteps=60000, episode_reward=-7.50 +/- 10.65
Episode length: 75.00 +/- 21.30
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 75       |
|    mean_reward          | -7.5     |
| time/                   |          |
|    total_timesteps      | 60000    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0175  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 79.5     |
|    n_updates            | 4680     |
|    policy_gradient_loss | 1.91e-09 |
|    value_loss           | 142      |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79.7     |
|    ep_rew_mean     | -6.22    |
| time/              |          |
|    fps             | 40       |
|    iterations      | 469      |
|    time_elapsed    | 1486     |
|    total_timesteps | 60032    |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80       |
|    ep_rew_mean          | -6.41    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 470      |
|    time_elapsed         | 1489     |
|    total_timesteps      | 60160    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0172  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 30.8     |
|    n_updates            | 4690     |
|    policy_gradient_loss | -1.3e-09 |
|    value_loss           | 79.7     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.2     |
|    ep_rew_mean          | -6.42    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 471      |
|    time_elapsed         | 1492     |
|    total_timesteps      | 60288    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0173  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 34.3     |
|    n_updates            | 4700     |
|    policy_gradient_loss | 3.26e-09 |
|    value_loss           | 79.2     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81        |
|    ep_rew_mean          | -6.88     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 472       |
|    time_elapsed         | 1495      |
|    total_timesteps      | 60416     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0175   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 66.5      |
|    n_updates            | 4710      |
|    policy_gradient_loss | -1.16e-09 |
|    value_loss           | 131       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.9     |
|    ep_rew_mean          | -6.96    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 473      |
|    time_elapsed         | 1498     |
|    total_timesteps      | 60544    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0179  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 59.8     |
|    n_updates            | 4720     |
|    policy_gradient_loss | 5.03e-09 |
|    value_loss           | 119      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.7      |
|    ep_rew_mean          | -6.66     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 474       |
|    time_elapsed         | 1501      |
|    total_timesteps      | 60672     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0182   |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 51.7      |
|    n_updates            | 4730      |
|    policy_gradient_loss | -8.61e-10 |
|    value_loss           | 121       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.6      |
|    ep_rew_mean          | -6.7      |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 475       |
|    time_elapsed         | 1504      |
|    total_timesteps      | 60800     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0183   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 109       |
|    n_updates            | 4740      |
|    policy_gradient_loss | -2.05e-09 |
|    value_loss           | 219       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.5      |
|    ep_rew_mean          | -6.64     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 476       |
|    time_elapsed         | 1507      |
|    total_timesteps      | 60928     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0183   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 73.9      |
|    n_updates            | 4750      |
|    policy_gradient_loss | -1.82e-09 |
|    value_loss           | 120       |
---------------------------------------
Num timesteps: 61000
Best mean reward: -1.70 - Last mean reward per episode: -6.97
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81       |
|    ep_rew_mean          | -6.78    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 477      |
|    time_elapsed         | 1511     |
|    total_timesteps      | 61056    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0186  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 61.7     |
|    n_updates            | 4760     |
|    policy_gradient_loss | 1.68e-09 |
|    value_loss           | 120      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.5      |
|    ep_rew_mean          | -6.54     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 478       |
|    time_elapsed         | 1515      |
|    total_timesteps      | 61184     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0192   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53.9      |
|    n_updates            | 4770      |
|    policy_gradient_loss | -4.38e-09 |
|    value_loss           | 147       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80.6         |
|    ep_rew_mean          | -6.5         |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 479          |
|    time_elapsed         | 1521         |
|    total_timesteps      | 61312        |
| train/                  |              |
|    approx_kl            | 0.0007694196 |
|    clip_fraction        | 0.00391      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0168      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 43.2         |
|    n_updates            | 4780         |
|    policy_gradient_loss | -0.000537    |
|    value_loss           | 78.9         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.7      |
|    ep_rew_mean          | -6.45     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 480       |
|    time_elapsed         | 1524      |
|    total_timesteps      | 61440     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0129   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 92.8      |
|    n_updates            | 4790      |
|    policy_gradient_loss | -6.01e-09 |
|    value_loss           | 209       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 80.7          |
|    ep_rew_mean          | -6.35         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 481           |
|    time_elapsed         | 1527          |
|    total_timesteps      | 61568         |
| train/                  |               |
|    approx_kl            | 1.6994309e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0124       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 86.4          |
|    n_updates            | 4800          |
|    policy_gradient_loss | -0.000205     |
|    value_loss           | 155           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 81.1          |
|    ep_rew_mean          | -6.43         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 482           |
|    time_elapsed         | 1531          |
|    total_timesteps      | 61696         |
| train/                  |               |
|    approx_kl            | 2.7136412e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0121       |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 103           |
|    n_updates            | 4810          |
|    policy_gradient_loss | -0.000255     |
|    value_loss           | 207           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.5      |
|    ep_rew_mean          | -6.64     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 483       |
|    time_elapsed         | 1534      |
|    total_timesteps      | 61824     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0115   |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 75.1      |
|    n_updates            | 4820      |
|    policy_gradient_loss | -3.54e-09 |
|    value_loss           | 117       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.6     |
|    ep_rew_mean          | -6.92    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 484      |
|    time_elapsed         | 1537     |
|    total_timesteps      | 61952    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0114  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 47.3     |
|    n_updates            | 4830     |
|    policy_gradient_loss | 8.61e-10 |
|    value_loss           | 112      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 62000
Best mean reward: -1.70 - Last mean reward per episode: -6.61
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.4      |
|    ep_rew_mean          | -6.88     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 485       |
|    time_elapsed         | 1540      |
|    total_timesteps      | 62080     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0115   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.4      |
|    n_updates            | 4840      |
|    policy_gradient_loss | -5.59e-10 |
|    value_loss           | 111       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82       |
|    ep_rew_mean          | -7.12    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 486      |
|    time_elapsed         | 1543     |
|    total_timesteps      | 62208    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0116  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 45.7     |
|    n_updates            | 4850     |
|    policy_gradient_loss | 2.98e-09 |
|    value_loss           | 77.7     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.4     |
|    ep_rew_mean          | -7.08    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 487      |
|    time_elapsed         | 1548     |
|    total_timesteps      | 62336    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0116  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.4     |
|    n_updates            | 4860     |
|    policy_gradient_loss | 4.66e-10 |
|    value_loss           | 118      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82        |
|    ep_rew_mean          | -7.09     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 488       |
|    time_elapsed         | 1551      |
|    total_timesteps      | 62464     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0117   |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 103       |
|    n_updates            | 4870      |
|    policy_gradient_loss | -3.02e-09 |
|    value_loss           | 190       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.8      |
|    ep_rew_mean          | -6.49     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 489       |
|    time_elapsed         | 1554      |
|    total_timesteps      | 62592     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0119   |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 56.8      |
|    n_updates            | 4880      |
|    policy_gradient_loss | -4.84e-09 |
|    value_loss           | 114       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 80.6          |
|    ep_rew_mean          | -6.41         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 490           |
|    time_elapsed         | 1557          |
|    total_timesteps      | 62720         |
| train/                  |               |
|    approx_kl            | 1.7601997e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.012        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 90.4          |
|    n_updates            | 4890          |
|    policy_gradient_loss | -1.27e-05     |
|    value_loss           | 197           |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.6     |
|    ep_rew_mean          | -6.61    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 491      |
|    time_elapsed         | 1560     |
|    total_timesteps      | 62848    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0122  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 67.7     |
|    n_updates            | 4900     |
|    policy_gradient_loss | 1.35e-09 |
|    value_loss           | 122      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.6      |
|    ep_rew_mean          | -6.62     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 492       |
|    time_elapsed         | 1563      |
|    total_timesteps      | 62976     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0123   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.4      |
|    n_updates            | 4910      |
|    policy_gradient_loss | -4.56e-09 |
|    value_loss           | 75.1      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 63000
Best mean reward: -1.70 - Last mean reward per episode: -6.67
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.1     |
|    ep_rew_mean          | -6.84    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 493      |
|    time_elapsed         | 1566     |
|    total_timesteps      | 63104    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0124  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 35.4     |
|    n_updates            | 4920     |
|    policy_gradient_loss | 1.56e-08 |
|    value_loss           | 84.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.1     |
|    ep_rew_mean          | -6.83    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 494      |
|    time_elapsed         | 1569     |
|    total_timesteps      | 63232    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0124  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 55.6     |
|    n_updates            | 4930     |
|    policy_gradient_loss | 7.73e-09 |
|    value_loss           | 153      |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80.4        |
|    ep_rew_mean          | -6.52       |
| time/                   |             |
|    fps                  | 40          |
|    iterations           | 495         |
|    time_elapsed         | 1573        |
|    total_timesteps      | 63360       |
| train/                  |             |
|    approx_kl            | 1.68439e-05 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0122     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 88.2        |
|    n_updates            | 4940        |
|    policy_gradient_loss | -0.000149   |
|    value_loss           | 192         |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.8     |
|    ep_rew_mean          | -6.51    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 496      |
|    time_elapsed         | 1576     |
|    total_timesteps      | 63488    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0116  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 48.4     |
|    n_updates            | 4950     |
|    policy_gradient_loss | 2.21e-09 |
|    value_loss           | 108      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81        |
|    ep_rew_mean          | -6.59     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 497       |
|    time_elapsed         | 1579      |
|    total_timesteps      | 63616     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0115   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53.5      |
|    n_updates            | 4960      |
|    policy_gradient_loss | -2.68e-09 |
|    value_loss           | 198       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.1      |
|    ep_rew_mean          | -6.54     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 498       |
|    time_elapsed         | 1583      |
|    total_timesteps      | 63744     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0115   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38        |
|    n_updates            | 4970      |
|    policy_gradient_loss | -1.54e-09 |
|    value_loss           | 73.9      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.1     |
|    ep_rew_mean          | -6.63    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 499      |
|    time_elapsed         | 1586     |
|    total_timesteps      | 63872    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0116  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 61.8     |
|    n_updates            | 4980     |
|    policy_gradient_loss | 3.73e-10 |
|    value_loss           | 144      |
--------------------------------------
Num timesteps: 64000
Best mean reward: -1.70 - Last mean reward per episode: -7.44
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.6      |
|    ep_rew_mean          | -6.82     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 500       |
|    time_elapsed         | 1589      |
|    total_timesteps      | 64000     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0118   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 56.2      |
|    n_updates            | 4990      |
|    policy_gradient_loss | -2.7e-09  |
|    value_loss           | 108       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.6      |
|    ep_rew_mean          | -6.71     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 501       |
|    time_elapsed         | 1592      |
|    total_timesteps      | 64128     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0122   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 58.9      |
|    n_updates            | 5000      |
|    policy_gradient_loss | 5.08e-09  |
|    value_loss           | 111       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.8      |
|    ep_rew_mean          | -6.72     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 502       |
|    time_elapsed         | 1595      |
|    total_timesteps      | 64256     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0125   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30.5      |
|    n_updates            | 5010      |
|    policy_gradient_loss | -2.14e-09 |
|    value_loss           | 85.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.1      |
|    ep_rew_mean          | -6.86     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 503       |
|    time_elapsed         | 1598      |
|    total_timesteps      | 64384     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0127   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 128       |
|    n_updates            | 5020      |
|    policy_gradient_loss | -2.98e-09 |
|    value_loss           | 269       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 81.8         |
|    ep_rew_mean          | -6.53        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 504          |
|    time_elapsed         | 1601         |
|    total_timesteps      | 64512        |
| train/                  |              |
|    approx_kl            | 0.0024405583 |
|    clip_fraction        | 0.00625      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00973     |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 56.5         |
|    n_updates            | 5030         |
|    policy_gradient_loss | -0.00107     |
|    value_loss           | 112          |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82       |
|    ep_rew_mean          | -6.58    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 505      |
|    time_elapsed         | 1604     |
|    total_timesteps      | 64640    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00752 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 54.2     |
|    n_updates            | 5040     |
|    policy_gradient_loss | 2.33e-10 |
|    value_loss           | 194      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.6      |
|    ep_rew_mean          | -6.81     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 506       |
|    time_elapsed         | 1607      |
|    total_timesteps      | 64768     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00732  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.9      |
|    n_updates            | 5050      |
|    policy_gradient_loss | -5.59e-10 |
|    value_loss           | 75.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.3      |
|    ep_rew_mean          | -6.86     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 507       |
|    time_elapsed         | 1610      |
|    total_timesteps      | 64896     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00731  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 69.6      |
|    n_updates            | 5060      |
|    policy_gradient_loss | -2.14e-09 |
|    value_loss           | 136       |
---------------------------------------
Num timesteps: 65000
Best mean reward: -1.70 - Last mean reward per episode: -6.94
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=65000, episode_reward=-9.50 +/- 22.58
Episode length: 95.00 +/- 36.55
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 95       |
|    mean_reward          | -9.5     |
| time/                   |          |
|    total_timesteps      | 65000    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00732 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 59.8     |
|    n_updates            | 5070     |
|    policy_gradient_loss | 3.68e-09 |
|    value_loss           | 99.8     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81.9     |
|    ep_rew_mean     | -6.64    |
| time/              |          |
|    fps             | 40       |
|    iterations      | 508      |
|    time_elapsed    | 1615     |
|    total_timesteps | 65024    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 82            |
|    ep_rew_mean          | -6.68         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 509           |
|    time_elapsed         | 1619          |
|    total_timesteps      | 65152         |
| train/                  |               |
|    approx_kl            | 6.8871304e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00732      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 36.8          |
|    n_updates            | 5080          |
|    policy_gradient_loss | -2.88e-06     |
|    value_loss           | 87.1          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82       |
|    ep_rew_mean          | -6.68    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 510      |
|    time_elapsed         | 1622     |
|    total_timesteps      | 65280    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00723 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.4     |
|    n_updates            | 5090     |
|    policy_gradient_loss | 3.26e-10 |
|    value_loss           | 101      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82       |
|    ep_rew_mean          | -6.68    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 511      |
|    time_elapsed         | 1626     |
|    total_timesteps      | 65408    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00724 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 26.4     |
|    n_updates            | 5100     |
|    policy_gradient_loss | 7e-08    |
|    value_loss           | 57.2     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82        |
|    ep_rew_mean          | -6.68     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 512       |
|    time_elapsed         | 1630      |
|    total_timesteps      | 65536     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00725  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 25.2      |
|    n_updates            | 5110      |
|    policy_gradient_loss | -8.65e-08 |
|    value_loss           | 54.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82        |
|    ep_rew_mean          | -6.68     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 513       |
|    time_elapsed         | 1634      |
|    total_timesteps      | 65664     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00725  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 25.5      |
|    n_updates            | 5120      |
|    policy_gradient_loss | 4.66e-09  |
|    value_loss           | 53.4      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.4     |
|    ep_rew_mean          | -9.32    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 514      |
|    time_elapsed         | 1638     |
|    total_timesteps      | 65792    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00726 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 25.4     |
|    n_updates            | 5130     |
|    policy_gradient_loss | 8.29e-08 |
|    value_loss           | 52.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88        |
|    ep_rew_mean          | -9.58     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 515       |
|    time_elapsed         | 1642      |
|    total_timesteps      | 65920     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00728  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45.9      |
|    n_updates            | 5140      |
|    policy_gradient_loss | -3.73e-10 |
|    value_loss           | 113       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 66000
Best mean reward: -1.70 - Last mean reward per episode: -10.71
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.4      |
|    ep_rew_mean          | -9.82     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 516       |
|    time_elapsed         | 1645      |
|    total_timesteps      | 66048     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00733  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 52.6      |
|    n_updates            | 5150      |
|    policy_gradient_loss | -8.38e-10 |
|    value_loss           | 75.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89        |
|    ep_rew_mean          | -9.89     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 517       |
|    time_elapsed         | 1649      |
|    total_timesteps      | 66176     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00736  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 47.9      |
|    n_updates            | 5160      |
|    policy_gradient_loss | 6.52e-10  |
|    value_loss           | 115       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.1      |
|    ep_rew_mean          | -10       |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 518       |
|    time_elapsed         | 1653      |
|    total_timesteps      | 66304     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0074   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 133       |
|    n_updates            | 5170      |
|    policy_gradient_loss | -4.19e-10 |
|    value_loss           | 169       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.3      |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 519       |
|    time_elapsed         | 1656      |
|    total_timesteps      | 66432     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00747  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 73.4      |
|    n_updates            | 5180      |
|    policy_gradient_loss | -4.38e-09 |
|    value_loss           | 120       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.7      |
|    ep_rew_mean          | -10.5     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 520       |
|    time_elapsed         | 1659      |
|    total_timesteps      | 66560     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00754  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.4      |
|    n_updates            | 5190      |
|    policy_gradient_loss | -2.56e-09 |
|    value_loss           | 155       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.7      |
|    ep_rew_mean          | -10.5     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 521       |
|    time_elapsed         | 1662      |
|    total_timesteps      | 66688     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00759  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 51.1      |
|    n_updates            | 5200      |
|    policy_gradient_loss | -6.52e-10 |
|    value_loss           | 109       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.3      |
|    ep_rew_mean          | -10.8     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 522       |
|    time_elapsed         | 1665      |
|    total_timesteps      | 66816     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00763  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 51.3      |
|    n_updates            | 5210      |
|    policy_gradient_loss | -7.64e-09 |
|    value_loss           | 103       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.2      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 523       |
|    time_elapsed         | 1668      |
|    total_timesteps      | 66944     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00765  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30.2      |
|    n_updates            | 5220      |
|    policy_gradient_loss | -1.54e-09 |
|    value_loss           | 79.4      |
---------------------------------------
Num timesteps: 67000
Best mean reward: -1.70 - Last mean reward per episode: -7.24
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.9      |
|    ep_rew_mean          | -6.74     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 524       |
|    time_elapsed         | 1671      |
|    total_timesteps      | 67072     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00767  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 99.4      |
|    n_updates            | 5230      |
|    policy_gradient_loss | -4.33e-09 |
|    value_loss           | 192       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.6     |
|    ep_rew_mean          | -6.41    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 525      |
|    time_elapsed         | 1675     |
|    total_timesteps      | 67200    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0077  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.1     |
|    n_updates            | 5240     |
|    policy_gradient_loss | 1.77e-09 |
|    value_loss           | 105      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 81.5          |
|    ep_rew_mean          | -6.25         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 526           |
|    time_elapsed         | 1678          |
|    total_timesteps      | 67328         |
| train/                  |               |
|    approx_kl            | 1.8365681e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00791      |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 120           |
|    n_updates            | 5250          |
|    policy_gradient_loss | -0.000153     |
|    value_loss           | 189           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 82.4          |
|    ep_rew_mean          | -6.71         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 527           |
|    time_elapsed         | 1681          |
|    total_timesteps      | 67456         |
| train/                  |               |
|    approx_kl            | 2.9684976e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00861      |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 65.6          |
|    n_updates            | 5260          |
|    policy_gradient_loss | -4e-05        |
|    value_loss           | 120           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.4      |
|    ep_rew_mean          | -6.62     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 528       |
|    time_elapsed         | 1685      |
|    total_timesteps      | 67584     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00885  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 52        |
|    n_updates            | 5270      |
|    policy_gradient_loss | -2e-09    |
|    value_loss           | 110       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.5     |
|    ep_rew_mean          | -6.65    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 529      |
|    time_elapsed         | 1688     |
|    total_timesteps      | 67712    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00898 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 87.5     |
|    n_updates            | 5280     |
|    policy_gradient_loss | 4.89e-09 |
|    value_loss           | 136      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.2     |
|    ep_rew_mean          | -6.61    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 530      |
|    time_elapsed         | 1691     |
|    total_timesteps      | 67840    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00904 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 62.9     |
|    n_updates            | 5290     |
|    policy_gradient_loss | 3.17e-09 |
|    value_loss           | 100      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.6      |
|    ep_rew_mean          | -6.71     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 531       |
|    time_elapsed         | 1694      |
|    total_timesteps      | 67968     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00909  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.9      |
|    n_updates            | 5300      |
|    policy_gradient_loss | -2.79e-10 |
|    value_loss           | 73.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 68000
Best mean reward: -1.70 - Last mean reward per episode: -6.38
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.2      |
|    ep_rew_mean          | -6.22     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 532       |
|    time_elapsed         | 1696      |
|    total_timesteps      | 68096     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00912  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 104       |
|    n_updates            | 5310      |
|    policy_gradient_loss | -7.82e-09 |
|    value_loss           | 190       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.2      |
|    ep_rew_mean          | -6.31     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 533       |
|    time_elapsed         | 1700      |
|    total_timesteps      | 68224     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00914  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 83.6      |
|    n_updates            | 5320      |
|    policy_gradient_loss | -4.42e-09 |
|    value_loss           | 221       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.2      |
|    ep_rew_mean          | -5.53     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 534       |
|    time_elapsed         | 1704      |
|    total_timesteps      | 68352     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00919  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46        |
|    n_updates            | 5330      |
|    policy_gradient_loss | -3.17e-09 |
|    value_loss           | 94.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.5     |
|    ep_rew_mean          | -5.25    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 535      |
|    time_elapsed         | 1707     |
|    total_timesteps      | 68480    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00928 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 102      |
|    n_updates            | 5340     |
|    policy_gradient_loss | 3.35e-09 |
|    value_loss           | 214      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80        |
|    ep_rew_mean          | -4.8      |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 536       |
|    time_elapsed         | 1710      |
|    total_timesteps      | 68608     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00936  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.3      |
|    n_updates            | 5350      |
|    policy_gradient_loss | -3.12e-09 |
|    value_loss           | 91.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80        |
|    ep_rew_mean          | -4.92     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 537       |
|    time_elapsed         | 1713      |
|    total_timesteps      | 68736     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00948  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 99.6      |
|    n_updates            | 5360      |
|    policy_gradient_loss | -9.31e-11 |
|    value_loss           | 168       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.7     |
|    ep_rew_mean          | -4.75    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 538      |
|    time_elapsed         | 1716     |
|    total_timesteps      | 68864    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00952 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 52.2     |
|    n_updates            | 5370     |
|    policy_gradient_loss | 8.38e-10 |
|    value_loss           | 116      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.1      |
|    ep_rew_mean          | -5.03     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 539       |
|    time_elapsed         | 1719      |
|    total_timesteps      | 68992     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0096   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 37.9      |
|    n_updates            | 5380      |
|    policy_gradient_loss | -4.96e-09 |
|    value_loss           | 69.8      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 69000
Best mean reward: -1.70 - Last mean reward per episode: -5.40
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.1      |
|    ep_rew_mean          | -4.93     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 540       |
|    time_elapsed         | 1721      |
|    total_timesteps      | 69120     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00968  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 48.9      |
|    n_updates            | 5390      |
|    policy_gradient_loss | -4.19e-10 |
|    value_loss           | 81.9      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80       |
|    ep_rew_mean          | -4.88    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 541      |
|    time_elapsed         | 1725     |
|    total_timesteps      | 69248    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00987 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 51.9     |
|    n_updates            | 5400     |
|    policy_gradient_loss | 2.79e-10 |
|    value_loss           | 110      |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 79.8        |
|    ep_rew_mean          | -4.99       |
| time/                   |             |
|    fps                  | 40          |
|    iterations           | 542         |
|    time_elapsed         | 1727        |
|    total_timesteps      | 69376       |
| train/                  |             |
|    approx_kl            | 0.002117551 |
|    clip_fraction        | 0.00547     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0131     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 65.5        |
|    n_updates            | 5410        |
|    policy_gradient_loss | -0.000545   |
|    value_loss           | 122         |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 79.8          |
|    ep_rew_mean          | -4.99         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 543           |
|    time_elapsed         | 1731          |
|    total_timesteps      | 69504         |
| train/                  |               |
|    approx_kl            | 5.0382223e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0181       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 41            |
|    n_updates            | 5420          |
|    policy_gradient_loss | 0.00026       |
|    value_loss           | 85.7          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.8     |
|    ep_rew_mean          | -4.99    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 544      |
|    time_elapsed         | 1734     |
|    total_timesteps      | 69632    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0185  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 26.6     |
|    n_updates            | 5430     |
|    policy_gradient_loss | 6.12e-08 |
|    value_loss           | 58.9     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.8     |
|    ep_rew_mean          | -4.99    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 545      |
|    time_elapsed         | 1737     |
|    total_timesteps      | 69760    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0185  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 26       |
|    n_updates            | 5440     |
|    policy_gradient_loss | 4.24e-08 |
|    value_loss           | 56.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.8      |
|    ep_rew_mean          | -4.99     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 546       |
|    time_elapsed         | 1741      |
|    total_timesteps      | 69888     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0186   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 25.3      |
|    n_updates            | 5450      |
|    policy_gradient_loss | -7.29e-08 |
|    value_loss           | 54.4      |
---------------------------------------
Num timesteps: 70000
Best mean reward: -1.70 - Last mean reward per episode: -5.55
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=70000, episode_reward=-6.70 +/- 19.29
Episode length: 81.40 +/- 29.28
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 81.4     |
|    mean_reward          | -6.7     |
| time/                   |          |
|    total_timesteps      | 70000    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0186  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 27.3     |
|    n_updates            | 5460     |
|    policy_gradient_loss | 6.15e-09 |
|    value_loss           | 55.5     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79.8     |
|    ep_rew_mean     | -4.99    |
| time/              |          |
|    fps             | 40       |
|    iterations      | 547      |
|    time_elapsed    | 1746     |
|    total_timesteps | 70016    |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.4      |
|    ep_rew_mean          | -4.88     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 548       |
|    time_elapsed         | 1749      |
|    total_timesteps      | 70144     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0187   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 26.1      |
|    n_updates            | 5470      |
|    policy_gradient_loss | -6.27e-08 |
|    value_loss           | 55        |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 79.7          |
|    ep_rew_mean          | -4.86         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 549           |
|    time_elapsed         | 1752          |
|    total_timesteps      | 70272         |
| train/                  |               |
|    approx_kl            | 0.00019186363 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0174       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 49.1          |
|    n_updates            | 5480          |
|    policy_gradient_loss | -0.000438     |
|    value_loss           | 97.3          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.1     |
|    ep_rew_mean          | -5.23    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 550      |
|    time_elapsed         | 1756     |
|    total_timesteps      | 70400    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0149  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 80.4     |
|    n_updates            | 5490     |
|    policy_gradient_loss | 1.14e-09 |
|    value_loss           | 160      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.1      |
|    ep_rew_mean          | -5.37     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 551       |
|    time_elapsed         | 1760      |
|    total_timesteps      | 70528     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0147   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 45.1      |
|    n_updates            | 5500      |
|    policy_gradient_loss | -2.33e-10 |
|    value_loss           | 77.1      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.8     |
|    ep_rew_mean          | -4.99    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 552      |
|    time_elapsed         | 1763     |
|    total_timesteps      | 70656    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0149  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 53.7     |
|    n_updates            | 5510     |
|    policy_gradient_loss | 2.65e-09 |
|    value_loss           | 107      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.4     |
|    ep_rew_mean          | -4.82    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 553      |
|    time_elapsed         | 1767     |
|    total_timesteps      | 70784    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0152  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 69.5     |
|    n_updates            | 5520     |
|    policy_gradient_loss | 4.94e-09 |
|    value_loss           | 152      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.8     |
|    ep_rew_mean          | -4.58    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 554      |
|    time_elapsed         | 1770     |
|    total_timesteps      | 70912    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0153  |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 45.3     |
|    n_updates            | 5530     |
|    policy_gradient_loss | 1.89e-09 |
|    value_loss           | 96.5     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 71000
Best mean reward: -1.70 - Last mean reward per episode: -4.72
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.3      |
|    ep_rew_mean          | -4.95     |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 555       |
|    time_elapsed         | 1773      |
|    total_timesteps      | 71040     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0154   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 35.3      |
|    n_updates            | 5540      |
|    policy_gradient_loss | -1.11e-08 |
|    value_loss           | 75.4      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.3     |
|    ep_rew_mean          | -4.83    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 556      |
|    time_elapsed         | 1777     |
|    total_timesteps      | 71168    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0156  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 89.3     |
|    n_updates            | 5550     |
|    policy_gradient_loss | 6.52e-10 |
|    value_loss           | 143      |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 78.8         |
|    ep_rew_mean          | -4.78        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 557          |
|    time_elapsed         | 1779         |
|    total_timesteps      | 71296        |
| train/                  |              |
|    approx_kl            | 0.0002797204 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0145      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 58.4         |
|    n_updates            | 5560         |
|    policy_gradient_loss | -0.000731    |
|    value_loss           | 137          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78        |
|    ep_rew_mean          | -4.5      |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 558       |
|    time_elapsed         | 1782      |
|    total_timesteps      | 71424     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0119   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 51        |
|    n_updates            | 5570      |
|    policy_gradient_loss | -2.84e-09 |
|    value_loss           | 95.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -4        |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 559       |
|    time_elapsed         | 1786      |
|    total_timesteps      | 71552     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0114   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53.3      |
|    n_updates            | 5580      |
|    policy_gradient_loss | -2.14e-09 |
|    value_loss           | 91.6      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.1         |
|    ep_rew_mean          | -3.94        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 560          |
|    time_elapsed         | 1789         |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 0.0024666176 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0138      |
|    explained_variance   | 2.38e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 64.6         |
|    n_updates            | 5590         |
|    policy_gradient_loss | -0.00259     |
|    value_loss           | 130          |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.3     |
|    ep_rew_mean          | -4.17    |
| time/                   |          |
|    fps                  | 40       |
|    iterations           | 561      |
|    time_elapsed         | 1791     |
|    total_timesteps      | 71808    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0169  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 61.9     |
|    n_updates            | 5600     |
|    policy_gradient_loss | 9.31e-11 |
|    value_loss           | 170      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.8          |
|    ep_rew_mean          | -4.18         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 562           |
|    time_elapsed         | 1794          |
|    total_timesteps      | 71936         |
| train/                  |               |
|    approx_kl            | 2.5288202e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.017        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 30.9          |
|    n_updates            | 5610          |
|    policy_gradient_loss | -9.74e-05     |
|    value_loss           | 69.7          |
-------------------------------------------
Num timesteps: 72000
Best mean reward: -1.70 - Last mean reward per episode: -4.72
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.8      |
|    ep_rew_mean          | -4.2      |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 563       |
|    time_elapsed         | 1798      |
|    total_timesteps      | 72064     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.016    |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 94.4      |
|    n_updates            | 5620      |
|    policy_gradient_loss | -3.26e-09 |
|    value_loss           | 181       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.8      |
|    ep_rew_mean          | -4.2      |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 564       |
|    time_elapsed         | 1802      |
|    total_timesteps      | 72192     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0159   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.8      |
|    n_updates            | 5630      |
|    policy_gradient_loss | -3.59e-09 |
|    value_loss           | 69.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.8      |
|    ep_rew_mean          | -4.2      |
| time/                   |           |
|    fps                  | 40        |
|    iterations           | 565       |
|    time_elapsed         | 1807      |
|    total_timesteps      | 72320     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0159   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 27.4      |
|    n_updates            | 5640      |
|    policy_gradient_loss | -6.43e-08 |
|    value_loss           | 58        |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.8          |
|    ep_rew_mean          | -4.2          |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 566           |
|    time_elapsed         | 1811          |
|    total_timesteps      | 72448         |
| train/                  |               |
|    approx_kl            | 7.6266006e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0157       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 27.2          |
|    n_updates            | 5650          |
|    policy_gradient_loss | -8.13e-05     |
|    value_loss           | 57.4          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.8     |
|    ep_rew_mean          | -4.2     |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 567      |
|    time_elapsed         | 1816     |
|    total_timesteps      | 72576    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0151  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 26.7     |
|    n_updates            | 5660     |
|    policy_gradient_loss | 1.99e-08 |
|    value_loss           | 56.9     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.8          |
|    ep_rew_mean          | -4.2          |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 568           |
|    time_elapsed         | 1820          |
|    total_timesteps      | 72704         |
| train/                  |               |
|    approx_kl            | 3.8640574e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0149       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 27.2          |
|    n_updates            | 5670          |
|    policy_gradient_loss | -3.09e-05     |
|    value_loss           | 56.2          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.8      |
|    ep_rew_mean          | -4.2      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 569       |
|    time_elapsed         | 1825      |
|    total_timesteps      | 72832     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0147   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26.3      |
|    n_updates            | 5680      |
|    policy_gradient_loss | -7.64e-09 |
|    value_loss           | 55.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.8      |
|    ep_rew_mean          | -4.2      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 570       |
|    time_elapsed         | 1829      |
|    total_timesteps      | 72960     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0146   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 27.4      |
|    n_updates            | 5690      |
|    policy_gradient_loss | -1.57e-08 |
|    value_loss           | 54.8      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 73000
Best mean reward: -1.70 - Last mean reward per episode: -5.01
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.8      |
|    ep_rew_mean          | -9.19     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 571       |
|    time_elapsed         | 1833      |
|    total_timesteps      | 73088     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0147   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26.7      |
|    n_updates            | 5700      |
|    policy_gradient_loss | -5.55e-08 |
|    value_loss           | 54.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87        |
|    ep_rew_mean          | -9.32     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 572       |
|    time_elapsed         | 1837      |
|    total_timesteps      | 73216     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0147   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.2      |
|    n_updates            | 5710      |
|    policy_gradient_loss | -8.85e-10 |
|    value_loss           | 65.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87       |
|    ep_rew_mean          | -9.29    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 573      |
|    time_elapsed         | 1841     |
|    total_timesteps      | 73344    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0149  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 53.5     |
|    n_updates            | 5720     |
|    policy_gradient_loss | 3.35e-09 |
|    value_loss           | 153      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87       |
|    ep_rew_mean          | -9.29    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 574      |
|    time_elapsed         | 1845     |
|    total_timesteps      | 73472    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.015   |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.1     |
|    n_updates            | 5730     |
|    policy_gradient_loss | -3.1e-09 |
|    value_loss           | 75.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87        |
|    ep_rew_mean          | -9.29     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 575       |
|    time_elapsed         | 1849      |
|    total_timesteps      | 73600     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.015    |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 25.2      |
|    n_updates            | 5740      |
|    policy_gradient_loss | -2.03e-09 |
|    value_loss           | 52.8      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87       |
|    ep_rew_mean          | -9.29    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 576      |
|    time_elapsed         | 1854     |
|    total_timesteps      | 73728    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0151  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 24.4     |
|    n_updates            | 5750     |
|    policy_gradient_loss | 3.55e-08 |
|    value_loss           | 51.8     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87        |
|    ep_rew_mean          | -9.29     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 577       |
|    time_elapsed         | 1858      |
|    total_timesteps      | 73856     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0151   |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 24        |
|    n_updates            | 5760      |
|    policy_gradient_loss | -2.77e-08 |
|    value_loss           | 50.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87        |
|    ep_rew_mean          | -9.29     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 578       |
|    time_elapsed         | 1862      |
|    total_timesteps      | 73984     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0151   |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 13.9      |
|    n_updates            | 5770      |
|    policy_gradient_loss | -4.64e-08 |
|    value_loss           | 42.1      |
---------------------------------------
Num timesteps: 74000
Best mean reward: -1.70 - Last mean reward per episode: -10.23
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 87            |
|    ep_rew_mean          | -9.29         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 579           |
|    time_elapsed         | 1867          |
|    total_timesteps      | 74112         |
| train/                  |               |
|    approx_kl            | 5.9423037e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.015        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 16.1          |
|    n_updates            | 5780          |
|    policy_gradient_loss | -4.89e-05     |
|    value_loss           | 37.6          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 87            |
|    ep_rew_mean          | -9.29         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 580           |
|    time_elapsed         | 1871          |
|    total_timesteps      | 74240         |
| train/                  |               |
|    approx_kl            | 2.6480295e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0142       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 19.3          |
|    n_updates            | 5790          |
|    policy_gradient_loss | -0.000175     |
|    value_loss           | 42.5          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 96.4     |
|    ep_rew_mean          | -14.3    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 581      |
|    time_elapsed         | 1875     |
|    total_timesteps      | 74368    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0135  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 19.3     |
|    n_updates            | 5800     |
|    policy_gradient_loss | 1.19e-08 |
|    value_loss           | 41.7     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 96.2     |
|    ep_rew_mean          | -14.3    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 582      |
|    time_elapsed         | 1879     |
|    total_timesteps      | 74496    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0134  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 14.6     |
|    n_updates            | 5810     |
|    policy_gradient_loss | 8.22e-09 |
|    value_loss           | 30.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 96.1     |
|    ep_rew_mean          | -14.3    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 583      |
|    time_elapsed         | 1882     |
|    total_timesteps      | 74624    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0134  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 62.9     |
|    n_updates            | 5820     |
|    policy_gradient_loss | 9.31e-11 |
|    value_loss           | 156      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 96.7          |
|    ep_rew_mean          | -14.8         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 584           |
|    time_elapsed         | 1886          |
|    total_timesteps      | 74752         |
| train/                  |               |
|    approx_kl            | 0.00018200697 |
|    clip_fraction        | 0.00156       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0144       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 123           |
|    n_updates            | 5830          |
|    policy_gradient_loss | -0.00105      |
|    value_loss           | 244           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 96.6      |
|    ep_rew_mean          | -14.5     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 585       |
|    time_elapsed         | 1889      |
|    total_timesteps      | 74880     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0165   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.2      |
|    n_updates            | 5840      |
|    policy_gradient_loss | -1.72e-09 |
|    value_loss           | 89.2      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 75000
Best mean reward: -1.70 - Last mean reward per episode: -14.68
Eval num_timesteps=75000, episode_reward=5.50 +/- 8.87
Episode length: 65.00 +/- 9.51
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 65        |
|    mean_reward          | 5.5       |
| time/                   |           |
|    total_timesteps      | 75000     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0172   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 106       |
|    n_updates            | 5850      |
|    policy_gradient_loss | 1.02e-09  |
|    value_loss           | 250       |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 96.8     |
|    ep_rew_mean     | -14.6    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 586      |
|    time_elapsed    | 1894     |
|    total_timesteps | 75008    |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 96.6     |
|    ep_rew_mean          | -14.5    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 587      |
|    time_elapsed         | 1898     |
|    total_timesteps      | 75136    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0174  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 97.2     |
|    n_updates            | 5860     |
|    policy_gradient_loss | 4.98e-09 |
|    value_loss           | 249      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 96.7     |
|    ep_rew_mean          | -14.7    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 588      |
|    time_elapsed         | 1901     |
|    total_timesteps      | 75264    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0175  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 54.1     |
|    n_updates            | 5870     |
|    policy_gradient_loss | 1.63e-09 |
|    value_loss           | 89.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 96.9      |
|    ep_rew_mean          | -14.6     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 589       |
|    time_elapsed         | 1905      |
|    total_timesteps      | 75392     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0179   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 64.7      |
|    n_updates            | 5880      |
|    policy_gradient_loss | 6.05e-09  |
|    value_loss           | 138       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 97        |
|    ep_rew_mean          | -14.6     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 590       |
|    time_elapsed         | 1909      |
|    total_timesteps      | 75520     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0181   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 118       |
|    n_updates            | 5890      |
|    policy_gradient_loss | -3.1e-09  |
|    value_loss           | 242       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 91.2      |
|    ep_rew_mean          | -11.8     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 591       |
|    time_elapsed         | 1912      |
|    total_timesteps      | 75648     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0182   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 91.1      |
|    n_updates            | 5900      |
|    policy_gradient_loss | -2.26e-09 |
|    value_loss           | 135       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 91.1     |
|    ep_rew_mean          | -11.7    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 592      |
|    time_elapsed         | 1914     |
|    total_timesteps      | 75776    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0183  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 64.8     |
|    n_updates            | 5910     |
|    policy_gradient_loss | 5.63e-09 |
|    value_loss           | 130      |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 91.2        |
|    ep_rew_mean          | -11.8       |
| time/                   |             |
|    fps                  | 39          |
|    iterations           | 593         |
|    time_elapsed         | 1918        |
|    total_timesteps      | 75904       |
| train/                  |             |
|    approx_kl            | 1.67205e-05 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0182     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 52.3        |
|    n_updates            | 5920        |
|    policy_gradient_loss | -2.92e-06   |
|    value_loss           | 84.2        |
-----------------------------------------
Num timesteps: 76000
Best mean reward: -1.70 - Last mean reward per episode: -11.39
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 90.7          |
|    ep_rew_mean          | -11.8         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 594           |
|    time_elapsed         | 1921          |
|    total_timesteps      | 76032         |
| train/                  |               |
|    approx_kl            | 0.00014435686 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0161       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 70.7          |
|    n_updates            | 5930          |
|    policy_gradient_loss | -0.000346     |
|    value_loss           | 131           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.5      |
|    ep_rew_mean          | -11.7     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 595       |
|    time_elapsed         | 1924      |
|    total_timesteps      | 76160     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0146   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 46.2      |
|    n_updates            | 5940      |
|    policy_gradient_loss | -2.79e-10 |
|    value_loss           | 84.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.5      |
|    ep_rew_mean          | -11.6     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 596       |
|    time_elapsed         | 1927      |
|    total_timesteps      | 76288     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0146   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 80        |
|    n_updates            | 5950      |
|    policy_gradient_loss | -7.73e-09 |
|    value_loss           | 136       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 90.3          |
|    ep_rew_mean          | -11.5         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 597           |
|    time_elapsed         | 1930          |
|    total_timesteps      | 76416         |
| train/                  |               |
|    approx_kl            | 4.8432034e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0143       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 106           |
|    n_updates            | 5960          |
|    policy_gradient_loss | -0.00025      |
|    value_loss           | 223           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.7      |
|    ep_rew_mean          | -11       |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 598       |
|    time_elapsed         | 1933      |
|    total_timesteps      | 76544     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0131   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 85.5      |
|    n_updates            | 5970      |
|    policy_gradient_loss | -2.56e-09 |
|    value_loss           | 172       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.7      |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 599       |
|    time_elapsed         | 1936      |
|    total_timesteps      | 76672     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0129   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 88        |
|    n_updates            | 5980      |
|    policy_gradient_loss | 9.01e-09  |
|    value_loss           | 166       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.5      |
|    ep_rew_mean          | -11.1     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 600       |
|    time_elapsed         | 1939      |
|    total_timesteps      | 76800     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0129   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 65.6      |
|    n_updates            | 5990      |
|    policy_gradient_loss | -7.59e-09 |
|    value_loss           | 163       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 90.2     |
|    ep_rew_mean          | -11.6    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 601      |
|    time_elapsed         | 1942     |
|    total_timesteps      | 76928    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.013   |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 47.4     |
|    n_updates            | 6000     |
|    policy_gradient_loss | 1.68e-09 |
|    value_loss           | 119      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 77000
Best mean reward: -1.70 - Last mean reward per episode: -11.24
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.3      |
|    ep_rew_mean          | -11.5     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 602       |
|    time_elapsed         | 1946      |
|    total_timesteps      | 77056     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0131   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.2      |
|    n_updates            | 6010      |
|    policy_gradient_loss | -6.52e-10 |
|    value_loss           | 75.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.3     |
|    ep_rew_mean          | -11.1    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 603      |
|    time_elapsed         | 1950     |
|    total_timesteps      | 77184    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0132  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 84.2     |
|    n_updates            | 6020     |
|    policy_gradient_loss | 3.45e-09 |
|    value_loss           | 200      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.9     |
|    ep_rew_mean          | -11.4    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 604      |
|    time_elapsed         | 1953     |
|    total_timesteps      | 77312    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0134  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 44.6     |
|    n_updates            | 6030     |
|    policy_gradient_loss | 1.19e-09 |
|    value_loss           | 114      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.5      |
|    ep_rew_mean          | -11.3     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 605       |
|    time_elapsed         | 1956      |
|    total_timesteps      | 77440     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0141   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.2      |
|    n_updates            | 6040      |
|    policy_gradient_loss | -2.93e-09 |
|    value_loss           | 106       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 89.3         |
|    ep_rew_mean          | -11.4        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 606          |
|    time_elapsed         | 1959         |
|    total_timesteps      | 77568        |
| train/                  |              |
|    approx_kl            | 0.0020940918 |
|    clip_fraction        | 0.00937      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0118      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 47.2         |
|    n_updates            | 6050         |
|    policy_gradient_loss | -0.00163     |
|    value_loss           | 102          |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.3     |
|    ep_rew_mean          | -11.5    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 607      |
|    time_elapsed         | 1961     |
|    total_timesteps      | 77696    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00911 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 46.1     |
|    n_updates            | 6060     |
|    policy_gradient_loss | 4.38e-09 |
|    value_loss           | 96.4     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.2     |
|    ep_rew_mean          | -11.5    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 608      |
|    time_elapsed         | 1964     |
|    total_timesteps      | 77824    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00887 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 52.8     |
|    n_updates            | 6070     |
|    policy_gradient_loss | 2.21e-09 |
|    value_loss           | 95.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.2     |
|    ep_rew_mean          | -11.5    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 609      |
|    time_elapsed         | 1967     |
|    total_timesteps      | 77952    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00891 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 60.4     |
|    n_updates            | 6080     |
|    policy_gradient_loss | -1.4e-09 |
|    value_loss           | 134      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 78000
Best mean reward: -1.70 - Last mean reward per episode: -12.16
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.3      |
|    ep_rew_mean          | -12.2     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 610       |
|    time_elapsed         | 1971      |
|    total_timesteps      | 78080     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00899  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 49.3      |
|    n_updates            | 6090      |
|    policy_gradient_loss | -4.33e-09 |
|    value_loss           | 78.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 91        |
|    ep_rew_mean          | -12.6     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 611       |
|    time_elapsed         | 1974      |
|    total_timesteps      | 78208     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00903  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.8      |
|    n_updates            | 6100      |
|    policy_gradient_loss | -9.36e-09 |
|    value_loss           | 69.6      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 91.3     |
|    ep_rew_mean          | -12.5    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 612      |
|    time_elapsed         | 1977     |
|    total_timesteps      | 78336    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00909 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 50.5     |
|    n_updates            | 6110     |
|    policy_gradient_loss | 3.47e-09 |
|    value_loss           | 107      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 91.3     |
|    ep_rew_mean          | -12.7    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 613      |
|    time_elapsed         | 1981     |
|    total_timesteps      | 78464    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00924 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 94.6     |
|    n_updates            | 6120     |
|    policy_gradient_loss | 1.86e-09 |
|    value_loss           | 170      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 92.2     |
|    ep_rew_mean          | -13.1    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 614      |
|    time_elapsed         | 1985     |
|    total_timesteps      | 78592    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00939 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 31.7     |
|    n_updates            | 6130     |
|    policy_gradient_loss | 2.75e-09 |
|    value_loss           | 78.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 92.5     |
|    ep_rew_mean          | -13.3    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 615      |
|    time_elapsed         | 1988     |
|    total_timesteps      | 78720    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00946 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 58.2     |
|    n_updates            | 6140     |
|    policy_gradient_loss | 3.31e-09 |
|    value_loss           | 145      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 92.8          |
|    ep_rew_mean          | -13.5         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 616           |
|    time_elapsed         | 1991          |
|    total_timesteps      | 78848         |
| train/                  |               |
|    approx_kl            | 0.00018873252 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00895      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 40.5          |
|    n_updates            | 6150          |
|    policy_gradient_loss | -0.000443     |
|    value_loss           | 72.3          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 92.6     |
|    ep_rew_mean          | -13.4    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 617      |
|    time_elapsed         | 1995     |
|    total_timesteps      | 78976    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00777 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 52.4     |
|    n_updates            | 6160     |
|    policy_gradient_loss | 1.54e-09 |
|    value_loss           | 98.6     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 79000
Best mean reward: -1.70 - Last mean reward per episode: -13.14
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 92.9      |
|    ep_rew_mean          | -13.5     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 618       |
|    time_elapsed         | 1998      |
|    total_timesteps      | 79104     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00758  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.4      |
|    n_updates            | 6170      |
|    policy_gradient_loss | -4.33e-09 |
|    value_loss           | 73.8      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94            |
|    ep_rew_mean          | -14.2         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 619           |
|    time_elapsed         | 2002          |
|    total_timesteps      | 79232         |
| train/                  |               |
|    approx_kl            | 5.6287274e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00734      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 39.5          |
|    n_updates            | 6180          |
|    policy_gradient_loss | -0.000188     |
|    value_loss           | 84.3          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.6      |
|    ep_rew_mean          | -13.8     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 620       |
|    time_elapsed         | 2006      |
|    total_timesteps      | 79360     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00677  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 45.2      |
|    n_updates            | 6190      |
|    policy_gradient_loss | -1.16e-09 |
|    value_loss           | 72.9      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 94.1     |
|    ep_rew_mean          | -13.9    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 621      |
|    time_elapsed         | 2010     |
|    total_timesteps      | 79488    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00666 |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 83.5     |
|    n_updates            | 6200     |
|    policy_gradient_loss | 1.68e-09 |
|    value_loss           | 170      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.8      |
|    ep_rew_mean          | -13.9     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 622       |
|    time_elapsed         | 2013      |
|    total_timesteps      | 79616     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00668  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 77.5      |
|    n_updates            | 6210      |
|    policy_gradient_loss | -3.67e-09 |
|    value_loss           | 215       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93        |
|    ep_rew_mean          | -13.3     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 623       |
|    time_elapsed         | 2016      |
|    total_timesteps      | 79744     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00669  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 86.7      |
|    n_updates            | 6220      |
|    policy_gradient_loss | -9.31e-10 |
|    value_loss           | 145       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93        |
|    ep_rew_mean          | -13.4     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 624       |
|    time_elapsed         | 2019      |
|    total_timesteps      | 79872     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00671  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 104       |
|    n_updates            | 6230      |
|    policy_gradient_loss | -5.59e-09 |
|    value_loss           | 176       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 80000
Best mean reward: -1.70 - Last mean reward per episode: -13.27
Eval num_timesteps=80000, episode_reward=-1.00 +/- 5.10
Episode length: 74.00 +/- 12.96
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 74        |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 80000     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00673  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 64.2      |
|    n_updates            | 6240      |
|    policy_gradient_loss | -2.12e-09 |
|    value_loss           | 135       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 93.6     |
|    ep_rew_mean     | -13.7    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 625      |
|    time_elapsed    | 2023     |
|    total_timesteps | 80000    |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.5      |
|    ep_rew_mean          | -13.7     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 626       |
|    time_elapsed         | 2026      |
|    total_timesteps      | 80128     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00675  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 40.9      |
|    n_updates            | 6250      |
|    policy_gradient_loss | -8.66e-09 |
|    value_loss           | 73.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.9      |
|    ep_rew_mean          | -13.8     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 627       |
|    time_elapsed         | 2029      |
|    total_timesteps      | 80256     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00677  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 39.1      |
|    n_updates            | 6260      |
|    policy_gradient_loss | 1.86e-09  |
|    value_loss           | 73.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.5      |
|    ep_rew_mean          | -14.2     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 628       |
|    time_elapsed         | 2033      |
|    total_timesteps      | 80384     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0068   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.7      |
|    n_updates            | 6270      |
|    policy_gradient_loss | -6.52e-10 |
|    value_loss           | 84.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.2      |
|    ep_rew_mean          | -14       |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 629       |
|    time_elapsed         | 2036      |
|    total_timesteps      | 80512     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00687  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 60.9      |
|    n_updates            | 6280      |
|    policy_gradient_loss | -1.26e-09 |
|    value_loss           | 110       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 94.7     |
|    ep_rew_mean          | -14.3    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 630      |
|    time_elapsed         | 2039     |
|    total_timesteps      | 80640    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00707 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 80.2     |
|    n_updates            | 6290     |
|    policy_gradient_loss | 5.59e-09 |
|    value_loss           | 152      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 95            |
|    ep_rew_mean          | -14.5         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 631           |
|    time_elapsed         | 2042          |
|    total_timesteps      | 80768         |
| train/                  |               |
|    approx_kl            | 5.1442534e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00738      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 37.1          |
|    n_updates            | 6300          |
|    policy_gradient_loss | -9.2e-05      |
|    value_loss           | 76            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 95            |
|    ep_rew_mean          | -14.3         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 632           |
|    time_elapsed         | 2046          |
|    total_timesteps      | 80896         |
| train/                  |               |
|    approx_kl            | 5.0703995e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00813      |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 31.4          |
|    n_updates            | 6310          |
|    policy_gradient_loss | -2.73e-05     |
|    value_loss           | 73.4          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 81000
Best mean reward: -1.70 - Last mean reward per episode: -8.99
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95        |
|    ep_rew_mean          | -14.3     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 633       |
|    time_elapsed         | 2049      |
|    total_timesteps      | 81024     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00843  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 108       |
|    n_updates            | 6320      |
|    policy_gradient_loss | 1.12e-09  |
|    value_loss           | 229       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 95.4          |
|    ep_rew_mean          | -14.6         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 634           |
|    time_elapsed         | 2052          |
|    total_timesteps      | 81152         |
| train/                  |               |
|    approx_kl            | 1.2028497e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00836      |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 35.1          |
|    n_updates            | 6330          |
|    policy_gradient_loss | -1.58e-05     |
|    value_loss           | 75.2          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 95.8     |
|    ep_rew_mean          | -15      |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 635      |
|    time_elapsed         | 2054     |
|    total_timesteps      | 81280    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00806 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 59.9     |
|    n_updates            | 6340     |
|    policy_gradient_loss | 1.54e-09 |
|    value_loss           | 103      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 95.8     |
|    ep_rew_mean          | -14.9    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 636      |
|    time_elapsed         | 2058     |
|    total_timesteps      | 81408    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00804 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 51.6     |
|    n_updates            | 6350     |
|    policy_gradient_loss | 1.89e-09 |
|    value_loss           | 74.5     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.9      |
|    ep_rew_mean          | -14.9     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 637       |
|    time_elapsed         | 2061      |
|    total_timesteps      | 81536     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00809  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 90.9      |
|    n_updates            | 6360      |
|    policy_gradient_loss | -1.06e-08 |
|    value_loss           | 147       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.9      |
|    ep_rew_mean          | -15.2     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 638       |
|    time_elapsed         | 2065      |
|    total_timesteps      | 81664     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00815  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.9      |
|    n_updates            | 6370      |
|    policy_gradient_loss | -7.73e-09 |
|    value_loss           | 75.8      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.8     |
|    ep_rew_mean          | -10.3    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 639      |
|    time_elapsed         | 2068     |
|    total_timesteps      | 81792    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00823 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 57.1     |
|    n_updates            | 6380     |
|    policy_gradient_loss | 1.16e-09 |
|    value_loss           | 113      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 87.7          |
|    ep_rew_mean          | -10.7         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 640           |
|    time_elapsed         | 2070          |
|    total_timesteps      | 81920         |
| train/                  |               |
|    approx_kl            | 0.00029719854 |
|    clip_fraction        | 0.00234       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00772      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 29            |
|    n_updates            | 6390          |
|    policy_gradient_loss | -0.000501     |
|    value_loss           | 74.6          |
-------------------------------------------
Num timesteps: 82000
Best mean reward: -1.70 - Last mean reward per episode: -5.05
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.3     |
|    ep_rew_mean          | -10.6    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 641      |
|    time_elapsed         | 2073     |
|    total_timesteps      | 82048    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0067  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 38.1     |
|    n_updates            | 6400     |
|    policy_gradient_loss | 4.84e-09 |
|    value_loss           | 74.6     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78        |
|    ep_rew_mean          | -5.5      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 642       |
|    time_elapsed         | 2076      |
|    total_timesteps      | 82176     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00658  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 60        |
|    n_updates            | 6410      |
|    policy_gradient_loss | -1.07e-09 |
|    value_loss           | 152       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.9     |
|    ep_rew_mean          | -5.54    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 643      |
|    time_elapsed         | 2079     |
|    total_timesteps      | 82304    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00669 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 58.9     |
|    n_updates            | 6420     |
|    policy_gradient_loss | 9.31e-11 |
|    value_loss           | 143      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78        |
|    ep_rew_mean          | -5.82     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 644       |
|    time_elapsed         | 2082      |
|    total_timesteps      | 82432     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00684  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 54.4      |
|    n_updates            | 6430      |
|    policy_gradient_loss | -1.63e-09 |
|    value_loss           | 105       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.1     |
|    ep_rew_mean          | -5.36    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 645      |
|    time_elapsed         | 2085     |
|    total_timesteps      | 82560    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00692 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 45.5     |
|    n_updates            | 6440     |
|    policy_gradient_loss | 6.88e-09 |
|    value_loss           | 107      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77        |
|    ep_rew_mean          | -5.33     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 646       |
|    time_elapsed         | 2088      |
|    total_timesteps      | 82688     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00698  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 51        |
|    n_updates            | 6450      |
|    policy_gradient_loss | -3.26e-09 |
|    value_loss           | 101       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.4     |
|    ep_rew_mean          | -5.5     |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 647      |
|    time_elapsed         | 2091     |
|    total_timesteps      | 82816    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00708 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 86.9     |
|    n_updates            | 6460     |
|    policy_gradient_loss | 3.14e-09 |
|    value_loss           | 185      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.7     |
|    ep_rew_mean          | -5.14    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 648      |
|    time_elapsed         | 2095     |
|    total_timesteps      | 82944    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00715 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 63.9     |
|    n_updates            | 6470     |
|    policy_gradient_loss | -2e-09   |
|    value_loss           | 159      |
--------------------------------------
Num timesteps: 83000
Best mean reward: -1.70 - Last mean reward per episode: -5.27
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.5     |
|    ep_rew_mean          | -5.04    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 649      |
|    time_elapsed         | 2098     |
|    total_timesteps      | 83072    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0073  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 51.9     |
|    n_updates            | 6480     |
|    policy_gradient_loss | 3.49e-09 |
|    value_loss           | 101      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.5     |
|    ep_rew_mean          | -5.17    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 650      |
|    time_elapsed         | 2101     |
|    total_timesteps      | 83200    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00751 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 50.5     |
|    n_updates            | 6490     |
|    policy_gradient_loss | 6.29e-10 |
|    value_loss           | 104      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.2     |
|    ep_rew_mean          | -5.4     |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 651      |
|    time_elapsed         | 2104     |
|    total_timesteps      | 83328    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00775 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 70.8     |
|    n_updates            | 6500     |
|    policy_gradient_loss | 1.54e-09 |
|    value_loss           | 137      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.2      |
|    ep_rew_mean          | -5.8      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 652       |
|    time_elapsed         | 2109      |
|    total_timesteps      | 83456     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00786  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 48.4      |
|    n_updates            | 6510      |
|    policy_gradient_loss | -2.1e-10  |
|    value_loss           | 107       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 78.3          |
|    ep_rew_mean          | -5.87         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 653           |
|    time_elapsed         | 2113          |
|    total_timesteps      | 83584         |
| train/                  |               |
|    approx_kl            | 0.00063112285 |
|    clip_fraction        | 0.00391       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00706      |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 32.2          |
|    n_updates            | 6520          |
|    policy_gradient_loss | -0.000555     |
|    value_loss           | 109           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.9          |
|    ep_rew_mean          | -5.67         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 654           |
|    time_elapsed         | 2116          |
|    total_timesteps      | 83712         |
| train/                  |               |
|    approx_kl            | 0.00016152812 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00571      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 39.4          |
|    n_updates            | 6530          |
|    policy_gradient_loss | -0.000226     |
|    value_loss           | 74.3          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.1     |
|    ep_rew_mean          | -5.75    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 655      |
|    time_elapsed         | 2120     |
|    total_timesteps      | 83840    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00478 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 53.8     |
|    n_updates            | 6540     |
|    policy_gradient_loss | 4.84e-09 |
|    value_loss           | 104      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78       |
|    ep_rew_mean          | -5.49    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 656      |
|    time_elapsed         | 2123     |
|    total_timesteps      | 83968    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00462 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 47.8     |
|    n_updates            | 6550     |
|    policy_gradient_loss | 1.35e-09 |
|    value_loss           | 96.2     |
--------------------------------------
Num timesteps: 84000
Best mean reward: -1.70 - Last mean reward per episode: -5.66
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.2     |
|    ep_rew_mean          | -5.58    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 657      |
|    time_elapsed         | 2126     |
|    total_timesteps      | 84096    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00464 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 77.6     |
|    n_updates            | 6560     |
|    policy_gradient_loss | -6.1e-09 |
|    value_loss           | 180      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.1      |
|    ep_rew_mean          | -5.45     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 658       |
|    time_elapsed         | 2130      |
|    total_timesteps      | 84224     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00467  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38        |
|    n_updates            | 6570      |
|    policy_gradient_loss | -3.54e-09 |
|    value_loss           | 107       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.1     |
|    ep_rew_mean          | -5.53    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 659      |
|    time_elapsed         | 2133     |
|    total_timesteps      | 84352    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00474 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.6     |
|    n_updates            | 6580     |
|    policy_gradient_loss | 6.98e-10 |
|    value_loss           | 130      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78        |
|    ep_rew_mean          | -5.68     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 660       |
|    time_elapsed         | 2136      |
|    total_timesteps      | 84480     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00483  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53.3      |
|    n_updates            | 6590      |
|    policy_gradient_loss | -1.35e-09 |
|    value_loss           | 95.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78        |
|    ep_rew_mean          | -5.67     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 661       |
|    time_elapsed         | 2139      |
|    total_timesteps      | 84608     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0049   |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 60.9      |
|    n_updates            | 6600      |
|    policy_gradient_loss | -7.92e-09 |
|    value_loss           | 128       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.2          |
|    ep_rew_mean          | -5.39         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 662           |
|    time_elapsed         | 2142          |
|    total_timesteps      | 84736         |
| train/                  |               |
|    approx_kl            | 0.00042111473 |
|    clip_fraction        | 0.00391       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00438      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 42.9          |
|    n_updates            | 6610          |
|    policy_gradient_loss | -0.000333     |
|    value_loss           | 94.4          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.3      |
|    ep_rew_mean          | -5.54     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 663       |
|    time_elapsed         | 2144      |
|    total_timesteps      | 84864     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00395  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50        |
|    n_updates            | 6620      |
|    policy_gradient_loss | -8.61e-10 |
|    value_loss           | 92.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.8     |
|    ep_rew_mean          | -5.81    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 664      |
|    time_elapsed         | 2148     |
|    total_timesteps      | 84992    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00394 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 34.4     |
|    n_updates            | 6630     |
|    policy_gradient_loss | 2.05e-09 |
|    value_loss           | 75.8     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 85000
Best mean reward: -1.70 - Last mean reward per episode: -5.54
Eval num_timesteps=85000, episode_reward=4.60 +/- 9.81
Episode length: 62.80 +/- 5.46
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 62.8      |
|    mean_reward          | 4.6       |
| time/                   |           |
|    total_timesteps      | 85000     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00397  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55.1      |
|    n_updates            | 6640      |
|    policy_gradient_loss | -1.68e-09 |
|    value_loss           | 99.8      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 77.7     |
|    ep_rew_mean     | -5.72    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 665      |
|    time_elapsed    | 2153     |
|    total_timesteps | 85120    |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.7      |
|    ep_rew_mean          | -5.53     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 666       |
|    time_elapsed         | 2156      |
|    total_timesteps      | 85248     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00402  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.1      |
|    n_updates            | 6650      |
|    policy_gradient_loss | -1.29e-08 |
|    value_loss           | 73.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.5      |
|    ep_rew_mean          | -5.36     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 667       |
|    time_elapsed         | 2159      |
|    total_timesteps      | 85376     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00404  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 89.9      |
|    n_updates            | 6660      |
|    policy_gradient_loss | -2.79e-09 |
|    value_loss           | 181       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.5     |
|    ep_rew_mean          | -5.36    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 668      |
|    time_elapsed         | 2161     |
|    total_timesteps      | 85504    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00405 |
|    explained_variance   | 2.38e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 86       |
|    n_updates            | 6670     |
|    policy_gradient_loss | 4.98e-09 |
|    value_loss           | 131      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.4     |
|    ep_rew_mean          | -5.72    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 669      |
|    time_elapsed         | 2164     |
|    total_timesteps      | 85632    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00407 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 32.8     |
|    n_updates            | 6680     |
|    policy_gradient_loss | -3.7e-09 |
|    value_loss           | 87.5     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79        |
|    ep_rew_mean          | -6        |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 670       |
|    time_elapsed         | 2167      |
|    total_timesteps      | 85760     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00409  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 55.9      |
|    n_updates            | 6690      |
|    policy_gradient_loss | 2.7e-09   |
|    value_loss           | 129       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79        |
|    ep_rew_mean          | -6.12     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 671       |
|    time_elapsed         | 2170      |
|    total_timesteps      | 85888     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0041   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.9      |
|    n_updates            | 6700      |
|    policy_gradient_loss | -7.68e-09 |
|    value_loss           | 70.7      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 86000
Best mean reward: -1.70 - Last mean reward per episode: -4.20
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -5.32     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 672       |
|    time_elapsed         | 2173      |
|    total_timesteps      | 86016     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00414  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 52.3      |
|    n_updates            | 6710      |
|    policy_gradient_loss | -3.59e-09 |
|    value_loss           | 100       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.6      |
|    ep_rew_mean          | -5.5      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 673       |
|    time_elapsed         | 2176      |
|    total_timesteps      | 86144     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00422  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 44.3      |
|    n_updates            | 6720      |
|    policy_gradient_loss | -1.07e-09 |
|    value_loss           | 97.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.5     |
|    ep_rew_mean          | -5.67    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 674      |
|    time_elapsed         | 2180     |
|    total_timesteps      | 86272    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00427 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 30.8     |
|    n_updates            | 6730     |
|    policy_gradient_loss | 1.49e-09 |
|    value_loss           | 73.4     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.8     |
|    ep_rew_mean          | -5.29    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 675      |
|    time_elapsed         | 2183     |
|    total_timesteps      | 86400    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00433 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.8     |
|    n_updates            | 6740     |
|    policy_gradient_loss | 5.26e-09 |
|    value_loss           | 100      |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.4         |
|    ep_rew_mean          | -5.59        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 676          |
|    time_elapsed         | 2186         |
|    total_timesteps      | 86528        |
| train/                  |              |
|    approx_kl            | 0.0036662752 |
|    clip_fraction        | 0.00625      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00669     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 74.8         |
|    n_updates            | 6750         |
|    policy_gradient_loss | -0.000381    |
|    value_loss           | 135          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.8         |
|    ep_rew_mean          | -5.81        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 677          |
|    time_elapsed         | 2190         |
|    total_timesteps      | 86656        |
| train/                  |              |
|    approx_kl            | 0.0001356965 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00815     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 40           |
|    n_updates            | 6760         |
|    policy_gradient_loss | -0.000222    |
|    value_loss           | 72.3         |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.2     |
|    ep_rew_mean          | -6.02    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 678      |
|    time_elapsed         | 2193     |
|    total_timesteps      | 86784    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00669 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 25.9     |
|    n_updates            | 6770     |
|    policy_gradient_loss | 3.56e-09 |
|    value_loss           | 73       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78        |
|    ep_rew_mean          | -5.79     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 679       |
|    time_elapsed         | 2196      |
|    total_timesteps      | 86912     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00637  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 33.4      |
|    n_updates            | 6780      |
|    policy_gradient_loss | -1.21e-09 |
|    value_loss           | 71        |
---------------------------------------
Num timesteps: 87000
Best mean reward: -1.70 - Last mean reward per episode: -5.47
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.9      |
|    ep_rew_mean          | -5.45     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 680       |
|    time_elapsed         | 2200      |
|    total_timesteps      | 87040     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00643  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 73.7      |
|    n_updates            | 6790      |
|    policy_gradient_loss | -2.61e-09 |
|    value_loss           | 136       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.3      |
|    ep_rew_mean          | -5.34     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 681       |
|    time_elapsed         | 2203      |
|    total_timesteps      | 87168     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00659  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55.6      |
|    n_updates            | 6800      |
|    policy_gradient_loss | -7.45e-10 |
|    value_loss           | 100       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.4     |
|    ep_rew_mean          | -5.42    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 682      |
|    time_elapsed         | 2206     |
|    total_timesteps      | 87296    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00669 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.8     |
|    n_updates            | 6810     |
|    policy_gradient_loss | 2.47e-09 |
|    value_loss           | 94.3     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.4      |
|    ep_rew_mean          | -5.91     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 683       |
|    time_elapsed         | 2209      |
|    total_timesteps      | 87424     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00677  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 32.6      |
|    n_updates            | 6820      |
|    policy_gradient_loss | -5.59e-10 |
|    value_loss           | 72.8      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.7     |
|    ep_rew_mean          | -6.26    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 684      |
|    time_elapsed         | 2213     |
|    total_timesteps      | 87552    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00682 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 33.6     |
|    n_updates            | 6830     |
|    policy_gradient_loss | 1.54e-09 |
|    value_loss           | 71.4     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.7          |
|    ep_rew_mean          | -6.26         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 685           |
|    time_elapsed         | 2216          |
|    total_timesteps      | 87680         |
| train/                  |               |
|    approx_kl            | 0.00069415336 |
|    clip_fraction        | 0.00391       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00585      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 43.5          |
|    n_updates            | 6840          |
|    policy_gradient_loss | -0.000524     |
|    value_loss           | 98.4          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -5.99     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 686       |
|    time_elapsed         | 2219      |
|    total_timesteps      | 87808     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0046   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 65.5      |
|    n_updates            | 6850      |
|    policy_gradient_loss | -3.59e-09 |
|    value_loss           | 130       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.1      |
|    ep_rew_mean          | -5.96     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 687       |
|    time_elapsed         | 2221      |
|    total_timesteps      | 87936     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00447  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 67        |
|    n_updates            | 6860      |
|    policy_gradient_loss | -4.19e-10 |
|    value_loss           | 133       |
---------------------------------------
Num timesteps: 88000
Best mean reward: -1.70 - Last mean reward per episode: -4.79
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.6     |
|    ep_rew_mean          | -5.71    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 688      |
|    time_elapsed         | 2224     |
|    total_timesteps      | 88064    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00449 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 54       |
|    n_updates            | 6870     |
|    policy_gradient_loss | -1.4e-10 |
|    value_loss           | 90.9     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.6     |
|    ep_rew_mean          | -5.71    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 689      |
|    time_elapsed         | 2227     |
|    total_timesteps      | 88192    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00455 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 46.9     |
|    n_updates            | 6880     |
|    policy_gradient_loss | 2.58e-09 |
|    value_loss           | 92.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.6      |
|    ep_rew_mean          | -5.71     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 690       |
|    time_elapsed         | 2232      |
|    total_timesteps      | 88320     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00463  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 29.5      |
|    n_updates            | 6890      |
|    policy_gradient_loss | -5.82e-09 |
|    value_loss           | 60.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.6     |
|    ep_rew_mean          | -5.71    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 691      |
|    time_elapsed         | 2236     |
|    total_timesteps      | 88448    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00465 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 28.4     |
|    n_updates            | 6900     |
|    policy_gradient_loss | 4.7e-08  |
|    value_loss           | 58.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.6      |
|    ep_rew_mean          | -5.71     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 692       |
|    time_elapsed         | 2241      |
|    total_timesteps      | 88576     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00466  |
|    explained_variance   | 2.38e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 26.5      |
|    n_updates            | 6910      |
|    policy_gradient_loss | -3.59e-08 |
|    value_loss           | 57.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.1      |
|    ep_rew_mean          | -7.75     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 693       |
|    time_elapsed         | 2249      |
|    total_timesteps      | 88704     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00466  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26.9      |
|    n_updates            | 6920      |
|    policy_gradient_loss | -7.48e-08 |
|    value_loss           | 56.7      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.4     |
|    ep_rew_mean          | -7.4     |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 694      |
|    time_elapsed         | 2252     |
|    total_timesteps      | 88832    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00467 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 101      |
|    n_updates            | 6930     |
|    policy_gradient_loss | 3.63e-09 |
|    value_loss           | 224      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.5     |
|    ep_rew_mean          | -7.36    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 695      |
|    time_elapsed         | 2255     |
|    total_timesteps      | 88960    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0047  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 52.4     |
|    n_updates            | 6940     |
|    policy_gradient_loss | 5.87e-09 |
|    value_loss           | 105      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 89000
Best mean reward: -1.70 - Last mean reward per episode: -7.01
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.2     |
|    ep_rew_mean          | -7.67    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 696      |
|    time_elapsed         | 2260     |
|    total_timesteps      | 89088    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00482 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 64.6     |
|    n_updates            | 6950     |
|    policy_gradient_loss | 1.54e-09 |
|    value_loss           | 110      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.8     |
|    ep_rew_mean          | -7.38    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 697      |
|    time_elapsed         | 2263     |
|    total_timesteps      | 89216    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00492 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 87.9     |
|    n_updates            | 6960     |
|    policy_gradient_loss | 5.59e-10 |
|    value_loss           | 179      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.8      |
|    ep_rew_mean          | -7.38     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 698       |
|    time_elapsed         | 2267      |
|    total_timesteps      | 89344     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00495  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 87.7      |
|    n_updates            | 6970      |
|    policy_gradient_loss | -6.98e-10 |
|    value_loss           | 134       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.9     |
|    ep_rew_mean          | -7.44    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 699      |
|    time_elapsed         | 2270     |
|    total_timesteps      | 89472    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00498 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 38.5     |
|    n_updates            | 6980     |
|    policy_gradient_loss | 2.1e-10  |
|    value_loss           | 72.7     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.7      |
|    ep_rew_mean          | -7.25     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 700       |
|    time_elapsed         | 2273      |
|    total_timesteps      | 89600     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.005    |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 30.5      |
|    n_updates            | 6990      |
|    policy_gradient_loss | 9.78e-10  |
|    value_loss           | 91.2      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80.1         |
|    ep_rew_mean          | -6.96        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 701          |
|    time_elapsed         | 2276         |
|    total_timesteps      | 89728        |
| train/                  |              |
|    approx_kl            | 0.0001200214 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00486     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 49.9         |
|    n_updates            | 7000         |
|    policy_gradient_loss | -0.000278    |
|    value_loss           | 175          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79        |
|    ep_rew_mean          | -6.38     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 702       |
|    time_elapsed         | 2279      |
|    total_timesteps      | 89856     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0044   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55.7      |
|    n_updates            | 7010      |
|    policy_gradient_loss | -1.35e-09 |
|    value_loss           | 89.5      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 79.4          |
|    ep_rew_mean          | -6.71         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 703           |
|    time_elapsed         | 2282          |
|    total_timesteps      | 89984         |
| train/                  |               |
|    approx_kl            | 0.00066394545 |
|    clip_fraction        | 0.00391       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0037       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 59            |
|    n_updates            | 7020          |
|    policy_gradient_loss | -0.0008       |
|    value_loss           | 87.4          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 90000
Best mean reward: -1.70 - Last mean reward per episode: -6.33
Eval num_timesteps=90000, episode_reward=2.90 +/- 16.13
Episode length: 70.20 +/- 20.63
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 70.2      |
|    mean_reward          | 2.9       |
| time/                   |           |
|    total_timesteps      | 90000     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00293  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 27.3      |
|    n_updates            | 7030      |
|    policy_gradient_loss | -7.75e-09 |
|    value_loss           | 69.7      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79.4     |
|    ep_rew_mean     | -6.68    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 704      |
|    time_elapsed    | 2287     |
|    total_timesteps | 90112    |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.2      |
|    ep_rew_mean          | -6.59     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 705       |
|    time_elapsed         | 2291      |
|    total_timesteps      | 90240     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00285  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 64.4      |
|    n_updates            | 7040      |
|    policy_gradient_loss | 2.91e-09  |
|    value_loss           | 126       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79        |
|    ep_rew_mean          | -6.42     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 706       |
|    time_elapsed         | 2294      |
|    total_timesteps      | 90368     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00289  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.1      |
|    n_updates            | 7050      |
|    policy_gradient_loss | -5.08e-09 |
|    value_loss           | 87.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -6.33     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 707       |
|    time_elapsed         | 2297      |
|    total_timesteps      | 90496     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00292  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 57.2      |
|    n_updates            | 7060      |
|    policy_gradient_loss | -4.19e-10 |
|    value_loss           | 131       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -6.37     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 708       |
|    time_elapsed         | 2300      |
|    total_timesteps      | 90624     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00296  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 72.9      |
|    n_updates            | 7070      |
|    policy_gradient_loss | -2.75e-09 |
|    value_loss           | 123       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.7      |
|    ep_rew_mean          | -6.66     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 709       |
|    time_elapsed         | 2303      |
|    total_timesteps      | 90752     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.003    |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 43.6      |
|    n_updates            | 7080      |
|    policy_gradient_loss | -7.08e-09 |
|    value_loss           | 77.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -6.75     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 710       |
|    time_elapsed         | 2307      |
|    total_timesteps      | 90880     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00302  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 96.2      |
|    n_updates            | 7090      |
|    policy_gradient_loss | -3.86e-09 |
|    value_loss           | 182       |
---------------------------------------
Num timesteps: 91000
Best mean reward: -1.70 - Last mean reward per episode: -5.42
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.7     |
|    ep_rew_mean          | -6.86    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 711      |
|    time_elapsed         | 2310     |
|    total_timesteps      | 91008    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00305 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 51.3     |
|    n_updates            | 7100     |
|    policy_gradient_loss | 3.54e-09 |
|    value_loss           | 94.4     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80       |
|    ep_rew_mean          | -6.89    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 712      |
|    time_elapsed         | 2313     |
|    total_timesteps      | 91136    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00311 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.1     |
|    n_updates            | 7110     |
|    policy_gradient_loss | 3.21e-09 |
|    value_loss           | 89.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.1      |
|    ep_rew_mean          | -7.04     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 713       |
|    time_elapsed         | 2315      |
|    total_timesteps      | 91264     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00315  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.5      |
|    n_updates            | 7120      |
|    policy_gradient_loss | -1.77e-09 |
|    value_loss           | 104       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80        |
|    ep_rew_mean          | -7        |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 714       |
|    time_elapsed         | 2319      |
|    total_timesteps      | 91392     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00318  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 56.7      |
|    n_updates            | 7130      |
|    policy_gradient_loss | -3.07e-09 |
|    value_loss           | 97.4      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.4     |
|    ep_rew_mean          | -6.78    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 715      |
|    time_elapsed         | 2323     |
|    total_timesteps      | 91520    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00322 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 63.8     |
|    n_updates            | 7140     |
|    policy_gradient_loss | 6.75e-10 |
|    value_loss           | 104      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -6.63     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 716       |
|    time_elapsed         | 2327      |
|    total_timesteps      | 91648     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00325  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.4      |
|    n_updates            | 7150      |
|    policy_gradient_loss | -3.75e-09 |
|    value_loss           | 89.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.7      |
|    ep_rew_mean          | -6.44     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 717       |
|    time_elapsed         | 2330      |
|    total_timesteps      | 91776     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0033   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30.2      |
|    n_updates            | 7160      |
|    policy_gradient_loss | -2.42e-09 |
|    value_loss           | 89.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.8     |
|    ep_rew_mean          | -6.48    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 718      |
|    time_elapsed         | 2333     |
|    total_timesteps      | 91904    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00334 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 35.2     |
|    n_updates            | 7170     |
|    policy_gradient_loss | 6.98e-09 |
|    value_loss           | 72.1     |
--------------------------------------
Num timesteps: 92000
Best mean reward: -1.70 - Last mean reward per episode: -6.39
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.8      |
|    ep_rew_mean          | -6.61     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 719       |
|    time_elapsed         | 2336      |
|    total_timesteps      | 92032     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00336  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.1      |
|    n_updates            | 7180      |
|    policy_gradient_loss | -3.26e-09 |
|    value_loss           | 88.3      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79        |
|    ep_rew_mean          | -6.88     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 720       |
|    time_elapsed         | 2339      |
|    total_timesteps      | 92160     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00337  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 84.4      |
|    n_updates            | 7190      |
|    policy_gradient_loss | -3.26e-10 |
|    value_loss           | 182       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.4     |
|    ep_rew_mean          | -7       |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 721      |
|    time_elapsed         | 2343     |
|    total_timesteps      | 92288    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00338 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 41.6     |
|    n_updates            | 7200     |
|    policy_gradient_loss | 2.51e-09 |
|    value_loss           | 81       |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.6     |
|    ep_rew_mean          | -7.08    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 722      |
|    time_elapsed         | 2346     |
|    total_timesteps      | 92416    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00341 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 64.2     |
|    n_updates            | 7210     |
|    policy_gradient_loss | 2.14e-09 |
|    value_loss           | 134      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -6.99     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 723       |
|    time_elapsed         | 2349      |
|    total_timesteps      | 92544     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00348  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 36.3      |
|    n_updates            | 7220      |
|    policy_gradient_loss | 5.12e-10  |
|    value_loss           | 92.8      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.1     |
|    ep_rew_mean          | -7.25    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 724      |
|    time_elapsed         | 2352     |
|    total_timesteps      | 92672    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00353 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 55.8     |
|    n_updates            | 7230     |
|    policy_gradient_loss | -6.1e-09 |
|    value_loss           | 130      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.4      |
|    ep_rew_mean          | -7.4      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 725       |
|    time_elapsed         | 2355      |
|    total_timesteps      | 92800     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00356  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 40.2      |
|    n_updates            | 7240      |
|    policy_gradient_loss | -1.25e-09 |
|    value_loss           | 70.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.4      |
|    ep_rew_mean          | -7.41     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 726       |
|    time_elapsed         | 2358      |
|    total_timesteps      | 92928     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0036   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 42.1      |
|    n_updates            | 7250      |
|    policy_gradient_loss | 1.54e-09  |
|    value_loss           | 93.7      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 93000
Best mean reward: -1.70 - Last mean reward per episode: -7.06
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.7      |
|    ep_rew_mean          | -7.46     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 727       |
|    time_elapsed         | 2362      |
|    total_timesteps      | 93056     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00369  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.9      |
|    n_updates            | 7260      |
|    policy_gradient_loss | -1.14e-09 |
|    value_loss           | 93.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.6      |
|    ep_rew_mean          | -7.42     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 728       |
|    time_elapsed         | 2366      |
|    total_timesteps      | 93184     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00378  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 46.1      |
|    n_updates            | 7270      |
|    policy_gradient_loss | -4.47e-09 |
|    value_loss           | 104       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.7      |
|    ep_rew_mean          | -7.46     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 729       |
|    time_elapsed         | 2369      |
|    total_timesteps      | 93312     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00384  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 54.7      |
|    n_updates            | 7280      |
|    policy_gradient_loss | 4.66e-11  |
|    value_loss           | 86.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.2      |
|    ep_rew_mean          | -7.48     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 730       |
|    time_elapsed         | 2373      |
|    total_timesteps      | 93440     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0039   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 88.9      |
|    n_updates            | 7290      |
|    policy_gradient_loss | -8.06e-09 |
|    value_loss           | 167       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.4     |
|    ep_rew_mean          | -7.71    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 731      |
|    time_elapsed         | 2377     |
|    total_timesteps      | 93568    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00395 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.1     |
|    n_updates            | 7300     |
|    policy_gradient_loss | 1.44e-09 |
|    value_loss           | 149      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.3      |
|    ep_rew_mean          | -7.66     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 732       |
|    time_elapsed         | 2380      |
|    total_timesteps      | 93696     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00405  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 32.8      |
|    n_updates            | 7310      |
|    policy_gradient_loss | -1.77e-09 |
|    value_loss           | 83.8      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 81.8          |
|    ep_rew_mean          | -7.82         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 733           |
|    time_elapsed         | 2383          |
|    total_timesteps      | 93824         |
| train/                  |               |
|    approx_kl            | 0.00030504446 |
|    clip_fraction        | 0.00234       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00376      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 36.6          |
|    n_updates            | 7320          |
|    policy_gradient_loss | -0.000531     |
|    value_loss           | 72.3          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.8     |
|    ep_rew_mean          | -7.71    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 734      |
|    time_elapsed         | 2387     |
|    total_timesteps      | 93952    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00308 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 61.8     |
|    n_updates            | 7330     |
|    policy_gradient_loss | 4.89e-09 |
|    value_loss           | 149      |
--------------------------------------
Num timesteps: 94000
Best mean reward: -1.70 - Last mean reward per episode: -7.31
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.3     |
|    ep_rew_mean          | -7.94    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 735      |
|    time_elapsed         | 2391     |
|    total_timesteps      | 94080    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00301 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 68.2     |
|    n_updates            | 7340     |
|    policy_gradient_loss | 9.08e-10 |
|    value_loss           | 102      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.5      |
|    ep_rew_mean          | -8.03     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 736       |
|    time_elapsed         | 2394      |
|    total_timesteps      | 94208     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00303  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 31.3      |
|    n_updates            | 7350      |
|    policy_gradient_loss | -2.14e-09 |
|    value_loss           | 70        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.2     |
|    ep_rew_mean          | -8.21    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 737      |
|    time_elapsed         | 2398     |
|    total_timesteps      | 94336    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00305 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 36.4     |
|    n_updates            | 7360     |
|    policy_gradient_loss | 3.17e-09 |
|    value_loss           | 78.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.5      |
|    ep_rew_mean          | -7.84     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 738       |
|    time_elapsed         | 2401      |
|    total_timesteps      | 94464     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00306  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 83.3      |
|    n_updates            | 7370      |
|    policy_gradient_loss | -2.65e-09 |
|    value_loss           | 179       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.8      |
|    ep_rew_mean          | -8.09     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 739       |
|    time_elapsed         | 2403      |
|    total_timesteps      | 94592     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00308  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 27.7      |
|    n_updates            | 7380      |
|    policy_gradient_loss | -4.19e-10 |
|    value_loss           | 93.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82        |
|    ep_rew_mean          | -7.72     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 740       |
|    time_elapsed         | 2406      |
|    total_timesteps      | 94720     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00314  |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 45.6      |
|    n_updates            | 7390      |
|    policy_gradient_loss | -1.35e-09 |
|    value_loss           | 92.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81       |
|    ep_rew_mean          | -6.99    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 741      |
|    time_elapsed         | 2410     |
|    total_timesteps      | 94848    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00322 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 49.1     |
|    n_updates            | 7400     |
|    policy_gradient_loss | 0        |
|    value_loss           | 89.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.4      |
|    ep_rew_mean          | -7.18     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 742       |
|    time_elapsed         | 2413      |
|    total_timesteps      | 94976     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00329  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 64.6      |
|    n_updates            | 7410      |
|    policy_gradient_loss | -3.24e-09 |
|    value_loss           | 155       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 95000
Best mean reward: -1.70 - Last mean reward per episode: -6.83
Eval num_timesteps=95000, episode_reward=2.70 +/- 6.45
Episode length: 66.60 +/- 8.48
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 66.6      |
|    mean_reward          | 2.7       |
| time/                   |           |
|    total_timesteps      | 95000     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00331  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 27.7      |
|    n_updates            | 7420      |
|    policy_gradient_loss | 6.98e-11  |
|    value_loss           | 69.7      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81.1     |
|    ep_rew_mean     | -7.13    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 743      |
|    time_elapsed    | 2418     |
|    total_timesteps | 95104    |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.2      |
|    ep_rew_mean          | -7.2      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 744       |
|    time_elapsed         | 2421      |
|    total_timesteps      | 95232     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00332  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 28.8      |
|    n_updates            | 7430      |
|    policy_gradient_loss | -3.54e-09 |
|    value_loss           | 69.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.2      |
|    ep_rew_mean          | -7.2      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 745       |
|    time_elapsed         | 2425      |
|    total_timesteps      | 95360     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00337  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.5      |
|    n_updates            | 7440      |
|    policy_gradient_loss | -1.82e-09 |
|    value_loss           | 97.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.2      |
|    ep_rew_mean          | -7.2      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 746       |
|    time_elapsed         | 2429      |
|    total_timesteps      | 95488     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00343  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.1      |
|    n_updates            | 7450      |
|    policy_gradient_loss | -1.43e-08 |
|    value_loss           | 60.6      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.2     |
|    ep_rew_mean          | -7.2     |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 747      |
|    time_elapsed         | 2433     |
|    total_timesteps      | 95616    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00345 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 29.3     |
|    n_updates            | 7460     |
|    policy_gradient_loss | 3.04e-08 |
|    value_loss           | 59       |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.3     |
|    ep_rew_mean          | -9.14    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 748      |
|    time_elapsed         | 2438     |
|    total_timesteps      | 95744    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00346 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 27.2     |
|    n_updates            | 7470     |
|    policy_gradient_loss | 6.71e-09 |
|    value_loss           | 57.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.6      |
|    ep_rew_mean          | -9.29     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 749       |
|    time_elapsed         | 2442      |
|    total_timesteps      | 95872     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00348  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 82.3      |
|    n_updates            | 7480      |
|    policy_gradient_loss | -2.24e-09 |
|    value_loss           | 105       |
---------------------------------------
Num timesteps: 96000
Best mean reward: -1.70 - Last mean reward per episode: -8.56
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85        |
|    ep_rew_mean          | -8.97     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 750       |
|    time_elapsed         | 2445      |
|    total_timesteps      | 96000     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00353  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 34.4      |
|    n_updates            | 7490      |
|    policy_gradient_loss | -2.93e-09 |
|    value_loss           | 95.3      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.8     |
|    ep_rew_mean          | -9.39    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 751      |
|    time_elapsed         | 2448     |
|    total_timesteps      | 96128    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00358 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 29.9     |
|    n_updates            | 7500     |
|    policy_gradient_loss | -4e-09   |
|    value_loss           | 71.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.7     |
|    ep_rew_mean          | -9.36    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 752      |
|    time_elapsed         | 2451     |
|    total_timesteps      | 96256    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0036  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 39.8     |
|    n_updates            | 7510     |
|    policy_gradient_loss | 2.79e-10 |
|    value_loss           | 76       |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.7     |
|    ep_rew_mean          | -9.56    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 753      |
|    time_elapsed         | 2454     |
|    total_timesteps      | 96384    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00364 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 34.4     |
|    n_updates            | 7520     |
|    policy_gradient_loss | 2.51e-09 |
|    value_loss           | 95.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.9      |
|    ep_rew_mean          | -9.56     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 754       |
|    time_elapsed         | 2457      |
|    total_timesteps      | 96512     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00371  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.6      |
|    n_updates            | 7530      |
|    policy_gradient_loss | -3.45e-09 |
|    value_loss           | 93.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86       |
|    ep_rew_mean          | -9.49    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 755      |
|    time_elapsed         | 2461     |
|    total_timesteps      | 96640    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00376 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 37.4     |
|    n_updates            | 7540     |
|    policy_gradient_loss | 2.42e-09 |
|    value_loss           | 110      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.4      |
|    ep_rew_mean          | -9.69     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 756       |
|    time_elapsed         | 2465      |
|    total_timesteps      | 96768     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00381  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 72        |
|    n_updates            | 7550      |
|    policy_gradient_loss | 7.31e-09  |
|    value_loss           | 123       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.5      |
|    ep_rew_mean          | -7.55     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 757       |
|    time_elapsed         | 2468      |
|    total_timesteps      | 96896     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00387  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 51.3      |
|    n_updates            | 7560      |
|    policy_gradient_loss | -8.38e-10 |
|    value_loss           | 102       |
---------------------------------------
Num timesteps: 97000
Best mean reward: -1.70 - Last mean reward per episode: -6.64
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.2      |
|    ep_rew_mean          | -7.39     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 758       |
|    time_elapsed         | 2471      |
|    total_timesteps      | 97024     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00392  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 48.8      |
|    n_updates            | 7570      |
|    policy_gradient_loss | 6.64e-10  |
|    value_loss           | 96.4      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.4     |
|    ep_rew_mean          | -7.31    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 759      |
|    time_elapsed         | 2474     |
|    total_timesteps      | 97152    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00398 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.8     |
|    n_updates            | 7580     |
|    policy_gradient_loss | 1.58e-09 |
|    value_loss           | 91.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.5      |
|    ep_rew_mean          | -7.35     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 760       |
|    time_elapsed         | 2477      |
|    total_timesteps      | 97280     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00406  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 51.8      |
|    n_updates            | 7590      |
|    policy_gradient_loss | -6.98e-11 |
|    value_loss           | 91.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.1      |
|    ep_rew_mean          | -7.74     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 761       |
|    time_elapsed         | 2481      |
|    total_timesteps      | 97408     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00414  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.8      |
|    n_updates            | 7600      |
|    policy_gradient_loss | -1.44e-09 |
|    value_loss           | 78.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.6     |
|    ep_rew_mean          | -7.49    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 762      |
|    time_elapsed         | 2484     |
|    total_timesteps      | 97536    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00423 |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 54.8     |
|    n_updates            | 7610     |
|    policy_gradient_loss | 1.63e-09 |
|    value_loss           | 101      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.8     |
|    ep_rew_mean          | -7.58    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 763      |
|    time_elapsed         | 2487     |
|    total_timesteps      | 97664    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00439 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 52.6     |
|    n_updates            | 7620     |
|    policy_gradient_loss | 6.52e-10 |
|    value_loss           | 93.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.9     |
|    ep_rew_mean          | -7.84    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 764      |
|    time_elapsed         | 2490     |
|    total_timesteps      | 97792    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00449 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 38.5     |
|    n_updates            | 7630     |
|    policy_gradient_loss | 9.59e-09 |
|    value_loss           | 70.6     |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 81.5         |
|    ep_rew_mean          | -8.18        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 765          |
|    time_elapsed         | 2493         |
|    total_timesteps      | 97920        |
| train/                  |              |
|    approx_kl            | 0.0021562623 |
|    clip_fraction        | 0.00391      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00362     |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 52.4         |
|    n_updates            | 7640         |
|    policy_gradient_loss | -0.000252    |
|    value_loss           | 92.6         |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 98000
Best mean reward: -1.70 - Last mean reward per episode: -8.26
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.1      |
|    ep_rew_mean          | -8.47     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 766       |
|    time_elapsed         | 2496      |
|    total_timesteps      | 98048     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00215  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 30.4      |
|    n_updates            | 7650      |
|    policy_gradient_loss | -5.12e-09 |
|    value_loss           | 70.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.6      |
|    ep_rew_mean          | -8.6      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 767       |
|    time_elapsed         | 2500      |
|    total_timesteps      | 98176     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00199  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45        |
|    n_updates            | 7660      |
|    policy_gradient_loss | -1.86e-09 |
|    value_loss           | 70.5      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 82.3          |
|    ep_rew_mean          | -8.45         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 768           |
|    time_elapsed         | 2503          |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 0.00024120929 |
|    clip_fraction        | 0.00156       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00186      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 80.4          |
|    n_updates            | 7670          |
|    policy_gradient_loss | -0.000215     |
|    value_loss           | 135           |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.3     |
|    ep_rew_mean          | -8.55    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 769      |
|    time_elapsed         | 2506     |
|    total_timesteps      | 98432    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00162 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 44       |
|    n_updates            | 7680     |
|    policy_gradient_loss | 4.66e-10 |
|    value_loss           | 95       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.3      |
|    ep_rew_mean          | -8.65     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 770       |
|    time_elapsed         | 2509      |
|    total_timesteps      | 98560     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00159  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.6      |
|    n_updates            | 7690      |
|    policy_gradient_loss | -4.49e-09 |
|    value_loss           | 90.6      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.4     |
|    ep_rew_mean          | -8.7     |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 771      |
|    time_elapsed         | 2513     |
|    total_timesteps      | 98688    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00159 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 57       |
|    n_updates            | 7700     |
|    policy_gradient_loss | 3.73e-09 |
|    value_loss           | 90.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.8      |
|    ep_rew_mean          | -8.99     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 772       |
|    time_elapsed         | 2516      |
|    total_timesteps      | 98816     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0016   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 36.5      |
|    n_updates            | 7710      |
|    policy_gradient_loss | 6.05e-10  |
|    value_loss           | 72.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.3      |
|    ep_rew_mean          | -8.56     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 773       |
|    time_elapsed         | 2519      |
|    total_timesteps      | 98944     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00161  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 51.7      |
|    n_updates            | 7720      |
|    policy_gradient_loss | -5.05e-09 |
|    value_loss           | 104       |
---------------------------------------
Num timesteps: 99000
Best mean reward: -1.70 - Last mean reward per episode: -8.22
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.2      |
|    ep_rew_mean          | -8.62     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 774       |
|    time_elapsed         | 2522      |
|    total_timesteps      | 99072     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00162  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 93.3      |
|    n_updates            | 7730      |
|    policy_gradient_loss | -3.41e-09 |
|    value_loss           | 174       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.8      |
|    ep_rew_mean          | -8.69     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 775       |
|    time_elapsed         | 2525      |
|    total_timesteps      | 99200     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00162  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.8      |
|    n_updates            | 7740      |
|    policy_gradient_loss | -1.47e-09 |
|    value_loss           | 109       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.6      |
|    ep_rew_mean          | -8.58     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 776       |
|    time_elapsed         | 2529      |
|    total_timesteps      | 99328     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00163  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 61.3      |
|    n_updates            | 7750      |
|    policy_gradient_loss | 2e-09     |
|    value_loss           | 184       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.1     |
|    ep_rew_mean          | -8.47    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 777      |
|    time_elapsed         | 2532     |
|    total_timesteps      | 99456    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00164 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 44.4     |
|    n_updates            | 7760     |
|    policy_gradient_loss | 1.77e-09 |
|    value_loss           | 89       |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.5     |
|    ep_rew_mean          | -8.68    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 778      |
|    time_elapsed         | 2535     |
|    total_timesteps      | 99584    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00166 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 43.5     |
|    n_updates            | 7770     |
|    policy_gradient_loss | 3.82e-09 |
|    value_loss           | 88.9     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82       |
|    ep_rew_mean          | -8.47    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 779      |
|    time_elapsed         | 2538     |
|    total_timesteps      | 99712    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00167 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 35.6     |
|    n_updates            | 7780     |
|    policy_gradient_loss | 1.37e-09 |
|    value_loss           | 70.1     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.9     |
|    ep_rew_mean          | -8.35    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 780      |
|    time_elapsed         | 2541     |
|    total_timesteps      | 99840    |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00167 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 41.9     |
|    n_updates            | 7790     |
|    policy_gradient_loss | -1.4e-08 |
|    value_loss           | 86.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.9      |
|    ep_rew_mean          | -8.35     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 781       |
|    time_elapsed         | 2544      |
|    total_timesteps      | 99968     |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00168  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 69.8      |
|    n_updates            | 7800      |
|    policy_gradient_loss | -5.22e-09 |
|    value_loss           | 131       |
---------------------------------------
Num timesteps: 100000
Best mean reward: -1.70 - Last mean reward per episode: -8.12
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=100000, episode_reward=1.40 +/- 10.29
Episode length: 69.20 +/- 11.07
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 69.2     |
|    mean_reward          | 1.4      |
| time/                   |          |
|    total_timesteps      | 100000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00168 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 36.7     |
|    n_updates            | 7810     |
|    policy_gradient_loss | 1.58e-09 |
|    value_loss           | 89.1     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81.8     |
|    ep_rew_mean     | -8.29    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 782      |
|    time_elapsed    | 2549     |
|    total_timesteps | 100096   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.5      |
|    ep_rew_mean          | -8.32     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 783       |
|    time_elapsed         | 2552      |
|    total_timesteps      | 100224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00169  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.1      |
|    n_updates            | 7820      |
|    policy_gradient_loss | -6.17e-09 |
|    value_loss           | 72        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.4     |
|    ep_rew_mean          | -8.29    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 784      |
|    time_elapsed         | 2556     |
|    total_timesteps      | 100352   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0017  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 51.6     |
|    n_updates            | 7830     |
|    policy_gradient_loss | 3.96e-10 |
|    value_loss           | 91.5     |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 81.3         |
|    ep_rew_mean          | -8.23        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 785          |
|    time_elapsed         | 2559         |
|    total_timesteps      | 100480       |
| train/                  |              |
|    approx_kl            | 0.0016303733 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00137     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 46.3         |
|    n_updates            | 7840         |
|    policy_gradient_loss | -0.000589    |
|    value_loss           | 96.7         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.7      |
|    ep_rew_mean          | -8.44     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 786       |
|    time_elapsed         | 2563      |
|    total_timesteps      | 100608    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0011   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 64.3      |
|    n_updates            | 7850      |
|    policy_gradient_loss | -9.31e-11 |
|    value_loss           | 105       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.6     |
|    ep_rew_mean          | -8.31    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 787      |
|    time_elapsed         | 2566     |
|    total_timesteps      | 100736   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00108 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.9     |
|    n_updates            | 7860     |
|    policy_gradient_loss | 4.8e-09  |
|    value_loss           | 85.6     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.4     |
|    ep_rew_mean          | -8.79    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 788      |
|    time_elapsed         | 2569     |
|    total_timesteps      | 100864   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00107 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 51.1     |
|    n_updates            | 7870     |
|    policy_gradient_loss | 6.05e-10 |
|    value_loss           | 109      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.5     |
|    ep_rew_mean          | -8.27    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 789      |
|    time_elapsed         | 2572     |
|    total_timesteps      | 100992   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00108 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.6     |
|    n_updates            | 7880     |
|    policy_gradient_loss | 2.35e-09 |
|    value_loss           | 97.9     |
--------------------------------------
Num timesteps: 101000
Best mean reward: -1.70 - Last mean reward per episode: -7.62
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82       |
|    ep_rew_mean          | -8.4     |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 790      |
|    time_elapsed         | 2576     |
|    total_timesteps      | 101120   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00108 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 65.1     |
|    n_updates            | 7890     |
|    policy_gradient_loss | -1.3e-09 |
|    value_loss           | 126      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.5     |
|    ep_rew_mean          | -8.63    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 791      |
|    time_elapsed         | 2580     |
|    total_timesteps      | 101248   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00109 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 45       |
|    n_updates            | 7900     |
|    policy_gradient_loss | 4.35e-09 |
|    value_loss           | 105      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.5      |
|    ep_rew_mean          | -8.24     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 792       |
|    time_elapsed         | 2583      |
|    total_timesteps      | 101376    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00109  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 58.1      |
|    n_updates            | 7910      |
|    policy_gradient_loss | -5.22e-09 |
|    value_loss           | 106       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.1     |
|    ep_rew_mean          | -8.55    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 793      |
|    time_elapsed         | 2585     |
|    total_timesteps      | 101504   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0011  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 43.8     |
|    n_updates            | 7920     |
|    policy_gradient_loss | 3.21e-09 |
|    value_loss           | 93.4     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.1     |
|    ep_rew_mean          | -8.74    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 794      |
|    time_elapsed         | 2589     |
|    total_timesteps      | 101632   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0011  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 29.2     |
|    n_updates            | 7930     |
|    policy_gradient_loss | 1.35e-09 |
|    value_loss           | 76.1     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.2     |
|    ep_rew_mean          | -9.01    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 795      |
|    time_elapsed         | 2592     |
|    total_timesteps      | 101760   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0011  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 49.7     |
|    n_updates            | 7940     |
|    policy_gradient_loss | 2.37e-09 |
|    value_loss           | 72.7     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82       |
|    ep_rew_mean          | -8.89    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 796      |
|    time_elapsed         | 2595     |
|    total_timesteps      | 101888   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00111 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 41       |
|    n_updates            | 7950     |
|    policy_gradient_loss | 1.07e-09 |
|    value_loss           | 100      |
--------------------------------------
Num timesteps: 102000
Best mean reward: -1.70 - Last mean reward per episode: -7.78
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.2      |
|    ep_rew_mean          | -8.97     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 797       |
|    time_elapsed         | 2597      |
|    total_timesteps      | 102016    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00111  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 38.4      |
|    n_updates            | 7960      |
|    policy_gradient_loss | 1.18e-08  |
|    value_loss           | 79.6      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.2     |
|    ep_rew_mean          | -8.6     |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 798      |
|    time_elapsed         | 2600     |
|    total_timesteps      | 102144   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00112 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 48.1     |
|    n_updates            | 7970     |
|    policy_gradient_loss | 5.12e-10 |
|    value_loss           | 107      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.2     |
|    ep_rew_mean          | -8.6     |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 799      |
|    time_elapsed         | 2603     |
|    total_timesteps      | 102272   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00112 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 68.7     |
|    n_updates            | 7980     |
|    policy_gradient_loss | 2.98e-09 |
|    value_loss           | 186      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.4      |
|    ep_rew_mean          | -8.71     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 800       |
|    time_elapsed         | 2606      |
|    total_timesteps      | 102400    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00113  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 28.1      |
|    n_updates            | 7990      |
|    policy_gradient_loss | -2.44e-08 |
|    value_loss           | 58.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.4      |
|    ep_rew_mean          | -8.71     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 801       |
|    time_elapsed         | 2609      |
|    total_timesteps      | 102528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00113  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 53.6      |
|    n_updates            | 8000      |
|    policy_gradient_loss | -4.05e-09 |
|    value_loss           | 96.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.4      |
|    ep_rew_mean          | -8.71     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 802       |
|    time_elapsed         | 2612      |
|    total_timesteps      | 102656    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00113  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 27.6      |
|    n_updates            | 8010      |
|    policy_gradient_loss | 8.49e-08  |
|    value_loss           | 58.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.4      |
|    ep_rew_mean          | -8.71     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 803       |
|    time_elapsed         | 2615      |
|    total_timesteps      | 102784    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00113  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 28.2      |
|    n_updates            | 8020      |
|    policy_gradient_loss | -4.98e-08 |
|    value_loss           | 56.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.4      |
|    ep_rew_mean          | -8.71     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 804       |
|    time_elapsed         | 2618      |
|    total_timesteps      | 102912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00113  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 27.5      |
|    n_updates            | 8030      |
|    policy_gradient_loss | 1.55e-08  |
|    value_loss           | 55.2      |
---------------------------------------
Num timesteps: 103000
Best mean reward: -1.70 - Last mean reward per episode: -8.26
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.4     |
|    ep_rew_mean          | -8.71    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 805      |
|    time_elapsed         | 2621     |
|    total_timesteps      | 103040   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00113 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 25.4     |
|    n_updates            | 8040     |
|    policy_gradient_loss | 3.26e-09 |
|    value_loss           | 54.1     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.4      |
|    ep_rew_mean          | -8.71     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 806       |
|    time_elapsed         | 2624      |
|    total_timesteps      | 103168    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00114  |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 24.1      |
|    n_updates            | 8050      |
|    policy_gradient_loss | -5.36e-08 |
|    value_loss           | 52.7      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.4     |
|    ep_rew_mean          | -8.71    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 807      |
|    time_elapsed         | 2628     |
|    total_timesteps      | 103296   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00114 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 13.2     |
|    n_updates            | 8060     |
|    policy_gradient_loss | 5.4e-09  |
|    value_loss           | 41.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 90.2     |
|    ep_rew_mean          | -13.6    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 808      |
|    time_elapsed         | 2631     |
|    total_timesteps      | 103424   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00114 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 19.7     |
|    n_updates            | 8070     |
|    policy_gradient_loss | -4.2e-08 |
|    value_loss           | 42.1     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 90.5     |
|    ep_rew_mean          | -13.7    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 809      |
|    time_elapsed         | 2633     |
|    total_timesteps      | 103552   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00114 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 15.1     |
|    n_updates            | 8080     |
|    policy_gradient_loss | 1.85e-08 |
|    value_loss           | 31.9     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 90.8     |
|    ep_rew_mean          | -13.7    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 810      |
|    time_elapsed         | 2637     |
|    total_timesteps      | 103680   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00114 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 63.4     |
|    n_updates            | 8090     |
|    policy_gradient_loss | 1.28e-09 |
|    value_loss           | 130      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 90.3     |
|    ep_rew_mean          | -13.1    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 811      |
|    time_elapsed         | 2640     |
|    total_timesteps      | 103808   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00114 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 75.3     |
|    n_updates            | 8100     |
|    policy_gradient_loss | 2.93e-09 |
|    value_loss           | 188      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 90.5     |
|    ep_rew_mean          | -13      |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 812      |
|    time_elapsed         | 2643     |
|    total_timesteps      | 103936   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00115 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 163      |
|    n_updates            | 8110     |
|    policy_gradient_loss | 4.8e-09  |
|    value_loss           | 270      |
--------------------------------------
Num timesteps: 104000
Best mean reward: -1.70 - Last mean reward per episode: -10.67
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 90       |
|    ep_rew_mean          | -12.8    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 813      |
|    time_elapsed         | 2647     |
|    total_timesteps      | 104064   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00115 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 138      |
|    n_updates            | 8120     |
|    policy_gradient_loss | 7.92e-10 |
|    value_loss           | 226      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.9      |
|    ep_rew_mean          | -12.6     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 814       |
|    time_elapsed         | 2649      |
|    total_timesteps      | 104192    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00115  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 107       |
|    n_updates            | 8130      |
|    policy_gradient_loss | -9.31e-10 |
|    value_loss           | 164       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.2      |
|    ep_rew_mean          | -12.8     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 815       |
|    time_elapsed         | 2652      |
|    total_timesteps      | 104320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00115  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 90.8      |
|    n_updates            | 8140      |
|    policy_gradient_loss | -3.77e-09 |
|    value_loss           | 162       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.8     |
|    ep_rew_mean          | -10.7    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 816      |
|    time_elapsed         | 2656     |
|    total_timesteps      | 104448   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00115 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 43.8     |
|    n_updates            | 8150     |
|    policy_gradient_loss | 2.28e-09 |
|    value_loss           | 80.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.2     |
|    ep_rew_mean          | -10.7    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 817      |
|    time_elapsed         | 2659     |
|    total_timesteps      | 104576   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00116 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 59.4     |
|    n_updates            | 8160     |
|    policy_gradient_loss | 3.91e-09 |
|    value_loss           | 120      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85        |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 818       |
|    time_elapsed         | 2662      |
|    total_timesteps      | 104704    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00116  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 72        |
|    n_updates            | 8170      |
|    policy_gradient_loss | -4.42e-10 |
|    value_loss           | 176       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.3     |
|    ep_rew_mean          | -10.2    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 819      |
|    time_elapsed         | 2666     |
|    total_timesteps      | 104832   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00117 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 75.4     |
|    n_updates            | 8180     |
|    policy_gradient_loss | 1.65e-09 |
|    value_loss           | 120      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.3      |
|    ep_rew_mean          | -10.2     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 820       |
|    time_elapsed         | 2669      |
|    total_timesteps      | 104960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00117  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.1      |
|    n_updates            | 8190      |
|    policy_gradient_loss | -4.68e-09 |
|    value_loss           | 112       |
---------------------------------------
Num timesteps: 105000
Best mean reward: -1.70 - Last mean reward per episode: -9.86
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=105000, episode_reward=-101.40 +/- 199.74
Episode length: 258.80 +/- 370.88
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 259       |
|    mean_reward          | -101      |
| time/                   |           |
|    total_timesteps      | 105000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00118  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 24.6      |
|    n_updates            | 8200      |
|    policy_gradient_loss | -1.47e-08 |
|    value_loss           | 52.4      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 85.4     |
|    ep_rew_mean     | -10.3    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 821      |
|    time_elapsed    | 2679     |
|    total_timesteps | 105088   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.9     |
|    ep_rew_mean          | -10.4    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 822      |
|    time_elapsed         | 2683     |
|    total_timesteps      | 105216   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00118 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.5     |
|    n_updates            | 8210     |
|    policy_gradient_loss | -1.4e-09 |
|    value_loss           | 81       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.4      |
|    ep_rew_mean          | -10.3     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 823       |
|    time_elapsed         | 2686      |
|    total_timesteps      | 105344    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00118  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 63.4      |
|    n_updates            | 8220      |
|    policy_gradient_loss | -5.1e-09  |
|    value_loss           | 119       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.9      |
|    ep_rew_mean          | -9.86     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 824       |
|    time_elapsed         | 2689      |
|    total_timesteps      | 105472    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0012   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 68        |
|    n_updates            | 8230      |
|    policy_gradient_loss | -1.07e-08 |
|    value_loss           | 159       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.1      |
|    ep_rew_mean          | -9.84     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 825       |
|    time_elapsed         | 2692      |
|    total_timesteps      | 105600    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0012   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 112       |
|    n_updates            | 8240      |
|    policy_gradient_loss | -1.18e-08 |
|    value_loss           | 215       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.5      |
|    ep_rew_mean          | -9.96     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 826       |
|    time_elapsed         | 2695      |
|    total_timesteps      | 105728    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0012   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 75.8      |
|    n_updates            | 8250      |
|    policy_gradient_loss | 3.26e-10  |
|    value_loss           | 147       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.5     |
|    ep_rew_mean          | -9.96    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 827      |
|    time_elapsed         | 2699     |
|    total_timesteps      | 105856   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00122 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 59.9     |
|    n_updates            | 8260     |
|    policy_gradient_loss | 1.44e-09 |
|    value_loss           | 117      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.5      |
|    ep_rew_mean          | -9.77     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 828       |
|    time_elapsed         | 2701      |
|    total_timesteps      | 105984    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00123  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 75.5      |
|    n_updates            | 8270      |
|    policy_gradient_loss | -7.92e-09 |
|    value_loss           | 130       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 106000
Best mean reward: -1.70 - Last mean reward per episode: -13.29
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85        |
|    ep_rew_mean          | -9.32     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 829       |
|    time_elapsed         | 2704      |
|    total_timesteps      | 106112    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00123  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 102       |
|    n_updates            | 8280      |
|    policy_gradient_loss | -6.15e-09 |
|    value_loss           | 200       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | -9.86     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 830       |
|    time_elapsed         | 2707      |
|    total_timesteps      | 106240    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00123  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 94.4      |
|    n_updates            | 8290      |
|    policy_gradient_loss | -2.37e-09 |
|    value_loss           | 170       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.1     |
|    ep_rew_mean          | -9.63    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 831      |
|    time_elapsed         | 2711     |
|    total_timesteps      | 106368   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00124 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.9     |
|    n_updates            | 8300     |
|    policy_gradient_loss | 2.14e-09 |
|    value_loss           | 84.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.4      |
|    ep_rew_mean          | -9.79     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 832       |
|    time_elapsed         | 2714      |
|    total_timesteps      | 106496    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00124  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 81.7      |
|    n_updates            | 8310      |
|    policy_gradient_loss | -2.56e-09 |
|    value_loss           | 202       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.2     |
|    ep_rew_mean          | -9.69    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 833      |
|    time_elapsed         | 2717     |
|    total_timesteps      | 106624   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00125 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 48.2     |
|    n_updates            | 8320     |
|    policy_gradient_loss | 7.92e-10 |
|    value_loss           | 78       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85        |
|    ep_rew_mean          | -9.12     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 834       |
|    time_elapsed         | 2720      |
|    total_timesteps      | 106752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00125  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 64.9      |
|    n_updates            | 8330      |
|    policy_gradient_loss | -4.66e-11 |
|    value_loss           | 109       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.6     |
|    ep_rew_mean          | -8.79    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 835      |
|    time_elapsed         | 2723     |
|    total_timesteps      | 106880   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00125 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 54.1     |
|    n_updates            | 8340     |
|    policy_gradient_loss | 6.43e-09 |
|    value_loss           | 110      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 107000
Best mean reward: -1.70 - Last mean reward per episode: -13.65
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.7     |
|    ep_rew_mean          | -8.85    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 836      |
|    time_elapsed         | 2727     |
|    total_timesteps      | 107008   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00126 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 119      |
|    n_updates            | 8350     |
|    policy_gradient_loss | 2.42e-09 |
|    value_loss           | 192      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.8      |
|    ep_rew_mean          | -8.89     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 837       |
|    time_elapsed         | 2729      |
|    total_timesteps      | 107136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00126  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53        |
|    n_updates            | 8360      |
|    policy_gradient_loss | -9.78e-10 |
|    value_loss           | 98.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.1     |
|    ep_rew_mean          | -9.04    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 838      |
|    time_elapsed         | 2732     |
|    total_timesteps      | 107264   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00127 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 42.3     |
|    n_updates            | 8370     |
|    policy_gradient_loss | 4.19e-10 |
|    value_loss           | 73.4     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.2     |
|    ep_rew_mean          | -9.09    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 839      |
|    time_elapsed         | 2735     |
|    total_timesteps      | 107392   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00127 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 54.1     |
|    n_updates            | 8380     |
|    policy_gradient_loss | 2.79e-10 |
|    value_loss           | 94.2     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.6      |
|    ep_rew_mean          | -9.32     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 840       |
|    time_elapsed         | 2738      |
|    total_timesteps      | 107520    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00129  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 47.7      |
|    n_updates            | 8390      |
|    policy_gradient_loss | 2.37e-09  |
|    value_loss           | 79.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.2      |
|    ep_rew_mean          | -9.02     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 841       |
|    time_elapsed         | 2740      |
|    total_timesteps      | 107648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00129  |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 50.8      |
|    n_updates            | 8400      |
|    policy_gradient_loss | -1.63e-09 |
|    value_loss           | 98.7      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.4     |
|    ep_rew_mean          | -9.32    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 842      |
|    time_elapsed         | 2744     |
|    total_timesteps      | 107776   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0013  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 56.5     |
|    n_updates            | 8410     |
|    policy_gradient_loss | -1.4e-10 |
|    value_loss           | 137      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.4      |
|    ep_rew_mean          | -9.38     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 843       |
|    time_elapsed         | 2747      |
|    total_timesteps      | 107904    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0013   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.7      |
|    n_updates            | 8420      |
|    policy_gradient_loss | -4.84e-09 |
|    value_loss           | 73.5      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 108000
Best mean reward: -1.70 - Last mean reward per episode: -13.93
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.9     |
|    ep_rew_mean          | -9.34    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 844      |
|    time_elapsed         | 2750     |
|    total_timesteps      | 108032   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00131 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 45.4     |
|    n_updates            | 8430     |
|    policy_gradient_loss | 2.24e-09 |
|    value_loss           | 105      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.8      |
|    ep_rew_mean          | -9.79     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 845       |
|    time_elapsed         | 2752      |
|    total_timesteps      | 108160    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00133  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 54.6      |
|    n_updates            | 8440      |
|    policy_gradient_loss | -1.58e-09 |
|    value_loss           | 103       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.8     |
|    ep_rew_mean          | -9.61    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 846      |
|    time_elapsed         | 2756     |
|    total_timesteps      | 108288   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00135 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 38.5     |
|    n_updates            | 8450     |
|    policy_gradient_loss | 1.3e-09  |
|    value_loss           | 72.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.3      |
|    ep_rew_mean          | -9.35     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 847       |
|    time_elapsed         | 2758      |
|    total_timesteps      | 108416    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00136  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 121       |
|    n_updates            | 8460      |
|    policy_gradient_loss | -1.96e-09 |
|    value_loss           | 195       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85        |
|    ep_rew_mean          | -9.28     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 848       |
|    time_elapsed         | 2761      |
|    total_timesteps      | 108544    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00137  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 48.8      |
|    n_updates            | 8470      |
|    policy_gradient_loss | -3.54e-09 |
|    value_loss           | 108       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.2     |
|    ep_rew_mean          | -9.29    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 849      |
|    time_elapsed         | 2764     |
|    total_timesteps      | 108672   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0014  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 52.9     |
|    n_updates            | 8480     |
|    policy_gradient_loss | 0        |
|    value_loss           | 103      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.1      |
|    ep_rew_mean          | -9.27     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 850       |
|    time_elapsed         | 2767      |
|    total_timesteps      | 108800    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00142  |
|    explained_variance   | 2.38e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 79.8      |
|    n_updates            | 8490      |
|    policy_gradient_loss | -2.44e-09 |
|    value_loss           | 140       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.2      |
|    ep_rew_mean          | -9.29     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 851       |
|    time_elapsed         | 2769      |
|    total_timesteps      | 108928    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00144  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 50.4      |
|    n_updates            | 8500      |
|    policy_gradient_loss | -1.86e-10 |
|    value_loss           | 94.8      |
---------------------------------------
Num timesteps: 109000
Best mean reward: -1.70 - Last mean reward per episode: -13.91
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.1      |
|    ep_rew_mean          | -9.15     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 852       |
|    time_elapsed         | 2773      |
|    total_timesteps      | 109056    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00146  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 38.5      |
|    n_updates            | 8510      |
|    policy_gradient_loss | 1.12e-09  |
|    value_loss           | 95.2      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.9      |
|    ep_rew_mean          | -8.94     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 853       |
|    time_elapsed         | 2776      |
|    total_timesteps      | 109184    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00147  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 64.7      |
|    n_updates            | 8520      |
|    policy_gradient_loss | -3.63e-09 |
|    value_loss           | 135       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.4      |
|    ep_rew_mean          | -8.71     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 854       |
|    time_elapsed         | 2780      |
|    total_timesteps      | 109312    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00149  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 72.8      |
|    n_updates            | 8530      |
|    policy_gradient_loss | -1.58e-09 |
|    value_loss           | 180       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.9      |
|    ep_rew_mean          | -8.44     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 855       |
|    time_elapsed         | 2783      |
|    total_timesteps      | 109440    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0015   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 46.7      |
|    n_updates            | 8540      |
|    policy_gradient_loss | -7.68e-09 |
|    value_loss           | 121       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.9     |
|    ep_rew_mean          | -8.35    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 856      |
|    time_elapsed         | 2786     |
|    total_timesteps      | 109568   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00153 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 44.3     |
|    n_updates            | 8550     |
|    policy_gradient_loss | 3.63e-09 |
|    value_loss           | 83.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.6      |
|    ep_rew_mean          | -8.22     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 857       |
|    time_elapsed         | 2790      |
|    total_timesteps      | 109696    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00156  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 89.1      |
|    n_updates            | 8560      |
|    policy_gradient_loss | -2.84e-09 |
|    value_loss           | 152       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.2      |
|    ep_rew_mean          | -7.91     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 858       |
|    time_elapsed         | 2793      |
|    total_timesteps      | 109824    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00158  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 61.6      |
|    n_updates            | 8570      |
|    policy_gradient_loss | 4.89e-10  |
|    value_loss           | 115       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.2      |
|    ep_rew_mean          | -7.91     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 859       |
|    time_elapsed         | 2796      |
|    total_timesteps      | 109952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0016   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55.2      |
|    n_updates            | 8580      |
|    policy_gradient_loss | -7.22e-09 |
|    value_loss           | 108       |
---------------------------------------
Num timesteps: 110000
Best mean reward: -1.70 - Last mean reward per episode: -12.37
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=110000, episode_reward=9.20 +/- 7.17
Episode length: 61.60 +/- 5.43
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 61.6      |
|    mean_reward          | 9.2       |
| time/                   |           |
|    total_timesteps      | 110000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00162  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.6      |
|    n_updates            | 8590      |
|    policy_gradient_loss | -2.42e-09 |
|    value_loss           | 69.3      |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 83.3     |
|    ep_rew_mean     | -7.97    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 860      |
|    time_elapsed    | 2801     |
|    total_timesteps | 110080   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.8     |
|    ep_rew_mean          | -7.6     |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 861      |
|    time_elapsed         | 2804     |
|    total_timesteps      | 110208   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00163 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 36       |
|    n_updates            | 8600     |
|    policy_gradient_loss | -1.4e-09 |
|    value_loss           | 74.2     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.2      |
|    ep_rew_mean          | -7.29     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 862       |
|    time_elapsed         | 2807      |
|    total_timesteps      | 110336    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00164  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 56.9      |
|    n_updates            | 8610      |
|    policy_gradient_loss | -4.19e-10 |
|    value_loss           | 108       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.9      |
|    ep_rew_mean          | -6.94     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 863       |
|    time_elapsed         | 2810      |
|    total_timesteps      | 110464    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00166  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.9      |
|    n_updates            | 8620      |
|    policy_gradient_loss | -1.16e-10 |
|    value_loss           | 73.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.9      |
|    ep_rew_mean          | -6.94     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 864       |
|    time_elapsed         | 2814      |
|    total_timesteps      | 110592    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00168  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 69.5      |
|    n_updates            | 8630      |
|    policy_gradient_loss | -1.12e-09 |
|    value_loss           | 151       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.7     |
|    ep_rew_mean          | -7.34    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 865      |
|    time_elapsed         | 2818     |
|    total_timesteps      | 110720   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0017  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 33.5     |
|    n_updates            | 8640     |
|    policy_gradient_loss | 1.5e-08  |
|    value_loss           | 69       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.5      |
|    ep_rew_mean          | -7.25     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 866       |
|    time_elapsed         | 2821      |
|    total_timesteps      | 110848    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0017   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 83.6      |
|    n_updates            | 8650      |
|    policy_gradient_loss | -3.05e-09 |
|    value_loss           | 131       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.2     |
|    ep_rew_mean          | -7.09    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 867      |
|    time_elapsed         | 2824     |
|    total_timesteps      | 110976   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00171 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 35.8     |
|    n_updates            | 8660     |
|    policy_gradient_loss | 2.44e-09 |
|    value_loss           | 74.2     |
--------------------------------------
Num timesteps: 111000
Best mean reward: -1.70 - Last mean reward per episode: -7.07
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.5     |
|    ep_rew_mean          | -1.75    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 868      |
|    time_elapsed         | 2827     |
|    total_timesteps      | 111104   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00172 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 39.4     |
|    n_updates            | 8670     |
|    policy_gradient_loss | 2.14e-09 |
|    value_loss           | 72.8     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.5      |
|    ep_rew_mean          | -1.95     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 869       |
|    time_elapsed         | 2830      |
|    total_timesteps      | 111232    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00176  |
|    explained_variance   | 2.38e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 65.7      |
|    n_updates            | 8680      |
|    policy_gradient_loss | -4.47e-09 |
|    value_loss           | 144       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 72.3         |
|    ep_rew_mean          | -2.26        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 870          |
|    time_elapsed         | 2833         |
|    total_timesteps      | 111360       |
| train/                  |              |
|    approx_kl            | 0.0054601156 |
|    clip_fraction        | 0.00625      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00094     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 34.5         |
|    n_updates            | 8690         |
|    policy_gradient_loss | -0.0012      |
|    value_loss           | 80.9         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.3      |
|    ep_rew_mean          | -2.26     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 871       |
|    time_elapsed         | 2836      |
|    total_timesteps      | 111488    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000526 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 42.6      |
|    n_updates            | 8700      |
|    policy_gradient_loss | 5.12e-10  |
|    value_loss           | 71.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.5      |
|    ep_rew_mean          | -2.46     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 872       |
|    time_elapsed         | 2839      |
|    total_timesteps      | 111616    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000495 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.3      |
|    n_updates            | 8710      |
|    policy_gradient_loss | 1.77e-09  |
|    value_loss           | 71.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.7      |
|    ep_rew_mean          | -2.67     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 873       |
|    time_elapsed         | 2842      |
|    total_timesteps      | 111744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000492 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45.6      |
|    n_updates            | 8720      |
|    policy_gradient_loss | 4.66e-11  |
|    value_loss           | 113       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.2      |
|    ep_rew_mean          | -2.5      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 874       |
|    time_elapsed         | 2846      |
|    total_timesteps      | 111872    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000493 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.6      |
|    n_updates            | 8730      |
|    policy_gradient_loss | -1.86e-09 |
|    value_loss           | 85.1      |
---------------------------------------
Num timesteps: 112000
Best mean reward: -1.70 - Last mean reward per episode: -1.79
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.1      |
|    ep_rew_mean          | -2.44     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 875       |
|    time_elapsed         | 2849      |
|    total_timesteps      | 112000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000494 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 57.3      |
|    n_updates            | 8740      |
|    policy_gradient_loss | 1.58e-09  |
|    value_loss           | 92.8      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.4      |
|    ep_rew_mean          | -2.59     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 876       |
|    time_elapsed         | 2852      |
|    total_timesteps      | 112128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000495 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 28        |
|    n_updates            | 8750      |
|    policy_gradient_loss | -6.71e-09 |
|    value_loss           | 67.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.2      |
|    ep_rew_mean          | -2.61     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 877       |
|    time_elapsed         | 2855      |
|    total_timesteps      | 112256    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000495 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.1      |
|    n_updates            | 8760      |
|    policy_gradient_loss | -3.17e-09 |
|    value_loss           | 82.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.2      |
|    ep_rew_mean          | -2.62     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 878       |
|    time_elapsed         | 2858      |
|    total_timesteps      | 112384    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000496 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 70.3      |
|    n_updates            | 8770      |
|    policy_gradient_loss | 7.59e-09  |
|    value_loss           | 103       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.2      |
|    ep_rew_mean          | -2.62     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 879       |
|    time_elapsed         | 2861      |
|    total_timesteps      | 112512    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000497 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53        |
|    n_updates            | 8780      |
|    policy_gradient_loss | 4.7e-09   |
|    value_loss           | 82.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.8      |
|    ep_rew_mean          | -2.4      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 880       |
|    time_elapsed         | 2864      |
|    total_timesteps      | 112640    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000498 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.6      |
|    n_updates            | 8790      |
|    policy_gradient_loss | -1.4e-10  |
|    value_loss           | 87.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.8      |
|    ep_rew_mean          | -2.4      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 881       |
|    time_elapsed         | 2867      |
|    total_timesteps      | 112768    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000499 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 76.1      |
|    n_updates            | 8800      |
|    policy_gradient_loss | -6.19e-09 |
|    value_loss           | 163       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.3      |
|    ep_rew_mean          | -2.73     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 882       |
|    time_elapsed         | 2870      |
|    total_timesteps      | 112896    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000499 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 35.2      |
|    n_updates            | 8810      |
|    policy_gradient_loss | 6.19e-09  |
|    value_loss           | 78.4      |
---------------------------------------
Num timesteps: 113000
Best mean reward: -1.70 - Last mean reward per episode: -2.29
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.4      |
|    ep_rew_mean          | -2.9      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 883       |
|    time_elapsed         | 2873      |
|    total_timesteps      | 113024    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0005   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 65.6      |
|    n_updates            | 8820      |
|    policy_gradient_loss | -3.49e-09 |
|    value_loss           | 119       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72        |
|    ep_rew_mean          | -2.67     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 884       |
|    time_elapsed         | 2876      |
|    total_timesteps      | 113152    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000501 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 39.6      |
|    n_updates            | 8830      |
|    policy_gradient_loss | -2.47e-09 |
|    value_loss           | 88.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72        |
|    ep_rew_mean          | -2.48     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 885       |
|    time_elapsed         | 2879      |
|    total_timesteps      | 113280    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000503 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 68.3      |
|    n_updates            | 8840      |
|    policy_gradient_loss | -8.38e-10 |
|    value_loss           | 120       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.1      |
|    ep_rew_mean          | -2.76     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 886       |
|    time_elapsed         | 2882      |
|    total_timesteps      | 113408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000504 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 76.9      |
|    n_updates            | 8850      |
|    policy_gradient_loss | 1.82e-09  |
|    value_loss           | 165       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.9      |
|    ep_rew_mean          | -2.23     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 887       |
|    time_elapsed         | 2885      |
|    total_timesteps      | 113536    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000505 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.5      |
|    n_updates            | 8860      |
|    policy_gradient_loss | -7.08e-09 |
|    value_loss           | 76.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.9      |
|    ep_rew_mean          | -2.23     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 888       |
|    time_elapsed         | 2888      |
|    total_timesteps      | 113664    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000506 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 68        |
|    n_updates            | 8870      |
|    policy_gradient_loss | 2.24e-09  |
|    value_loss           | 123       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.1      |
|    ep_rew_mean          | -3.04     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 889       |
|    time_elapsed         | 2892      |
|    total_timesteps      | 113792    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000507 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 32.6      |
|    n_updates            | 8880      |
|    policy_gradient_loss | -8.36e-08 |
|    value_loss           | 62.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.1      |
|    ep_rew_mean          | -2.94     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 890       |
|    time_elapsed         | 2895      |
|    total_timesteps      | 113920    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000508 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48        |
|    n_updates            | 8890      |
|    policy_gradient_loss | 3.31e-09  |
|    value_loss           | 87.1      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 114000
Best mean reward: -1.70 - Last mean reward per episode: -2.56
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.1      |
|    ep_rew_mean          | -2.96     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 891       |
|    time_elapsed         | 2899      |
|    total_timesteps      | 114048    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000509 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 73.3      |
|    n_updates            | 8900      |
|    policy_gradient_loss | 3.73e-10  |
|    value_loss           | 120       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72        |
|    ep_rew_mean          | -3.08     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 892       |
|    time_elapsed         | 2901      |
|    total_timesteps      | 114176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00051  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 37.2      |
|    n_updates            | 8910      |
|    policy_gradient_loss | -5.42e-09 |
|    value_loss           | 68        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.8      |
|    ep_rew_mean          | -2.91     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 893       |
|    time_elapsed         | 2905      |
|    total_timesteps      | 114304    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000511 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 46.8      |
|    n_updates            | 8920      |
|    policy_gradient_loss | -3.82e-09 |
|    value_loss           | 94.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.9      |
|    ep_rew_mean          | -2.96     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 894       |
|    time_elapsed         | 2908      |
|    total_timesteps      | 114432    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000512 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 68.3      |
|    n_updates            | 8930      |
|    policy_gradient_loss | 4.66e-11  |
|    value_loss           | 113       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.3      |
|    ep_rew_mean          | -3.08     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 895       |
|    time_elapsed         | 2911      |
|    total_timesteps      | 114560    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000512 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 34.9      |
|    n_updates            | 8940      |
|    policy_gradient_loss | -2.07e-09 |
|    value_loss           | 68.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.1      |
|    ep_rew_mean          | -2.97     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 896       |
|    time_elapsed         | 2915      |
|    total_timesteps      | 114688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000513 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 85.4      |
|    n_updates            | 8950      |
|    policy_gradient_loss | 5.45e-09  |
|    value_loss           | 128       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.5      |
|    ep_rew_mean          | -2.44     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 897       |
|    time_elapsed         | 2918      |
|    total_timesteps      | 114816    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000514 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.7      |
|    n_updates            | 8960      |
|    policy_gradient_loss | 3.03e-10  |
|    value_loss           | 67.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.3      |
|    ep_rew_mean          | -2.87     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 898       |
|    time_elapsed         | 2921      |
|    total_timesteps      | 114944    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000514 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 89.7      |
|    n_updates            | 8970      |
|    policy_gradient_loss | -1.3e-09  |
|    value_loss           | 168       |
---------------------------------------
Num timesteps: 115000
Best mean reward: -1.70 - Last mean reward per episode: -2.21
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=115000, episode_reward=-98.00 +/- 201.05
Episode length: 256.00 +/- 372.46
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 256       |
|    mean_reward          | -98       |
| time/                   |           |
|    total_timesteps      | 115000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000515 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.8      |
|    n_updates            | 8980      |
|    policy_gradient_loss | -7.36e-09 |
|    value_loss           | 69.3      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 72.2     |
|    ep_rew_mean     | -2.89    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 899      |
|    time_elapsed    | 2931     |
|    total_timesteps | 115072   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.8      |
|    ep_rew_mean          | -2.62     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 900       |
|    time_elapsed         | 2934      |
|    total_timesteps      | 115200    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000515 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.1      |
|    n_updates            | 8990      |
|    policy_gradient_loss | 3.96e-10  |
|    value_loss           | 90        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.9      |
|    ep_rew_mean          | -2.56     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 901       |
|    time_elapsed         | 2937      |
|    total_timesteps      | 115328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000518 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 64.8      |
|    n_updates            | 9000      |
|    policy_gradient_loss | 2.14e-09  |
|    value_loss           | 115       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71        |
|    ep_rew_mean          | -2.1      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 902       |
|    time_elapsed         | 2940      |
|    total_timesteps      | 115456    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000519 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45.6      |
|    n_updates            | 9010      |
|    policy_gradient_loss | 2.79e-09  |
|    value_loss           | 112       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.3      |
|    ep_rew_mean          | -2.23     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 903       |
|    time_elapsed         | 2943      |
|    total_timesteps      | 115584    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00052  |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 37.2      |
|    n_updates            | 9020      |
|    policy_gradient_loss | -9.78e-10 |
|    value_loss           | 77.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.8      |
|    ep_rew_mean          | -2.31     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 904       |
|    time_elapsed         | 2946      |
|    total_timesteps      | 115712    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000521 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 65.2      |
|    n_updates            | 9030      |
|    policy_gradient_loss | 1.14e-09  |
|    value_loss           | 160       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.2      |
|    ep_rew_mean          | -2.3      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 905       |
|    time_elapsed         | 2950      |
|    total_timesteps      | 115840    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000522 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 59        |
|    n_updates            | 9040      |
|    policy_gradient_loss | -1.4e-09  |
|    value_loss           | 145       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.1      |
|    ep_rew_mean          | -2.15     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 906       |
|    time_elapsed         | 2954      |
|    total_timesteps      | 115968    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000523 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 81.9      |
|    n_updates            | 9050      |
|    policy_gradient_loss | 1.68e-09  |
|    value_loss           | 140       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 116000
Best mean reward: -1.70 - Last mean reward per episode: -6.80
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.8      |
|    ep_rew_mean          | -2.1      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 907       |
|    time_elapsed         | 2957      |
|    total_timesteps      | 116096    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000525 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.9      |
|    n_updates            | 9060      |
|    policy_gradient_loss | 3.17e-09  |
|    value_loss           | 117       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.1      |
|    ep_rew_mean          | -2.15     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 908       |
|    time_elapsed         | 2960      |
|    total_timesteps      | 116224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000527 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.6      |
|    n_updates            | 9070      |
|    policy_gradient_loss | -2.47e-09 |
|    value_loss           | 88.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.1      |
|    ep_rew_mean          | -2.64     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 909       |
|    time_elapsed         | 2963      |
|    total_timesteps      | 116352    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000529 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 60.3      |
|    n_updates            | 9080      |
|    policy_gradient_loss | -2.42e-09 |
|    value_loss           | 117       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.3      |
|    ep_rew_mean          | -2.74     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 910       |
|    time_elapsed         | 2967      |
|    total_timesteps      | 116480    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00053  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.9      |
|    n_updates            | 9090      |
|    policy_gradient_loss | -7.12e-09 |
|    value_loss           | 80.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.5      |
|    ep_rew_mean          | -2.65     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 911       |
|    time_elapsed         | 2969      |
|    total_timesteps      | 116608    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000531 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.5      |
|    n_updates            | 9100      |
|    policy_gradient_loss | -1.49e-08 |
|    value_loss           | 66.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.2      |
|    ep_rew_mean          | -2.68     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 912       |
|    time_elapsed         | 2972      |
|    total_timesteps      | 116736    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000531 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 87.2      |
|    n_updates            | 9110      |
|    policy_gradient_loss | 7.57e-10  |
|    value_loss           | 173       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.2      |
|    ep_rew_mean          | -2.77     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 913       |
|    time_elapsed         | 2975      |
|    total_timesteps      | 116864    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000533 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 43.6      |
|    n_updates            | 9120      |
|    policy_gradient_loss | 2.37e-09  |
|    value_loss           | 89.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.3      |
|    ep_rew_mean          | -2.66     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 914       |
|    time_elapsed         | 2978      |
|    total_timesteps      | 116992    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000535 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.3      |
|    n_updates            | 9130      |
|    policy_gradient_loss | 2.79e-10  |
|    value_loss           | 84.5      |
---------------------------------------
Num timesteps: 117000
Best mean reward: -1.70 - Last mean reward per episode: -7.56
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.4      |
|    ep_rew_mean          | -2.72     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 915       |
|    time_elapsed         | 2981      |
|    total_timesteps      | 117120    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000536 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 67.8      |
|    n_updates            | 9140      |
|    policy_gradient_loss | -6.31e-09 |
|    value_loss           | 146       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.4      |
|    ep_rew_mean          | -3.21     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 916       |
|    time_elapsed         | 2984      |
|    total_timesteps      | 117248    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000536 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 94.5      |
|    n_updates            | 9150      |
|    policy_gradient_loss | -3.56e-09 |
|    value_loss           | 156       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.2      |
|    ep_rew_mean          | -3.2      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 917       |
|    time_elapsed         | 2987      |
|    total_timesteps      | 117376    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000536 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 38.4      |
|    n_updates            | 9160      |
|    policy_gradient_loss | -9.71e-09 |
|    value_loss           | 80.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.4      |
|    ep_rew_mean          | -3.19     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 918       |
|    time_elapsed         | 2990      |
|    total_timesteps      | 117504    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000537 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43        |
|    n_updates            | 9170      |
|    policy_gradient_loss | 4.54e-09  |
|    value_loss           | 82.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.3      |
|    ep_rew_mean          | -3.27     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 919       |
|    time_elapsed         | 2993      |
|    total_timesteps      | 117632    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00054  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 60.1      |
|    n_updates            | 9180      |
|    policy_gradient_loss | 4.19e-09  |
|    value_loss           | 144       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.7      |
|    ep_rew_mean          | -3.35     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 920       |
|    time_elapsed         | 2996      |
|    total_timesteps      | 117760    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000542 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 37.3      |
|    n_updates            | 9190      |
|    policy_gradient_loss | -5.26e-09 |
|    value_loss           | 80.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75        |
|    ep_rew_mean          | -3.49     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 921       |
|    time_elapsed         | 2999      |
|    total_timesteps      | 117888    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000546 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 65.6      |
|    n_updates            | 9200      |
|    policy_gradient_loss | -9.08e-10 |
|    value_loss           | 131       |
---------------------------------------
Num timesteps: 118000
Best mean reward: -1.70 - Last mean reward per episode: -7.62
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.1      |
|    ep_rew_mean          | -3.65     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 922       |
|    time_elapsed         | 3002      |
|    total_timesteps      | 118016    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000549 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 33        |
|    n_updates            | 9210      |
|    policy_gradient_loss | 9.03e-09  |
|    value_loss           | 67.5      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.1      |
|    ep_rew_mean          | -3.65     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 923       |
|    time_elapsed         | 3005      |
|    total_timesteps      | 118144    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00055  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 72.1      |
|    n_updates            | 9220      |
|    policy_gradient_loss | -5.45e-09 |
|    value_loss           | 126       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -4.01     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 924       |
|    time_elapsed         | 3010      |
|    total_timesteps      | 118272    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000552 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 28.9      |
|    n_updates            | 9230      |
|    policy_gradient_loss | -2.81e-08 |
|    value_loss           | 63.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -4.11     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 925       |
|    time_elapsed         | 3014      |
|    total_timesteps      | 118400    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000552 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 48.2      |
|    n_updates            | 9240      |
|    policy_gradient_loss | 3.28e-09  |
|    value_loss           | 102       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75        |
|    ep_rew_mean          | -3.71     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 926       |
|    time_elapsed         | 3016      |
|    total_timesteps      | 118528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000554 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 53.8      |
|    n_updates            | 9250      |
|    policy_gradient_loss | 4.42e-09  |
|    value_loss           | 83.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.5      |
|    ep_rew_mean          | -3.96     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 927       |
|    time_elapsed         | 3019      |
|    total_timesteps      | 118656    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000556 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.6      |
|    n_updates            | 9260      |
|    policy_gradient_loss | -5.36e-09 |
|    value_loss           | 88.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -4.29     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 928       |
|    time_elapsed         | 3022      |
|    total_timesteps      | 118784    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000558 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30.6      |
|    n_updates            | 9270      |
|    policy_gradient_loss | 3.91e-09  |
|    value_loss           | 68        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.5      |
|    ep_rew_mean          | -4.05     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 929       |
|    time_elapsed         | 3025      |
|    total_timesteps      | 118912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000559 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.2      |
|    n_updates            | 9280      |
|    policy_gradient_loss | 2.17e-09  |
|    value_loss           | 84.2      |
---------------------------------------
Num timesteps: 119000
Best mean reward: -1.70 - Last mean reward per episode: -8.73
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.6      |
|    ep_rew_mean          | -3.98     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 930       |
|    time_elapsed         | 3029      |
|    total_timesteps      | 119040    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00056  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 70.3      |
|    n_updates            | 9290      |
|    policy_gradient_loss | -1.23e-09 |
|    value_loss           | 127       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.4      |
|    ep_rew_mean          | -4        |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 931       |
|    time_elapsed         | 3031      |
|    total_timesteps      | 119168    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000562 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 54.1      |
|    n_updates            | 9300      |
|    policy_gradient_loss | -3.82e-09 |
|    value_loss           | 118       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.6      |
|    ep_rew_mean          | -3.89     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 932       |
|    time_elapsed         | 3034      |
|    total_timesteps      | 119296    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000563 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.6      |
|    n_updates            | 9310      |
|    policy_gradient_loss | 7.52e-09  |
|    value_loss           | 77.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.7      |
|    ep_rew_mean          | -3.75     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 933       |
|    time_elapsed         | 3038      |
|    total_timesteps      | 119424    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000564 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 79.3      |
|    n_updates            | 9320      |
|    policy_gradient_loss | 2.7e-09   |
|    value_loss           | 172       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.6      |
|    ep_rew_mean          | -3.71     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 934       |
|    time_elapsed         | 3042      |
|    total_timesteps      | 119552    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000564 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 88.2      |
|    n_updates            | 9330      |
|    policy_gradient_loss | -2.77e-09 |
|    value_loss           | 153       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.2      |
|    ep_rew_mean          | -4        |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 935       |
|    time_elapsed         | 3045      |
|    total_timesteps      | 119680    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000565 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.7      |
|    n_updates            | 9340      |
|    policy_gradient_loss | 1.34e-08  |
|    value_loss           | 74.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -3.78     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 936       |
|    time_elapsed         | 3048      |
|    total_timesteps      | 119808    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000566 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.1      |
|    n_updates            | 9350      |
|    policy_gradient_loss | 4.42e-10  |
|    value_loss           | 98        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.4      |
|    ep_rew_mean          | -3.59     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 937       |
|    time_elapsed         | 3052      |
|    total_timesteps      | 119936    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000566 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 57.4      |
|    n_updates            | 9360      |
|    policy_gradient_loss | 9.31e-10  |
|    value_loss           | 121       |
---------------------------------------
Num timesteps: 120000
Best mean reward: -1.70 - Last mean reward per episode: -8.15
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=120000, episode_reward=-19.00 +/- 44.87
Episode length: 106.00 +/- 85.16
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 106       |
|    mean_reward          | -19       |
| time/                   |           |
|    total_timesteps      | 120000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000568 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.8      |
|    n_updates            | 9370      |
|    policy_gradient_loss | -2.75e-09 |
|    value_loss           | 84.1      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.2     |
|    ep_rew_mean     | -3.32    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 938      |
|    time_elapsed    | 3058     |
|    total_timesteps | 120064   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.6      |
|    ep_rew_mean          | -3.5      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 939       |
|    time_elapsed         | 3061      |
|    total_timesteps      | 120192    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000571 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 74.7      |
|    n_updates            | 9380      |
|    policy_gradient_loss | -4.52e-09 |
|    value_loss           | 170       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.5      |
|    ep_rew_mean          | -3.67     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 940       |
|    time_elapsed         | 3064      |
|    total_timesteps      | 120320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000572 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 37        |
|    n_updates            | 9390      |
|    policy_gradient_loss | -1.58e-09 |
|    value_loss           | 68.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.6      |
|    ep_rew_mean          | -3.72     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 941       |
|    time_elapsed         | 3067      |
|    total_timesteps      | 120448    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000573 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.9      |
|    n_updates            | 9400      |
|    policy_gradient_loss | -6.29e-09 |
|    value_loss           | 79.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.5      |
|    ep_rew_mean          | -3.65     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 942       |
|    time_elapsed         | 3070      |
|    total_timesteps      | 120576    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000575 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.8      |
|    n_updates            | 9410      |
|    policy_gradient_loss | -4.66e-10 |
|    value_loss           | 93.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.9      |
|    ep_rew_mean          | -3.96     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 943       |
|    time_elapsed         | 3074      |
|    total_timesteps      | 120704    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000578 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 42.9      |
|    n_updates            | 9420      |
|    policy_gradient_loss | 4.19e-10  |
|    value_loss           | 127       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -4        |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 944       |
|    time_elapsed         | 3076      |
|    total_timesteps      | 120832    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000581 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 44.2      |
|    n_updates            | 9430      |
|    policy_gradient_loss | -6.98e-11 |
|    value_loss           | 94.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.6      |
|    ep_rew_mean          | -4.29     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 945       |
|    time_elapsed         | 3079      |
|    total_timesteps      | 120960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000581 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 70.9      |
|    n_updates            | 9440      |
|    policy_gradient_loss | 7.82e-09  |
|    value_loss           | 165       |
---------------------------------------
Num timesteps: 121000
Best mean reward: -1.70 - Last mean reward per episode: -9.21
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.8      |
|    ep_rew_mean          | -4.38     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 946       |
|    time_elapsed         | 3083      |
|    total_timesteps      | 121088    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000582 |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 40.3      |
|    n_updates            | 9450      |
|    policy_gradient_loss | -8.38e-10 |
|    value_loss           | 71.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.3      |
|    ep_rew_mean          | -4.54     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 947       |
|    time_elapsed         | 3087      |
|    total_timesteps      | 121216    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000582 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 31.2      |
|    n_updates            | 9460      |
|    policy_gradient_loss | -2.28e-09 |
|    value_loss           | 69.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -3.88     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 948       |
|    time_elapsed         | 3091      |
|    total_timesteps      | 121344    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000583 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 82.5      |
|    n_updates            | 9470      |
|    policy_gradient_loss | -1.14e-09 |
|    value_loss           | 168       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.5      |
|    ep_rew_mean          | -4.12     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 949       |
|    time_elapsed         | 3094      |
|    total_timesteps      | 121472    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000584 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 39.5      |
|    n_updates            | 9480      |
|    policy_gradient_loss | 2.51e-09  |
|    value_loss           | 91.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -3.98     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 950       |
|    time_elapsed         | 3097      |
|    total_timesteps      | 121600    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000586 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.4      |
|    n_updates            | 9490      |
|    policy_gradient_loss | 7.78e-09  |
|    value_loss           | 73.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -3.92     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 951       |
|    time_elapsed         | 3100      |
|    total_timesteps      | 121728    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000587 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.2      |
|    n_updates            | 9500      |
|    policy_gradient_loss | -3.84e-09 |
|    value_loss           | 84.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -3.92     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 952       |
|    time_elapsed         | 3103      |
|    total_timesteps      | 121856    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000589 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36        |
|    n_updates            | 9510      |
|    policy_gradient_loss | -2.98e-09 |
|    value_loss           | 78.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.8     |
|    ep_rew_mean          | -3.92    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 953      |
|    time_elapsed         | 3106     |
|    total_timesteps      | 121984   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00059 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 29.4     |
|    n_updates            | 9520     |
|    policy_gradient_loss | 5.59e-09 |
|    value_loss           | 59.8     |
--------------------------------------
Num timesteps: 122000
Best mean reward: -1.70 - Last mean reward per episode: -9.41
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -3.92     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 954       |
|    time_elapsed         | 3109      |
|    total_timesteps      | 122112    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00059  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 29        |
|    n_updates            | 9530      |
|    policy_gradient_loss | 7.07e-08  |
|    value_loss           | 58.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -3.92     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 955       |
|    time_elapsed         | 3113      |
|    total_timesteps      | 122240    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000591 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 24.8      |
|    n_updates            | 9540      |
|    policy_gradient_loss | -5.14e-08 |
|    value_loss           | 56.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -3.92     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 956       |
|    time_elapsed         | 3116      |
|    total_timesteps      | 122368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000591 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 18.2      |
|    n_updates            | 9550      |
|    policy_gradient_loss | -4.41e-08 |
|    value_loss           | 47        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -3.92     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 957       |
|    time_elapsed         | 3119      |
|    total_timesteps      | 122496    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000591 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 18.7      |
|    n_updates            | 9560      |
|    policy_gradient_loss | -9.72e-08 |
|    value_loss           | 45.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -3.92     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 958       |
|    time_elapsed         | 3122      |
|    total_timesteps      | 122624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000591 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 22.5      |
|    n_updates            | 9570      |
|    policy_gradient_loss | -2.48e-08 |
|    value_loss           | 48.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.2      |
|    ep_rew_mean          | -8.93     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 959       |
|    time_elapsed         | 3125      |
|    total_timesteps      | 122752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000591 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 22.5      |
|    n_updates            | 9580      |
|    policy_gradient_loss | 1.17e-08  |
|    value_loss           | 48.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.6      |
|    ep_rew_mean          | -9.09     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 960       |
|    time_elapsed         | 3129      |
|    total_timesteps      | 122880    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000593 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 32.2      |
|    n_updates            | 9590      |
|    policy_gradient_loss | 3.49e-09  |
|    value_loss           | 77.6      |
---------------------------------------
Num timesteps: 123000
Best mean reward: -1.70 - Last mean reward per episode: -14.30
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.3      |
|    ep_rew_mean          | -9.07     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 961       |
|    time_elapsed         | 3131      |
|    total_timesteps      | 123008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000595 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 64.8      |
|    n_updates            | 9600      |
|    policy_gradient_loss | -8.66e-09 |
|    value_loss           | 127       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.6      |
|    ep_rew_mean          | -8.71     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 962       |
|    time_elapsed         | 3134      |
|    total_timesteps      | 123136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000597 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 65.5      |
|    n_updates            | 9610      |
|    policy_gradient_loss | -3.82e-09 |
|    value_loss           | 125       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.5      |
|    ep_rew_mean          | -8.66     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 963       |
|    time_elapsed         | 3136      |
|    total_timesteps      | 123264    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000599 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 80.2      |
|    n_updates            | 9620      |
|    policy_gradient_loss | 4.19e-10  |
|    value_loss           | 159       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.7      |
|    ep_rew_mean          | -8.77     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 964       |
|    time_elapsed         | 3140      |
|    total_timesteps      | 123392    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000602 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.5      |
|    n_updates            | 9630      |
|    policy_gradient_loss | 2.65e-09  |
|    value_loss           | 122       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.7      |
|    ep_rew_mean          | -8.77     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 965       |
|    time_elapsed         | 3144      |
|    total_timesteps      | 123520    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000605 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 96.8      |
|    n_updates            | 9640      |
|    policy_gradient_loss | -2.79e-10 |
|    value_loss           | 184       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86        |
|    ep_rew_mean          | -9.29     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 966       |
|    time_elapsed         | 3149      |
|    total_timesteps      | 123648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000609 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 24.1      |
|    n_updates            | 9650      |
|    policy_gradient_loss | -3.39e-08 |
|    value_loss           | 50.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86        |
|    ep_rew_mean          | -9.29     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 967       |
|    time_elapsed         | 3152      |
|    total_timesteps      | 123776    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000611 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 86        |
|    n_updates            | 9660      |
|    policy_gradient_loss | -3.45e-09 |
|    value_loss           | 158       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.4      |
|    ep_rew_mean          | -9.61     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 968       |
|    time_elapsed         | 3155      |
|    total_timesteps      | 123904    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000611 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 27.2      |
|    n_updates            | 9670      |
|    policy_gradient_loss | -5.12e-10 |
|    value_loss           | 86        |
---------------------------------------
Num timesteps: 124000
Best mean reward: -1.70 - Last mean reward per episode: -10.81
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.3      |
|    ep_rew_mean          | -9.93     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 969       |
|    time_elapsed         | 3158      |
|    total_timesteps      | 124032    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000612 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 52.4      |
|    n_updates            | 9680      |
|    policy_gradient_loss | -2.79e-09 |
|    value_loss           | 122       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.5      |
|    ep_rew_mean          | -10.2     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 970       |
|    time_elapsed         | 3162      |
|    total_timesteps      | 124160    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000615 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 56.8      |
|    n_updates            | 9690      |
|    policy_gradient_loss | -3.26e-10 |
|    value_loss           | 121       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.8      |
|    ep_rew_mean          | -10.3     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 971       |
|    time_elapsed         | 3164      |
|    total_timesteps      | 124288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000619 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 69        |
|    n_updates            | 9700      |
|    policy_gradient_loss | -7.17e-09 |
|    value_loss           | 114       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.9      |
|    ep_rew_mean          | -10.4     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 972       |
|    time_elapsed         | 3168      |
|    total_timesteps      | 124416    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000621 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.3      |
|    n_updates            | 9710      |
|    policy_gradient_loss | 5.87e-09  |
|    value_loss           | 77.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.2      |
|    ep_rew_mean          | -10.5     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 973       |
|    time_elapsed         | 3171      |
|    total_timesteps      | 124544    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000622 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 89.8      |
|    n_updates            | 9720      |
|    policy_gradient_loss | 4.19e-09  |
|    value_loss           | 158       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.7      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 974       |
|    time_elapsed         | 3174      |
|    total_timesteps      | 124672    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000623 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 56.6      |
|    n_updates            | 9730      |
|    policy_gradient_loss | -6.98e-10 |
|    value_loss           | 118       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88        |
|    ep_rew_mean          | -10.9     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 975       |
|    time_elapsed         | 3178      |
|    total_timesteps      | 124800    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000626 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 54.1      |
|    n_updates            | 9740      |
|    policy_gradient_loss | -9.78e-10 |
|    value_loss           | 121       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.6      |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 976       |
|    time_elapsed         | 3181      |
|    total_timesteps      | 124928    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000631 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.5      |
|    n_updates            | 9750      |
|    policy_gradient_loss | 8.57e-09  |
|    value_loss           | 77        |
---------------------------------------
Num timesteps: 125000
Best mean reward: -1.70 - Last mean reward per episode: -11.81
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=125000, episode_reward=-5.10 +/- 7.84
Episode length: 78.20 +/- 25.19
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 78.2      |
|    mean_reward          | -5.1      |
| time/                   |           |
|    total_timesteps      | 125000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000633 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38        |
|    n_updates            | 9760      |
|    policy_gradient_loss | 3.86e-09  |
|    value_loss           | 78.1      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 88.8     |
|    ep_rew_mean     | -11.3    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 977      |
|    time_elapsed    | 3186     |
|    total_timesteps | 125056   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.6      |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 978       |
|    time_elapsed         | 3189      |
|    total_timesteps      | 125184    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000636 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 61.6      |
|    n_updates            | 9770      |
|    policy_gradient_loss | 1.56e-09  |
|    value_loss           | 91.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.3      |
|    ep_rew_mean          | -10.9     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 979       |
|    time_elapsed         | 3192      |
|    total_timesteps      | 125312    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000637 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.7      |
|    n_updates            | 9780      |
|    policy_gradient_loss | -4.72e-08 |
|    value_loss           | 74        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.6      |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 980       |
|    time_elapsed         | 3196      |
|    total_timesteps      | 125440    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000638 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 81.8      |
|    n_updates            | 9790      |
|    policy_gradient_loss | 4.38e-09  |
|    value_loss           | 152       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.6      |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 981       |
|    time_elapsed         | 3199      |
|    total_timesteps      | 125568    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00064  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 85.8      |
|    n_updates            | 9800      |
|    policy_gradient_loss | -2.61e-09 |
|    value_loss           | 159       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.6      |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 982       |
|    time_elapsed         | 3202      |
|    total_timesteps      | 125696    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000641 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 87.1      |
|    n_updates            | 9810      |
|    policy_gradient_loss | 2.42e-09  |
|    value_loss           | 159       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.5      |
|    ep_rew_mean          | -11.1     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 983       |
|    time_elapsed         | 3206      |
|    total_timesteps      | 125824    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000641 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 70        |
|    n_updates            | 9820      |
|    policy_gradient_loss | 1.89e-09  |
|    value_loss           | 113       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.7      |
|    ep_rew_mean          | -11.4     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 984       |
|    time_elapsed         | 3209      |
|    total_timesteps      | 125952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000642 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.9      |
|    n_updates            | 9830      |
|    policy_gradient_loss | -1.44e-09 |
|    value_loss           | 82.5      |
---------------------------------------
Num timesteps: 126000
Best mean reward: -1.70 - Last mean reward per episode: -11.99
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.5      |
|    ep_rew_mean          | -11.4     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 985       |
|    time_elapsed         | 3212      |
|    total_timesteps      | 126080    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000644 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 41.8      |
|    n_updates            | 9840      |
|    policy_gradient_loss | -4.1e-09  |
|    value_loss           | 118       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88        |
|    ep_rew_mean          | -11.1     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 986       |
|    time_elapsed         | 3215      |
|    total_timesteps      | 126208    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000646 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 96.4      |
|    n_updates            | 9850      |
|    policy_gradient_loss | -7.5e-09  |
|    value_loss           | 212       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.6      |
|    ep_rew_mean          | -11.1     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 987       |
|    time_elapsed         | 3218      |
|    total_timesteps      | 126336    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000647 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 72.6      |
|    n_updates            | 9860      |
|    policy_gradient_loss | 1.02e-09  |
|    value_loss           | 112       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88        |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 988       |
|    time_elapsed         | 3221      |
|    total_timesteps      | 126464    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000649 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.7      |
|    n_updates            | 9870      |
|    policy_gradient_loss | -6.1e-09  |
|    value_loss           | 107       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88        |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 989       |
|    time_elapsed         | 3224      |
|    total_timesteps      | 126592    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000651 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 66.7      |
|    n_updates            | 9880      |
|    policy_gradient_loss | -1.14e-09 |
|    value_loss           | 115       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.7      |
|    ep_rew_mean          | -12.1     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 990       |
|    time_elapsed         | 3227      |
|    total_timesteps      | 126720    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000654 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 25.4      |
|    n_updates            | 9890      |
|    policy_gradient_loss | 3.44e-08  |
|    value_loss           | 52.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.9      |
|    ep_rew_mean          | -11.8     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 991       |
|    time_elapsed         | 3230      |
|    total_timesteps      | 126848    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000656 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.7      |
|    n_updates            | 9900      |
|    policy_gradient_loss | -2.19e-09 |
|    value_loss           | 107       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.6      |
|    ep_rew_mean          | -11.7     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 992       |
|    time_elapsed         | 3233      |
|    total_timesteps      | 126976    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000657 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48        |
|    n_updates            | 9910      |
|    policy_gradient_loss | -3.49e-09 |
|    value_loss           | 106       |
---------------------------------------
Num timesteps: 127000
Best mean reward: -1.70 - Last mean reward per episode: -11.81
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.1      |
|    ep_rew_mean          | -11.1     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 993       |
|    time_elapsed         | 3236      |
|    total_timesteps      | 127104    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000658 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 54.7      |
|    n_updates            | 9920      |
|    policy_gradient_loss | -1.21e-09 |
|    value_loss           | 106       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.1      |
|    ep_rew_mean          | -11.1     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 994       |
|    time_elapsed         | 3239      |
|    total_timesteps      | 127232    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00066  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 59.6      |
|    n_updates            | 9930      |
|    policy_gradient_loss | -4.66e-11 |
|    value_loss           | 105       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.2      |
|    ep_rew_mean          | -11.6     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 995       |
|    time_elapsed         | 3243      |
|    total_timesteps      | 127360    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000662 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 26.6      |
|    n_updates            | 9940      |
|    policy_gradient_loss | -4.35e-08 |
|    value_loss           | 55.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.4      |
|    ep_rew_mean          | -11.7     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 996       |
|    time_elapsed         | 3246      |
|    total_timesteps      | 127488    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000663 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 54.1      |
|    n_updates            | 9950      |
|    policy_gradient_loss | 5.26e-09  |
|    value_loss           | 101       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.6      |
|    ep_rew_mean          | -11.5     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 997       |
|    time_elapsed         | 3250      |
|    total_timesteps      | 127616    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000665 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.7      |
|    n_updates            | 9960      |
|    policy_gradient_loss | -8.38e-10 |
|    value_loss           | 79.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.4      |
|    ep_rew_mean          | -11.5     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 998       |
|    time_elapsed         | 3253      |
|    total_timesteps      | 127744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000666 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 110       |
|    n_updates            | 9970      |
|    policy_gradient_loss | 4.66e-11  |
|    value_loss           | 228       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.6      |
|    ep_rew_mean          | -11.6     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 999       |
|    time_elapsed         | 3256      |
|    total_timesteps      | 127872    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000666 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 50.2      |
|    n_updates            | 9980      |
|    policy_gradient_loss | -1.19e-08 |
|    value_loss           | 99.6      |
---------------------------------------
Num timesteps: 128000
Best mean reward: -1.70 - Last mean reward per episode: -12.54
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.9      |
|    ep_rew_mean          | -11.6     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1000      |
|    time_elapsed         | 3259      |
|    total_timesteps      | 128000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000668 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30.6      |
|    n_updates            | 9990      |
|    policy_gradient_loss | -8.85e-10 |
|    value_loss           | 74.6      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.7      |
|    ep_rew_mean          | -11.5     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1001      |
|    time_elapsed         | 3262      |
|    total_timesteps      | 128128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00067  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 70.1      |
|    n_updates            | 10000     |
|    policy_gradient_loss | -1.49e-09 |
|    value_loss           | 181       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.4      |
|    ep_rew_mean          | -11.9     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1002      |
|    time_elapsed         | 3265      |
|    total_timesteps      | 128256    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000672 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 59.2      |
|    n_updates            | 10010     |
|    policy_gradient_loss | 6.98e-10  |
|    value_loss           | 106       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.3      |
|    ep_rew_mean          | -12.1     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1003      |
|    time_elapsed         | 3268      |
|    total_timesteps      | 128384    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000677 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.5      |
|    n_updates            | 10020     |
|    policy_gradient_loss | 1.86e-09  |
|    value_loss           | 72.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.2      |
|    ep_rew_mean          | -11.8     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1004      |
|    time_elapsed         | 3271      |
|    total_timesteps      | 128512    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000681 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55        |
|    n_updates            | 10030     |
|    policy_gradient_loss | 7.96e-09  |
|    value_loss           | 145       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.7      |
|    ep_rew_mean          | -11.6     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1005      |
|    time_elapsed         | 3274      |
|    total_timesteps      | 128640    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000685 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 123       |
|    n_updates            | 10040     |
|    policy_gradient_loss | -4e-09    |
|    value_loss           | 231       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.7      |
|    ep_rew_mean          | -11.6     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1006      |
|    time_elapsed         | 3277      |
|    total_timesteps      | 128768    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000687 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 61.3      |
|    n_updates            | 10050     |
|    policy_gradient_loss | 6.66e-09  |
|    value_loss           | 95.1      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 88.9     |
|    ep_rew_mean          | -11.7    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1007     |
|    time_elapsed         | 3280     |
|    total_timesteps      | 128896   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00069 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 31.7     |
|    n_updates            | 10060    |
|    policy_gradient_loss | 6.52e-10 |
|    value_loss           | 127      |
--------------------------------------
Num timesteps: 129000
Best mean reward: -1.70 - Last mean reward per episode: -11.50
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89        |
|    ep_rew_mean          | -11.7     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1008      |
|    time_elapsed         | 3283      |
|    total_timesteps      | 129024    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000692 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.9      |
|    n_updates            | 10070     |
|    policy_gradient_loss | 1.26e-09  |
|    value_loss           | 70.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.7      |
|    ep_rew_mean          | -11.5     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1009      |
|    time_elapsed         | 3287      |
|    total_timesteps      | 129152    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000693 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 74.5      |
|    n_updates            | 10080     |
|    policy_gradient_loss | -9.31e-11 |
|    value_loss           | 155       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.2      |
|    ep_rew_mean          | -11.3     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1010      |
|    time_elapsed         | 3289      |
|    total_timesteps      | 129280    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000695 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47        |
|    n_updates            | 10090     |
|    policy_gradient_loss | -6.61e-09 |
|    value_loss           | 89.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.8      |
|    ep_rew_mean          | -11.5     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1011      |
|    time_elapsed         | 3292      |
|    total_timesteps      | 129408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000701 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.1      |
|    n_updates            | 10100     |
|    policy_gradient_loss | -9.31e-11 |
|    value_loss           | 86.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.8      |
|    ep_rew_mean          | -11.6     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1012      |
|    time_elapsed         | 3296      |
|    total_timesteps      | 129536    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000707 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 49.9      |
|    n_updates            | 10110     |
|    policy_gradient_loss | -2.33e-10 |
|    value_loss           | 107       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.8      |
|    ep_rew_mean          | -11.6     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1013      |
|    time_elapsed         | 3299      |
|    total_timesteps      | 129664    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000711 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.7      |
|    n_updates            | 10120     |
|    policy_gradient_loss | -1.49e-09 |
|    value_loss           | 83.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.9      |
|    ep_rew_mean          | -11.8     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1014      |
|    time_elapsed         | 3303      |
|    total_timesteps      | 129792    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000716 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 42.7      |
|    n_updates            | 10130     |
|    policy_gradient_loss | -1.72e-09 |
|    value_loss           | 69.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.3      |
|    ep_rew_mean          | -11.6     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1015      |
|    time_elapsed         | 3305      |
|    total_timesteps      | 129920    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000719 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 57.9      |
|    n_updates            | 10140     |
|    policy_gradient_loss | 3.73e-10  |
|    value_loss           | 84.3      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 130000
Best mean reward: -1.70 - Last mean reward per episode: -11.14
Eval num_timesteps=130000, episode_reward=-2.50 +/- 11.20
Episode length: 77.00 +/- 23.27
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 77        |
|    mean_reward          | -2.5      |
| time/                   |           |
|    total_timesteps      | 130000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000723 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.4      |
|    n_updates            | 10150     |
|    policy_gradient_loss | -2.05e-09 |
|    value_loss           | 84.3      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 87.6     |
|    ep_rew_mean     | -11.2    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 1016     |
|    time_elapsed    | 3310     |
|    total_timesteps | 130048   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88        |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1017      |
|    time_elapsed         | 3313      |
|    total_timesteps      | 130176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000729 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 65.8      |
|    n_updates            | 10160     |
|    policy_gradient_loss | -2.93e-09 |
|    value_loss           | 152       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.8      |
|    ep_rew_mean          | -11.1     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1018      |
|    time_elapsed         | 3316      |
|    total_timesteps      | 130304    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000741 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 86.7      |
|    n_updates            | 10170     |
|    policy_gradient_loss | 8.5e-10   |
|    value_loss           | 174       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.8      |
|    ep_rew_mean          | -10.8     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1019      |
|    time_elapsed         | 3320      |
|    total_timesteps      | 130432    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00075  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.9      |
|    n_updates            | 10180     |
|    policy_gradient_loss | -8.43e-09 |
|    value_loss           | 76        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.3      |
|    ep_rew_mean          | -11       |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1020      |
|    time_elapsed         | 3324      |
|    total_timesteps      | 130560    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000756 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 64.5      |
|    n_updates            | 10190     |
|    policy_gradient_loss | -1.82e-09 |
|    value_loss           | 146       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.2      |
|    ep_rew_mean          | -6.19     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1021      |
|    time_elapsed         | 3328      |
|    total_timesteps      | 130688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000765 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.3      |
|    n_updates            | 10200     |
|    policy_gradient_loss | -9.22e-09 |
|    value_loss           | 97.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.7      |
|    ep_rew_mean          | -6.43     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1022      |
|    time_elapsed         | 3331      |
|    total_timesteps      | 130816    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000777 |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 43.2      |
|    n_updates            | 10210     |
|    policy_gradient_loss | -1.38e-08 |
|    value_loss           | 68.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.8      |
|    ep_rew_mean          | -6.5      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1023      |
|    time_elapsed         | 3334      |
|    total_timesteps      | 130944    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000781 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.9      |
|    n_updates            | 10220     |
|    policy_gradient_loss | -5.12e-09 |
|    value_loss           | 70.2      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 131000
Best mean reward: -1.70 - Last mean reward per episode: -6.17
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.3      |
|    ep_rew_mean          | -6.43     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1024      |
|    time_elapsed         | 3338      |
|    total_timesteps      | 131072    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000783 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.3      |
|    n_updates            | 10230     |
|    policy_gradient_loss | 3.73e-10  |
|    value_loss           | 84.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.3      |
|    ep_rew_mean          | -6.43     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1025      |
|    time_elapsed         | 3341      |
|    total_timesteps      | 131200    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000784 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 112       |
|    n_updates            | 10240     |
|    policy_gradient_loss | -4.12e-09 |
|    value_loss           | 215       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.5      |
|    ep_rew_mean          | -6.56     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1026      |
|    time_elapsed         | 3344      |
|    total_timesteps      | 131328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000785 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 36.9      |
|    n_updates            | 10250     |
|    policy_gradient_loss | -6.29e-09 |
|    value_loss           | 71.6      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80.6         |
|    ep_rew_mean          | -6.69        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 1027         |
|    time_elapsed         | 3347         |
|    total_timesteps      | 131456       |
| train/                  |              |
|    approx_kl            | 0.0038194042 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00111     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 71.5         |
|    n_updates            | 10260        |
|    policy_gradient_loss | -0.000759    |
|    value_loss           | 134          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.9      |
|    ep_rew_mean          | -5.83     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1028      |
|    time_elapsed         | 3351      |
|    total_timesteps      | 131584    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00154  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 55.3      |
|    n_updates            | 10270     |
|    policy_gradient_loss | 1.56e-09  |
|    value_loss           | 129       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79        |
|    ep_rew_mean          | -5.89     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1029      |
|    time_elapsed         | 3355      |
|    total_timesteps      | 131712    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00163  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 66        |
|    n_updates            | 10280     |
|    policy_gradient_loss | 2.07e-09  |
|    value_loss           | 104       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.4     |
|    ep_rew_mean          | -5.51    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1030     |
|    time_elapsed         | 3358     |
|    total_timesteps      | 131840   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00166 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.5     |
|    n_updates            | 10290    |
|    policy_gradient_loss | 2.79e-10 |
|    value_loss           | 93.2     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.8     |
|    ep_rew_mean          | -5.17    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1031     |
|    time_elapsed         | 3361     |
|    total_timesteps      | 131968   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00172 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 67.9     |
|    n_updates            | 10300    |
|    policy_gradient_loss | 9.78e-10 |
|    value_loss           | 132      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 132000
Best mean reward: -1.70 - Last mean reward per episode: -4.50
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78        |
|    ep_rew_mean          | -5.32     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1032      |
|    time_elapsed         | 3364      |
|    total_timesteps      | 132096    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00176  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 82        |
|    n_updates            | 10310     |
|    policy_gradient_loss | -4.28e-09 |
|    value_loss           | 135       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79        |
|    ep_rew_mean          | -5.79     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1033      |
|    time_elapsed         | 3367      |
|    total_timesteps      | 132224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00179  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.4      |
|    n_updates            | 10320     |
|    policy_gradient_loss | -3.54e-09 |
|    value_loss           | 69.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.6     |
|    ep_rew_mean          | -5.7     |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1034     |
|    time_elapsed         | 3371     |
|    total_timesteps      | 132352   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0018  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 41.6     |
|    n_updates            | 10330    |
|    policy_gradient_loss | 0        |
|    value_loss           | 81.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.3      |
|    ep_rew_mean          | -5.56     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1035      |
|    time_elapsed         | 3374      |
|    total_timesteps      | 132480    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00182  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 51        |
|    n_updates            | 10340     |
|    policy_gradient_loss | -2.24e-09 |
|    value_loss           | 90        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.4     |
|    ep_rew_mean          | -5.22    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1036     |
|    time_elapsed         | 3376     |
|    total_timesteps      | 132608   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00185 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 45.8     |
|    n_updates            | 10350    |
|    policy_gradient_loss | 1.94e-09 |
|    value_loss           | 88.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77        |
|    ep_rew_mean          | -4.99     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1037      |
|    time_elapsed         | 3379      |
|    total_timesteps      | 132736    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00189  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.2      |
|    n_updates            | 10360     |
|    policy_gradient_loss | -3.91e-09 |
|    value_loss           | 88.9      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.2     |
|    ep_rew_mean          | -4.72    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1038     |
|    time_elapsed         | 3383     |
|    total_timesteps      | 132864   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00193 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 39.8     |
|    n_updates            | 10370    |
|    policy_gradient_loss | 3.35e-09 |
|    value_loss           | 89.2     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.2      |
|    ep_rew_mean          | -4.72     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1039      |
|    time_elapsed         | 3386      |
|    total_timesteps      | 132992    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00199  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.6      |
|    n_updates            | 10380     |
|    policy_gradient_loss | -5.15e-09 |
|    value_loss           | 84.1      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 133000
Best mean reward: -1.70 - Last mean reward per episode: -5.25
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.9     |
|    ep_rew_mean          | -5.17    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1040     |
|    time_elapsed         | 3390     |
|    total_timesteps      | 133120   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00202 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 29.5     |
|    n_updates            | 10390    |
|    policy_gradient_loss | 3.49e-09 |
|    value_loss           | 63       |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.8     |
|    ep_rew_mean          | -4.99    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1041     |
|    time_elapsed         | 3393     |
|    total_timesteps      | 133248   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00204 |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 55.7     |
|    n_updates            | 10400    |
|    policy_gradient_loss | -7.5e-09 |
|    value_loss           | 91.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.8     |
|    ep_rew_mean          | -5.03    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1042     |
|    time_elapsed         | 3397     |
|    total_timesteps      | 133376   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00207 |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 88.9     |
|    n_updates            | 10410    |
|    policy_gradient_loss | 2.03e-09 |
|    value_loss           | 167      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.5      |
|    ep_rew_mean          | -5.37     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1043      |
|    time_elapsed         | 3400      |
|    total_timesteps      | 133504    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00209  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 39.4      |
|    n_updates            | 10420     |
|    policy_gradient_loss | 1.44e-09  |
|    value_loss           | 112       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77        |
|    ep_rew_mean          | -5.11     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1044      |
|    time_elapsed         | 3403      |
|    total_timesteps      | 133632    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00213  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.1      |
|    n_updates            | 10430     |
|    policy_gradient_loss | -6.52e-10 |
|    value_loss           | 94.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -5.18     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1045      |
|    time_elapsed         | 3406      |
|    total_timesteps      | 133760    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00223  |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 48.6      |
|    n_updates            | 10440     |
|    policy_gradient_loss | -3.26e-09 |
|    value_loss           | 94.7      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.8     |
|    ep_rew_mean          | -5.58    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1046     |
|    time_elapsed         | 3410     |
|    total_timesteps      | 133888   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00233 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 61.9     |
|    n_updates            | 10450    |
|    policy_gradient_loss | 2.05e-09 |
|    value_loss           | 94.1     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 134000
Best mean reward: -1.70 - Last mean reward per episode: -4.82
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.1      |
|    ep_rew_mean          | -5.75     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1047      |
|    time_elapsed         | 3413      |
|    total_timesteps      | 134016    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00241  |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 42.6      |
|    n_updates            | 10460     |
|    policy_gradient_loss | -4.07e-09 |
|    value_loss           | 104       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78        |
|    ep_rew_mean          | -5.72     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1048      |
|    time_elapsed         | 3416      |
|    total_timesteps      | 134144    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00246  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35        |
|    n_updates            | 10470     |
|    policy_gradient_loss | -1.24e-08 |
|    value_loss           | 69.6      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.9     |
|    ep_rew_mean          | -5.74    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1049     |
|    time_elapsed         | 3419     |
|    total_timesteps      | 134272   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0025  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 41.8     |
|    n_updates            | 10480    |
|    policy_gradient_loss | 1.28e-09 |
|    value_loss           | 101      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.3      |
|    ep_rew_mean          | -4.95     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1050      |
|    time_elapsed         | 3422      |
|    total_timesteps      | 134400    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00259  |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 36        |
|    n_updates            | 10490     |
|    policy_gradient_loss | -4.13e-09 |
|    value_loss           | 91.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.6     |
|    ep_rew_mean          | -5.09    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1051     |
|    time_elapsed         | 3425     |
|    total_timesteps      | 134528   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00269 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 35.5     |
|    n_updates            | 10500    |
|    policy_gradient_loss | 4.24e-09 |
|    value_loss           | 94.2     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.5      |
|    ep_rew_mean          | -5.08     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1052      |
|    time_elapsed         | 3428      |
|    total_timesteps      | 134656    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0028   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 52.3      |
|    n_updates            | 10510     |
|    policy_gradient_loss | -6.29e-10 |
|    value_loss           | 95.6      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.6     |
|    ep_rew_mean          | -4.91    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1053     |
|    time_elapsed         | 3431     |
|    total_timesteps      | 134784   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00292 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 38.1     |
|    n_updates            | 10520    |
|    policy_gradient_loss | 1.22e-08 |
|    value_loss           | 74.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.6     |
|    ep_rew_mean          | -4.38    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1054     |
|    time_elapsed         | 3434     |
|    total_timesteps      | 134912   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.003   |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 91.9     |
|    n_updates            | 10530    |
|    policy_gradient_loss | -1.3e-09 |
|    value_loss           | 173      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 135000
Best mean reward: -1.70 - Last mean reward per episode: -4.35
Eval num_timesteps=135000, episode_reward=-4.00 +/- 11.06
Episode length: 72.00 +/- 17.71
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 72        |
|    mean_reward          | -4        |
| time/                   |           |
|    total_timesteps      | 135000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00319  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.2      |
|    n_updates            | 10540     |
|    policy_gradient_loss | -5.12e-10 |
|    value_loss           | 97.6      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | -4.42    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 1055     |
|    time_elapsed    | 3439     |
|    total_timesteps | 135040   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.1      |
|    ep_rew_mean          | -4.13     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1056      |
|    time_elapsed         | 3442      |
|    total_timesteps      | 135168    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00344  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 52.3      |
|    n_updates            | 10550     |
|    policy_gradient_loss | -4.28e-09 |
|    value_loss           | 95.9      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.3     |
|    ep_rew_mean          | -4.25    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1057     |
|    time_elapsed         | 3446     |
|    total_timesteps      | 135296   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0037  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 119      |
|    n_updates            | 10560    |
|    policy_gradient_loss | 1.56e-09 |
|    value_loss           | 213      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.5     |
|    ep_rew_mean          | -4.38    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1058     |
|    time_elapsed         | 3448     |
|    total_timesteps      | 135424   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0038  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 36.5     |
|    n_updates            | 10570    |
|    policy_gradient_loss | -5.1e-09 |
|    value_loss           | 70.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.6      |
|    ep_rew_mean          | -4.48     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1059      |
|    time_elapsed         | 3451      |
|    total_timesteps      | 135552    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0039   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33        |
|    n_updates            | 10580     |
|    policy_gradient_loss | -5.12e-10 |
|    value_loss           | 87.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.9      |
|    ep_rew_mean          | -4.75     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1060      |
|    time_elapsed         | 3455      |
|    total_timesteps      | 135680    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00416  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26        |
|    n_updates            | 10590     |
|    policy_gradient_loss | -5.87e-09 |
|    value_loss           | 70.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75       |
|    ep_rew_mean          | -4.08    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1061     |
|    time_elapsed         | 3458     |
|    total_timesteps      | 135808   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00442 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 55.4     |
|    n_updates            | 10600    |
|    policy_gradient_loss | 1.63e-10 |
|    value_loss           | 92       |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.4     |
|    ep_rew_mean          | -4.4     |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1062     |
|    time_elapsed         | 3461     |
|    total_timesteps      | 135936   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00485 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 102      |
|    n_updates            | 10610    |
|    policy_gradient_loss | 7.92e-10 |
|    value_loss           | 174      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 136000
Best mean reward: -1.70 - Last mean reward per episode: -5.00
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76       |
|    ep_rew_mean          | -4.82    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1063     |
|    time_elapsed         | 3464     |
|    total_timesteps      | 136064   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00529 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 33.2     |
|    n_updates            | 10620    |
|    policy_gradient_loss | 4.66e-10 |
|    value_loss           | 87.3     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -4.71     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1064      |
|    time_elapsed         | 3467      |
|    total_timesteps      | 136192    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00569  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55.4      |
|    n_updates            | 10630     |
|    policy_gradient_loss | -4.19e-10 |
|    value_loss           | 107       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -4.83     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1065      |
|    time_elapsed         | 3471      |
|    total_timesteps      | 136320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00597  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 72.2      |
|    n_updates            | 10640     |
|    policy_gradient_loss | -1.26e-09 |
|    value_loss           | 121       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.7      |
|    ep_rew_mean          | -5.13     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1066      |
|    time_elapsed         | 3474      |
|    total_timesteps      | 136448    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00617  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 43.4      |
|    n_updates            | 10650     |
|    policy_gradient_loss | -1.4e-09  |
|    value_loss           | 69.4      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.3     |
|    ep_rew_mean          | -5.17    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1067     |
|    time_elapsed         | 3478     |
|    total_timesteps      | 136576   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00634 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 33.7     |
|    n_updates            | 10660    |
|    policy_gradient_loss | 3.86e-09 |
|    value_loss           | 68.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.4     |
|    ep_rew_mean          | -5.29    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1068     |
|    time_elapsed         | 3481     |
|    total_timesteps      | 136704   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00666 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 64.3     |
|    n_updates            | 10670    |
|    policy_gradient_loss | 1.26e-09 |
|    value_loss           | 114      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.5      |
|    ep_rew_mean          | -5.37     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1069      |
|    time_elapsed         | 3483      |
|    total_timesteps      | 136832    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00744  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.7      |
|    n_updates            | 10680     |
|    policy_gradient_loss | -6.98e-10 |
|    value_loss           | 86.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.5      |
|    ep_rew_mean          | -5.17     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1070      |
|    time_elapsed         | 3486      |
|    total_timesteps      | 136960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0083   |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 24.1      |
|    n_updates            | 10690     |
|    policy_gradient_loss | -6.33e-09 |
|    value_loss           | 70.2      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 137000
Best mean reward: -1.70 - Last mean reward per episode: -4.96
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.8     |
|    ep_rew_mean          | -4.92    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1071     |
|    time_elapsed         | 3490     |
|    total_timesteps      | 137088   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0087  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 106      |
|    n_updates            | 10700    |
|    policy_gradient_loss | 2.61e-09 |
|    value_loss           | 197      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.8     |
|    ep_rew_mean          | -4.92    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1072     |
|    time_elapsed         | 3492     |
|    total_timesteps      | 137216   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00918 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 43.5     |
|    n_updates            | 10710    |
|    policy_gradient_loss | 1.23e-09 |
|    value_loss           | 85.3     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.9      |
|    ep_rew_mean          | -4.75     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1073      |
|    time_elapsed         | 3496      |
|    total_timesteps      | 137344    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0104   |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 29        |
|    n_updates            | 10720     |
|    policy_gradient_loss | -7.03e-09 |
|    value_loss           | 73        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -4.72     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1074      |
|    time_elapsed         | 3501      |
|    total_timesteps      | 137472    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0112   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 70.7      |
|    n_updates            | 10730     |
|    policy_gradient_loss | -1.26e-09 |
|    value_loss           | 155       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 75.8         |
|    ep_rew_mean          | -4.69        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 1075         |
|    time_elapsed         | 3504         |
|    total_timesteps      | 137600       |
| train/                  |              |
|    approx_kl            | 0.0040337257 |
|    clip_fraction        | 0.00625      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00687     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 38.9         |
|    n_updates            | 10740        |
|    policy_gradient_loss | -0.00132     |
|    value_loss           | 86.9         |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.3     |
|    ep_rew_mean          | -4.93    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1076     |
|    time_elapsed         | 3507     |
|    total_timesteps      | 137728   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00403 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 79.6     |
|    n_updates            | 10750    |
|    policy_gradient_loss | 4.56e-09 |
|    value_loss           | 161      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.9     |
|    ep_rew_mean          | -4.86    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1077     |
|    time_elapsed         | 3510     |
|    total_timesteps      | 137856   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00381 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 35.1     |
|    n_updates            | 10760    |
|    policy_gradient_loss | 2.21e-09 |
|    value_loss           | 68.8     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.3     |
|    ep_rew_mean          | -5.05    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1078     |
|    time_elapsed         | 3515     |
|    total_timesteps      | 137984   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00379 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 49.9     |
|    n_updates            | 10770    |
|    policy_gradient_loss | 9.43e-09 |
|    value_loss           | 117      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 138000
Best mean reward: -1.70 - Last mean reward per episode: -4.68
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.1     |
|    ep_rew_mean          | -4.97    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1079     |
|    time_elapsed         | 3519     |
|    total_timesteps      | 138112   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00381 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 63.8     |
|    n_updates            | 10780    |
|    policy_gradient_loss | 5.82e-10 |
|    value_loss           | 139      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.5     |
|    ep_rew_mean          | -4.63    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1080     |
|    time_elapsed         | 3522     |
|    total_timesteps      | 138240   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00386 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 66.1     |
|    n_updates            | 10790    |
|    policy_gradient_loss | 7.92e-10 |
|    value_loss           | 122      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.1     |
|    ep_rew_mean          | -4.44    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1081     |
|    time_elapsed         | 3525     |
|    total_timesteps      | 138368   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00393 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 43.2     |
|    n_updates            | 10800    |
|    policy_gradient_loss | 3.26e-10 |
|    value_loss           | 93.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.6     |
|    ep_rew_mean          | -4.5     |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1082     |
|    time_elapsed         | 3527     |
|    total_timesteps      | 138496   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00406 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 47.2     |
|    n_updates            | 10810    |
|    policy_gradient_loss | 2.33e-10 |
|    value_loss           | 93.3     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.6      |
|    ep_rew_mean          | -4.5      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1083      |
|    time_elapsed         | 3530      |
|    total_timesteps      | 138624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00418  |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 41.8      |
|    n_updates            | 10820     |
|    policy_gradient_loss | 1.49e-09  |
|    value_loss           | 85.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.1      |
|    ep_rew_mean          | -4.37     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1084      |
|    time_elapsed         | 3533      |
|    total_timesteps      | 138752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00428  |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 32.9      |
|    n_updates            | 10830     |
|    policy_gradient_loss | -2.05e-09 |
|    value_loss           | 82.7      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.8     |
|    ep_rew_mean          | -4.29    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1085     |
|    time_elapsed         | 3537     |
|    total_timesteps      | 138880   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00439 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.1     |
|    n_updates            | 10840    |
|    policy_gradient_loss | 5.03e-09 |
|    value_loss           | 86.2     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 139000
Best mean reward: -1.70 - Last mean reward per episode: -3.96
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.3      |
|    ep_rew_mean          | -3.94     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1086      |
|    time_elapsed         | 3540      |
|    total_timesteps      | 139008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00454  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 43.5      |
|    n_updates            | 10850     |
|    policy_gradient_loss | 3.32e-09  |
|    value_loss           | 91.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.3      |
|    ep_rew_mean          | -3.94     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1087      |
|    time_elapsed         | 3543      |
|    total_timesteps      | 139136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00464  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 98.5      |
|    n_updates            | 10860     |
|    policy_gradient_loss | -1.91e-09 |
|    value_loss           | 173       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74        |
|    ep_rew_mean          | -4.19     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1088      |
|    time_elapsed         | 3547      |
|    total_timesteps      | 139264    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00468  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 55.8      |
|    n_updates            | 10870     |
|    policy_gradient_loss | 2.65e-09  |
|    value_loss           | 111       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -4.01     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1089      |
|    time_elapsed         | 3550      |
|    total_timesteps      | 139392    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00471  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42        |
|    n_updates            | 10880     |
|    policy_gradient_loss | -7.03e-09 |
|    value_loss           | 105       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.8      |
|    ep_rew_mean          | -3.38     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1090      |
|    time_elapsed         | 3554      |
|    total_timesteps      | 139520    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00476  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 73        |
|    n_updates            | 10890     |
|    policy_gradient_loss | 4.52e-09  |
|    value_loss           | 143       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.1     |
|    ep_rew_mean          | -3.46    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1091     |
|    time_elapsed         | 3558     |
|    total_timesteps      | 139648   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0049  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 67       |
|    n_updates            | 10900    |
|    policy_gradient_loss | 6.01e-09 |
|    value_loss           | 121      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.3     |
|    ep_rew_mean          | -3.38    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1092     |
|    time_elapsed         | 3562     |
|    total_timesteps      | 139776   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00502 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 34.9     |
|    n_updates            | 10910    |
|    policy_gradient_loss | 2.35e-09 |
|    value_loss           | 99.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.9      |
|    ep_rew_mean          | -3.63     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1093      |
|    time_elapsed         | 3567      |
|    total_timesteps      | 139904    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0051   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 64.4      |
|    n_updates            | 10920     |
|    policy_gradient_loss | -1.33e-09 |
|    value_loss           | 164       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 140000
Best mean reward: -1.70 - Last mean reward per episode: -3.19
Eval num_timesteps=140000, episode_reward=-17.30 +/- 16.01
Episode length: 98.60 +/- 38.63
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 98.6      |
|    mean_reward          | -17.3     |
| time/                   |           |
|    total_timesteps      | 140000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00516  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.2      |
|    n_updates            | 10930     |
|    policy_gradient_loss | -2.17e-09 |
|    value_loss           | 102       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 73.9     |
|    ep_rew_mean     | -3.63    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 1094     |
|    time_elapsed    | 3574     |
|    total_timesteps | 140032   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -3.48     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1095      |
|    time_elapsed         | 3577      |
|    total_timesteps      | 140160    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00527  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.1      |
|    n_updates            | 10940     |
|    policy_gradient_loss | -8.78e-09 |
|    value_loss           | 68.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -3.38     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1096      |
|    time_elapsed         | 3581      |
|    total_timesteps      | 140288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00532  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 62.6      |
|    n_updates            | 10950     |
|    policy_gradient_loss | -6.52e-10 |
|    value_loss           | 118       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.5     |
|    ep_rew_mean          | -2.56    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1097     |
|    time_elapsed         | 3584     |
|    total_timesteps      | 140416   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00537 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 46.6     |
|    n_updates            | 10960    |
|    policy_gradient_loss | 1.96e-09 |
|    value_loss           | 115      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.1      |
|    ep_rew_mean          | -2.83     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1098      |
|    time_elapsed         | 3588      |
|    total_timesteps      | 140544    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00541  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 76.2      |
|    n_updates            | 10970     |
|    policy_gradient_loss | -1.86e-10 |
|    value_loss           | 161       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73       |
|    ep_rew_mean          | -2.99    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1099     |
|    time_elapsed         | 3591     |
|    total_timesteps      | 140672   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00544 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 33.7     |
|    n_updates            | 10980    |
|    policy_gradient_loss | 1.35e-09 |
|    value_loss           | 68.6     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.6     |
|    ep_rew_mean          | -2.62    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1100     |
|    time_elapsed         | 3595     |
|    total_timesteps      | 140800   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00551 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 73.6     |
|    n_updates            | 10990    |
|    policy_gradient_loss | 4.47e-09 |
|    value_loss           | 123      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.6     |
|    ep_rew_mean          | -2.52    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1101     |
|    time_elapsed         | 3599     |
|    total_timesteps      | 140928   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00565 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 84.3     |
|    n_updates            | 11000    |
|    policy_gradient_loss | 5.33e-09 |
|    value_loss           | 159      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 141000
Best mean reward: -1.70 - Last mean reward per episode: -2.65
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.5      |
|    ep_rew_mean          | -2.37     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1102      |
|    time_elapsed         | 3602      |
|    total_timesteps      | 141056    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00571  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 63.9      |
|    n_updates            | 11010     |
|    policy_gradient_loss | -1.51e-10 |
|    value_loss           | 114       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 71.3     |
|    ep_rew_mean          | -1.56    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1103     |
|    time_elapsed         | 3605     |
|    total_timesteps      | 141184   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00585 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.3     |
|    n_updates            | 11020    |
|    policy_gradient_loss | 1.72e-09 |
|    value_loss           | 118      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 71.4     |
|    ep_rew_mean          | -1.6     |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1104     |
|    time_elapsed         | 3608     |
|    total_timesteps      | 141312   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00607 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 78       |
|    n_updates            | 11030    |
|    policy_gradient_loss | 2.21e-09 |
|    value_loss           | 178      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.1      |
|    ep_rew_mean          | -1.34     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1105      |
|    time_elapsed         | 3611      |
|    total_timesteps      | 141440    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00629  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 37.9      |
|    n_updates            | 11040     |
|    policy_gradient_loss | -2.54e-09 |
|    value_loss           | 82.6      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 71.5     |
|    ep_rew_mean          | -1.54    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1106     |
|    time_elapsed         | 3614     |
|    total_timesteps      | 141568   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00645 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 62       |
|    n_updates            | 11050    |
|    policy_gradient_loss | 9.31e-10 |
|    value_loss           | 115      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.3      |
|    ep_rew_mean          | -1.27     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1107      |
|    time_elapsed         | 3617      |
|    total_timesteps      | 141696    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0067   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.1      |
|    n_updates            | 11060     |
|    policy_gradient_loss | -1.35e-09 |
|    value_loss           | 82.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 71.8     |
|    ep_rew_mean          | -1.51    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1108     |
|    time_elapsed         | 3620     |
|    total_timesteps      | 141824   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00694 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 58.1     |
|    n_updates            | 11070    |
|    policy_gradient_loss | 6.05e-10 |
|    value_loss           | 156      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.6      |
|    ep_rew_mean          | -1.51     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1109      |
|    time_elapsed         | 3624      |
|    total_timesteps      | 141952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00705  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 36.4      |
|    n_updates            | 11080     |
|    policy_gradient_loss | 1.44e-09  |
|    value_loss           | 68.8      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 142000
Best mean reward: -1.70 - Last mean reward per episode: -2.44
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.5      |
|    ep_rew_mean          | -1.47     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1110      |
|    time_elapsed         | 3629      |
|    total_timesteps      | 142080    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00713  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55.8      |
|    n_updates            | 11090     |
|    policy_gradient_loss | -2.93e-09 |
|    value_loss           | 112       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.8      |
|    ep_rew_mean          | -1.5      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1111      |
|    time_elapsed         | 3632      |
|    total_timesteps      | 142208    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00741  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 40.3      |
|    n_updates            | 11100     |
|    policy_gradient_loss | 2.05e-09  |
|    value_loss           | 74.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 71.4     |
|    ep_rew_mean          | -1.61    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1112     |
|    time_elapsed         | 3635     |
|    total_timesteps      | 142336   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00783 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 49.7     |
|    n_updates            | 11110    |
|    policy_gradient_loss | 1.04e-08 |
|    value_loss           | 95.9     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 70.9     |
|    ep_rew_mean          | -1.24    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1113     |
|    time_elapsed         | 3638     |
|    total_timesteps      | 142464   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0081  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 38.3     |
|    n_updates            | 11120    |
|    policy_gradient_loss | 5.54e-09 |
|    value_loss           | 88.7     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 70.5     |
|    ep_rew_mean          | -1.07    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1114     |
|    time_elapsed         | 3641     |
|    total_timesteps      | 142592   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00849 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 57.1     |
|    n_updates            | 11130    |
|    policy_gradient_loss | 2.61e-09 |
|    value_loss           | 108      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 70.3     |
|    ep_rew_mean          | -0.835   |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1115     |
|    time_elapsed         | 3644     |
|    total_timesteps      | 142720   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00901 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 35.1     |
|    n_updates            | 11140    |
|    policy_gradient_loss | 1.35e-09 |
|    value_loss           | 74.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 70.5     |
|    ep_rew_mean          | -1.06    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1116     |
|    time_elapsed         | 3647     |
|    total_timesteps      | 142848   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00979 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.6     |
|    n_updates            | 11150    |
|    policy_gradient_loss | 3.03e-09 |
|    value_loss           | 102      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70        |
|    ep_rew_mean          | -0.815    |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1117      |
|    time_elapsed         | 3651      |
|    total_timesteps      | 142976    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0103   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 55.5      |
|    n_updates            | 11160     |
|    policy_gradient_loss | -4.56e-09 |
|    value_loss           | 105       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 143000
Best mean reward: -1.70 - Last mean reward per episode: -0.99
Saving new best model at 265316 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 69.7      |
|    ep_rew_mean          | -0.65     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1118      |
|    time_elapsed         | 3654      |
|    total_timesteps      | 143104    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0108   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 32.2      |
|    n_updates            | 11170     |
|    policy_gradient_loss | -4.94e-09 |
|    value_loss           | 66.6      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 70.1         |
|    ep_rew_mean          | -0.94        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 1119         |
|    time_elapsed         | 3657         |
|    total_timesteps      | 143232       |
| train/                  |              |
|    approx_kl            | 0.0008313735 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00892     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 51.5         |
|    n_updates            | 11180        |
|    policy_gradient_loss | -0.000765    |
|    value_loss           | 96.9         |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 69.1     |
|    ep_rew_mean          | -0.23    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1120     |
|    time_elapsed         | 3660     |
|    total_timesteps      | 143360   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00729 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 45.6     |
|    n_updates            | 11190    |
|    policy_gradient_loss | 4.89e-09 |
|    value_loss           | 92.8     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 69.1      |
|    ep_rew_mean          | -0.23     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1121      |
|    time_elapsed         | 3663      |
|    total_timesteps      | 143488    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00718  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 57.7      |
|    n_updates            | 11200     |
|    policy_gradient_loss | -5.59e-09 |
|    value_loss           | 147       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 69.2      |
|    ep_rew_mean          | -0.195    |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1122      |
|    time_elapsed         | 3666      |
|    total_timesteps      | 143616    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0073   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42        |
|    n_updates            | 11210     |
|    policy_gradient_loss | -1.63e-09 |
|    value_loss           | 73.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 69.2      |
|    ep_rew_mean          | 0.075     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1123      |
|    time_elapsed         | 3669      |
|    total_timesteps      | 143744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00759  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 50.3      |
|    n_updates            | 11220     |
|    policy_gradient_loss | -5.59e-10 |
|    value_loss           | 103       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 69.2      |
|    ep_rew_mean          | 0.075     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1124      |
|    time_elapsed         | 3673      |
|    total_timesteps      | 143872    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00778  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 85.5      |
|    n_updates            | 11230     |
|    policy_gradient_loss | -1.15e-08 |
|    value_loss           | 174       |
---------------------------------------
Num timesteps: 144000
Best mean reward: -0.99 - Last mean reward per episode: -1.28
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.3      |
|    ep_rew_mean          | -0.63     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1125      |
|    time_elapsed         | 3677      |
|    total_timesteps      | 144000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00786  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 36        |
|    n_updates            | 11240     |
|    policy_gradient_loss | 4.38e-09  |
|    value_loss           | 70.1      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.3      |
|    ep_rew_mean          | -0.67     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1126      |
|    time_elapsed         | 3683      |
|    total_timesteps      | 144128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00798  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    n_updates            | 11250     |
|    policy_gradient_loss | 3.26e-10  |
|    value_loss           | 78.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.8      |
|    ep_rew_mean          | -0.82     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1127      |
|    time_elapsed         | 3687      |
|    total_timesteps      | 144256    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00833  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.4      |
|    n_updates            | 11260     |
|    policy_gradient_loss | -3.63e-09 |
|    value_loss           | 75.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.3      |
|    ep_rew_mean          | -0.63     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1128      |
|    time_elapsed         | 3691      |
|    total_timesteps      | 144384    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00906  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 81.1      |
|    n_updates            | 11270     |
|    policy_gradient_loss | -4.66e-10 |
|    value_loss           | 124       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 70.5     |
|    ep_rew_mean          | -0.855   |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1129     |
|    time_elapsed         | 3694     |
|    total_timesteps      | 144512   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00954 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 37.4     |
|    n_updates            | 11280    |
|    policy_gradient_loss | 6.52e-09 |
|    value_loss           | 65.7     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.6      |
|    ep_rew_mean          | -0.82     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1130      |
|    time_elapsed         | 3697      |
|    total_timesteps      | 144640    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00985  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 28.4      |
|    n_updates            | 11290     |
|    policy_gradient_loss | -5.87e-09 |
|    value_loss           | 74.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.9      |
|    ep_rew_mean          | -1.16     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1131      |
|    time_elapsed         | 3700      |
|    total_timesteps      | 144768    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0104   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 43.3      |
|    n_updates            | 11300     |
|    policy_gradient_loss | -5.61e-09 |
|    value_loss           | 97.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.7      |
|    ep_rew_mean          | -1.05     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1132      |
|    time_elapsed         | 3703      |
|    total_timesteps      | 144896    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0109   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.3      |
|    n_updates            | 11310     |
|    policy_gradient_loss | -7.92e-10 |
|    value_loss           | 86.2      |
---------------------------------------
Num timesteps: 145000
Best mean reward: -0.99 - Last mean reward per episode: -1.96
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=145000, episode_reward=-15.60 +/- 12.98
Episode length: 95.20 +/- 22.27
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 95.2     |
|    mean_reward          | -15.6    |
| time/                   |          |
|    total_timesteps      | 145000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0117  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 42.2     |
|    n_updates            | 11320    |
|    policy_gradient_loss | 4.54e-09 |
|    value_loss           | 105      |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 70.4     |
|    ep_rew_mean     | -1.12    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 1133     |
|    time_elapsed    | 3708     |
|    total_timesteps | 145024   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.3      |
|    ep_rew_mean          | -1.04     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1134      |
|    time_elapsed         | 3711      |
|    total_timesteps      | 145152    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0121   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26.5      |
|    n_updates            | 11330     |
|    policy_gradient_loss | -1.06e-08 |
|    value_loss           | 68.9      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 70.7     |
|    ep_rew_mean          | -1.24    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1135     |
|    time_elapsed         | 3714     |
|    total_timesteps      | 145280   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0124  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 43.3     |
|    n_updates            | 11340    |
|    policy_gradient_loss | 1.86e-09 |
|    value_loss           | 112      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.8      |
|    ep_rew_mean          | -1.32     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1136      |
|    time_elapsed         | 3717      |
|    total_timesteps      | 145408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0127   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.4      |
|    n_updates            | 11350     |
|    policy_gradient_loss | -4.52e-09 |
|    value_loss           | 67.8      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 70.6         |
|    ep_rew_mean          | -1.19        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 1137         |
|    time_elapsed         | 3720         |
|    total_timesteps      | 145536       |
| train/                  |              |
|    approx_kl            | 0.0028422885 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00896     |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 44.7         |
|    n_updates            | 11360        |
|    policy_gradient_loss | -0.00108     |
|    value_loss           | 90.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 71.3         |
|    ep_rew_mean          | -1.57        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 1138         |
|    time_elapsed         | 3723         |
|    total_timesteps      | 145664       |
| train/                  |              |
|    approx_kl            | 0.0013994491 |
|    clip_fraction        | 0.00625      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00502     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 47.1         |
|    n_updates            | 11370        |
|    policy_gradient_loss | -0.00101     |
|    value_loss           | 91.2         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.4      |
|    ep_rew_mean          | -1.59     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1139      |
|    time_elapsed         | 3726      |
|    total_timesteps      | 145792    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00424  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 39.7      |
|    n_updates            | 11380     |
|    policy_gradient_loss | -5.36e-09 |
|    value_loss           | 69        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.8      |
|    ep_rew_mean          | -1.79     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1140      |
|    time_elapsed         | 3729      |
|    total_timesteps      | 145920    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00424  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.8      |
|    n_updates            | 11390     |
|    policy_gradient_loss | -2.24e-09 |
|    value_loss           | 89.2      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 146000
Best mean reward: -0.99 - Last mean reward per episode: -3.54
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 71.9     |
|    ep_rew_mean          | -1.66    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1141     |
|    time_elapsed         | 3732     |
|    total_timesteps      | 146048   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00434 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 41.8     |
|    n_updates            | 11400    |
|    policy_gradient_loss | 2.97e-09 |
|    value_loss           | 68.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.4      |
|    ep_rew_mean          | -1.9      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1142      |
|    time_elapsed         | 3735      |
|    total_timesteps      | 146176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00443  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 97.2      |
|    n_updates            | 11410     |
|    policy_gradient_loss | -3.82e-09 |
|    value_loss           | 162       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.4     |
|    ep_rew_mean          | -1.7     |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1143     |
|    time_elapsed         | 3738     |
|    total_timesteps      | 146304   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00461 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 26.9     |
|    n_updates            | 11420    |
|    policy_gradient_loss | -1.4e-09 |
|    value_loss           | 85.2     |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 73           |
|    ep_rew_mean          | -2.17        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 1144         |
|    time_elapsed         | 3741         |
|    total_timesteps      | 146432       |
| train/                  |              |
|    approx_kl            | 0.0007123668 |
|    clip_fraction        | 0.00313      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00415     |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 110          |
|    n_updates            | 11430        |
|    policy_gradient_loss | -0.00057     |
|    value_loss           | 164          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.6      |
|    ep_rew_mean          | -2.62     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1145      |
|    time_elapsed         | 3745      |
|    total_timesteps      | 146560    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00337  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.4      |
|    n_updates            | 11440     |
|    policy_gradient_loss | -2.72e-09 |
|    value_loss           | 68.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.3      |
|    ep_rew_mean          | -2.53     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1146      |
|    time_elapsed         | 3748      |
|    total_timesteps      | 146688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00328  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39        |
|    n_updates            | 11450     |
|    policy_gradient_loss | -2.33e-11 |
|    value_loss           | 67.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.2      |
|    ep_rew_mean          | -2.79     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1147      |
|    time_elapsed         | 3751      |
|    total_timesteps      | 146816    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0033   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 35.1      |
|    n_updates            | 11460     |
|    policy_gradient_loss | -2.24e-09 |
|    value_loss           | 84        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.3     |
|    ep_rew_mean          | -2.27    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1148     |
|    time_elapsed         | 3755     |
|    total_timesteps      | 146944   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00338 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 37.2     |
|    n_updates            | 11470    |
|    policy_gradient_loss | 7.45e-10 |
|    value_loss           | 87.7     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 147000
Best mean reward: -0.99 - Last mean reward per episode: -2.84
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.1      |
|    ep_rew_mean          | -2.17     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1149      |
|    time_elapsed         | 3758      |
|    total_timesteps      | 147072    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00345  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 62.4      |
|    n_updates            | 11480     |
|    policy_gradient_loss | -8.61e-10 |
|    value_loss           | 148       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.9      |
|    ep_rew_mean          | -2.75     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1150      |
|    time_elapsed         | 3762      |
|    total_timesteps      | 147200    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00348  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.7      |
|    n_updates            | 11490     |
|    policy_gradient_loss | -4.14e-09 |
|    value_loss           | 72.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.4      |
|    ep_rew_mean          | -2.5      |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1151      |
|    time_elapsed         | 3765      |
|    total_timesteps      | 147328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00349  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41        |
|    n_updates            | 11500     |
|    policy_gradient_loss | -1.01e-08 |
|    value_loss           | 80.8      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.8     |
|    ep_rew_mean          | -2.69    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1152     |
|    time_elapsed         | 3768     |
|    total_timesteps      | 147456   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00351 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 38.4     |
|    n_updates            | 11510    |
|    policy_gradient_loss | 4.42e-10 |
|    value_loss           | 73.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.7      |
|    ep_rew_mean          | -2.52     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1153      |
|    time_elapsed         | 3771      |
|    total_timesteps      | 147584    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00352  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 52.3      |
|    n_updates            | 11520     |
|    policy_gradient_loss | -2.1e-09  |
|    value_loss           | 88.1      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.9     |
|    ep_rew_mean          | -2.87    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1154     |
|    time_elapsed         | 3775     |
|    total_timesteps      | 147712   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00356 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 65.7     |
|    n_updates            | 11530    |
|    policy_gradient_loss | 2.33e-09 |
|    value_loss           | 174      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.9      |
|    ep_rew_mean          | -2.87     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1155      |
|    time_elapsed         | 3778      |
|    total_timesteps      | 147840    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00362  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.4      |
|    n_updates            | 11540     |
|    policy_gradient_loss | -5.96e-09 |
|    value_loss           | 124       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.7      |
|    ep_rew_mean          | -3.05     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1156      |
|    time_elapsed         | 3783      |
|    total_timesteps      | 147968    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00365  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30.6      |
|    n_updates            | 11550     |
|    policy_gradient_loss | -1.46e-08 |
|    value_loss           | 61.8      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 148000
Best mean reward: -0.99 - Last mean reward per episode: -4.11
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.7      |
|    ep_rew_mean          | -3.05     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1157      |
|    time_elapsed         | 3786      |
|    total_timesteps      | 148096    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00367  |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 76.1      |
|    n_updates            | 11560     |
|    policy_gradient_loss | -5.03e-09 |
|    value_loss           | 172       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.4     |
|    ep_rew_mean          | -3.08    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1158     |
|    time_elapsed         | 3789     |
|    total_timesteps      | 148224   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00369 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 57.7     |
|    n_updates            | 11570    |
|    policy_gradient_loss | 3.17e-09 |
|    value_loss           | 127      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -3.38     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1159      |
|    time_elapsed         | 3792      |
|    total_timesteps      | 148352    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00375  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 48.8      |
|    n_updates            | 11580     |
|    policy_gradient_loss | -3.73e-09 |
|    value_loss           | 113       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -3.48     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1160      |
|    time_elapsed         | 3795      |
|    total_timesteps      | 148480    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00378  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 35.4      |
|    n_updates            | 11590     |
|    policy_gradient_loss | -4.47e-09 |
|    value_loss           | 69.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.2      |
|    ep_rew_mean          | -3.88     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1161      |
|    time_elapsed         | 3797      |
|    total_timesteps      | 148608    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00382  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53.7      |
|    n_updates            | 11600     |
|    policy_gradient_loss | -3.17e-09 |
|    value_loss           | 86.6      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75       |
|    ep_rew_mean          | -4.28    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1162     |
|    time_elapsed         | 3800     |
|    total_timesteps      | 148736   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00392 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 36       |
|    n_updates            | 11610    |
|    policy_gradient_loss | 8.38e-10 |
|    value_loss           | 69.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -4.41     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1163      |
|    time_elapsed         | 3803      |
|    total_timesteps      | 148864    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00398  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 37.8      |
|    n_updates            | 11620     |
|    policy_gradient_loss | -5.94e-09 |
|    value_loss           | 101       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.2     |
|    ep_rew_mean          | -4.41    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1164     |
|    time_elapsed         | 3807     |
|    total_timesteps      | 148992   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0041  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 39       |
|    n_updates            | 11630    |
|    policy_gradient_loss | 2.1e-10  |
|    value_loss           | 84.3     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 149000
Best mean reward: -0.99 - Last mean reward per episode: -5.44
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.8     |
|    ep_rew_mean          | -4.62    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1165     |
|    time_elapsed         | 3812     |
|    total_timesteps      | 149120   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00425 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 32.4     |
|    n_updates            | 11640    |
|    policy_gradient_loss | 2.88e-08 |
|    value_loss           | 61.9     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.8     |
|    ep_rew_mean          | -4.62    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1166     |
|    time_elapsed         | 3815     |
|    total_timesteps      | 149248   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0043  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 89.7     |
|    n_updates            | 11650    |
|    policy_gradient_loss | 5.59e-09 |
|    value_loss           | 153      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -4.62     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1167      |
|    time_elapsed         | 3819      |
|    total_timesteps      | 149376    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00433  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30.6      |
|    n_updates            | 11660     |
|    policy_gradient_loss | -1.35e-08 |
|    value_loss           | 62.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -4.62     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1168      |
|    time_elapsed         | 3823      |
|    total_timesteps      | 149504    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00434  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 30.2      |
|    n_updates            | 11670     |
|    policy_gradient_loss | -1.68e-08 |
|    value_loss           | 59.9      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.8     |
|    ep_rew_mean          | -4.62    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1169     |
|    time_elapsed         | 3827     |
|    total_timesteps      | 149632   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00435 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 28.1     |
|    n_updates            | 11680    |
|    policy_gradient_loss | 4.54e-08 |
|    value_loss           | 58.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -4.62     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1170      |
|    time_elapsed         | 3831      |
|    total_timesteps      | 149760    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00436  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 27.7      |
|    n_updates            | 11690     |
|    policy_gradient_loss | -1.93e-08 |
|    value_loss           | 57.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -4.62     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1171      |
|    time_elapsed         | 3834      |
|    total_timesteps      | 149888    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00438  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 25.6      |
|    n_updates            | 11700     |
|    policy_gradient_loss | -3.15e-08 |
|    value_loss           | 56.6      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 150000
Best mean reward: -0.99 - Last mean reward per episode: -9.02
Eval num_timesteps=150000, episode_reward=-8.70 +/- 7.39
Episode length: 81.40 +/- 21.70
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 81.4      |
|    mean_reward          | -8.7      |
| time/                   |           |
|    total_timesteps      | 150000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00439  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 21.6      |
|    n_updates            | 11710     |
|    policy_gradient_loss | -2.09e-08 |
|    value_loss           | 51.9      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 83.2     |
|    ep_rew_mean     | -8.3     |
| time/              |          |
|    fps             | 39       |
|    iterations      | 1172     |
|    time_elapsed    | 3841     |
|    total_timesteps | 150016   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83        |
|    ep_rew_mean          | -8.42     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1173      |
|    time_elapsed         | 3844      |
|    total_timesteps      | 150144    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00441  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 37.1      |
|    n_updates            | 11720     |
|    policy_gradient_loss | -1.56e-09 |
|    value_loss           | 74.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.8      |
|    ep_rew_mean          | -8.41     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1174      |
|    time_elapsed         | 3847      |
|    total_timesteps      | 150272    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00447  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 66.1      |
|    n_updates            | 11730     |
|    policy_gradient_loss | -6.75e-09 |
|    value_loss           | 107       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.7     |
|    ep_rew_mean          | -8.35    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1175     |
|    time_elapsed         | 3850     |
|    total_timesteps      | 150400   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00457 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 60       |
|    n_updates            | 11740    |
|    policy_gradient_loss | 2.37e-09 |
|    value_loss           | 112      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.5      |
|    ep_rew_mean          | -8.32     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1176      |
|    time_elapsed         | 3852      |
|    total_timesteps      | 150528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00467  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 40.7      |
|    n_updates            | 11750     |
|    policy_gradient_loss | -3.07e-09 |
|    value_loss           | 104       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.5      |
|    ep_rew_mean          | -8.32     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1177      |
|    time_elapsed         | 3855      |
|    total_timesteps      | 150656    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00474  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.3      |
|    n_updates            | 11760     |
|    policy_gradient_loss | -2.42e-09 |
|    value_loss           | 103       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.5      |
|    ep_rew_mean          | -8.32     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1178      |
|    time_elapsed         | 3858      |
|    total_timesteps      | 150784    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0048   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 28.1      |
|    n_updates            | 11770     |
|    policy_gradient_loss | 7.38e-08  |
|    value_loss           | 56.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.5     |
|    ep_rew_mean          | -8.32    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1179     |
|    time_elapsed         | 3861     |
|    total_timesteps      | 150912   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00483 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 25.4     |
|    n_updates            | 11780    |
|    policy_gradient_loss | 1.4e-09  |
|    value_loss           | 53.8     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 151000
Best mean reward: -0.99 - Last mean reward per episode: -9.58
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.5     |
|    ep_rew_mean          | -8.32    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1180     |
|    time_elapsed         | 3865     |
|    total_timesteps      | 151040   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00485 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 25.1     |
|    n_updates            | 11790    |
|    policy_gradient_loss | 2.79e-08 |
|    value_loss           | 52.8     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.5     |
|    ep_rew_mean          | -8.32    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1181     |
|    time_elapsed         | 3868     |
|    total_timesteps      | 151168   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00486 |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 24.8     |
|    n_updates            | 11800    |
|    policy_gradient_loss | 1.67e-08 |
|    value_loss           | 52       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.5      |
|    ep_rew_mean          | -8.32     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1182      |
|    time_elapsed         | 3871      |
|    total_timesteps      | 151296    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00488  |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 25.8      |
|    n_updates            | 11810     |
|    policy_gradient_loss | -3.95e-08 |
|    value_loss           | 51.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.5      |
|    ep_rew_mean          | -8.32     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1183      |
|    time_elapsed         | 3874      |
|    total_timesteps      | 151424    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0049   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 24.2      |
|    n_updates            | 11820     |
|    policy_gradient_loss | 2.7e-09   |
|    value_loss           | 50.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 91.9      |
|    ep_rew_mean          | -13.3     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1184      |
|    time_elapsed         | 3877      |
|    total_timesteps      | 151552    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00491  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 21.8      |
|    n_updates            | 11830     |
|    policy_gradient_loss | -4.78e-08 |
|    value_loss           | 49.1      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 91.9     |
|    ep_rew_mean          | -13.3    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1185     |
|    time_elapsed         | 3881     |
|    total_timesteps      | 151680   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00493 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 17.2     |
|    n_updates            | 11840    |
|    policy_gradient_loss | -7.4e-09 |
|    value_loss           | 36.7     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 92.3      |
|    ep_rew_mean          | -13.4     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1186      |
|    time_elapsed         | 3884      |
|    total_timesteps      | 151808    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00496  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 54.1      |
|    n_updates            | 11850     |
|    policy_gradient_loss | -2.19e-09 |
|    value_loss           | 89.1      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 92.3     |
|    ep_rew_mean          | -13.4    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1187     |
|    time_elapsed         | 3888     |
|    total_timesteps      | 151936   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.005   |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 70.9     |
|    n_updates            | 11860    |
|    policy_gradient_loss | 2.65e-09 |
|    value_loss           | 130      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 152000
Best mean reward: -0.99 - Last mean reward per episode: -15.64
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 94.2     |
|    ep_rew_mean          | -14.2    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1188     |
|    time_elapsed         | 3892     |
|    total_timesteps      | 152064   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00503 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 21.5     |
|    n_updates            | 11870    |
|    policy_gradient_loss | 3.22e-08 |
|    value_loss           | 45.7     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.1          |
|    ep_rew_mean          | -14.1         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 1189          |
|    time_elapsed         | 3895          |
|    total_timesteps      | 152192        |
| train/                  |               |
|    approx_kl            | 3.1706877e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00492      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 134           |
|    n_updates            | 11880         |
|    policy_gradient_loss | -6.02e-05     |
|    value_loss           | 272           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.9      |
|    ep_rew_mean          | -13.9     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1190      |
|    time_elapsed         | 3898      |
|    total_timesteps      | 152320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00461  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 101       |
|    n_updates            | 11890     |
|    policy_gradient_loss | -4.47e-09 |
|    value_loss           | 168       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 93.9     |
|    ep_rew_mean          | -14.1    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1191     |
|    time_elapsed         | 3901     |
|    total_timesteps      | 152448   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00456 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 104      |
|    n_updates            | 11900    |
|    policy_gradient_loss | 5.4e-09  |
|    value_loss           | 163      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.3      |
|    ep_rew_mean          | -14.2     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1192      |
|    time_elapsed         | 3906      |
|    total_timesteps      | 152576    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00458  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.4      |
|    n_updates            | 11910     |
|    policy_gradient_loss | -1.86e-09 |
|    value_loss           | 87.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.5      |
|    ep_rew_mean          | -14.3     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1193      |
|    time_elapsed         | 3909      |
|    total_timesteps      | 152704    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00462  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 132       |
|    n_updates            | 11920     |
|    policy_gradient_loss | -7.22e-09 |
|    value_loss           | 225       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 94.4     |
|    ep_rew_mean          | -14.2    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1194     |
|    time_elapsed         | 3912     |
|    total_timesteps      | 152832   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00465 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 52.5     |
|    n_updates            | 11930    |
|    policy_gradient_loss | 2.79e-10 |
|    value_loss           | 120      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.7      |
|    ep_rew_mean          | -14.4     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1195      |
|    time_elapsed         | 3915      |
|    total_timesteps      | 152960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00471  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 57.6      |
|    n_updates            | 11940     |
|    policy_gradient_loss | -2.14e-09 |
|    value_loss           | 79.7      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 153000
Best mean reward: -0.99 - Last mean reward per episode: -15.24
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95        |
|    ep_rew_mean          | -14.5     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1196      |
|    time_elapsed         | 3918      |
|    total_timesteps      | 153088    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00478  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 101       |
|    n_updates            | 11950     |
|    policy_gradient_loss | -1.44e-09 |
|    value_loss           | 208       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.5      |
|    ep_rew_mean          | -14.8     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1197      |
|    time_elapsed         | 3921      |
|    total_timesteps      | 153216    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00483  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.6      |
|    n_updates            | 11960     |
|    policy_gradient_loss | -2.58e-09 |
|    value_loss           | 80        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 95.3     |
|    ep_rew_mean          | -15      |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1198     |
|    time_elapsed         | 3925     |
|    total_timesteps      | 153344   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00492 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 65       |
|    n_updates            | 11970    |
|    policy_gradient_loss | -2.7e-09 |
|    value_loss           | 126      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.2      |
|    ep_rew_mean          | -14.4     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1199      |
|    time_elapsed         | 3928      |
|    total_timesteps      | 153472    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.005    |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 67.9      |
|    n_updates            | 11980     |
|    policy_gradient_loss | -1.12e-09 |
|    value_loss           | 116       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 94.3     |
|    ep_rew_mean          | -14.2    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1200     |
|    time_elapsed         | 3931     |
|    total_timesteps      | 153600   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00506 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 75       |
|    n_updates            | 11990    |
|    policy_gradient_loss | 8.85e-10 |
|    value_loss           | 157      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.7      |
|    ep_rew_mean          | -14.4     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1201      |
|    time_elapsed         | 3935      |
|    total_timesteps      | 153728    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00518  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 111       |
|    n_updates            | 12000     |
|    policy_gradient_loss | -1.91e-09 |
|    value_loss           | 177       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.7      |
|    ep_rew_mean          | -14.4     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1202      |
|    time_elapsed         | 3938      |
|    total_timesteps      | 153856    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00545  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.8      |
|    n_updates            | 12010     |
|    policy_gradient_loss | -9.31e-10 |
|    value_loss           | 117       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.7      |
|    ep_rew_mean          | -14.4     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1203      |
|    time_elapsed         | 3943      |
|    total_timesteps      | 153984    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00561  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 27.3      |
|    n_updates            | 12020     |
|    policy_gradient_loss | -4.33e-09 |
|    value_loss           | 52.5      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 154000
Best mean reward: -0.99 - Last mean reward per episode: -15.11
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 94.7     |
|    ep_rew_mean          | -14.4    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1204     |
|    time_elapsed         | 3947     |
|    total_timesteps      | 154112   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00567 |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 23       |
|    n_updates            | 12030    |
|    policy_gradient_loss | 5.52e-08 |
|    value_loss           | 50.1     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 94.7     |
|    ep_rew_mean          | -14.4    |
| time/                   |          |
|    fps                  | 39       |
|    iterations           | 1205     |
|    time_elapsed         | 3951     |
|    total_timesteps      | 154240   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0057  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 23.2     |
|    n_updates            | 12040    |
|    policy_gradient_loss | 3.76e-08 |
|    value_loss           | 49.2     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.7      |
|    ep_rew_mean          | -14.4     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1206      |
|    time_elapsed         | 3956      |
|    total_timesteps      | 154368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00572  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 24.5      |
|    n_updates            | 12050     |
|    policy_gradient_loss | 5.31e-09  |
|    value_loss           | 48.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.7      |
|    ep_rew_mean          | -14.4     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1207      |
|    time_elapsed         | 3960      |
|    total_timesteps      | 154496    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00575  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 23.1      |
|    n_updates            | 12060     |
|    policy_gradient_loss | -1.51e-09 |
|    value_loss           | 47.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.7      |
|    ep_rew_mean          | -14.4     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 1208      |
|    time_elapsed         | 3964      |
|    total_timesteps      | 154624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00578  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 21.6      |
|    n_updates            | 12070     |
|    policy_gradient_loss | -9.97e-09 |
|    value_loss           | 46.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 104       |
|    ep_rew_mean          | -19.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1209      |
|    time_elapsed         | 3968      |
|    total_timesteps      | 154752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00581  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 21.7      |
|    n_updates            | 12080     |
|    policy_gradient_loss | -2.65e-08 |
|    value_loss           | 45.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 103       |
|    ep_rew_mean          | -18.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1210      |
|    time_elapsed         | 3972      |
|    total_timesteps      | 154880    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00595  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 79.8      |
|    n_updates            | 12090     |
|    policy_gradient_loss | -6.75e-09 |
|    value_loss           | 119       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 155000
Best mean reward: -0.99 - Last mean reward per episode: -19.13
Eval num_timesteps=155000, episode_reward=-0.10 +/- 2.20
Episode length: 60.20 +/- 4.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 60.2      |
|    mean_reward          | -0.1      |
| time/                   |           |
|    total_timesteps      | 155000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00623  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 140       |
|    n_updates            | 12100     |
|    policy_gradient_loss | -4.84e-09 |
|    value_loss           | 226       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 103      |
|    ep_rew_mean     | -18.6    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1211     |
|    time_elapsed    | 3977     |
|    total_timesteps | 155008   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 103       |
|    ep_rew_mean          | -18.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1212      |
|    time_elapsed         | 3981      |
|    total_timesteps      | 155136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00635  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 58.2      |
|    n_updates            | 12110     |
|    policy_gradient_loss | 0         |
|    value_loss           | 90.8      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 103          |
|    ep_rew_mean          | -18.6        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1213         |
|    time_elapsed         | 3985         |
|    total_timesteps      | 155264       |
| train/                  |              |
|    approx_kl            | 0.0038803364 |
|    clip_fraction        | 0.0109       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00438     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 54.8         |
|    n_updates            | 12120        |
|    policy_gradient_loss | -0.0016      |
|    value_loss           | 81.6         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 104       |
|    ep_rew_mean          | -19.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1214      |
|    time_elapsed         | 3989      |
|    total_timesteps      | 155392    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00281  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 48.5      |
|    n_updates            | 12130     |
|    policy_gradient_loss | -1.58e-09 |
|    value_loss           | 132       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 104       |
|    ep_rew_mean          | -19.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1215      |
|    time_elapsed         | 3992      |
|    total_timesteps      | 155520    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00268  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 64.5      |
|    n_updates            | 12140     |
|    policy_gradient_loss | -5.17e-09 |
|    value_loss           | 135       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 104      |
|    ep_rew_mean          | -19.2    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1216     |
|    time_elapsed         | 3996     |
|    total_timesteps      | 155648   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00268 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 37.8     |
|    n_updates            | 12150    |
|    policy_gradient_loss | 7.45e-10 |
|    value_loss           | 85       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 103       |
|    ep_rew_mean          | -18.9     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1217      |
|    time_elapsed         | 3999      |
|    total_timesteps      | 155776    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00271  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 89        |
|    n_updates            | 12160     |
|    policy_gradient_loss | -1.63e-09 |
|    value_loss           | 136       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 103      |
|    ep_rew_mean          | -18.8    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1218     |
|    time_elapsed         | 4002     |
|    total_timesteps      | 155904   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00273 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 99       |
|    n_updates            | 12170    |
|    policy_gradient_loss | 1.07e-09 |
|    value_loss           | 205      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 156000
Best mean reward: -0.99 - Last mean reward per episode: -18.70
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 102          |
|    ep_rew_mean          | -18.4        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1219         |
|    time_elapsed         | 4005         |
|    total_timesteps      | 156032       |
| train/                  |              |
|    approx_kl            | 0.0005158372 |
|    clip_fraction        | 0.00313      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00245     |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 61.6         |
|    n_updates            | 12180        |
|    policy_gradient_loss | -0.000663    |
|    value_loss           | 124          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 103       |
|    ep_rew_mean          | -18.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1220      |
|    time_elapsed         | 4008      |
|    total_timesteps      | 156160    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00207  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 64.2      |
|    n_updates            | 12190     |
|    policy_gradient_loss | -2.56e-09 |
|    value_loss           | 122       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 102       |
|    ep_rew_mean          | -18.4     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1221      |
|    time_elapsed         | 4012      |
|    total_timesteps      | 156288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00204  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 87        |
|    n_updates            | 12200     |
|    policy_gradient_loss | -8.38e-10 |
|    value_loss           | 123       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 102       |
|    ep_rew_mean          | -18.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1222      |
|    time_elapsed         | 4015      |
|    total_timesteps      | 156416    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00209  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 71.2      |
|    n_updates            | 12210     |
|    policy_gradient_loss | -1.26e-09 |
|    value_loss           | 127       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 102      |
|    ep_rew_mean          | -18.3    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1223     |
|    time_elapsed         | 4018     |
|    total_timesteps      | 156544   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00211 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 73.8     |
|    n_updates            | 12220    |
|    policy_gradient_loss | 1.96e-09 |
|    value_loss           | 120      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 102       |
|    ep_rew_mean          | -18.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1224      |
|    time_elapsed         | 4021      |
|    total_timesteps      | 156672    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00212  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 64.3      |
|    n_updates            | 12230     |
|    policy_gradient_loss | -5.17e-09 |
|    value_loss           | 119       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 101      |
|    ep_rew_mean          | -18.3    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1225     |
|    time_elapsed         | 4024     |
|    total_timesteps      | 156800   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00213 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 55.2     |
|    n_updates            | 12240    |
|    policy_gradient_loss | 5.77e-09 |
|    value_loss           | 121      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 101       |
|    ep_rew_mean          | -18       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1226      |
|    time_elapsed         | 4028      |
|    total_timesteps      | 156928    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00215  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45.8      |
|    n_updates            | 12250     |
|    policy_gradient_loss | -9.73e-09 |
|    value_loss           | 90.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 157000
Best mean reward: -0.99 - Last mean reward per episode: -18.19
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 101      |
|    ep_rew_mean          | -17.9    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1227     |
|    time_elapsed         | 4030     |
|    total_timesteps      | 157056   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00216 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 62.1     |
|    n_updates            | 12260    |
|    policy_gradient_loss | 5.54e-09 |
|    value_loss           | 127      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 101      |
|    ep_rew_mean          | -18.2    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1228     |
|    time_elapsed         | 4034     |
|    total_timesteps      | 157184   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00217 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 45.9     |
|    n_updates            | 12270    |
|    policy_gradient_loss | 3.21e-09 |
|    value_loss           | 80.2     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 102      |
|    ep_rew_mean          | -18.3    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1229     |
|    time_elapsed         | 4038     |
|    total_timesteps      | 157312   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00219 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 87.3     |
|    n_updates            | 12280    |
|    policy_gradient_loss | 7.12e-09 |
|    value_loss           | 194      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 102       |
|    ep_rew_mean          | -18.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1230      |
|    time_elapsed         | 4042      |
|    total_timesteps      | 157440    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0022   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 81.2      |
|    n_updates            | 12290     |
|    policy_gradient_loss | -1.35e-09 |
|    value_loss           | 151       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 101       |
|    ep_rew_mean          | -18.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1231      |
|    time_elapsed         | 4045      |
|    total_timesteps      | 157568    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00221  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.1      |
|    n_updates            | 12300     |
|    policy_gradient_loss | -1.12e-09 |
|    value_loss           | 76.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 101       |
|    ep_rew_mean          | -17.9     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1232      |
|    time_elapsed         | 4048      |
|    total_timesteps      | 157696    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00224  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.4      |
|    n_updates            | 12310     |
|    policy_gradient_loss | -1.86e-10 |
|    value_loss           | 111       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 101      |
|    ep_rew_mean          | -18.2    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1233     |
|    time_elapsed         | 4051     |
|    total_timesteps      | 157824   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00226 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 98.6     |
|    n_updates            | 12320    |
|    policy_gradient_loss | 1.86e-09 |
|    value_loss           | 153      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 101       |
|    ep_rew_mean          | -18.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1234      |
|    time_elapsed         | 4054      |
|    total_timesteps      | 157952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00227  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 63.7      |
|    n_updates            | 12330     |
|    policy_gradient_loss | 1.84e-09  |
|    value_loss           | 106       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 158000
Best mean reward: -0.99 - Last mean reward per episode: -18.23
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 99.8     |
|    ep_rew_mean          | -17.8    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1235     |
|    time_elapsed         | 4058     |
|    total_timesteps      | 158080   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00229 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 32.6     |
|    n_updates            | 12340    |
|    policy_gradient_loss | 3.96e-09 |
|    value_loss           | 75       |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 100      |
|    ep_rew_mean          | -17.8    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1236     |
|    time_elapsed         | 4061     |
|    total_timesteps      | 158208   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00231 |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 51.4     |
|    n_updates            | 12350    |
|    policy_gradient_loss | 2.93e-09 |
|    value_loss           | 82.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 100       |
|    ep_rew_mean          | -17.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1237      |
|    time_elapsed         | 4064      |
|    total_timesteps      | 158336    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00234  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 79.5      |
|    n_updates            | 12360     |
|    policy_gradient_loss | -2.47e-09 |
|    value_loss           | 153       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 99.8      |
|    ep_rew_mean          | -17.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1238      |
|    time_elapsed         | 4067      |
|    total_timesteps      | 158464    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00236  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 98.6      |
|    n_updates            | 12370     |
|    policy_gradient_loss | -5.03e-09 |
|    value_loss           | 204       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 99.8      |
|    ep_rew_mean          | -17.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1239      |
|    time_elapsed         | 4070      |
|    total_timesteps      | 158592    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00237  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 71.5      |
|    n_updates            | 12380     |
|    policy_gradient_loss | -3.17e-09 |
|    value_loss           | 143       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 99.5      |
|    ep_rew_mean          | -17.4     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1240      |
|    time_elapsed         | 4073      |
|    total_timesteps      | 158720    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00238  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45.4      |
|    n_updates            | 12390     |
|    policy_gradient_loss | -5.82e-09 |
|    value_loss           | 99.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 98.4      |
|    ep_rew_mean          | -16.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1241      |
|    time_elapsed         | 4076      |
|    total_timesteps      | 158848    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0024   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 28.7      |
|    n_updates            | 12400     |
|    policy_gradient_loss | -5.17e-09 |
|    value_loss           | 75.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 98.4      |
|    ep_rew_mean          | -16.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1242      |
|    time_elapsed         | 4080      |
|    total_timesteps      | 158976    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00242  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 83        |
|    n_updates            | 12410     |
|    policy_gradient_loss | 7.59e-09  |
|    value_loss           | 196       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 159000
Best mean reward: -0.99 - Last mean reward per episode: -12.70
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 98.4     |
|    ep_rew_mean          | -16.7    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1243     |
|    time_elapsed         | 4085     |
|    total_timesteps      | 159104   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00244 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 28.3     |
|    n_updates            | 12420    |
|    policy_gradient_loss | 5.96e-09 |
|    value_loss           | 56.2     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 101       |
|    ep_rew_mean          | -17.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1244      |
|    time_elapsed         | 4090      |
|    total_timesteps      | 159232    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00245  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 26.3      |
|    n_updates            | 12430     |
|    policy_gradient_loss | 4.12e-08  |
|    value_loss           | 53.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 101       |
|    ep_rew_mean          | -17.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1245      |
|    time_elapsed         | 4093      |
|    total_timesteps      | 159360    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00245  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 156       |
|    n_updates            | 12440     |
|    policy_gradient_loss | -3.73e-09 |
|    value_loss           | 192       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.9      |
|    ep_rew_mean          | -14.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1246      |
|    time_elapsed         | 4097      |
|    total_timesteps      | 159488    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00246  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.4      |
|    n_updates            | 12450     |
|    policy_gradient_loss | -5.82e-09 |
|    value_loss           | 77.6      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 93.9     |
|    ep_rew_mean          | -14.3    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1247     |
|    time_elapsed         | 4100     |
|    total_timesteps      | 159616   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00248 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 66.2     |
|    n_updates            | 12460    |
|    policy_gradient_loss | 4.54e-10 |
|    value_loss           | 143      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.4      |
|    ep_rew_mean          | -14.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1248      |
|    time_elapsed         | 4102      |
|    total_timesteps      | 159744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0025   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.9      |
|    n_updates            | 12470     |
|    policy_gradient_loss | -4.66e-11 |
|    value_loss           | 77.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 94       |
|    ep_rew_mean          | -14.3    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1249     |
|    time_elapsed         | 4105     |
|    total_timesteps      | 159872   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00253 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 38.1     |
|    n_updates            | 12480    |
|    policy_gradient_loss | 2.33e-09 |
|    value_loss           | 95.5     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 160000
Best mean reward: -0.99 - Last mean reward per episode: -8.38
Eval num_timesteps=160000, episode_reward=-9.60 +/- 22.72
Episode length: 83.20 +/- 42.41
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 83.2      |
|    mean_reward          | -9.6      |
| time/                   |           |
|    total_timesteps      | 160000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00261  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 75.9      |
|    n_updates            | 12490     |
|    policy_gradient_loss | -1.35e-09 |
|    value_loss           | 150       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 94.2     |
|    ep_rew_mean     | -14.4    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1250     |
|    time_elapsed    | 4111     |
|    total_timesteps | 160000   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.5      |
|    ep_rew_mean          | -14.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1251      |
|    time_elapsed         | 4114      |
|    total_timesteps      | 160128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00269  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 49        |
|    n_updates            | 12500     |
|    policy_gradient_loss | -4.03e-09 |
|    value_loss           | 102       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.5      |
|    ep_rew_mean          | -9.76     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1252      |
|    time_elapsed         | 4117      |
|    total_timesteps      | 160256    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00273  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30.3      |
|    n_updates            | 12510     |
|    policy_gradient_loss | -6.52e-10 |
|    value_loss           | 75        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.6      |
|    ep_rew_mean          | -9.99     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1253      |
|    time_elapsed         | 4120      |
|    total_timesteps      | 160384    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00276  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 27.3      |
|    n_updates            | 12520     |
|    policy_gradient_loss | -3.17e-09 |
|    value_loss           | 73.9      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.8     |
|    ep_rew_mean          | -9.01    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1254     |
|    time_elapsed         | 4123     |
|    total_timesteps      | 160512   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00279 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 49.6     |
|    n_updates            | 12530    |
|    policy_gradient_loss | 6.52e-10 |
|    value_loss           | 103      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.9      |
|    ep_rew_mean          | -9.03     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1255      |
|    time_elapsed         | 4126      |
|    total_timesteps      | 160640    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00282  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 67.6      |
|    n_updates            | 12540     |
|    policy_gradient_loss | -6.98e-10 |
|    value_loss           | 143       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.8      |
|    ep_rew_mean          | -9.02     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1256      |
|    time_elapsed         | 4129      |
|    total_timesteps      | 160768    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00284  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 105       |
|    n_updates            | 12550     |
|    policy_gradient_loss | -7.22e-09 |
|    value_loss           | 189       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84       |
|    ep_rew_mean          | -9.18    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1257     |
|    time_elapsed         | 4133     |
|    total_timesteps      | 160896   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00286 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 75.1     |
|    n_updates            | 12560    |
|    policy_gradient_loss | 1.35e-09 |
|    value_loss           | 135      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 161000
Best mean reward: -0.99 - Last mean reward per episode: -8.85
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84       |
|    ep_rew_mean          | -9.18    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1258     |
|    time_elapsed         | 4136     |
|    total_timesteps      | 161024   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0029  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 50.9     |
|    n_updates            | 12570    |
|    policy_gradient_loss | 4.61e-09 |
|    value_loss           | 98.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84        |
|    ep_rew_mean          | -9.18     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1259      |
|    time_elapsed         | 4139      |
|    total_timesteps      | 161152    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00295  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 27.9      |
|    n_updates            | 12580     |
|    policy_gradient_loss | 1.42e-08  |
|    value_loss           | 58.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84        |
|    ep_rew_mean          | -9.18     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1260      |
|    time_elapsed         | 4143      |
|    total_timesteps      | 161280    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00297  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 27.1      |
|    n_updates            | 12590     |
|    policy_gradient_loss | -1.35e-08 |
|    value_loss           | 55.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84        |
|    ep_rew_mean          | -9.18     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1261      |
|    time_elapsed         | 4146      |
|    total_timesteps      | 161408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00298  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 24.9      |
|    n_updates            | 12600     |
|    policy_gradient_loss | -1.34e-08 |
|    value_loss           | 54.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84       |
|    ep_rew_mean          | -9.18    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1262     |
|    time_elapsed         | 4150     |
|    total_timesteps      | 161536   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00299 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 25.9     |
|    n_updates            | 12610    |
|    policy_gradient_loss | 8.94e-09 |
|    value_loss           | 53.7     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84        |
|    ep_rew_mean          | -9.18     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1263      |
|    time_elapsed         | 4153      |
|    total_timesteps      | 161664    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.003    |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 24.6      |
|    n_updates            | 12620     |
|    policy_gradient_loss | 1.02e-07  |
|    value_loss           | 52.8      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84       |
|    ep_rew_mean          | -9.18    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1264     |
|    time_elapsed         | 4157     |
|    total_timesteps      | 161792   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00301 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 24.6     |
|    n_updates            | 12630    |
|    policy_gradient_loss | 1.37e-08 |
|    value_loss           | 51.9     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 92.8     |
|    ep_rew_mean          | -14.1    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1265     |
|    time_elapsed         | 4160     |
|    total_timesteps      | 161920   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00302 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 24.6     |
|    n_updates            | 12640    |
|    policy_gradient_loss | 5.75e-08 |
|    value_loss           | 51.1     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 162000
Best mean reward: -0.99 - Last mean reward per episode: -13.96
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 92.7      |
|    ep_rew_mean          | -13.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1266      |
|    time_elapsed         | 4163      |
|    total_timesteps      | 162048    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00303  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 17.1      |
|    n_updates            | 12650     |
|    policy_gradient_loss | -1.51e-08 |
|    value_loss           | 37.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.5      |
|    ep_rew_mean          | -14.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1267      |
|    time_elapsed         | 4167      |
|    total_timesteps      | 162176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00304  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 114       |
|    n_updates            | 12660     |
|    policy_gradient_loss | -3.17e-09 |
|    value_loss           | 209       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.1      |
|    ep_rew_mean          | -14.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1268      |
|    time_elapsed         | 4171      |
|    total_timesteps      | 162304    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00306  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 34.3      |
|    n_updates            | 12670     |
|    policy_gradient_loss | 8.01e-09  |
|    value_loss           | 81        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 92.7     |
|    ep_rew_mean          | -14.1    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1269     |
|    time_elapsed         | 4173     |
|    total_timesteps      | 162432   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0031  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 70.1     |
|    n_updates            | 12680    |
|    policy_gradient_loss | 4.42e-09 |
|    value_loss           | 111      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 92.1     |
|    ep_rew_mean          | -13.8    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1270     |
|    time_elapsed         | 4176     |
|    total_timesteps      | 162560   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00314 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 62.3     |
|    n_updates            | 12690    |
|    policy_gradient_loss | 4.14e-09 |
|    value_loss           | 109      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 92.1      |
|    ep_rew_mean          | -13.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1271      |
|    time_elapsed         | 4179      |
|    total_timesteps      | 162688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00319  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.9      |
|    n_updates            | 12700     |
|    policy_gradient_loss | -3.82e-09 |
|    value_loss           | 107       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 92.6      |
|    ep_rew_mean          | -14       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1272      |
|    time_elapsed         | 4182      |
|    total_timesteps      | 162816    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00324  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.7      |
|    n_updates            | 12710     |
|    policy_gradient_loss | -6.52e-10 |
|    value_loss           | 85        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.8      |
|    ep_rew_mean          | -14.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1273      |
|    time_elapsed         | 4186      |
|    total_timesteps      | 162944    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00328  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41        |
|    n_updates            | 12720     |
|    policy_gradient_loss | -2.05e-09 |
|    value_loss           | 87.6      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 163000
Best mean reward: -0.99 - Last mean reward per episode: -10.28
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 93.9     |
|    ep_rew_mean          | -14.8    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1274     |
|    time_elapsed         | 4189     |
|    total_timesteps      | 163072   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00338 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 76.4     |
|    n_updates            | 12730    |
|    policy_gradient_loss | 7.45e-10 |
|    value_loss           | 138      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84       |
|    ep_rew_mean          | -9.4     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1275     |
|    time_elapsed         | 4192     |
|    total_timesteps      | 163200   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00364 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 38.2     |
|    n_updates            | 12740    |
|    policy_gradient_loss | -2e-09   |
|    value_loss           | 76.7     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.1      |
|    ep_rew_mean          | -9.56     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1276      |
|    time_elapsed         | 4196      |
|    total_timesteps      | 163328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00378  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 123       |
|    n_updates            | 12750     |
|    policy_gradient_loss | -4.07e-09 |
|    value_loss           | 238       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.3     |
|    ep_rew_mean          | -9.73    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1277     |
|    time_elapsed         | 4199     |
|    total_timesteps      | 163456   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00385 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 41.3     |
|    n_updates            | 12760    |
|    policy_gradient_loss | 2.19e-09 |
|    value_loss           | 77.9     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84       |
|    ep_rew_mean          | -9.51    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1278     |
|    time_elapsed         | 4202     |
|    total_timesteps      | 163584   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00396 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 31.4     |
|    n_updates            | 12770    |
|    policy_gradient_loss | 4.66e-11 |
|    value_loss           | 91       |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.6     |
|    ep_rew_mean          | -9.21    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1279     |
|    time_elapsed         | 4205     |
|    total_timesteps      | 163712   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00415 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 49.6     |
|    n_updates            | 12780    |
|    policy_gradient_loss | 1.7e-09  |
|    value_loss           | 92.2     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.5     |
|    ep_rew_mean          | -9.17    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1280     |
|    time_elapsed         | 4209     |
|    total_timesteps      | 163840   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00438 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 100      |
|    n_updates            | 12790    |
|    policy_gradient_loss | 2.79e-10 |
|    value_loss           | 219      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.5     |
|    ep_rew_mean          | -9.44    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1281     |
|    time_elapsed         | 4212     |
|    total_timesteps      | 163968   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00449 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 53.6     |
|    n_updates            | 12800    |
|    policy_gradient_loss | 3.03e-09 |
|    value_loss           | 84.3     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 164000
Best mean reward: -0.99 - Last mean reward per episode: -9.91
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.6      |
|    ep_rew_mean          | -9.52     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1282      |
|    time_elapsed         | 4216      |
|    total_timesteps      | 164096    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00464  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 62.4      |
|    n_updates            | 12810     |
|    policy_gradient_loss | -1.12e-09 |
|    value_loss           | 176       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.6      |
|    ep_rew_mean          | -9.52     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1283      |
|    time_elapsed         | 4220      |
|    total_timesteps      | 164224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00496  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 70.5      |
|    n_updates            | 12820     |
|    policy_gradient_loss | -2.79e-10 |
|    value_loss           | 130       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85       |
|    ep_rew_mean          | -9.48    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1284     |
|    time_elapsed         | 4223     |
|    total_timesteps      | 164352   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00541 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 43.7     |
|    n_updates            | 12830    |
|    policy_gradient_loss | 2.21e-09 |
|    value_loss           | 81       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.2      |
|    ep_rew_mean          | -9.59     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1285      |
|    time_elapsed         | 4227      |
|    total_timesteps      | 164480    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00576  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 130       |
|    n_updates            | 12840     |
|    policy_gradient_loss | -1.7e-09  |
|    value_loss           | 260       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.2     |
|    ep_rew_mean          | -9.57    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1286     |
|    time_elapsed         | 4230     |
|    total_timesteps      | 164608   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00603 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 51.6     |
|    n_updates            | 12850    |
|    policy_gradient_loss | -1.3e-09 |
|    value_loss           | 99       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.2      |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1287      |
|    time_elapsed         | 4233      |
|    total_timesteps      | 164736    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00663  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.6      |
|    n_updates            | 12860     |
|    policy_gradient_loss | -3.07e-09 |
|    value_loss           | 90.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.9     |
|    ep_rew_mean          | -9.96    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1288     |
|    time_elapsed         | 4236     |
|    total_timesteps      | 164864   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00695 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 63.3     |
|    n_updates            | 12870    |
|    policy_gradient_loss | 1.07e-09 |
|    value_loss           | 82.5     |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 86.9         |
|    ep_rew_mean          | -10.4        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1289         |
|    time_elapsed         | 4239         |
|    total_timesteps      | 164992       |
| train/                  |              |
|    approx_kl            | 0.0014238367 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00928     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 64.5         |
|    n_updates            | 12880        |
|    policy_gradient_loss | -4.72e-05    |
|    value_loss           | 142          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 165000
Best mean reward: -0.99 - Last mean reward per episode: -10.88
Eval num_timesteps=165000, episode_reward=-10.70 +/- 11.75
Episode length: 93.40 +/- 20.16
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 93.4          |
|    mean_reward          | -10.7         |
| time/                   |               |
|    total_timesteps      | 165000        |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.012        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 27.2          |
|    n_updates            | 12890         |
|    policy_gradient_loss | -1.68e-09     |
|    value_loss           | 83.5          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 86.9     |
|    ep_rew_mean     | -10.4    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1290     |
|    time_elapsed    | 4245     |
|    total_timesteps | 165120   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 86.9        |
|    ep_rew_mean          | -10.5       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 1291        |
|    time_elapsed         | 4248        |
|    total_timesteps      | 165248      |
| train/                  |             |
|    approx_kl            | 0.006886609 |
|    clip_fraction        | 0.0133      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00783    |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 31.8        |
|    n_updates            | 12900       |
|    policy_gradient_loss | -0.00163    |
|    value_loss           | 81.1        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.3      |
|    ep_rew_mean          | -10.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1292      |
|    time_elapsed         | 4250      |
|    total_timesteps      | 165376    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00502  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 68.8      |
|    n_updates            | 12910     |
|    policy_gradient_loss | -2.79e-09 |
|    value_loss           | 118       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.2      |
|    ep_rew_mean          | -10.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1293      |
|    time_elapsed         | 4254      |
|    total_timesteps      | 165504    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00506  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 85.8      |
|    n_updates            | 12920     |
|    policy_gradient_loss | -1.07e-09 |
|    value_loss           | 131       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 88.2         |
|    ep_rew_mean          | -10.8        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1294         |
|    time_elapsed         | 4257         |
|    total_timesteps      | 165632       |
| train/                  |              |
|    approx_kl            | 1.657568e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00541     |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 89.5         |
|    n_updates            | 12930        |
|    policy_gradient_loss | 6.49e-08     |
|    value_loss           | 215          |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 88.2     |
|    ep_rew_mean          | -10.8    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1295     |
|    time_elapsed         | 4261     |
|    total_timesteps      | 165760   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00561 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 44.9     |
|    n_updates            | 12940    |
|    policy_gradient_loss | 2.79e-10 |
|    value_loss           | 83.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.2     |
|    ep_rew_mean          | -11.3    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1296     |
|    time_elapsed         | 4264     |
|    total_timesteps      | 165888   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00582 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 27.6     |
|    n_updates            | 12950    |
|    policy_gradient_loss | 8.61e-10 |
|    value_loss           | 83.6     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 166000
Best mean reward: -0.99 - Last mean reward per episode: -11.66
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.4      |
|    ep_rew_mean          | -11.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1297      |
|    time_elapsed         | 4267      |
|    total_timesteps      | 166016    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00605  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 33.9      |
|    n_updates            | 12960     |
|    policy_gradient_loss | -7.78e-09 |
|    value_loss           | 82.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.3      |
|    ep_rew_mean          | -11.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1298      |
|    time_elapsed         | 4271      |
|    total_timesteps      | 166144    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00627  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 155       |
|    n_updates            | 12970     |
|    policy_gradient_loss | -7.92e-10 |
|    value_loss           | 236       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.3      |
|    ep_rew_mean          | -11.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1299      |
|    time_elapsed         | 4274      |
|    total_timesteps      | 166272    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00649  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.1      |
|    n_updates            | 12980     |
|    policy_gradient_loss | -5.54e-09 |
|    value_loss           | 84        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.9      |
|    ep_rew_mean          | -11.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1300      |
|    time_elapsed         | 4278      |
|    total_timesteps      | 166400    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00694  |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 86.9      |
|    n_updates            | 12990     |
|    policy_gradient_loss | -2.93e-09 |
|    value_loss           | 175       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.7      |
|    ep_rew_mean          | -11.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1301      |
|    time_elapsed         | 4282      |
|    total_timesteps      | 166528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0073   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 51        |
|    n_updates            | 13000     |
|    policy_gradient_loss | 2.14e-09  |
|    value_loss           | 128       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.8      |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1302      |
|    time_elapsed         | 4286      |
|    total_timesteps      | 166656    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00783  |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 95.4      |
|    n_updates            | 13010     |
|    policy_gradient_loss | -1.86e-10 |
|    value_loss           | 221       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 89.4       |
|    ep_rew_mean          | -11.1      |
| time/                   |            |
|    fps                  | 38         |
|    iterations           | 1303       |
|    time_elapsed         | 4289       |
|    total_timesteps      | 166784     |
| train/                  |            |
|    approx_kl            | 0.00216369 |
|    clip_fraction        | 0.00547    |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0108    |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 47.7       |
|    n_updates            | 13020      |
|    policy_gradient_loss | -0.00183   |
|    value_loss           | 126        |
----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 89.1          |
|    ep_rew_mean          | -10.9         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1304          |
|    time_elapsed         | 4292          |
|    total_timesteps      | 166912        |
| train/                  |               |
|    approx_kl            | 2.9802322e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0145       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 68.8          |
|    n_updates            | 13030         |
|    policy_gradient_loss | -1.49e-09     |
|    value_loss           | 126           |
-------------------------------------------
Num timesteps: 167000
Best mean reward: -0.99 - Last mean reward per episode: -12.29
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.6      |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1305      |
|    time_elapsed         | 4295      |
|    total_timesteps      | 167040    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0157   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 69.9      |
|    n_updates            | 13040     |
|    policy_gradient_loss | -2.28e-09 |
|    value_loss           | 127       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 89.6          |
|    ep_rew_mean          | -11.2         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1306          |
|    time_elapsed         | 4299          |
|    total_timesteps      | 167168        |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.017        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 66.2          |
|    n_updates            | 13050         |
|    policy_gradient_loss | -1.96e-09     |
|    value_loss           | 129           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 89.8          |
|    ep_rew_mean          | -11.2         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1307          |
|    time_elapsed         | 4302          |
|    total_timesteps      | 167296        |
| train/                  |               |
|    approx_kl            | 1.7881393e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0199       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 59            |
|    n_updates            | 13060         |
|    policy_gradient_loss | -2.98e-09     |
|    value_loss           | 120           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 89.8         |
|    ep_rew_mean          | -11.4        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1308         |
|    time_elapsed         | 4304         |
|    total_timesteps      | 167424       |
| train/                  |              |
|    approx_kl            | 1.013279e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0267      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 73.6         |
|    n_updates            | 13070        |
|    policy_gradient_loss | -1.28e-09    |
|    value_loss           | 131          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 89.9        |
|    ep_rew_mean          | -11.5       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 1309        |
|    time_elapsed         | 4307        |
|    total_timesteps      | 167552      |
| train/                  |             |
|    approx_kl            | 0.002211776 |
|    clip_fraction        | 0.00625     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0218     |
|    explained_variance   | 1.19e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 74.7        |
|    n_updates            | 13080       |
|    policy_gradient_loss | -0.000846   |
|    value_loss           | 123         |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 90.4     |
|    ep_rew_mean          | -11.7    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1310     |
|    time_elapsed         | 4310     |
|    total_timesteps      | 167680   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0153  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 46.1     |
|    n_updates            | 13090    |
|    policy_gradient_loss | 6.43e-09 |
|    value_loss           | 86.5     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.1      |
|    ep_rew_mean          | -11.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1311      |
|    time_elapsed         | 4314      |
|    total_timesteps      | 167808    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0155   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 109       |
|    n_updates            | 13100     |
|    policy_gradient_loss | -1.02e-09 |
|    value_loss           | 169       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87       |
|    ep_rew_mean          | -10.4    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1312     |
|    time_elapsed         | 4316     |
|    total_timesteps      | 167936   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0162  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 62.8     |
|    n_updates            | 13110    |
|    policy_gradient_loss | 1.72e-09 |
|    value_loss           | 117      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 168000
Best mean reward: -0.99 - Last mean reward per episode: -10.88
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.3      |
|    ep_rew_mean          | -10.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1313      |
|    time_elapsed         | 4319      |
|    total_timesteps      | 168064    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0168   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.7      |
|    n_updates            | 13120     |
|    policy_gradient_loss | -4.47e-09 |
|    value_loss           | 112       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.5     |
|    ep_rew_mean          | -10.1    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1314     |
|    time_elapsed         | 4323     |
|    total_timesteps      | 168192   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0175  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 54       |
|    n_updates            | 13130    |
|    policy_gradient_loss | 1.91e-09 |
|    value_loss           | 117      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.5      |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1315      |
|    time_elapsed         | 4326      |
|    total_timesteps      | 168320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.019    |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 68.2      |
|    n_updates            | 13140     |
|    policy_gradient_loss | -7.92e-10 |
|    value_loss           | 183       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 86.4         |
|    ep_rew_mean          | -9.99        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1316         |
|    time_elapsed         | 4328         |
|    total_timesteps      | 168448       |
| train/                  |              |
|    approx_kl            | 0.0018078433 |
|    clip_fraction        | 0.0102       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0237      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 33.2         |
|    n_updates            | 13150        |
|    policy_gradient_loss | -0.00144     |
|    value_loss           | 78.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 86.8          |
|    ep_rew_mean          | -10.3         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1317          |
|    time_elapsed         | 4332          |
|    total_timesteps      | 168576        |
| train/                  |               |
|    approx_kl            | 0.00081084203 |
|    clip_fraction        | 0.0125        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0356       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 39.5          |
|    n_updates            | 13160         |
|    policy_gradient_loss | -0.00147      |
|    value_loss           | 83.9          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 86.6        |
|    ep_rew_mean          | -10.2       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 1318        |
|    time_elapsed         | 4335        |
|    total_timesteps      | 168704      |
| train/                  |             |
|    approx_kl            | 8.34465e-07 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0283     |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 44.1        |
|    n_updates            | 13170       |
|    policy_gradient_loss | -3.49e-09   |
|    value_loss           | 111         |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 86            |
|    ep_rew_mean          | -9.72         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1319          |
|    time_elapsed         | 4338          |
|    total_timesteps      | 168832        |
| train/                  |               |
|    approx_kl            | 5.3152442e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0247       |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 41            |
|    n_updates            | 13180         |
|    policy_gradient_loss | -9.42e-05     |
|    value_loss           | 110           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 85.5         |
|    ep_rew_mean          | -9.44        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1320         |
|    time_elapsed         | 4342         |
|    total_timesteps      | 168960       |
| train/                  |              |
|    approx_kl            | 0.0005126237 |
|    clip_fraction        | 0.00391      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.022       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 127          |
|    n_updates            | 13190        |
|    policy_gradient_loss | -0.00083     |
|    value_loss           | 202          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 169000
Best mean reward: -0.99 - Last mean reward per episode: -10.28
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 85.4         |
|    ep_rew_mean          | -9.52        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1321         |
|    time_elapsed         | 4345         |
|    total_timesteps      | 169088       |
| train/                  |              |
|    approx_kl            | 0.0005239812 |
|    clip_fraction        | 0.00313      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0177      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 57.6         |
|    n_updates            | 13200        |
|    policy_gradient_loss | -0.000849    |
|    value_loss           | 105          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 85.4          |
|    ep_rew_mean          | -9.6          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1322          |
|    time_elapsed         | 4348          |
|    total_timesteps      | 169216        |
| train/                  |               |
|    approx_kl            | 0.00016632769 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0145       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 60.5          |
|    n_updates            | 13210         |
|    policy_gradient_loss | -1.17e-05     |
|    value_loss           | 104           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.5      |
|    ep_rew_mean          | -9.74     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1323      |
|    time_elapsed         | 4351      |
|    total_timesteps      | 169344    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0156   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 72.6      |
|    n_updates            | 13220     |
|    policy_gradient_loss | -3.26e-09 |
|    value_loss           | 138       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.5     |
|    ep_rew_mean          | -9.68    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1324     |
|    time_elapsed         | 4354     |
|    total_timesteps      | 169472   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0162  |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 53.1     |
|    n_updates            | 13230    |
|    policy_gradient_loss | 3.05e-09 |
|    value_loss           | 100      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.1     |
|    ep_rew_mean          | -4.63    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1325     |
|    time_elapsed         | 4358     |
|    total_timesteps      | 169600   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0167  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 62.6     |
|    n_updates            | 13240    |
|    policy_gradient_loss | 6.47e-09 |
|    value_loss           | 133      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.1     |
|    ep_rew_mean          | -4.63    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1326     |
|    time_elapsed         | 4362     |
|    total_timesteps      | 169728   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0172  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.2     |
|    n_updates            | 13250    |
|    policy_gradient_loss | 2.84e-09 |
|    value_loss           | 88.2     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.7      |
|    ep_rew_mean          | -4.25     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1327      |
|    time_elapsed         | 4365      |
|    total_timesteps      | 169856    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0184   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 62        |
|    n_updates            | 13260     |
|    policy_gradient_loss | -3.07e-09 |
|    value_loss           | 155       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 75.5         |
|    ep_rew_mean          | -4.15        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1328         |
|    time_elapsed         | 4369         |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 0.0027931072 |
|    clip_fraction        | 0.00625      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0146      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 63.6         |
|    n_updates            | 13270        |
|    policy_gradient_loss | -0.000857    |
|    value_loss           | 159          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 170000
Best mean reward: -0.99 - Last mean reward per episode: -4.25
Eval num_timesteps=170000, episode_reward=-0.70 +/- 3.40
Episode length: 61.40 +/- 6.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 61.4      |
|    mean_reward          | -0.7      |
| time/                   |           |
|    total_timesteps      | 170000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0118   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.8      |
|    n_updates            | 13280     |
|    policy_gradient_loss | -6.47e-09 |
|    value_loss           | 92        |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.8     |
|    ep_rew_mean     | -4.31    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1329     |
|    time_elapsed    | 4374     |
|    total_timesteps | 170112   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.9      |
|    ep_rew_mean          | -4.26     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1330      |
|    time_elapsed         | 4377      |
|    total_timesteps      | 170240    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0122   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 53.4      |
|    n_updates            | 13290     |
|    policy_gradient_loss | -2.56e-09 |
|    value_loss           | 94.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.8      |
|    ep_rew_mean          | -3.78     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1331      |
|    time_elapsed         | 4380      |
|    total_timesteps      | 170368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0125   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 56.9      |
|    n_updates            | 13300     |
|    policy_gradient_loss | -3.68e-09 |
|    value_loss           | 117       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74       |
|    ep_rew_mean          | -3.42    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1332     |
|    time_elapsed         | 4384     |
|    total_timesteps      | 170496   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0129  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 41.2     |
|    n_updates            | 13310    |
|    policy_gradient_loss | 2.44e-09 |
|    value_loss           | 84.5     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.2      |
|    ep_rew_mean          | -3.4      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1333      |
|    time_elapsed         | 4387      |
|    total_timesteps      | 170624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0136   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46        |
|    n_updates            | 13320     |
|    policy_gradient_loss | -1.58e-09 |
|    value_loss           | 88.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.1      |
|    ep_rew_mean          | -3.44     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1334      |
|    time_elapsed         | 4390      |
|    total_timesteps      | 170752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0143   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 71.3      |
|    n_updates            | 13330     |
|    policy_gradient_loss | -6.47e-09 |
|    value_loss           | 157       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.3      |
|    ep_rew_mean          | -3.46     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1335      |
|    time_elapsed         | 4393      |
|    total_timesteps      | 170880    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0148   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.9      |
|    n_updates            | 13340     |
|    policy_gradient_loss | -4.66e-10 |
|    value_loss           | 82.3      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 171000
Best mean reward: -0.99 - Last mean reward per episode: -3.87
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.8      |
|    ep_rew_mean          | -3.8      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1336      |
|    time_elapsed         | 4396      |
|    total_timesteps      | 171008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0156   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 92.7      |
|    n_updates            | 13350     |
|    policy_gradient_loss | -6.29e-09 |
|    value_loss           | 154       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.4      |
|    ep_rew_mean          | -3.62     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1337      |
|    time_elapsed         | 4399      |
|    total_timesteps      | 171136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0159   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 28        |
|    n_updates            | 13360     |
|    policy_gradient_loss | -1.15e-08 |
|    value_loss           | 68.1      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.4     |
|    ep_rew_mean          | -3.79    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1338     |
|    time_elapsed         | 4402     |
|    total_timesteps      | 171264   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0163  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 34       |
|    n_updates            | 13370    |
|    policy_gradient_loss | 2.84e-09 |
|    value_loss           | 83.1     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 73.2          |
|    ep_rew_mean          | -3.42         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1339          |
|    time_elapsed         | 4405          |
|    total_timesteps      | 171392        |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0177       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 42            |
|    n_updates            | 13380         |
|    policy_gradient_loss | -2.17e-09     |
|    value_loss           | 79.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 73.1          |
|    ep_rew_mean          | -3.15         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1340          |
|    time_elapsed         | 4408          |
|    total_timesteps      | 171520        |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0197       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 48.8          |
|    n_updates            | 13390         |
|    policy_gradient_loss | -4.38e-09     |
|    value_loss           | 83.5          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 72.8         |
|    ep_rew_mean          | -3.09        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1341         |
|    time_elapsed         | 4411         |
|    total_timesteps      | 171648       |
| train/                  |              |
|    approx_kl            | 0.0012582606 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0267      |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 81.2         |
|    n_updates            | 13400        |
|    policy_gradient_loss | -0.000676    |
|    value_loss           | 164          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 73            |
|    ep_rew_mean          | -3.31         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1342          |
|    time_elapsed         | 4414          |
|    total_timesteps      | 171776        |
| train/                  |               |
|    approx_kl            | 2.3841858e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0354       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 36.9          |
|    n_updates            | 13410         |
|    policy_gradient_loss | -2.14e-09     |
|    value_loss           | 75            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 73.6          |
|    ep_rew_mean          | -3.6          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1343          |
|    time_elapsed         | 4417          |
|    total_timesteps      | 171904        |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0377       |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 68            |
|    n_updates            | 13420         |
|    policy_gradient_loss | 6.52e-10      |
|    value_loss           | 118           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 172000
Best mean reward: -0.99 - Last mean reward per episode: -2.72
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73        |
|    ep_rew_mean          | -3.31     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1344      |
|    time_elapsed         | 4420      |
|    total_timesteps      | 172032    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.039    |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 31.9      |
|    n_updates            | 13430     |
|    policy_gradient_loss | -3.05e-09 |
|    value_loss           | 71.5      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 72.8         |
|    ep_rew_mean          | -3.23        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1345         |
|    time_elapsed         | 4424         |
|    total_timesteps      | 172160       |
| train/                  |              |
|    approx_kl            | 9.110989e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0376      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 27.9         |
|    n_updates            | 13440        |
|    policy_gradient_loss | -0.000248    |
|    value_loss           | 66.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 71.6         |
|    ep_rew_mean          | -2.62        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1346         |
|    time_elapsed         | 4427         |
|    total_timesteps      | 172288       |
| train/                  |              |
|    approx_kl            | 0.0005366616 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0399      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 63.7         |
|    n_updates            | 13450        |
|    policy_gradient_loss | -0.000378    |
|    value_loss           | 114          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 71.5         |
|    ep_rew_mean          | -2.44        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1347         |
|    time_elapsed         | 4430         |
|    total_timesteps      | 172416       |
| train/                  |              |
|    approx_kl            | 0.0018201964 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0327      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 37.2         |
|    n_updates            | 13460        |
|    policy_gradient_loss | -0.000767    |
|    value_loss           | 85.7         |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 70.3     |
|    ep_rew_mean          | -2.04    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1348     |
|    time_elapsed         | 4433     |
|    total_timesteps      | 172544   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0233  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 62.1     |
|    n_updates            | 13470    |
|    policy_gradient_loss | 2.13e-09 |
|    value_loss           | 120      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.8      |
|    ep_rew_mean          | -2.12     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1349      |
|    time_elapsed         | 4436      |
|    total_timesteps      | 172672    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0234   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 75.3      |
|    n_updates            | 13480     |
|    policy_gradient_loss | -8.85e-10 |
|    value_loss           | 132       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.2      |
|    ep_rew_mean          | -1.78     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1350      |
|    time_elapsed         | 4440      |
|    total_timesteps      | 172800    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0238   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 66.7      |
|    n_updates            | 13490     |
|    policy_gradient_loss | -1.86e-09 |
|    value_loss           | 145       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 70.3         |
|    ep_rew_mean          | -1.85        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1351         |
|    time_elapsed         | 4444         |
|    total_timesteps      | 172928       |
| train/                  |              |
|    approx_kl            | 2.142042e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0243      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 42.9         |
|    n_updates            | 13500        |
|    policy_gradient_loss | 4.58e-06     |
|    value_loss           | 72           |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 173000
Best mean reward: -0.99 - Last mean reward per episode: -1.52
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 70.4         |
|    ep_rew_mean          | -2.1         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1352         |
|    time_elapsed         | 4447         |
|    total_timesteps      | 173056       |
| train/                  |              |
|    approx_kl            | 7.404573e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.023       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 38           |
|    n_updates            | 13510        |
|    policy_gradient_loss | -0.000297    |
|    value_loss           | 66.4         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.4      |
|    ep_rew_mean          | -2.12     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1353      |
|    time_elapsed         | 4450      |
|    total_timesteps      | 173184    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0206   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 38.6      |
|    n_updates            | 13520     |
|    policy_gradient_loss | 2.19e-09  |
|    value_loss           | 109       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 70.8     |
|    ep_rew_mean          | -2.41    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1354     |
|    time_elapsed         | 4454     |
|    total_timesteps      | 173312   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0204  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 33.1     |
|    n_updates            | 13530    |
|    policy_gradient_loss | 1.14e-08 |
|    value_loss           | 67.7     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 70       |
|    ep_rew_mean          | -2.21    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1355     |
|    time_elapsed         | 4457     |
|    total_timesteps      | 173440   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0206  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.2     |
|    n_updates            | 13540    |
|    policy_gradient_loss | 7.68e-10 |
|    value_loss           | 90.4     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 70       |
|    ep_rew_mean          | -2.29    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1356     |
|    time_elapsed         | 4460     |
|    total_timesteps      | 173568   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0213  |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 29.5     |
|    n_updates            | 13550    |
|    policy_gradient_loss | 7.24e-09 |
|    value_loss           | 87.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70        |
|    ep_rew_mean          | -2.27     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1357      |
|    time_elapsed         | 4463      |
|    total_timesteps      | 173696    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.022    |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 40.9      |
|    n_updates            | 13560     |
|    policy_gradient_loss | -5.77e-09 |
|    value_loss           | 69.1      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 70.2          |
|    ep_rew_mean          | -2.3          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1358          |
|    time_elapsed         | 4467          |
|    total_timesteps      | 173824        |
| train/                  |               |
|    approx_kl            | 2.9406045e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0228       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 38            |
|    n_updates            | 13570         |
|    policy_gradient_loss | -1.98e-05     |
|    value_loss           | 92.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 70.2          |
|    ep_rew_mean          | -2.3          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1359          |
|    time_elapsed         | 4469          |
|    total_timesteps      | 173952        |
| train/                  |               |
|    approx_kl            | 2.0456966e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0235       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 47.2          |
|    n_updates            | 13580         |
|    policy_gradient_loss | -6.21e-05     |
|    value_loss           | 102           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 174000
Best mean reward: -0.99 - Last mean reward per episode: -2.27
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 70.1          |
|    ep_rew_mean          | -2.23         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1360          |
|    time_elapsed         | 4472          |
|    total_timesteps      | 174080        |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0201       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 51.2          |
|    n_updates            | 13590         |
|    policy_gradient_loss | -1.04e-08     |
|    value_loss           | 90.9          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 69.8     |
|    ep_rew_mean          | -2.19    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1361     |
|    time_elapsed         | 4475     |
|    total_timesteps      | 174208   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0194  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 50.1     |
|    n_updates            | 13600    |
|    policy_gradient_loss | 4.33e-09 |
|    value_loss           | 89.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 70.3     |
|    ep_rew_mean          | -2.45    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1362     |
|    time_elapsed         | 4479     |
|    total_timesteps      | 174336   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0197  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.9     |
|    n_updates            | 13610    |
|    policy_gradient_loss | 4.47e-09 |
|    value_loss           | 84.3     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.3      |
|    ep_rew_mean          | -2.26     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1363      |
|    time_elapsed         | 4482      |
|    total_timesteps      | 174464    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.02     |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 75.2      |
|    n_updates            | 13620     |
|    policy_gradient_loss | -5.36e-09 |
|    value_loss           | 130       |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 70.4        |
|    ep_rew_mean          | -2.19       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 1364        |
|    time_elapsed         | 4485        |
|    total_timesteps      | 174592      |
| train/                  |             |
|    approx_kl            | 0.001412299 |
|    clip_fraction        | 0.00391     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0251     |
|    explained_variance   | -2.38e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 76.5        |
|    n_updates            | 13630       |
|    policy_gradient_loss | -0.00154    |
|    value_loss           | 161         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 70.3         |
|    ep_rew_mean          | -2.25        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1365         |
|    time_elapsed         | 4489         |
|    total_timesteps      | 174720       |
| train/                  |              |
|    approx_kl            | 5.662441e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0358      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 75.8         |
|    n_updates            | 13640        |
|    policy_gradient_loss | 3.73e-09     |
|    value_loss           | 128          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 70.4         |
|    ep_rew_mean          | -2.22        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1366         |
|    time_elapsed         | 4492         |
|    total_timesteps      | 174848       |
| train/                  |              |
|    approx_kl            | 5.066395e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.041       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 47.7         |
|    n_updates            | 13650        |
|    policy_gradient_loss | 4.1e-09      |
|    value_loss           | 85.8         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 70.7          |
|    ep_rew_mean          | -2.36         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1367          |
|    time_elapsed         | 4495          |
|    total_timesteps      | 174976        |
| train/                  |               |
|    approx_kl            | 1.7881393e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0457       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 63.1          |
|    n_updates            | 13660         |
|    policy_gradient_loss | 3.17e-09      |
|    value_loss           | 102           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 175000
Best mean reward: -0.99 - Last mean reward per episode: -2.48
Eval num_timesteps=175000, episode_reward=0.80 +/- 14.96
Episode length: 78.40 +/- 19.16
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 78.4          |
|    mean_reward          | 0.8           |
| time/                   |               |
|    total_timesteps      | 175000        |
| train/                  |               |
|    approx_kl            | 0.00050659664 |
|    clip_fraction        | 0.00391       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0399       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 50.3          |
|    n_updates            | 13670         |
|    policy_gradient_loss | -0.00104      |
|    value_loss           | 88.1          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 70.7     |
|    ep_rew_mean     | -2.36    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1368     |
|    time_elapsed    | 4500     |
|    total_timesteps | 175104   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 70.9      |
|    ep_rew_mean          | -2.56     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1369      |
|    time_elapsed         | 4504      |
|    total_timesteps      | 175232    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0331   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30.3      |
|    n_updates            | 13680     |
|    policy_gradient_loss | -5.37e-08 |
|    value_loss           | 62.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.1      |
|    ep_rew_mean          | -2.65     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1370      |
|    time_elapsed         | 4507      |
|    total_timesteps      | 175360    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0325   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50        |
|    n_updates            | 13690     |
|    policy_gradient_loss | -4.31e-09 |
|    value_loss           | 112       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 71.6         |
|    ep_rew_mean          | -3.02        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1371         |
|    time_elapsed         | 4510         |
|    total_timesteps      | 175488       |
| train/                  |              |
|    approx_kl            | 4.374655e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0315      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 37.6         |
|    n_updates            | 13700        |
|    policy_gradient_loss | -0.000195    |
|    value_loss           | 69           |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72       |
|    ep_rew_mean          | -3.23    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1372     |
|    time_elapsed         | 4513     |
|    total_timesteps      | 175616   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0286  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 33.1     |
|    n_updates            | 13710    |
|    policy_gradient_loss | 2.98e-09 |
|    value_loss           | 69.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 71.4     |
|    ep_rew_mean          | -2.92    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1373     |
|    time_elapsed         | 4516     |
|    total_timesteps      | 175744   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0283  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 48.5     |
|    n_updates            | 13720    |
|    policy_gradient_loss | 4.67e-09 |
|    value_loss           | 85.5     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 71.4          |
|    ep_rew_mean          | -2.72         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1374          |
|    time_elapsed         | 4518          |
|    total_timesteps      | 175872        |
| train/                  |               |
|    approx_kl            | 2.9802322e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0293       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 33.5          |
|    n_updates            | 13730         |
|    policy_gradient_loss | 7.45e-10      |
|    value_loss           | 87.4          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 176000
Best mean reward: -0.99 - Last mean reward per episode: -2.92
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 71.6      |
|    ep_rew_mean          | -2.79     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1375      |
|    time_elapsed         | 4521      |
|    total_timesteps      | 176000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.031    |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 72.1      |
|    n_updates            | 13740     |
|    policy_gradient_loss | -3.96e-09 |
|    value_loss           | 167       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 72            |
|    ep_rew_mean          | -2.99         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1376          |
|    time_elapsed         | 4526          |
|    total_timesteps      | 176128        |
| train/                  |               |
|    approx_kl            | 3.1888485e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0318       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 32.8          |
|    n_updates            | 13750         |
|    policy_gradient_loss | 3.85e-06      |
|    value_loss           | 74.8          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.3      |
|    ep_rew_mean          | -3.15     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1377      |
|    time_elapsed         | 4529      |
|    total_timesteps      | 176256    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0321   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 89.2      |
|    n_updates            | 13760     |
|    policy_gradient_loss | -4.56e-09 |
|    value_loss           | 168       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.1     |
|    ep_rew_mean          | -3.06    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1378     |
|    time_elapsed         | 4533     |
|    total_timesteps      | 176384   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0329  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 41.7     |
|    n_updates            | 13770    |
|    policy_gradient_loss | 7.45e-10 |
|    value_loss           | 81.6     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 72.1          |
|    ep_rew_mean          | -2.96         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1379          |
|    time_elapsed         | 4536          |
|    total_timesteps      | 176512        |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.035        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 41.6          |
|    n_updates            | 13780         |
|    policy_gradient_loss | 1.91e-09      |
|    value_loss           | 80.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 72.1          |
|    ep_rew_mean          | -2.96         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1380          |
|    time_elapsed         | 4540          |
|    total_timesteps      | 176640        |
| train/                  |               |
|    approx_kl            | 2.5049783e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0359       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 66.9          |
|    n_updates            | 13790         |
|    policy_gradient_loss | -9.62e-05     |
|    value_loss           | 111           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 72.1         |
|    ep_rew_mean          | -2.96        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1381         |
|    time_elapsed         | 4545         |
|    total_timesteps      | 176768       |
| train/                  |              |
|    approx_kl            | 4.174933e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0323      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 29           |
|    n_updates            | 13800        |
|    policy_gradient_loss | -0.000247    |
|    value_loss           | 61.8         |
------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 75.5           |
|    ep_rew_mean          | -4.62          |
| time/                   |                |
|    fps                  | 38             |
|    iterations           | 1382           |
|    time_elapsed         | 4549           |
|    total_timesteps      | 176896         |
| train/                  |                |
|    approx_kl            | 0.000101102516 |
|    clip_fraction        | 0              |
|    clip_range           | 0.2            |
|    entropy_loss         | -0.0295        |
|    explained_variance   | -1.19e-07      |
|    learning_rate        | 0.0003         |
|    loss                 | 29.1           |
|    n_updates            | 13810          |
|    policy_gradient_loss | -0.000402      |
|    value_loss           | 60.8           |
--------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 177000
Best mean reward: -0.99 - Last mean reward per episode: -4.61
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.3      |
|    ep_rew_mean          | -4.47     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1383      |
|    time_elapsed         | 4553      |
|    total_timesteps      | 177024    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0275   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 67.6      |
|    n_updates            | 13820     |
|    policy_gradient_loss | -2.19e-09 |
|    value_loss           | 127       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.5          |
|    ep_rew_mean          | -4.46         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1384          |
|    time_elapsed         | 4556          |
|    total_timesteps      | 177152        |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0284       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 51.7          |
|    n_updates            | 13830         |
|    policy_gradient_loss | 3.26e-10      |
|    value_loss           | 125           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.6          |
|    ep_rew_mean          | -4.72         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1385          |
|    time_elapsed         | 4559          |
|    total_timesteps      | 177280        |
| train/                  |               |
|    approx_kl            | 2.6717316e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0301       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 81.3          |
|    n_updates            | 13840         |
|    policy_gradient_loss | -6.62e-05     |
|    value_loss           | 163           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.4          |
|    ep_rew_mean          | -4.7          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1386          |
|    time_elapsed         | 4563          |
|    total_timesteps      | 177408        |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.033        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 39.7          |
|    n_updates            | 13850         |
|    policy_gradient_loss | 5.54e-09      |
|    value_loss           | 84.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.4          |
|    ep_rew_mean          | -4.68         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1387          |
|    time_elapsed         | 4566          |
|    total_timesteps      | 177536        |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0361       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 33.1          |
|    n_updates            | 13860         |
|    policy_gradient_loss | -2.24e-09     |
|    value_loss           | 68.1          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.2     |
|    ep_rew_mean          | -4.58    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1388     |
|    time_elapsed         | 4569     |
|    total_timesteps      | 177664   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0374  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 78.8     |
|    n_updates            | 13870    |
|    policy_gradient_loss | 1.54e-09 |
|    value_loss           | 142      |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 75          |
|    ep_rew_mean          | -4.33       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 1389        |
|    time_elapsed         | 4572        |
|    total_timesteps      | 177792      |
| train/                  |             |
|    approx_kl            | 0.004786651 |
|    clip_fraction        | 0.00625     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0579     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 56.9        |
|    n_updates            | 13880       |
|    policy_gradient_loss | -0.00263    |
|    value_loss           | 87          |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 75.3         |
|    ep_rew_mean          | -4.36        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1390         |
|    time_elapsed         | 4576         |
|    total_timesteps      | 177920       |
| train/                  |              |
|    approx_kl            | 0.0016530696 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0756      |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 66.3         |
|    n_updates            | 13890        |
|    policy_gradient_loss | -0.000128    |
|    value_loss           | 146          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 178000
Best mean reward: -0.99 - Last mean reward per episode: -4.38
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.4          |
|    ep_rew_mean          | -4.32         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1391          |
|    time_elapsed         | 4579          |
|    total_timesteps      | 178048        |
| train/                  |               |
|    approx_kl            | 1.5497208e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0478       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 53.7          |
|    n_updates            | 13900         |
|    policy_gradient_loss | 5.59e-10      |
|    value_loss           | 155           |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.7     |
|    ep_rew_mean          | -4.46    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1392     |
|    time_elapsed         | 4582     |
|    total_timesteps      | 178176   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0451  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 52       |
|    n_updates            | 13910    |
|    policy_gradient_loss | 4.38e-09 |
|    value_loss           | 123      |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 75.8         |
|    ep_rew_mean          | -4.5         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1393         |
|    time_elapsed         | 4586         |
|    total_timesteps      | 178304       |
| train/                  |              |
|    approx_kl            | 9.558629e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0455      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 40.7         |
|    n_updates            | 13920        |
|    policy_gradient_loss | -6.34e-05    |
|    value_loss           | 84.9         |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.7     |
|    ep_rew_mean          | -4.67    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1394     |
|    time_elapsed         | 4589     |
|    total_timesteps      | 178432   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.043   |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 34.3     |
|    n_updates            | 13930    |
|    policy_gradient_loss | 2.79e-09 |
|    value_loss           | 159      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.3          |
|    ep_rew_mean          | -4.43         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1395          |
|    time_elapsed         | 4592          |
|    total_timesteps      | 178560        |
| train/                  |               |
|    approx_kl            | 0.00074730534 |
|    clip_fraction        | 0.00547       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0344       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 45            |
|    n_updates            | 13940         |
|    policy_gradient_loss | -0.00114      |
|    value_loss           | 87            |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.3      |
|    ep_rew_mean          | -4.37     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1396      |
|    time_elapsed         | 4595      |
|    total_timesteps      | 178688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0284   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 32        |
|    n_updates            | 13950     |
|    policy_gradient_loss | -1.86e-09 |
|    value_loss           | 84.6      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.5          |
|    ep_rew_mean          | -4.46         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1397          |
|    time_elapsed         | 4599          |
|    total_timesteps      | 178816        |
| train/                  |               |
|    approx_kl            | 0.00032308698 |
|    clip_fraction        | 0.00156       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.026        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 58.6          |
|    n_updates            | 13960         |
|    policy_gradient_loss | -0.00073      |
|    value_loss           | 113           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76            |
|    ep_rew_mean          | -4.5          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1398          |
|    time_elapsed         | 4602          |
|    total_timesteps      | 178944        |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0203       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 41            |
|    n_updates            | 13970         |
|    policy_gradient_loss | -4.89e-09     |
|    value_loss           | 68.1          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 179000
Best mean reward: -0.99 - Last mean reward per episode: -4.42
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76       |
|    ep_rew_mean          | -4.39    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1399     |
|    time_elapsed         | 4606     |
|    total_timesteps      | 179072   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0195  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 87       |
|    n_updates            | 13980    |
|    policy_gradient_loss | 3.61e-09 |
|    value_loss           | 161      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.1      |
|    ep_rew_mean          | -4.96     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1400      |
|    time_elapsed         | 4609      |
|    total_timesteps      | 179200    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0195   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 59.1      |
|    n_updates            | 13990     |
|    policy_gradient_loss | -8.43e-09 |
|    value_loss           | 99.9      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77       |
|    ep_rew_mean          | -4.91    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1401     |
|    time_elapsed         | 4613     |
|    total_timesteps      | 179328   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0197  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 37.7     |
|    n_updates            | 14000    |
|    policy_gradient_loss | -5.1e-09 |
|    value_loss           | 69.2     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.8     |
|    ep_rew_mean          | -4.91    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1402     |
|    time_elapsed         | 4616     |
|    total_timesteps      | 179456   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0198  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 84.9     |
|    n_updates            | 14010    |
|    policy_gradient_loss | 7.87e-09 |
|    value_loss           | 144      |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.4         |
|    ep_rew_mean          | -5           |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1403         |
|    time_elapsed         | 4620         |
|    total_timesteps      | 179584       |
| train/                  |              |
|    approx_kl            | 1.238659e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0198      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 30.8         |
|    n_updates            | 14020        |
|    policy_gradient_loss | -1.51e-08    |
|    value_loss           | 68.3         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.5      |
|    ep_rew_mean          | -5.54     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1404      |
|    time_elapsed         | 4624      |
|    total_timesteps      | 179712    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0201   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 58.5      |
|    n_updates            | 14030     |
|    policy_gradient_loss | -1.12e-09 |
|    value_loss           | 148       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.1     |
|    ep_rew_mean          | -5.37    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1405     |
|    time_elapsed         | 4628     |
|    total_timesteps      | 179840   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0206  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 37.2     |
|    n_updates            | 14040    |
|    policy_gradient_loss | 0        |
|    value_loss           | 68.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.3      |
|    ep_rew_mean          | -5.53     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1406      |
|    time_elapsed         | 4631      |
|    total_timesteps      | 179968    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0209   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 29.8      |
|    n_updates            | 14050     |
|    policy_gradient_loss | -1.91e-09 |
|    value_loss           | 71.4      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 180000
Best mean reward: -0.99 - Last mean reward per episode: -5.63
Eval num_timesteps=180000, episode_reward=-0.60 +/- 2.06
Episode length: 61.20 +/- 4.12
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 61.2      |
|    mean_reward          | -0.6      |
| time/                   |           |
|    total_timesteps      | 180000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0212   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.3      |
|    n_updates            | 14060     |
|    policy_gradient_loss | -5.15e-09 |
|    value_loss           | 85.9      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 78.3     |
|    ep_rew_mean     | -5.53    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1407     |
|    time_elapsed    | 4636     |
|    total_timesteps | 180096   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.9      |
|    ep_rew_mean          | -5.83     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1408      |
|    time_elapsed         | 4639      |
|    total_timesteps      | 180224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0217   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 31.2      |
|    n_updates            | 14070     |
|    policy_gradient_loss | -4.19e-09 |
|    value_loss           | 62        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.9     |
|    ep_rew_mean          | -6.37    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1409     |
|    time_elapsed         | 4642     |
|    total_timesteps      | 180352   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0218  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 38.3     |
|    n_updates            | 14080    |
|    policy_gradient_loss | 9.08e-09 |
|    value_loss           | 80.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.4     |
|    ep_rew_mean          | -6.59    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1410     |
|    time_elapsed         | 4646     |
|    total_timesteps      | 180480   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0221  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 57.1     |
|    n_updates            | 14090    |
|    policy_gradient_loss | 1.68e-09 |
|    value_loss           | 93       |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 80.4          |
|    ep_rew_mean          | -6.69         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1411          |
|    time_elapsed         | 4649          |
|    total_timesteps      | 180608        |
| train/                  |               |
|    approx_kl            | 1.2761448e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0221       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 26            |
|    n_updates            | 14100         |
|    policy_gradient_loss | -5.86e-05     |
|    value_loss           | 70.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 80.9          |
|    ep_rew_mean          | -6.95         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1412          |
|    time_elapsed         | 4652          |
|    total_timesteps      | 180736        |
| train/                  |               |
|    approx_kl            | 0.00018992368 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0201       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 40.7          |
|    n_updates            | 14110         |
|    policy_gradient_loss | -0.000511     |
|    value_loss           | 81.8          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.6     |
|    ep_rew_mean          | -7       |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1413     |
|    time_elapsed         | 4656     |
|    total_timesteps      | 180864   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.018   |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 60.5     |
|    n_updates            | 14120    |
|    policy_gradient_loss | 3.86e-09 |
|    value_loss           | 100      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 79.5          |
|    ep_rew_mean          | -6.46         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1414          |
|    time_elapsed         | 4659          |
|    total_timesteps      | 180992        |
| train/                  |               |
|    approx_kl            | 2.0816922e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0176       |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 75.3          |
|    n_updates            | 14130         |
|    policy_gradient_loss | -0.000103     |
|    value_loss           | 129           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 181000
Best mean reward: -0.99 - Last mean reward per episode: -5.80
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -6.46     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1415      |
|    time_elapsed         | 4662      |
|    total_timesteps      | 181120    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0164   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 39.3      |
|    n_updates            | 14140     |
|    policy_gradient_loss | -8.85e-10 |
|    value_loss           | 98.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.9     |
|    ep_rew_mean          | -7.14    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1416     |
|    time_elapsed         | 4665     |
|    total_timesteps      | 181248   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0165  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 30.5     |
|    n_updates            | 14150    |
|    policy_gradient_loss | 1.42e-09 |
|    value_loss           | 59.7     |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80.1         |
|    ep_rew_mean          | -6.44        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1417         |
|    time_elapsed         | 4669         |
|    total_timesteps      | 181376       |
| train/                  |              |
|    approx_kl            | 4.733028e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.016       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 63.2         |
|    n_updates            | 14160        |
|    policy_gradient_loss | -0.000149    |
|    value_loss           | 124          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.6      |
|    ep_rew_mean          | -6.59     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1418      |
|    time_elapsed         | 4672      |
|    total_timesteps      | 181504    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0145   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 93.8      |
|    n_updates            | 14170     |
|    policy_gradient_loss | 1.86e-10  |
|    value_loss           | 211       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 81.3         |
|    ep_rew_mean          | -6.93        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1419         |
|    time_elapsed         | 4676         |
|    total_timesteps      | 181632       |
| train/                  |              |
|    approx_kl            | 0.0003575473 |
|    clip_fraction        | 0.00234      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0127      |
|    explained_variance   | 1.79e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 47.7         |
|    n_updates            | 14180        |
|    policy_gradient_loss | -0.000603    |
|    value_loss           | 105          |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81       |
|    ep_rew_mean          | -6.6     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1420     |
|    time_elapsed         | 4679     |
|    total_timesteps      | 181760   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0103  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 28.2     |
|    n_updates            | 14190    |
|    policy_gradient_loss | 1.25e-08 |
|    value_loss           | 70.4     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81       |
|    ep_rew_mean          | -6.58    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1421     |
|    time_elapsed         | 4683     |
|    total_timesteps      | 181888   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.01    |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 90.7     |
|    n_updates            | 14200    |
|    policy_gradient_loss | -6.1e-09 |
|    value_loss           | 178      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 182000
Best mean reward: -0.99 - Last mean reward per episode: -6.58
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 81.4         |
|    ep_rew_mean          | -6.79        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1422         |
|    time_elapsed         | 4686         |
|    total_timesteps      | 182016       |
| train/                  |              |
|    approx_kl            | 0.0012009321 |
|    clip_fraction        | 0.00859      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0119      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 51.7         |
|    n_updates            | 14210        |
|    policy_gradient_loss | 0.000818     |
|    value_loss           | 98.7         |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.7     |
|    ep_rew_mean          | -7.04    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1423     |
|    time_elapsed         | 4690     |
|    total_timesteps      | 182144   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.012   |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40       |
|    n_updates            | 14220    |
|    policy_gradient_loss | 7.64e-09 |
|    value_loss           | 72.3     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.3      |
|    ep_rew_mean          | -7.34     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1424      |
|    time_elapsed         | 4693      |
|    total_timesteps      | 182272    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0114   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.9      |
|    n_updates            | 14230     |
|    policy_gradient_loss | -2.98e-09 |
|    value_loss           | 91        |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 82           |
|    ep_rew_mean          | -7.12        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1425         |
|    time_elapsed         | 4696         |
|    total_timesteps      | 182400       |
| train/                  |              |
|    approx_kl            | 5.283393e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0112      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 39.5         |
|    n_updates            | 14240        |
|    policy_gradient_loss | -4.88e-05    |
|    value_loss           | 70.4         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.6      |
|    ep_rew_mean          | -7        |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1426      |
|    time_elapsed         | 4700      |
|    total_timesteps      | 182528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0108   |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 62.4      |
|    n_updates            | 14250     |
|    policy_gradient_loss | 7.45e-10  |
|    value_loss           | 129       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.2     |
|    ep_rew_mean          | -7.29    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1427     |
|    time_elapsed         | 4703     |
|    total_timesteps      | 182656   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0108  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 54.1     |
|    n_updates            | 14260    |
|    policy_gradient_loss | 1.96e-09 |
|    value_loss           | 90       |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.4     |
|    ep_rew_mean          | -7.5     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1428     |
|    time_elapsed         | 4707     |
|    total_timesteps      | 182784   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0108  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 28.8     |
|    n_updates            | 14270    |
|    policy_gradient_loss | -1.4e-10 |
|    value_loss           | 70.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.7      |
|    ep_rew_mean          | -7.66     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1429      |
|    time_elapsed         | 4710      |
|    total_timesteps      | 182912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0109   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.6      |
|    n_updates            | 14280     |
|    policy_gradient_loss | -3.68e-09 |
|    value_loss           | 73.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 183000
Best mean reward: -0.99 - Last mean reward per episode: -7.42
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.8     |
|    ep_rew_mean          | -7.78    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1430     |
|    time_elapsed         | 4714     |
|    total_timesteps      | 183040   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0109  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 92.1     |
|    n_updates            | 14290    |
|    policy_gradient_loss | 2.14e-09 |
|    value_loss           | 131      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.6     |
|    ep_rew_mean          | -7.61    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1431     |
|    time_elapsed         | 4717     |
|    total_timesteps      | 183168   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0111  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 57.1     |
|    n_updates            | 14300    |
|    policy_gradient_loss | 4.89e-10 |
|    value_loss           | 109      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.4     |
|    ep_rew_mean          | -7.48    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1432     |
|    time_elapsed         | 4721     |
|    total_timesteps      | 183296   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0113  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 76.1     |
|    n_updates            | 14310    |
|    policy_gradient_loss | 5.26e-09 |
|    value_loss           | 174      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82       |
|    ep_rew_mean          | -7.32    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1433     |
|    time_elapsed         | 4724     |
|    total_timesteps      | 183424   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0114  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 33.4     |
|    n_updates            | 14320    |
|    policy_gradient_loss | 2.14e-09 |
|    value_loss           | 72.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.3      |
|    ep_rew_mean          | -7.46     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1434      |
|    time_elapsed         | 4727      |
|    total_timesteps      | 183552    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0115   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 59.3      |
|    n_updates            | 14330     |
|    policy_gradient_loss | 2.72e-09  |
|    value_loss           | 99.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.6      |
|    ep_rew_mean          | -7.11     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1435      |
|    time_elapsed         | 4730      |
|    total_timesteps      | 183680    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0118   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 40.5      |
|    n_updates            | 14340     |
|    policy_gradient_loss | 8.85e-10  |
|    value_loss           | 97.9      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81       |
|    ep_rew_mean          | -6.8     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1436     |
|    time_elapsed         | 4733     |
|    total_timesteps      | 183808   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0121  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 63.4     |
|    n_updates            | 14350    |
|    policy_gradient_loss | 2.89e-09 |
|    value_loss           | 97.7     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.2     |
|    ep_rew_mean          | -7.38    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1437     |
|    time_elapsed         | 4737     |
|    total_timesteps      | 183936   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0123  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 36.4     |
|    n_updates            | 14360    |
|    policy_gradient_loss | 1.1e-08  |
|    value_loss           | 85       |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 184000
Best mean reward: -0.99 - Last mean reward per episode: -7.49
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.3     |
|    ep_rew_mean          | -7.46    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1438     |
|    time_elapsed         | 4740     |
|    total_timesteps      | 184064   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0123  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 46.5     |
|    n_updates            | 14370    |
|    policy_gradient_loss | 2.93e-09 |
|    value_loss           | 91.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.6      |
|    ep_rew_mean          | -7.62     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1439      |
|    time_elapsed         | 4744      |
|    total_timesteps      | 184192    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0124   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 32.7      |
|    n_updates            | 14380     |
|    policy_gradient_loss | -1.96e-09 |
|    value_loss           | 71.4      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 83.1          |
|    ep_rew_mean          | -7.66         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1440          |
|    time_elapsed         | 4748          |
|    total_timesteps      | 184320        |
| train/                  |               |
|    approx_kl            | 0.00021244353 |
|    clip_fraction        | 0.00156       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0113       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 104           |
|    n_updates            | 14390         |
|    policy_gradient_loss | -0.000479     |
|    value_loss           | 164           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.6      |
|    ep_rew_mean          | -8.12     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1441      |
|    time_elapsed         | 4752      |
|    total_timesteps      | 184448    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00977  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 101       |
|    n_updates            | 14400     |
|    policy_gradient_loss | -7.22e-10 |
|    value_loss           | 182       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.3      |
|    ep_rew_mean          | -7.97     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1442      |
|    time_elapsed         | 4755      |
|    total_timesteps      | 184576    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00957  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 31.8      |
|    n_updates            | 14410     |
|    policy_gradient_loss | -2.79e-09 |
|    value_loss           | 82.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.4      |
|    ep_rew_mean          | -8        |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1443      |
|    time_elapsed         | 4758      |
|    total_timesteps      | 184704    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00957  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43        |
|    n_updates            | 14420     |
|    policy_gradient_loss | -3.12e-09 |
|    value_loss           | 91.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.5      |
|    ep_rew_mean          | -8.56     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1444      |
|    time_elapsed         | 4762      |
|    total_timesteps      | 184832    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00962  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 31.7      |
|    n_updates            | 14430     |
|    policy_gradient_loss | -9.36e-09 |
|    value_loss           | 72.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.2      |
|    ep_rew_mean          | -8.89     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1445      |
|    time_elapsed         | 4765      |
|    total_timesteps      | 184960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00966  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 28.1      |
|    n_updates            | 14440     |
|    policy_gradient_loss | -7.36e-09 |
|    value_loss           | 71.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 185000
Best mean reward: -0.99 - Last mean reward per episode: -7.61
Eval num_timesteps=185000, episode_reward=-16.40 +/- 20.26
Episode length: 96.80 +/- 40.45
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 96.8      |
|    mean_reward          | -16.4     |
| time/                   |           |
|    total_timesteps      | 185000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00968  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 46.2      |
|    n_updates            | 14450     |
|    policy_gradient_loss | -3.47e-09 |
|    value_loss           | 71.7      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 85.2     |
|    ep_rew_mean     | -8.99    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1446     |
|    time_elapsed    | 4771     |
|    total_timesteps | 185088   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.6     |
|    ep_rew_mean          | -7.7     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1447     |
|    time_elapsed         | 4775     |
|    total_timesteps      | 185216   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00971 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 35.6     |
|    n_updates            | 14460    |
|    policy_gradient_loss | 8.15e-10 |
|    value_loss           | 72.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.7     |
|    ep_rew_mean          | -7.86    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1448     |
|    time_elapsed         | 4778     |
|    total_timesteps      | 185344   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00977 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 72.6     |
|    n_updates            | 14470    |
|    policy_gradient_loss | 5.36e-10 |
|    value_loss           | 109      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.1     |
|    ep_rew_mean          | -8.04    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1449     |
|    time_elapsed         | 4782     |
|    total_timesteps      | 185472   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0099  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 60.8     |
|    n_updates            | 14480    |
|    policy_gradient_loss | 1.86e-09 |
|    value_loss           | 111      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.9      |
|    ep_rew_mean          | -8.16     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1450      |
|    time_elapsed         | 4785      |
|    total_timesteps      | 185600    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.01     |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.6      |
|    n_updates            | 14490     |
|    policy_gradient_loss | -3.54e-09 |
|    value_loss           | 73.9      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.8     |
|    ep_rew_mean          | -8       |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1451     |
|    time_elapsed         | 4787     |
|    total_timesteps      | 185728   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0101  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 63       |
|    n_updates            | 14500    |
|    policy_gradient_loss | 2.96e-09 |
|    value_loss           | 110      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83        |
|    ep_rew_mean          | -8.1      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1452      |
|    time_elapsed         | 4791      |
|    total_timesteps      | 185856    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0103   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 56.4      |
|    n_updates            | 14510     |
|    policy_gradient_loss | -2.28e-09 |
|    value_loss           | 147       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.8      |
|    ep_rew_mean          | -8.62     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1453      |
|    time_elapsed         | 4794      |
|    total_timesteps      | 185984    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0104   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.7      |
|    n_updates            | 14520     |
|    policy_gradient_loss | -8.06e-09 |
|    value_loss           | 77.8      |
---------------------------------------
Num timesteps: 186000
Best mean reward: -0.99 - Last mean reward per episode: -9.82
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.4      |
|    ep_rew_mean          | -8.88     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1454      |
|    time_elapsed         | 4797      |
|    total_timesteps      | 186112    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0104   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.7      |
|    n_updates            | 14530     |
|    policy_gradient_loss | -2.78e-09 |
|    value_loss           | 73.3      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.2      |
|    ep_rew_mean          | -8.62     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1455      |
|    time_elapsed         | 4800      |
|    total_timesteps      | 186240    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0105   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 48.3      |
|    n_updates            | 14540     |
|    policy_gradient_loss | -1.54e-09 |
|    value_loss           | 110       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.4      |
|    ep_rew_mean          | -8.9      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1456      |
|    time_elapsed         | 4803      |
|    total_timesteps      | 186368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0105   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 110       |
|    n_updates            | 14550     |
|    policy_gradient_loss | -6.98e-09 |
|    value_loss           | 191       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.7      |
|    ep_rew_mean          | -9.05     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1457      |
|    time_elapsed         | 4806      |
|    total_timesteps      | 186496    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0106   |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 43.6      |
|    n_updates            | 14560     |
|    policy_gradient_loss | -2.56e-09 |
|    value_loss           | 76.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.6      |
|    ep_rew_mean          | -9.12     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1458      |
|    time_elapsed         | 4810      |
|    total_timesteps      | 186624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0106   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 124       |
|    n_updates            | 14570     |
|    policy_gradient_loss | -3.91e-09 |
|    value_loss           | 190       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.2     |
|    ep_rew_mean          | -8.92    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1459     |
|    time_elapsed         | 4813     |
|    total_timesteps      | 186752   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0106  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 62.7     |
|    n_updates            | 14580    |
|    policy_gradient_loss | -1e-09   |
|    value_loss           | 103      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.2      |
|    ep_rew_mean          | -9.08     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1460      |
|    time_elapsed         | 4816      |
|    total_timesteps      | 186880    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0107   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 35.1      |
|    n_updates            | 14590     |
|    policy_gradient_loss | 7.92e-10  |
|    value_loss           | 98.5      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 187000
Best mean reward: -0.99 - Last mean reward per episode: -9.15
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.2      |
|    ep_rew_mean          | -8.98     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1461      |
|    time_elapsed         | 4819      |
|    total_timesteps      | 187008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0108   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 58        |
|    n_updates            | 14600     |
|    policy_gradient_loss | -4.66e-10 |
|    value_loss           | 102       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.3      |
|    ep_rew_mean          | -9.45     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1462      |
|    time_elapsed         | 4822      |
|    total_timesteps      | 187136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.011    |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 47.8      |
|    n_updates            | 14610     |
|    policy_gradient_loss | 3.4e-09   |
|    value_loss           | 123       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.3      |
|    ep_rew_mean          | -9.26     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1463      |
|    time_elapsed         | 4827      |
|    total_timesteps      | 187264    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0111   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 49.4      |
|    n_updates            | 14620     |
|    policy_gradient_loss | -2.56e-10 |
|    value_loss           | 108       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.8      |
|    ep_rew_mean          | -9.53     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1464      |
|    time_elapsed         | 4830      |
|    total_timesteps      | 187392    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0113   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 74.8      |
|    n_updates            | 14630     |
|    policy_gradient_loss | -3.59e-09 |
|    value_loss           | 193       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.2     |
|    ep_rew_mean          | -9.68    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1465     |
|    time_elapsed         | 4833     |
|    total_timesteps      | 187520   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0114  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 35.6     |
|    n_updates            | 14640    |
|    policy_gradient_loss | 2.65e-09 |
|    value_loss           | 73.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.2      |
|    ep_rew_mean          | -9.71     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1466      |
|    time_elapsed         | 4838      |
|    total_timesteps      | 187648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0115   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 91.6      |
|    n_updates            | 14650     |
|    policy_gradient_loss | -2.51e-09 |
|    value_loss           | 150       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 86.2          |
|    ep_rew_mean          | -9.8          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1467          |
|    time_elapsed         | 4841          |
|    total_timesteps      | 187776        |
| train/                  |               |
|    approx_kl            | 0.00021231174 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0113       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 51.8          |
|    n_updates            | 14660         |
|    policy_gradient_loss | -0.00032      |
|    value_loss           | 77.4          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.2     |
|    ep_rew_mean          | -10.4    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1468     |
|    time_elapsed         | 4844     |
|    total_timesteps      | 187904   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0107  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 52.4     |
|    n_updates            | 14670    |
|    policy_gradient_loss | 5.96e-09 |
|    value_loss           | 114      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 188000
Best mean reward: -0.99 - Last mean reward per episode: -9.62
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86        |
|    ep_rew_mean          | -9.88     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1469      |
|    time_elapsed         | 4847      |
|    total_timesteps      | 188032    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0107   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.7      |
|    n_updates            | 14680     |
|    policy_gradient_loss | -7.68e-10 |
|    value_loss           | 72.8      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.3     |
|    ep_rew_mean          | -9.95    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1470     |
|    time_elapsed         | 4850     |
|    total_timesteps      | 188160   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0108  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 56.4     |
|    n_updates            | 14690    |
|    policy_gradient_loss | 2.61e-09 |
|    value_loss           | 109      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.3      |
|    ep_rew_mean          | -9.95     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1471      |
|    time_elapsed         | 4854      |
|    total_timesteps      | 188288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0109   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 104       |
|    n_updates            | 14700     |
|    policy_gradient_loss | -3.82e-09 |
|    value_loss           | 201       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.5     |
|    ep_rew_mean          | -10.7    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1472     |
|    time_elapsed         | 4857     |
|    total_timesteps      | 188416   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.011   |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 26.9     |
|    n_updates            | 14710    |
|    policy_gradient_loss | 6.04e-08 |
|    value_loss           | 55.9     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.6     |
|    ep_rew_mean          | -10.1    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1473     |
|    time_elapsed         | 4861     |
|    total_timesteps      | 188544   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0111  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 45.5     |
|    n_updates            | 14720    |
|    policy_gradient_loss | 3.54e-09 |
|    value_loss           | 73.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.3      |
|    ep_rew_mean          | -9.97     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1474      |
|    time_elapsed         | 4864      |
|    total_timesteps      | 188672    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0111   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 82.3      |
|    n_updates            | 14730     |
|    policy_gradient_loss | -1.42e-08 |
|    value_loss           | 181       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86       |
|    ep_rew_mean          | -9.81    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1475     |
|    time_elapsed         | 4867     |
|    total_timesteps      | 188800   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0111  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 44       |
|    n_updates            | 14740    |
|    policy_gradient_loss | 7.64e-09 |
|    value_loss           | 75.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.7      |
|    ep_rew_mean          | -9.66     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1476      |
|    time_elapsed         | 4871      |
|    total_timesteps      | 188928    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0112   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.4      |
|    n_updates            | 14750     |
|    policy_gradient_loss | -6.71e-09 |
|    value_loss           | 106       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 189000
Best mean reward: -0.99 - Last mean reward per episode: -9.88
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.7     |
|    ep_rew_mean          | -9.66    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1477     |
|    time_elapsed         | 4874     |
|    total_timesteps      | 189056   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0113  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.9     |
|    n_updates            | 14760    |
|    policy_gradient_loss | 4.94e-09 |
|    value_loss           | 77.1     |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 87.6         |
|    ep_rew_mean          | -10.6        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1478         |
|    time_elapsed         | 4878         |
|    total_timesteps      | 189184       |
| train/                  |              |
|    approx_kl            | 7.543713e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0113      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 25           |
|    n_updates            | 14770        |
|    policy_gradient_loss | -6.99e-07    |
|    value_loss           | 53.4         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.1      |
|    ep_rew_mean          | -10.4     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1479      |
|    time_elapsed         | 4881      |
|    total_timesteps      | 189312    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0113   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.1      |
|    n_updates            | 14780     |
|    policy_gradient_loss | -3.73e-10 |
|    value_loss           | 80.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.8     |
|    ep_rew_mean          | -10.1    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1480     |
|    time_elapsed         | 4884     |
|    total_timesteps      | 189440   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0113  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 56.1     |
|    n_updates            | 14790    |
|    policy_gradient_loss | 1.4e-09  |
|    value_loss           | 105      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.7      |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1481      |
|    time_elapsed         | 4888      |
|    total_timesteps      | 189568    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0114   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 73.3      |
|    n_updates            | 14800     |
|    policy_gradient_loss | -1.68e-09 |
|    value_loss           | 145       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.7     |
|    ep_rew_mean          | -10.2    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1482     |
|    time_elapsed         | 4890     |
|    total_timesteps      | 189696   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0114  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 34.1     |
|    n_updates            | 14810    |
|    policy_gradient_loss | 9.99e-09 |
|    value_loss           | 74.9     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.7     |
|    ep_rew_mean          | -10.2    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1483     |
|    time_elapsed         | 4895     |
|    total_timesteps      | 189824   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0115  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 32.8     |
|    n_updates            | 14820    |
|    policy_gradient_loss | 1.91e-08 |
|    value_loss           | 59.7     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 86.7          |
|    ep_rew_mean          | -10.2         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1484          |
|    time_elapsed         | 4900          |
|    total_timesteps      | 189952        |
| train/                  |               |
|    approx_kl            | 2.5738962e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0114       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 23.4          |
|    n_updates            | 14830         |
|    policy_gradient_loss | -8.33e-05     |
|    value_loss           | 51.8          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 190000
Best mean reward: -0.99 - Last mean reward per episode: -12.12
Eval num_timesteps=190000, episode_reward=-12.90 +/- 17.61
Episode length: 85.80 +/- 35.23
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 85.8          |
|    mean_reward          | -12.9         |
| time/                   |               |
|    total_timesteps      | 190000        |
| train/                  |               |
|    approx_kl            | 1.0284595e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.011        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 24.8          |
|    n_updates            | 14840         |
|    policy_gradient_loss | -0.000106     |
|    value_loss           | 50.9          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 90.3     |
|    ep_rew_mean     | -11.8    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1485     |
|    time_elapsed    | 4907     |
|    total_timesteps | 190080   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.3      |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1486      |
|    time_elapsed         | 4911      |
|    total_timesteps      | 190208    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0105   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 121       |
|    n_updates            | 14850     |
|    policy_gradient_loss | -1.63e-09 |
|    value_loss           | 214       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.6     |
|    ep_rew_mean          | -11.4    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1487     |
|    time_elapsed         | 4914     |
|    total_timesteps      | 190336   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0104  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 73.1     |
|    n_updates            | 14860    |
|    policy_gradient_loss | 1.86e-09 |
|    value_loss           | 119      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.5      |
|    ep_rew_mean          | -11.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1488      |
|    time_elapsed         | 4918      |
|    total_timesteps      | 190464    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0105   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 77.3      |
|    n_updates            | 14870     |
|    policy_gradient_loss | -1.21e-09 |
|    value_loss           | 205       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.8      |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1489      |
|    time_elapsed         | 4921      |
|    total_timesteps      | 190592    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0106   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.6      |
|    n_updates            | 14880     |
|    policy_gradient_loss | -3.77e-09 |
|    value_loss           | 77.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.5      |
|    ep_rew_mean          | -11.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1490      |
|    time_elapsed         | 4924      |
|    total_timesteps      | 190720    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0107   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.7      |
|    n_updates            | 14890     |
|    policy_gradient_loss | -2.42e-09 |
|    value_loss           | 108       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.4     |
|    ep_rew_mean          | -11.6    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1491     |
|    time_elapsed         | 4928     |
|    total_timesteps      | 190848   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0107  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 49.2     |
|    n_updates            | 14900    |
|    policy_gradient_loss | 4.56e-09 |
|    value_loss           | 79       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.6      |
|    ep_rew_mean          | -11.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1492      |
|    time_elapsed         | 4931      |
|    total_timesteps      | 190976    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0108   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 66.5      |
|    n_updates            | 14910     |
|    policy_gradient_loss | -2.12e-09 |
|    value_loss           | 149       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 191000
Best mean reward: -0.99 - Last mean reward per episode: -11.87
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.6      |
|    ep_rew_mean          | -11.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1493      |
|    time_elapsed         | 4935      |
|    total_timesteps      | 191104    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0109   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.7      |
|    n_updates            | 14920     |
|    policy_gradient_loss | -3.93e-09 |
|    value_loss           | 121       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.7      |
|    ep_rew_mean          | -12.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1494      |
|    time_elapsed         | 4938      |
|    total_timesteps      | 191232    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.011    |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 24.8      |
|    n_updates            | 14930     |
|    policy_gradient_loss | -2.72e-08 |
|    value_loss           | 51.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 90.7     |
|    ep_rew_mean          | -12.1    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1495     |
|    time_elapsed         | 4941     |
|    total_timesteps      | 191360   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0111  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 64.8     |
|    n_updates            | 14940    |
|    policy_gradient_loss | 1.35e-09 |
|    value_loss           | 109      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.3      |
|    ep_rew_mean          | -11.9     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1496      |
|    time_elapsed         | 4945      |
|    total_timesteps      | 191488    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0111   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.3      |
|    n_updates            | 14950     |
|    policy_gradient_loss | -3.45e-09 |
|    value_loss           | 81.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.2      |
|    ep_rew_mean          | -11.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1497      |
|    time_elapsed         | 4949      |
|    total_timesteps      | 191616    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0112   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 81.7      |
|    n_updates            | 14960     |
|    policy_gradient_loss | -2.33e-09 |
|    value_loss           | 154       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.2      |
|    ep_rew_mean          | -11.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1498      |
|    time_elapsed         | 4953      |
|    total_timesteps      | 191744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0114   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 143       |
|    n_updates            | 14970     |
|    policy_gradient_loss | 5.54e-09  |
|    value_loss           | 179       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.7     |
|    ep_rew_mean          | -11.4    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1499     |
|    time_elapsed         | 4956     |
|    total_timesteps      | 191872   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0115  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 83.2     |
|    n_updates            | 14980    |
|    policy_gradient_loss | 7.92e-10 |
|    value_loss           | 150      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 192000
Best mean reward: -0.99 - Last mean reward per episode: -12.52
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.6      |
|    ep_rew_mean          | -11.4     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1500      |
|    time_elapsed         | 4959      |
|    total_timesteps      | 192000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0116   |
|    explained_variance   | 2.38e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 52.3      |
|    n_updates            | 14990     |
|    policy_gradient_loss | -5.75e-09 |
|    value_loss           | 106       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.8      |
|    ep_rew_mean          | -11.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1501      |
|    time_elapsed         | 4963      |
|    total_timesteps      | 192128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0117   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 45        |
|    n_updates            | 15000     |
|    policy_gradient_loss | 8.1e-09   |
|    value_loss           | 78.6      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 90.2         |
|    ep_rew_mean          | -11.3        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1502         |
|    time_elapsed         | 4968         |
|    total_timesteps      | 192256       |
| train/                  |              |
|    approx_kl            | 0.0008387165 |
|    clip_fraction        | 0.00391      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00986     |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 101          |
|    n_updates            | 15010        |
|    policy_gradient_loss | -0.000618    |
|    value_loss           | 168          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.4      |
|    ep_rew_mean          | -11.4     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1503      |
|    time_elapsed         | 4971      |
|    total_timesteps      | 192384    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00725  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 136       |
|    n_updates            | 15020     |
|    policy_gradient_loss | -2.84e-09 |
|    value_loss           | 201       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.1      |
|    ep_rew_mean          | -11.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1504      |
|    time_elapsed         | 4975      |
|    total_timesteps      | 192512    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00695  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 104       |
|    n_updates            | 15030     |
|    policy_gradient_loss | -4.17e-09 |
|    value_loss           | 192       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.3      |
|    ep_rew_mean          | -11.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1505      |
|    time_elapsed         | 4978      |
|    total_timesteps      | 192640    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00694  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 48.5      |
|    n_updates            | 15040     |
|    policy_gradient_loss | 2.56e-09  |
|    value_loss           | 103       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 91       |
|    ep_rew_mean          | -11.6    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1506     |
|    time_elapsed         | 4982     |
|    total_timesteps      | 192768   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.007   |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 60.8     |
|    n_updates            | 15050    |
|    policy_gradient_loss | 0        |
|    value_loss           | 112      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 91        |
|    ep_rew_mean          | -11.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1507      |
|    time_elapsed         | 4985      |
|    total_timesteps      | 192896    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00709  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 52.4      |
|    n_updates            | 15060     |
|    policy_gradient_loss | -1.04e-08 |
|    value_loss           | 107       |
---------------------------------------
Num timesteps: 193000
Best mean reward: -0.99 - Last mean reward per episode: -11.37
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90.6      |
|    ep_rew_mean          | -11.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1508      |
|    time_elapsed         | 4988      |
|    total_timesteps      | 193024    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00715  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 76.3      |
|    n_updates            | 15070     |
|    policy_gradient_loss | -3.26e-10 |
|    value_loss           | 136       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 90.3     |
|    ep_rew_mean          | -11.1    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1509     |
|    time_elapsed         | 4990     |
|    total_timesteps      | 193152   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00718 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42       |
|    n_updates            | 15080    |
|    policy_gradient_loss | 1.63e-10 |
|    value_loss           | 75.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.3     |
|    ep_rew_mean          | -10.9    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1510     |
|    time_elapsed         | 4993     |
|    total_timesteps      | 193280   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0072  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.9     |
|    n_updates            | 15090    |
|    policy_gradient_loss | 1.03e-08 |
|    value_loss           | 100      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.2      |
|    ep_rew_mean          | -10.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1511      |
|    time_elapsed         | 4996      |
|    total_timesteps      | 193408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00726  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 57.4      |
|    n_updates            | 15100     |
|    policy_gradient_loss | -5.12e-09 |
|    value_loss           | 105       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 88.8     |
|    ep_rew_mean          | -10.8    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1512     |
|    time_elapsed         | 4999     |
|    total_timesteps      | 193536   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00739 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 54.6     |
|    n_updates            | 15110    |
|    policy_gradient_loss | 6.98e-10 |
|    value_loss           | 99.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.5      |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1513      |
|    time_elapsed         | 5003      |
|    total_timesteps      | 193664    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00747  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 31.3      |
|    n_updates            | 15120     |
|    policy_gradient_loss | -8.48e-09 |
|    value_loss           | 72        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.5      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1514      |
|    time_elapsed         | 5006      |
|    total_timesteps      | 193792    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00751  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 35.4      |
|    n_updates            | 15130     |
|    policy_gradient_loss | 8.38e-10  |
|    value_loss           | 71.4      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.9     |
|    ep_rew_mean          | -10.3    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1515     |
|    time_elapsed         | 5009     |
|    total_timesteps      | 193920   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00757 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 43.8     |
|    n_updates            | 15140    |
|    policy_gradient_loss | 3.14e-09 |
|    value_loss           | 102      |
--------------------------------------
Num timesteps: 194000
Best mean reward: -0.99 - Last mean reward per episode: -10.45
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87       |
|    ep_rew_mean          | -9.9     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1516     |
|    time_elapsed         | 5012     |
|    total_timesteps      | 194048   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00773 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 62.6     |
|    n_updates            | 15150    |
|    policy_gradient_loss | 1.63e-09 |
|    value_loss           | 107      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87        |
|    ep_rew_mean          | -9.9      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1517      |
|    time_elapsed         | 5014      |
|    total_timesteps      | 194176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00789  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 89.5      |
|    n_updates            | 15160     |
|    policy_gradient_loss | -3.82e-09 |
|    value_loss           | 160       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.4     |
|    ep_rew_mean          | -10.1    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1518     |
|    time_elapsed         | 5018     |
|    total_timesteps      | 194304   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00795 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 29.1     |
|    n_updates            | 15170    |
|    policy_gradient_loss | 1.14e-08 |
|    value_loss           | 57.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.5     |
|    ep_rew_mean          | -10      |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1519     |
|    time_elapsed         | 5021     |
|    total_timesteps      | 194432   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.008   |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 62.3     |
|    n_updates            | 15180    |
|    policy_gradient_loss | 6.87e-09 |
|    value_loss           | 101      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.1      |
|    ep_rew_mean          | -9.87     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1520      |
|    time_elapsed         | 5024      |
|    total_timesteps      | 194560    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00816  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 77.7      |
|    n_updates            | 15190     |
|    policy_gradient_loss | -1.54e-09 |
|    value_loss           | 173       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.2     |
|    ep_rew_mean          | -9.12    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1521     |
|    time_elapsed         | 5027     |
|    total_timesteps      | 194688   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0084  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 54.2     |
|    n_updates            | 15200    |
|    policy_gradient_loss | 3.38e-09 |
|    value_loss           | 106      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.2     |
|    ep_rew_mean          | -9.12    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1522     |
|    time_elapsed         | 5030     |
|    total_timesteps      | 194816   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00861 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 106      |
|    n_updates            | 15210    |
|    policy_gradient_loss | 5.59e-10 |
|    value_loss           | 181      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.8     |
|    ep_rew_mean          | -9.6     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1523     |
|    time_elapsed         | 5034     |
|    total_timesteps      | 194944   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00878 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.3     |
|    n_updates            | 15220    |
|    policy_gradient_loss | 5.68e-09 |
|    value_loss           | 73.2     |
--------------------------------------
Num timesteps: 195000
Best mean reward: -0.99 - Last mean reward per episode: -10.11
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=195000, episode_reward=-4.40 +/- 12.94
Episode length: 84.80 +/- 20.68
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 84.8      |
|    mean_reward          | -4.4      |
| time/                   |           |
|    total_timesteps      | 195000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00887  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.7      |
|    n_updates            | 15230     |
|    policy_gradient_loss | -1.21e-09 |
|    value_loss           | 95.8      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 86.3     |
|    ep_rew_mean     | -9.34    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1524     |
|    time_elapsed    | 5039     |
|    total_timesteps | 195072   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.3      |
|    ep_rew_mean          | -9.46     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1525      |
|    time_elapsed         | 5042      |
|    total_timesteps      | 195200    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.009    |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 49.9      |
|    n_updates            | 15240     |
|    policy_gradient_loss | -5.91e-09 |
|    value_loss           | 95.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.3      |
|    ep_rew_mean          | -9.44     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1526      |
|    time_elapsed         | 5045      |
|    total_timesteps      | 195328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00916  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 50.5      |
|    n_updates            | 15250     |
|    policy_gradient_loss | 8.38e-10  |
|    value_loss           | 129       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.3     |
|    ep_rew_mean          | -9.34    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1527     |
|    time_elapsed         | 5048     |
|    total_timesteps      | 195456   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00925 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 62.4     |
|    n_updates            | 15260    |
|    policy_gradient_loss | 6.05e-10 |
|    value_loss           | 92.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87        |
|    ep_rew_mean          | -9.72     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1528      |
|    time_elapsed         | 5051      |
|    total_timesteps      | 195584    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00935  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.4      |
|    n_updates            | 15270     |
|    policy_gradient_loss | -2.28e-09 |
|    value_loss           | 124       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.7     |
|    ep_rew_mean          | -9.23    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1529     |
|    time_elapsed         | 5055     |
|    total_timesteps      | 195712   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00942 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 34.1     |
|    n_updates            | 15280    |
|    policy_gradient_loss | 7.68e-09 |
|    value_loss           | 74       |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.8     |
|    ep_rew_mean          | -9.51    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1530     |
|    time_elapsed         | 5058     |
|    total_timesteps      | 195840   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0095  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 36.2     |
|    n_updates            | 15290    |
|    policy_gradient_loss | 2.65e-09 |
|    value_loss           | 88.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.9      |
|    ep_rew_mean          | -9.36     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1531      |
|    time_elapsed         | 5061      |
|    total_timesteps      | 195968    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00983  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.4      |
|    n_updates            | 15300     |
|    policy_gradient_loss | -3.82e-09 |
|    value_loss           | 95.6      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 196000
Best mean reward: -0.99 - Last mean reward per episode: -8.36
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.2      |
|    ep_rew_mean          | -8.99     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1532      |
|    time_elapsed         | 5065      |
|    total_timesteps      | 196096    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0102   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 75.6      |
|    n_updates            | 15310     |
|    policy_gradient_loss | -2.47e-09 |
|    value_loss           | 153       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.1      |
|    ep_rew_mean          | -8.83     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1533      |
|    time_elapsed         | 5069      |
|    total_timesteps      | 196224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0104   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.9      |
|    n_updates            | 15320     |
|    policy_gradient_loss | -4.66e-10 |
|    value_loss           | 122       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.5     |
|    ep_rew_mean          | -8.54    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1534     |
|    time_elapsed         | 5072     |
|    total_timesteps      | 196352   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0106  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 39.6     |
|    n_updates            | 15330    |
|    policy_gradient_loss | 0        |
|    value_loss           | 103      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.6      |
|    ep_rew_mean          | -8.51     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1535      |
|    time_elapsed         | 5076      |
|    total_timesteps      | 196480    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0108   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 49.1      |
|    n_updates            | 15340     |
|    policy_gradient_loss | -1.91e-09 |
|    value_loss           | 131       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.2     |
|    ep_rew_mean          | -8.28    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1536     |
|    time_elapsed         | 5079     |
|    total_timesteps      | 196608   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0111  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 57       |
|    n_updates            | 15350    |
|    policy_gradient_loss | 1.35e-09 |
|    value_loss           | 128      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.4      |
|    ep_rew_mean          | -7.41     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1537      |
|    time_elapsed         | 5083      |
|    total_timesteps      | 196736    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0112   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 95.7      |
|    n_updates            | 15360     |
|    policy_gradient_loss | 3.17e-09  |
|    value_loss           | 164       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.3     |
|    ep_rew_mean          | -7.44    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1538     |
|    time_elapsed         | 5086     |
|    total_timesteps      | 196864   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0113  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 61.3     |
|    n_updates            | 15370    |
|    policy_gradient_loss | 4.66e-10 |
|    value_loss           | 119      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 82.3          |
|    ep_rew_mean          | -7.46         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1539          |
|    time_elapsed         | 5092          |
|    total_timesteps      | 196992        |
| train/                  |               |
|    approx_kl            | 3.7252903e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0115       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 44            |
|    n_updates            | 15380         |
|    policy_gradient_loss | -2.17e-06     |
|    value_loss           | 69.2          |
-------------------------------------------
Num timesteps: 197000
Best mean reward: -0.99 - Last mean reward per episode: -5.36
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.7     |
|    ep_rew_mean          | -7.12    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1540     |
|    time_elapsed         | 5095     |
|    total_timesteps      | 197120   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0119  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 46.4     |
|    n_updates            | 15390    |
|    policy_gradient_loss | 3.63e-09 |
|    value_loss           | 82.5     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.7     |
|    ep_rew_mean          | -5.97    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1541     |
|    time_elapsed         | 5098     |
|    total_timesteps      | 197248   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0126  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 30.3     |
|    n_updates            | 15400    |
|    policy_gradient_loss | 4.19e-10 |
|    value_loss           | 79.9     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.7     |
|    ep_rew_mean          | -5.86    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1542     |
|    time_elapsed         | 5101     |
|    total_timesteps      | 197376   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0134  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 46.1     |
|    n_updates            | 15410    |
|    policy_gradient_loss | 2.84e-09 |
|    value_loss           | 147      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.5     |
|    ep_rew_mean          | -5.76    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1543     |
|    time_elapsed         | 5105     |
|    total_timesteps      | 197504   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0141  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 68.8     |
|    n_updates            | 15420    |
|    policy_gradient_loss | 9.69e-09 |
|    value_loss           | 137      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.8      |
|    ep_rew_mean          | -5.78     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1544      |
|    time_elapsed         | 5108      |
|    total_timesteps      | 197632    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0145   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 62.6      |
|    n_updates            | 15430     |
|    policy_gradient_loss | -1.63e-09 |
|    value_loss           | 111       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.7     |
|    ep_rew_mean          | -4.47    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1545     |
|    time_elapsed         | 5111     |
|    total_timesteps      | 197760   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0149  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 54.1     |
|    n_updates            | 15440    |
|    policy_gradient_loss | 2.27e-09 |
|    value_loss           | 98.7     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76.4          |
|    ep_rew_mean          | -4.4          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1546          |
|    time_elapsed         | 5114          |
|    total_timesteps      | 197888        |
| train/                  |               |
|    approx_kl            | 0.00076296367 |
|    clip_fraction        | 0.00391       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0126       |
|    explained_variance   | 1.79e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 49            |
|    n_updates            | 15450         |
|    policy_gradient_loss | -0.00085      |
|    value_loss           | 94.4          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 198000
Best mean reward: -0.99 - Last mean reward per episode: -4.06
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.1      |
|    ep_rew_mean          | -4.45     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1547      |
|    time_elapsed         | 5117      |
|    total_timesteps      | 198016    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00975  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 25.3      |
|    n_updates            | 15460     |
|    policy_gradient_loss | -1.58e-09 |
|    value_loss           | 67        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.6      |
|    ep_rew_mean          | -4.19     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1548      |
|    time_elapsed         | 5120      |
|    total_timesteps      | 198144    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00944  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45.2      |
|    n_updates            | 15470     |
|    policy_gradient_loss | -1.89e-09 |
|    value_loss           | 77.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.9      |
|    ep_rew_mean          | -3.86     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1549      |
|    time_elapsed         | 5124      |
|    total_timesteps      | 198272    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00948  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.9      |
|    n_updates            | 15480     |
|    policy_gradient_loss | -2.51e-09 |
|    value_loss           | 102       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.2     |
|    ep_rew_mean          | -3.98    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1550     |
|    time_elapsed         | 5128     |
|    total_timesteps      | 198400   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00965 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 35.4     |
|    n_updates            | 15490    |
|    policy_gradient_loss | 1.54e-09 |
|    value_loss           | 70.8     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.6      |
|    ep_rew_mean          | -4.81     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1551      |
|    time_elapsed         | 5132      |
|    total_timesteps      | 198528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00974  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 36.3      |
|    n_updates            | 15500     |
|    policy_gradient_loss | -2.02e-08 |
|    value_loss           | 73.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.4      |
|    ep_rew_mean          | -3.78     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1552      |
|    time_elapsed         | 5135      |
|    total_timesteps      | 198656    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00978  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 31        |
|    n_updates            | 15510     |
|    policy_gradient_loss | 8.5e-09   |
|    value_loss           | 68.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.5     |
|    ep_rew_mean          | -3.56    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1553     |
|    time_elapsed         | 5139     |
|    total_timesteps      | 198784   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00992 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 51.9     |
|    n_updates            | 15520    |
|    policy_gradient_loss | 3.73e-10 |
|    value_loss           | 97.7     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.1      |
|    ep_rew_mean          | -3.35     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1554      |
|    time_elapsed         | 5142      |
|    total_timesteps      | 198912    |
| train/                  |           |
|    approx_kl            | 0.0049744 |
|    clip_fraction        | 0.00625   |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0162   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 55.5      |
|    n_updates            | 15530     |
|    policy_gradient_loss | -0.00208  |
|    value_loss           | 181       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 199000
Best mean reward: -0.99 - Last mean reward per episode: -3.79
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.8          |
|    ep_rew_mean          | -3.92         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1555          |
|    time_elapsed         | 5145          |
|    total_timesteps      | 199040        |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0241       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 52.1          |
|    n_updates            | 15540         |
|    policy_gradient_loss | -1.3e-09      |
|    value_loss           | 91.7          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.1     |
|    ep_rew_mean          | -3.65    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1556     |
|    time_elapsed         | 5148     |
|    total_timesteps      | 199168   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0259  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.8     |
|    n_updates            | 15550    |
|    policy_gradient_loss | 8.38e-10 |
|    value_loss           | 94.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.1      |
|    ep_rew_mean          | -3.33     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1557      |
|    time_elapsed         | 5151      |
|    total_timesteps      | 199296    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0273   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.4      |
|    n_updates            | 15560     |
|    policy_gradient_loss | -6.89e-09 |
|    value_loss           | 89.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.8      |
|    ep_rew_mean          | -2.9      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1558      |
|    time_elapsed         | 5155      |
|    total_timesteps      | 199424    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0284   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 119       |
|    n_updates            | 15570     |
|    policy_gradient_loss | -1.58e-09 |
|    value_loss           | 204       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.9      |
|    ep_rew_mean          | -3.17     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1559      |
|    time_elapsed         | 5158      |
|    total_timesteps      | 199552    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0292   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 48        |
|    n_updates            | 15580     |
|    policy_gradient_loss | -7.45e-10 |
|    value_loss           | 88.7      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 73            |
|    ep_rew_mean          | -3.4          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1560          |
|    time_elapsed         | 5161          |
|    total_timesteps      | 199680        |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0313       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 44.1          |
|    n_updates            | 15590         |
|    policy_gradient_loss | 4.59e-09      |
|    value_loss           | 86.3          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 73.1        |
|    ep_rew_mean          | -3.44       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 1561        |
|    time_elapsed         | 5164        |
|    total_timesteps      | 199808      |
| train/                  |             |
|    approx_kl            | 0.000668508 |
|    clip_fraction        | 0.00313     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.029      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 41.6        |
|    n_updates            | 15600       |
|    policy_gradient_loss | -0.000499   |
|    value_loss           | 94.2        |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.2     |
|    ep_rew_mean          | -3.12    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1562     |
|    time_elapsed         | 5167     |
|    total_timesteps      | 199936   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0221  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.7     |
|    n_updates            | 15610    |
|    policy_gradient_loss | -1.3e-09 |
|    value_loss           | 82.2     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 200000
Best mean reward: -0.99 - Last mean reward per episode: -3.10
Eval num_timesteps=200000, episode_reward=-3.60 +/- 4.27
Episode length: 67.20 +/- 8.54
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 67.2      |
|    mean_reward          | -3.6      |
| time/                   |           |
|    total_timesteps      | 200000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.022    |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30        |
|    n_updates            | 15620     |
|    policy_gradient_loss | -7.61e-09 |
|    value_loss           | 81.2      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 72.3     |
|    ep_rew_mean     | -3.04    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1563     |
|    time_elapsed    | 5171     |
|    total_timesteps | 200064   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.5     |
|    ep_rew_mean          | -3.25    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1564     |
|    time_elapsed         | 5175     |
|    total_timesteps      | 200192   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0226  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.1     |
|    n_updates            | 15630    |
|    policy_gradient_loss | 3.75e-09 |
|    value_loss           | 101      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.5      |
|    ep_rew_mean          | -3.15     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1565      |
|    time_elapsed         | 5178      |
|    total_timesteps      | 200320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.023    |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 40.8      |
|    n_updates            | 15640     |
|    policy_gradient_loss | -1.5e-08  |
|    value_loss           | 83.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.6      |
|    ep_rew_mean          | -3.2      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1566      |
|    time_elapsed         | 5181      |
|    total_timesteps      | 200448    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0237   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 69.3      |
|    n_updates            | 15650     |
|    policy_gradient_loss | -4.24e-09 |
|    value_loss           | 126       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 73.5         |
|    ep_rew_mean          | -3.63        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1567         |
|    time_elapsed         | 5184         |
|    total_timesteps      | 200576       |
| train/                  |              |
|    approx_kl            | 3.516674e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0244      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 45.3         |
|    n_updates            | 15660        |
|    policy_gradient_loss | -2.38e-05    |
|    value_loss           | 83.2         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 73.5          |
|    ep_rew_mean          | -3.63         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1568          |
|    time_elapsed         | 5188          |
|    total_timesteps      | 200704        |
| train/                  |               |
|    approx_kl            | 5.0989445e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0231       |
|    explained_variance   | -2.38e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 34.6          |
|    n_updates            | 15670         |
|    policy_gradient_loss | -7.25e-05     |
|    value_loss           | 87.3          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.1      |
|    ep_rew_mean          | -4.36     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1569      |
|    time_elapsed         | 5192      |
|    total_timesteps      | 200832    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0208   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 27.8      |
|    n_updates            | 15680     |
|    policy_gradient_loss | -2.24e-09 |
|    value_loss           | 59.1      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.3     |
|    ep_rew_mean          | -4.46    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1570     |
|    time_elapsed         | 5196     |
|    total_timesteps      | 200960   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0203  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 53.2     |
|    n_updates            | 15690    |
|    policy_gradient_loss | 2.33e-10 |
|    value_loss           | 128      |
--------------------------------------
Num timesteps: 201000
Best mean reward: -0.99 - Last mean reward per episode: -3.85
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.1          |
|    ep_rew_mean          | -3.86         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1571          |
|    time_elapsed         | 5199          |
|    total_timesteps      | 201088        |
| train/                  |               |
|    approx_kl            | 0.00010267645 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0197       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 29.2          |
|    n_updates            | 15700         |
|    policy_gradient_loss | -0.000246     |
|    value_loss           | 69.9          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.2      |
|    ep_rew_mean          | -3.88     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1572      |
|    time_elapsed         | 5202      |
|    total_timesteps      | 201216    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0171   |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 59.1      |
|    n_updates            | 15710     |
|    policy_gradient_loss | -4.21e-09 |
|    value_loss           | 92.3      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74.6          |
|    ep_rew_mean          | -3.98         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1573          |
|    time_elapsed         | 5205          |
|    total_timesteps      | 201344        |
| train/                  |               |
|    approx_kl            | 2.9802322e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0177       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 47.1          |
|    n_updates            | 15720         |
|    policy_gradient_loss | -2.1e-09      |
|    value_loss           | 99.2          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.2     |
|    ep_rew_mean          | -4.22    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1574     |
|    time_elapsed         | 5209     |
|    total_timesteps      | 201472   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0194  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 69.1     |
|    n_updates            | 15730    |
|    policy_gradient_loss | 2.33e-10 |
|    value_loss           | 106      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 75.7          |
|    ep_rew_mean          | -4.45         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1575          |
|    time_elapsed         | 5212          |
|    total_timesteps      | 201600        |
| train/                  |               |
|    approx_kl            | 0.00022982899 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0188       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 65.5          |
|    n_updates            | 15740         |
|    policy_gradient_loss | -0.000617     |
|    value_loss           | 127           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.9      |
|    ep_rew_mean          | -3.84     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1576      |
|    time_elapsed         | 5216      |
|    total_timesteps      | 201728    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0159   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 30        |
|    n_updates            | 15750     |
|    policy_gradient_loss | -4.91e-09 |
|    value_loss           | 71.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75        |
|    ep_rew_mean          | -4.01     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1577      |
|    time_elapsed         | 5219      |
|    total_timesteps      | 201856    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0154   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 83        |
|    n_updates            | 15760     |
|    policy_gradient_loss | 5.54e-09  |
|    value_loss           | 218       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.9     |
|    ep_rew_mean          | -3.85    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1578     |
|    time_elapsed         | 5223     |
|    total_timesteps      | 201984   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0156  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 68.8     |
|    n_updates            | 15770    |
|    policy_gradient_loss | -1.3e-09 |
|    value_loss           | 134      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 202000
Best mean reward: -0.99 - Last mean reward per episode: -4.04
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -4.18     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1579      |
|    time_elapsed         | 5227      |
|    total_timesteps      | 202112    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0165   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 71.1      |
|    n_updates            | 15780     |
|    policy_gradient_loss | 1.23e-09  |
|    value_loss           | 125       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 74.8         |
|    ep_rew_mean          | -4.08        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1580         |
|    time_elapsed         | 5230         |
|    total_timesteps      | 202240       |
| train/                  |              |
|    approx_kl            | 0.0013655527 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0211      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 58.1         |
|    n_updates            | 15790        |
|    policy_gradient_loss | -0.00184     |
|    value_loss           | 94.5         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 74.3        |
|    ep_rew_mean          | -3.83       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 1581        |
|    time_elapsed         | 5233        |
|    total_timesteps      | 202368      |
| train/                  |             |
|    approx_kl            | 0.001866445 |
|    clip_fraction        | 0.00547     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0197     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 40          |
|    n_updates            | 15800       |
|    policy_gradient_loss | -0.000833   |
|    value_loss           | 88.6        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.1      |
|    ep_rew_mean          | -3.77     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1582      |
|    time_elapsed         | 5236      |
|    total_timesteps      | 202496    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0149   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.8      |
|    n_updates            | 15810     |
|    policy_gradient_loss | -1.96e-09 |
|    value_loss           | 85.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.1     |
|    ep_rew_mean          | -3.73    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1583     |
|    time_elapsed         | 5240     |
|    total_timesteps      | 202624   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0151  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 34.3     |
|    n_updates            | 15820    |
|    policy_gradient_loss | 4.07e-09 |
|    value_loss           | 83.2     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 74            |
|    ep_rew_mean          | -3.31         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1584          |
|    time_elapsed         | 5243          |
|    total_timesteps      | 202752        |
| train/                  |               |
|    approx_kl            | 0.00014135474 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.015        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 39.6          |
|    n_updates            | 15830         |
|    policy_gradient_loss | -0.000386     |
|    value_loss           | 114           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.1      |
|    ep_rew_mean          | -3.36     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1585      |
|    time_elapsed         | 5246      |
|    total_timesteps      | 202880    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0131   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 99.9      |
|    n_updates            | 15840     |
|    policy_gradient_loss | -8.36e-09 |
|    value_loss           | 235       |
---------------------------------------
Num timesteps: 203000
Best mean reward: -0.99 - Last mean reward per episode: -2.79
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.5      |
|    ep_rew_mean          | -2.83     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1586      |
|    time_elapsed         | 5249      |
|    total_timesteps      | 203008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0127   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 51        |
|    n_updates            | 15850     |
|    policy_gradient_loss | -1.91e-09 |
|    value_loss           | 113       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.7     |
|    ep_rew_mean          | -2.95    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1587     |
|    time_elapsed         | 5252     |
|    total_timesteps      | 203136   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.013   |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 71.3     |
|    n_updates            | 15860    |
|    policy_gradient_loss | -1.4e-09 |
|    value_loss           | 160      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.8     |
|    ep_rew_mean          | -2.7     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1588     |
|    time_elapsed         | 5255     |
|    total_timesteps      | 203264   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0136  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 53.9     |
|    n_updates            | 15870    |
|    policy_gradient_loss | -5.4e-09 |
|    value_loss           | 74.6     |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 72.8         |
|    ep_rew_mean          | -2.81        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1589         |
|    time_elapsed         | 5258         |
|    total_timesteps      | 203392       |
| train/                  |              |
|    approx_kl            | 0.0023658397 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0109      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 38.3         |
|    n_updates            | 15880        |
|    policy_gradient_loss | -0.00111     |
|    value_loss           | 74.8         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.3      |
|    ep_rew_mean          | -2.65     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1590      |
|    time_elapsed         | 5262      |
|    total_timesteps      | 203520    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00821  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.3      |
|    n_updates            | 15890     |
|    policy_gradient_loss | -4.19e-10 |
|    value_loss           | 79.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.6      |
|    ep_rew_mean          | -2.68     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1591      |
|    time_elapsed         | 5265      |
|    total_timesteps      | 203648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00818  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.2      |
|    n_updates            | 15900     |
|    policy_gradient_loss | -3.17e-09 |
|    value_loss           | 80.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.9     |
|    ep_rew_mean          | -2.97    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1592     |
|    time_elapsed         | 5268     |
|    total_timesteps      | 203776   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00833 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 94.7     |
|    n_updates            | 15910    |
|    policy_gradient_loss | 1.47e-09 |
|    value_loss           | 150      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.9     |
|    ep_rew_mean          | -3.17    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1593     |
|    time_elapsed         | 5271     |
|    total_timesteps      | 203904   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0084  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40       |
|    n_updates            | 15920    |
|    policy_gradient_loss | 4.45e-09 |
|    value_loss           | 74.2     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 204000
Best mean reward: -0.99 - Last mean reward per episode: -2.99
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 72.7        |
|    ep_rew_mean          | -3.13       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 1594        |
|    time_elapsed         | 5274        |
|    total_timesteps      | 204032      |
| train/                  |             |
|    approx_kl            | 0.000603992 |
|    clip_fraction        | 0.00391     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00727    |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 47.3        |
|    n_updates            | 15930       |
|    policy_gradient_loss | -0.000799   |
|    value_loss           | 74.3        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.2      |
|    ep_rew_mean          | -2.69     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1595      |
|    time_elapsed         | 5277      |
|    total_timesteps      | 204160    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00611  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 28.1      |
|    n_updates            | 15940     |
|    policy_gradient_loss | -3.63e-09 |
|    value_loss           | 73.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.3      |
|    ep_rew_mean          | -2.75     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1596      |
|    time_elapsed         | 5280      |
|    total_timesteps      | 204288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00606  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 65.5      |
|    n_updates            | 15950     |
|    policy_gradient_loss | -6.43e-09 |
|    value_loss           | 152       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.5     |
|    ep_rew_mean          | -2.85    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1597     |
|    time_elapsed         | 5283     |
|    total_timesteps      | 204416   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0061  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 32.4     |
|    n_updates            | 15960    |
|    policy_gradient_loss | 1.86e-10 |
|    value_loss           | 74.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.4     |
|    ep_rew_mean          | -2.81    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1598     |
|    time_elapsed         | 5286     |
|    total_timesteps      | 204544   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00619 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 27.9     |
|    n_updates            | 15970    |
|    policy_gradient_loss | 7.92e-09 |
|    value_loss           | 66       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 72.8      |
|    ep_rew_mean          | -3.09     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1599      |
|    time_elapsed         | 5289      |
|    total_timesteps      | 204672    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00624  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 74.4      |
|    n_updates            | 15980     |
|    policy_gradient_loss | -6.52e-10 |
|    value_loss           | 156       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 72.8     |
|    ep_rew_mean          | -3.09    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1600     |
|    time_elapsed         | 5292     |
|    total_timesteps      | 204800   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00633 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 43.5     |
|    n_updates            | 15990    |
|    policy_gradient_loss | 2.61e-09 |
|    value_loss           | 87.1     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.2     |
|    ep_rew_mean          | -3.33    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1601     |
|    time_elapsed         | 5296     |
|    total_timesteps      | 204928   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00643 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 28.4     |
|    n_updates            | 16000    |
|    policy_gradient_loss | 3.05e-09 |
|    value_loss           | 69.3     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 205000
Best mean reward: -0.99 - Last mean reward per episode: -3.05
Eval num_timesteps=205000, episode_reward=-1.10 +/- 7.14
Episode length: 66.20 +/- 11.77
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 66.2     |
|    mean_reward          | -1.1     |
| time/                   |          |
|    total_timesteps      | 205000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00652 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 103      |
|    n_updates            | 16010    |
|    policy_gradient_loss | 7.4e-09  |
|    value_loss           | 159      |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 73.1     |
|    ep_rew_mean     | -3.25    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1602     |
|    time_elapsed    | 5300     |
|    total_timesteps | 205056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 72.5        |
|    ep_rew_mean          | -2.98       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 1603        |
|    time_elapsed         | 5303        |
|    total_timesteps      | 205184      |
| train/                  |             |
|    approx_kl            | 9.56906e-05 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00639    |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 40.7        |
|    n_updates            | 16020       |
|    policy_gradient_loss | -0.000172   |
|    value_loss           | 74.7        |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73       |
|    ep_rew_mean          | -3.18    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1604     |
|    time_elapsed         | 5307     |
|    total_timesteps      | 205312   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00585 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 36.9     |
|    n_updates            | 16030    |
|    policy_gradient_loss | 3.12e-09 |
|    value_loss           | 77.2     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73       |
|    ep_rew_mean          | -3.18    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1605     |
|    time_elapsed         | 5309     |
|    total_timesteps      | 205440   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00579 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 29.9     |
|    n_updates            | 16040    |
|    policy_gradient_loss | 2.19e-09 |
|    value_loss           | 76.6     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73       |
|    ep_rew_mean          | -3.18    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1606     |
|    time_elapsed         | 5313     |
|    total_timesteps      | 205568   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00588 |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 32.1     |
|    n_updates            | 16050    |
|    policy_gradient_loss | 4.05e-08 |
|    value_loss           | 65.1     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73       |
|    ep_rew_mean          | -3.18    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1607     |
|    time_elapsed         | 5317     |
|    total_timesteps      | 205696   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00591 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 30.6     |
|    n_updates            | 16060    |
|    policy_gradient_loss | 8.72e-08 |
|    value_loss           | 62.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73        |
|    ep_rew_mean          | -3.18     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1608      |
|    time_elapsed         | 5320      |
|    total_timesteps      | 205824    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00592  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 29.8      |
|    n_updates            | 16070     |
|    policy_gradient_loss | -1.19e-09 |
|    value_loss           | 61.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73        |
|    ep_rew_mean          | -3.18     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1609      |
|    time_elapsed         | 5324      |
|    total_timesteps      | 205952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00593  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 27.2      |
|    n_updates            | 16080     |
|    policy_gradient_loss | -1.62e-08 |
|    value_loss           | 60.1      |
---------------------------------------
Num timesteps: 206000
Best mean reward: -0.99 - Last mean reward per episode: -6.07
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.1     |
|    ep_rew_mean          | -6.26    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1610     |
|    time_elapsed         | 5327     |
|    total_timesteps      | 206080   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00593 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 28.5     |
|    n_updates            | 16090    |
|    policy_gradient_loss | 2.28e-08 |
|    value_loss           | 59.5     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80        |
|    ep_rew_mean          | -6.62     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1611      |
|    time_elapsed         | 5331      |
|    total_timesteps      | 206208    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00597  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.2      |
|    n_updates            | 16100     |
|    policy_gradient_loss | -6.75e-10 |
|    value_loss           | 91        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80       |
|    ep_rew_mean          | -6.42    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1612     |
|    time_elapsed         | 5335     |
|    total_timesteps      | 206336   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00608 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 59       |
|    n_updates            | 16110    |
|    policy_gradient_loss | 1.16e-09 |
|    value_loss           | 106      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -5.96     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1613      |
|    time_elapsed         | 5338      |
|    total_timesteps      | 206464    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00615  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 80.9      |
|    n_updates            | 16120     |
|    policy_gradient_loss | -4.84e-09 |
|    value_loss           | 160       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.7      |
|    ep_rew_mean          | -6.25     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1614      |
|    time_elapsed         | 5341      |
|    total_timesteps      | 206592    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00623  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45.4      |
|    n_updates            | 16130     |
|    policy_gradient_loss | -5.77e-09 |
|    value_loss           | 77.1      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 79.7          |
|    ep_rew_mean          | -6.47         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1615          |
|    time_elapsed         | 5345          |
|    total_timesteps      | 206720        |
| train/                  |               |
|    approx_kl            | 0.00012232037 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00594      |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 32.8          |
|    n_updates            | 16140         |
|    policy_gradient_loss | -0.000389     |
|    value_loss           | 70.3          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.8     |
|    ep_rew_mean          | -6.61    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1616     |
|    time_elapsed         | 5348     |
|    total_timesteps      | 206848   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00519 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42       |
|    n_updates            | 16150    |
|    policy_gradient_loss | 1.49e-09 |
|    value_loss           | 94.8     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.7      |
|    ep_rew_mean          | -6.66     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1617      |
|    time_elapsed         | 5351      |
|    total_timesteps      | 206976    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00505  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.2      |
|    n_updates            | 16160     |
|    policy_gradient_loss | -7.68e-09 |
|    value_loss           | 77.6      |
---------------------------------------
Num timesteps: 207000
Best mean reward: -0.99 - Last mean reward per episode: -7.11
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -6.56     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1618      |
|    time_elapsed         | 5354      |
|    total_timesteps      | 207104    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00505  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 68.2      |
|    n_updates            | 16170     |
|    policy_gradient_loss | -3.73e-09 |
|    value_loss           | 125       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.7      |
|    ep_rew_mean          | -6.54     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1619      |
|    time_elapsed         | 5358      |
|    total_timesteps      | 207232    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00506  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 28.7      |
|    n_updates            | 16180     |
|    policy_gradient_loss | -5.68e-09 |
|    value_loss           | 72.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.2      |
|    ep_rew_mean          | -6.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1620      |
|    time_elapsed         | 5361      |
|    total_timesteps      | 207360    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00508  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.2      |
|    n_updates            | 16190     |
|    policy_gradient_loss | -4.19e-10 |
|    value_loss           | 83.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.4     |
|    ep_rew_mean          | -6.82    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1621     |
|    time_elapsed         | 5364     |
|    total_timesteps      | 207488   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00512 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 63.1     |
|    n_updates            | 16200    |
|    policy_gradient_loss | 3.73e-10 |
|    value_loss           | 141      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.4      |
|    ep_rew_mean          | -6.79     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1622      |
|    time_elapsed         | 5367      |
|    total_timesteps      | 207616    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0052   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 73.4      |
|    n_updates            | 16210     |
|    policy_gradient_loss | -1.49e-09 |
|    value_loss           | 189       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.9      |
|    ep_rew_mean          | -6.95     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1623      |
|    time_elapsed         | 5370      |
|    total_timesteps      | 207744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00525  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46        |
|    n_updates            | 16220     |
|    policy_gradient_loss | -2.12e-09 |
|    value_loss           | 94.1      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.7     |
|    ep_rew_mean          | -6.83    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1624     |
|    time_elapsed         | 5373     |
|    total_timesteps      | 207872   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00531 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 49.6     |
|    n_updates            | 16230    |
|    policy_gradient_loss | 1.4e-09  |
|    value_loss           | 108      |
--------------------------------------
Num timesteps: 208000
Best mean reward: -0.99 - Last mean reward per episode: -6.72
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81       |
|    ep_rew_mean          | -7       |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1625     |
|    time_elapsed         | 5375     |
|    total_timesteps      | 208000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00539 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 56.9     |
|    n_updates            | 16240    |
|    policy_gradient_loss | 6.05e-10 |
|    value_loss           | 94.4     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.7      |
|    ep_rew_mean          | -6.95     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1626      |
|    time_elapsed         | 5378      |
|    total_timesteps      | 208128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0055   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 51.9      |
|    n_updates            | 16250     |
|    policy_gradient_loss | -4.89e-10 |
|    value_loss           | 103       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.8     |
|    ep_rew_mean          | -6.32    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1627     |
|    time_elapsed         | 5381     |
|    total_timesteps      | 208256   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00565 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 51.9     |
|    n_updates            | 16260    |
|    policy_gradient_loss | 0        |
|    value_loss           | 90.9     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.8     |
|    ep_rew_mean          | -6.42    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1628     |
|    time_elapsed         | 5385     |
|    total_timesteps      | 208384   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00574 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 92.8     |
|    n_updates            | 16270    |
|    policy_gradient_loss | 6.52e-09 |
|    value_loss           | 175      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81        |
|    ep_rew_mean          | -6.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1629      |
|    time_elapsed         | 5389      |
|    total_timesteps      | 208512    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00577  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 27.6      |
|    n_updates            | 16280     |
|    policy_gradient_loss | -2.37e-09 |
|    value_loss           | 80.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81        |
|    ep_rew_mean          | -6.69     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1630      |
|    time_elapsed         | 5393      |
|    total_timesteps      | 208640    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0058   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 58.2      |
|    n_updates            | 16290     |
|    policy_gradient_loss | -1.89e-09 |
|    value_loss           | 105       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -5.76     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1631      |
|    time_elapsed         | 5397      |
|    total_timesteps      | 208768    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0059   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 82.7      |
|    n_updates            | 16300     |
|    policy_gradient_loss | -4.54e-09 |
|    value_loss           | 154       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79       |
|    ep_rew_mean          | -5.5     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1632     |
|    time_elapsed         | 5400     |
|    total_timesteps      | 208896   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00613 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 61.9     |
|    n_updates            | 16310    |
|    policy_gradient_loss | 1.3e-09  |
|    value_loss           | 135      |
--------------------------------------
Num timesteps: 209000
Best mean reward: -0.99 - Last mean reward per episode: -4.99
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 79.3         |
|    ep_rew_mean          | -5.55        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1633         |
|    time_elapsed         | 5403         |
|    total_timesteps      | 209024       |
| train/                  |              |
|    approx_kl            | 0.0073990114 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00984     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 94.7         |
|    n_updates            | 16320        |
|    policy_gradient_loss | -0.00309     |
|    value_loss           | 162          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 79.1          |
|    ep_rew_mean          | -5.46         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1634          |
|    time_elapsed         | 5407          |
|    total_timesteps      | 209152        |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0154       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 82.2          |
|    n_updates            | 16330         |
|    policy_gradient_loss | 3.03e-10      |
|    value_loss           | 136           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 78.7         |
|    ep_rew_mean          | -5.25        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1635         |
|    time_elapsed         | 5410         |
|    total_timesteps      | 209280       |
| train/                  |              |
|    approx_kl            | 0.0018377206 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0139      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 67.1         |
|    n_updates            | 16340        |
|    policy_gradient_loss | -0.000928    |
|    value_loss           | 88.8         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.6      |
|    ep_rew_mean          | -5.12     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1636      |
|    time_elapsed         | 5414      |
|    total_timesteps      | 209408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0108   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 67.1      |
|    n_updates            | 16350     |
|    policy_gradient_loss | 1.79e-09  |
|    value_loss           | 113       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 78.6          |
|    ep_rew_mean          | -5.01         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1637          |
|    time_elapsed         | 5417          |
|    total_timesteps      | 209536        |
| train/                  |               |
|    approx_kl            | 2.8919894e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0102       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 81.3          |
|    n_updates            | 16360         |
|    policy_gradient_loss | -0.000195     |
|    value_loss           | 179           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.6      |
|    ep_rew_mean          | -5.21     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1638      |
|    time_elapsed         | 5420      |
|    total_timesteps      | 209664    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00949  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 78.6      |
|    n_updates            | 16370     |
|    policy_gradient_loss | -8.89e-09 |
|    value_loss           | 165       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.2     |
|    ep_rew_mean          | -5.58    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1639     |
|    time_elapsed         | 5424     |
|    total_timesteps      | 209792   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00935 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 31.4     |
|    n_updates            | 16380    |
|    policy_gradient_loss | 8.43e-09 |
|    value_loss           | 72.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.3      |
|    ep_rew_mean          | -5.78     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1640      |
|    time_elapsed         | 5428      |
|    total_timesteps      | 209920    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00938  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.7      |
|    n_updates            | 16390     |
|    policy_gradient_loss | -1.28e-09 |
|    value_loss           | 90.7      |
---------------------------------------
Num timesteps: 210000
Best mean reward: -0.99 - Last mean reward per episode: -5.70
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=210000, episode_reward=-3.30 +/- 18.32
Episode length: 74.60 +/- 30.29
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 74.6     |
|    mean_reward          | -3.3     |
| time/                   |          |
|    total_timesteps      | 210000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00945 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 33.5     |
|    n_updates            | 16400    |
|    policy_gradient_loss | 2.19e-09 |
|    value_loss           | 69.4     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79.5     |
|    ep_rew_mean     | -5.88    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1641     |
|    time_elapsed    | 5432     |
|    total_timesteps | 210048   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -5.84     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1642      |
|    time_elapsed         | 5434      |
|    total_timesteps      | 210176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00948  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.5      |
|    n_updates            | 16410     |
|    policy_gradient_loss | -2.17e-09 |
|    value_loss           | 80.8      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.4     |
|    ep_rew_mean          | -5.82    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1643     |
|    time_elapsed         | 5437     |
|    total_timesteps      | 210304   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00954 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 54.5     |
|    n_updates            | 16420    |
|    policy_gradient_loss | 6.05e-09 |
|    value_loss           | 97.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80       |
|    ep_rew_mean          | -6.02    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1644     |
|    time_elapsed         | 5441     |
|    total_timesteps      | 210432   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00965 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 36.1     |
|    n_updates            | 16430    |
|    policy_gradient_loss | 5.33e-09 |
|    value_loss           | 76.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.9      |
|    ep_rew_mean          | -6.46     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1645      |
|    time_elapsed         | 5444      |
|    total_timesteps      | 210560    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0097   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 62.5      |
|    n_updates            | 16440     |
|    policy_gradient_loss | -9.78e-10 |
|    value_loss           | 118       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.5      |
|    ep_rew_mean          | -6.74     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1646      |
|    time_elapsed         | 5448      |
|    total_timesteps      | 210688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00974  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 47.6      |
|    n_updates            | 16450     |
|    policy_gradient_loss | 4.66e-11  |
|    value_loss           | 85.5      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 81.6        |
|    ep_rew_mean          | -6.82       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 1647        |
|    time_elapsed         | 5451        |
|    total_timesteps      | 210816      |
| train/                  |             |
|    approx_kl            | 4.33987e-05 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0095     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 35.6        |
|    n_updates            | 16460       |
|    policy_gradient_loss | -0.000205   |
|    value_loss           | 73.6        |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.1     |
|    ep_rew_mean          | -6.94    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1648     |
|    time_elapsed         | 5455     |
|    total_timesteps      | 210944   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00867 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 34.3     |
|    n_updates            | 16470    |
|    policy_gradient_loss | 7.14e-09 |
|    value_loss           | 74.9     |
--------------------------------------
Num timesteps: 211000
Best mean reward: -0.99 - Last mean reward per episode: -8.04
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.9      |
|    ep_rew_mean          | -7.66     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1649      |
|    time_elapsed         | 5458      |
|    total_timesteps      | 211072    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00849  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 68.4      |
|    n_updates            | 16480     |
|    policy_gradient_loss | -5.91e-09 |
|    value_loss           | 125       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83        |
|    ep_rew_mean          | -7.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1650      |
|    time_elapsed         | 5462      |
|    total_timesteps      | 211200    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00851  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 61.7      |
|    n_updates            | 16490     |
|    policy_gradient_loss | 1.93e-09  |
|    value_loss           | 105       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83        |
|    ep_rew_mean          | -7.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1651      |
|    time_elapsed         | 5465      |
|    total_timesteps      | 211328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0086   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30.8      |
|    n_updates            | 16500     |
|    policy_gradient_loss | -3.42e-09 |
|    value_loss           | 76.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83        |
|    ep_rew_mean          | -7.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1652      |
|    time_elapsed         | 5469      |
|    total_timesteps      | 211456    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00865  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 23.1      |
|    n_updates            | 16510     |
|    policy_gradient_loss | -5.66e-09 |
|    value_loss           | 49.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83        |
|    ep_rew_mean          | -7.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1653      |
|    time_elapsed         | 5472      |
|    total_timesteps      | 211584    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00866  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 22.8      |
|    n_updates            | 16520     |
|    policy_gradient_loss | -5.39e-08 |
|    value_loss           | 48.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83        |
|    ep_rew_mean          | -7.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1654      |
|    time_elapsed         | 5476      |
|    total_timesteps      | 211712    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00867  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 22.9      |
|    n_updates            | 16530     |
|    policy_gradient_loss | -7.35e-08 |
|    value_loss           | 47.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83        |
|    ep_rew_mean          | -7.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1655      |
|    time_elapsed         | 5480      |
|    total_timesteps      | 211840    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00868  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 22.1      |
|    n_updates            | 16540     |
|    policy_gradient_loss | -2.25e-08 |
|    value_loss           | 47        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83        |
|    ep_rew_mean          | -7.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1656      |
|    time_elapsed         | 5483      |
|    total_timesteps      | 211968    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00869  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 22.2      |
|    n_updates            | 16550     |
|    policy_gradient_loss | -3.21e-08 |
|    value_loss           | 46.2      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 212000
Best mean reward: -0.99 - Last mean reward per episode: -8.30
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83       |
|    ep_rew_mean          | -7.92    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1657     |
|    time_elapsed         | 5487     |
|    total_timesteps      | 212096   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0087  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 22.6     |
|    n_updates            | 16560    |
|    policy_gradient_loss | 7.73e-08 |
|    value_loss           | 45.4     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 92.4     |
|    ep_rew_mean          | -13      |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1658     |
|    time_elapsed         | 5491     |
|    total_timesteps      | 212224   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0087  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 22.1     |
|    n_updates            | 16570    |
|    policy_gradient_loss | 6.64e-08 |
|    value_loss           | 44.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 92.6      |
|    ep_rew_mean          | -13.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1659      |
|    time_elapsed         | 5494      |
|    total_timesteps      | 212352    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00873  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.9      |
|    n_updates            | 16580     |
|    policy_gradient_loss | -3.89e-09 |
|    value_loss           | 76.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 92.3      |
|    ep_rew_mean          | -13.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1660      |
|    time_elapsed         | 5497      |
|    total_timesteps      | 212480    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00883  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.7      |
|    n_updates            | 16590     |
|    policy_gradient_loss | -8.57e-09 |
|    value_loss           | 130       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 92.4     |
|    ep_rew_mean          | -13.2    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1661     |
|    time_elapsed         | 5500     |
|    total_timesteps      | 212608   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00888 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 82.4     |
|    n_updates            | 16600    |
|    policy_gradient_loss | 0        |
|    value_loss           | 131      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 92.5          |
|    ep_rew_mean          | -13.2         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1662          |
|    time_elapsed         | 5503          |
|    total_timesteps      | 212736        |
| train/                  |               |
|    approx_kl            | 0.00020645559 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00942      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 64.5          |
|    n_updates            | 16610         |
|    policy_gradient_loss | -0.000378     |
|    value_loss           | 131           |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 92.5     |
|    ep_rew_mean          | -13.2    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1663     |
|    time_elapsed         | 5506     |
|    total_timesteps      | 212864   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0113  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 66.4     |
|    n_updates            | 16620    |
|    policy_gradient_loss | 4.28e-09 |
|    value_loss           | 128      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 92.5     |
|    ep_rew_mean          | -13.2    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1664     |
|    time_elapsed         | 5509     |
|    total_timesteps      | 212992   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0118  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 120      |
|    n_updates            | 16630    |
|    policy_gradient_loss | 9.97e-09 |
|    value_loss           | 169      |
--------------------------------------
Num timesteps: 213000
Best mean reward: -0.99 - Last mean reward per episode: -13.07
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94            |
|    ep_rew_mean          | -14.1         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1665          |
|    time_elapsed         | 5512          |
|    total_timesteps      | 213120        |
| train/                  |               |
|    approx_kl            | 1.1182856e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0117       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 24.9          |
|    n_updates            | 16640         |
|    policy_gradient_loss | -8.45e-05     |
|    value_loss           | 49.8          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 93.5     |
|    ep_rew_mean          | -13.6    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1666     |
|    time_elapsed         | 5515     |
|    total_timesteps      | 213248   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0112  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 26.5     |
|    n_updates            | 16650    |
|    policy_gradient_loss | -5.1e-09 |
|    value_loss           | 79.7     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.8      |
|    ep_rew_mean          | -13.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1667      |
|    time_elapsed         | 5518      |
|    total_timesteps      | 213376    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0112   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 69.7      |
|    n_updates            | 16660     |
|    policy_gradient_loss | -4.66e-11 |
|    value_loss           | 206       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.8      |
|    ep_rew_mean          | -13.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1668      |
|    time_elapsed         | 5522      |
|    total_timesteps      | 213504    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0113   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.3      |
|    n_updates            | 16670     |
|    policy_gradient_loss | -1.33e-09 |
|    value_loss           | 81.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 93.8     |
|    ep_rew_mean          | -13.8    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1669     |
|    time_elapsed         | 5527     |
|    total_timesteps      | 213632   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0115  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 21.6     |
|    n_updates            | 16680    |
|    policy_gradient_loss | 4.79e-08 |
|    value_loss           | 46.8     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.8      |
|    ep_rew_mean          | -13.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1670      |
|    time_elapsed         | 5533      |
|    total_timesteps      | 213760    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0115   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 20        |
|    n_updates            | 16690     |
|    policy_gradient_loss | -8.93e-08 |
|    value_loss           | 45.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.8      |
|    ep_rew_mean          | -13.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1671      |
|    time_elapsed         | 5538      |
|    total_timesteps      | 213888    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0115   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 21.5      |
|    n_updates            | 16700     |
|    policy_gradient_loss | -3.79e-08 |
|    value_loss           | 44.8      |
---------------------------------------
Num timesteps: 214000
Best mean reward: -0.99 - Last mean reward per episode: -14.08
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 100       |
|    ep_rew_mean          | -16.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1672      |
|    time_elapsed         | 5543      |
|    total_timesteps      | 214016    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0115   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 20.8      |
|    n_updates            | 16710     |
|    policy_gradient_loss | -2.54e-08 |
|    value_loss           | 44.1      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 101      |
|    ep_rew_mean          | -17      |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1673     |
|    time_elapsed         | 5548     |
|    total_timesteps      | 214144   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0116  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 92.2     |
|    n_updates            | 16720    |
|    policy_gradient_loss | -2e-09   |
|    value_loss           | 193      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 101           |
|    ep_rew_mean          | -17           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1674          |
|    time_elapsed         | 5551          |
|    total_timesteps      | 214272        |
| train/                  |               |
|    approx_kl            | 0.00048934296 |
|    clip_fraction        | 0.00313       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0132       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 43.1          |
|    n_updates            | 16730         |
|    policy_gradient_loss | -0.000509     |
|    value_loss           | 85.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -16.9         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1675          |
|    time_elapsed         | 5554          |
|    total_timesteps      | 214400        |
| train/                  |               |
|    approx_kl            | 2.3902394e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0154       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 73.8          |
|    n_updates            | 16740         |
|    policy_gradient_loss | 5.59e-05      |
|    value_loss           | 140           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 100       |
|    ep_rew_mean          | -16.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1676      |
|    time_elapsed         | 5557      |
|    total_timesteps      | 214528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0145   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 118       |
|    n_updates            | 16750     |
|    policy_gradient_loss | 3.26e-09  |
|    value_loss           | 224       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -16.9         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1677          |
|    time_elapsed         | 5560          |
|    total_timesteps      | 214656        |
| train/                  |               |
|    approx_kl            | 0.00040160818 |
|    clip_fraction        | 0.00234       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0156       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 37.7          |
|    n_updates            | 16760         |
|    policy_gradient_loss | -0.000166     |
|    value_loss           | 130           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 101           |
|    ep_rew_mean          | -17.2         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1678          |
|    time_elapsed         | 5564          |
|    total_timesteps      | 214784        |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0194       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 131           |
|    n_updates            | 16770         |
|    policy_gradient_loss | -2.77e-09     |
|    value_loss           | 198           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 101       |
|    ep_rew_mean          | -16.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1679      |
|    time_elapsed         | 5567      |
|    total_timesteps      | 214912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0207   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 58        |
|    n_updates            | 16780     |
|    policy_gradient_loss | -2.89e-09 |
|    value_loss           | 83.9      |
---------------------------------------
Num timesteps: 215000
Best mean reward: -0.99 - Last mean reward per episode: -16.57
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=215000, episode_reward=-7.70 +/- 9.90
Episode length: 79.40 +/- 21.65
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 79.4          |
|    mean_reward          | -7.7          |
| time/                   |               |
|    total_timesteps      | 215000        |
| train/                  |               |
|    approx_kl            | 3.0290335e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0209       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 122           |
|    n_updates            | 16790         |
|    policy_gradient_loss | -0.000172     |
|    value_loss           | 235           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 99.9     |
|    ep_rew_mean     | -16.6    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1680     |
|    time_elapsed    | 5572     |
|    total_timesteps | 215040   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -16.8         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1681          |
|    time_elapsed         | 5575          |
|    total_timesteps      | 215168        |
| train/                  |               |
|    approx_kl            | 0.00034521986 |
|    clip_fraction        | 0.00313       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0178       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 65.8          |
|    n_updates            | 16800         |
|    policy_gradient_loss | -0.000635     |
|    value_loss           | 133           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 100       |
|    ep_rew_mean          | -16.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1682      |
|    time_elapsed         | 5578      |
|    total_timesteps      | 215296    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0153   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 85.4      |
|    n_updates            | 16810     |
|    policy_gradient_loss | -9.08e-10 |
|    value_loss           | 131       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 93.7     |
|    ep_rew_mean          | -13.2    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1683     |
|    time_elapsed         | 5581     |
|    total_timesteps      | 215424   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0151  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 45.9     |
|    n_updates            | 16820    |
|    policy_gradient_loss | 5.12e-10 |
|    value_loss           | 85.7     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 93.7     |
|    ep_rew_mean          | -13.2    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1684     |
|    time_elapsed         | 5585     |
|    total_timesteps      | 215552   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0152  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 178      |
|    n_updates            | 16830    |
|    policy_gradient_loss | 7.45e-10 |
|    value_loss           | 366      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 94.8     |
|    ep_rew_mean          | -13.6    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1685     |
|    time_elapsed         | 5589     |
|    total_timesteps      | 215680   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0152  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 24.4     |
|    n_updates            | 16840    |
|    policy_gradient_loss | 8.22e-08 |
|    value_loss           | 48.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.9      |
|    ep_rew_mean          | -13.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1686      |
|    time_elapsed         | 5593      |
|    total_timesteps      | 215808    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0154   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 62.5      |
|    n_updates            | 16850     |
|    policy_gradient_loss | -1.82e-09 |
|    value_loss           | 130       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 95       |
|    ep_rew_mean          | -13.7    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1687     |
|    time_elapsed         | 5596     |
|    total_timesteps      | 215936   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0159  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 145      |
|    n_updates            | 16860    |
|    policy_gradient_loss | 3.73e-09 |
|    value_loss           | 211      |
--------------------------------------
Num timesteps: 216000
Best mean reward: -0.99 - Last mean reward per episode: -13.49
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 94       |
|    ep_rew_mean          | -13.2    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1688     |
|    time_elapsed         | 5599     |
|    total_timesteps      | 216064   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0163  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 44.5     |
|    n_updates            | 16870    |
|    policy_gradient_loss | 9.31e-11 |
|    value_loss           | 125      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.8      |
|    ep_rew_mean          | -12.9     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1689      |
|    time_elapsed         | 5602      |
|    total_timesteps      | 216192    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.017    |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 65.8      |
|    n_updates            | 16880     |
|    policy_gradient_loss | -6.52e-10 |
|    value_loss           | 127       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 94.3     |
|    ep_rew_mean          | -13.2    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1690     |
|    time_elapsed         | 5605     |
|    total_timesteps      | 216320   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0173  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 93.9     |
|    n_updates            | 16890    |
|    policy_gradient_loss | 4.84e-09 |
|    value_loss           | 224      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.1          |
|    ep_rew_mean          | -13.1         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1691          |
|    time_elapsed         | 5609          |
|    total_timesteps      | 216448        |
| train/                  |               |
|    approx_kl            | 0.00011893967 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0169       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 37.8          |
|    n_updates            | 16900         |
|    policy_gradient_loss | -0.000182     |
|    value_loss           | 80.2          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 94.3         |
|    ep_rew_mean          | -13.1        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1692         |
|    time_elapsed         | 5612         |
|    total_timesteps      | 216576       |
| train/                  |              |
|    approx_kl            | 0.0043478236 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0237      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 55.6         |
|    n_updates            | 16910        |
|    policy_gradient_loss | -0.00178     |
|    value_loss           | 126          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 94.2         |
|    ep_rew_mean          | -13.1        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1693         |
|    time_elapsed         | 5615         |
|    total_timesteps      | 216704       |
| train/                  |              |
|    approx_kl            | 5.662441e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0367      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 70.8         |
|    n_updates            | 16920        |
|    policy_gradient_loss | 3.86e-09     |
|    value_loss           | 125          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94            |
|    ep_rew_mean          | -13           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1694          |
|    time_elapsed         | 5619          |
|    total_timesteps      | 216832        |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0402       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 50.2          |
|    n_updates            | 16930         |
|    policy_gradient_loss | 2.1e-09       |
|    value_loss           | 125           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 94.4         |
|    ep_rew_mean          | -13.3        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1695         |
|    time_elapsed         | 5622         |
|    total_timesteps      | 216960       |
| train/                  |              |
|    approx_kl            | 8.428469e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.041       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 114          |
|    n_updates            | 16940        |
|    policy_gradient_loss | 1.35e-05     |
|    value_loss           | 215          |
------------------------------------------
Num timesteps: 217000
Best mean reward: -0.99 - Last mean reward per episode: -13.46
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 94.2         |
|    ep_rew_mean          | -13.1        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1696         |
|    time_elapsed         | 5626         |
|    total_timesteps      | 217088       |
| train/                  |              |
|    approx_kl            | 8.940697e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0419      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 39.5         |
|    n_updates            | 16950        |
|    policy_gradient_loss | -5.66e-09    |
|    value_loss           | 119          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.5          |
|    ep_rew_mean          | -13.2         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1697          |
|    time_elapsed         | 5629          |
|    total_timesteps      | 217216        |
| train/                  |               |
|    approx_kl            | 0.00047660945 |
|    clip_fraction        | 0.00156       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0406       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 51.8          |
|    n_updates            | 16960         |
|    policy_gradient_loss | -0.000516     |
|    value_loss           | 91.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.4          |
|    ep_rew_mean          | -13.1         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1698          |
|    time_elapsed         | 5633          |
|    total_timesteps      | 217344        |
| train/                  |               |
|    approx_kl            | 0.00011594547 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0316       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 47.5          |
|    n_updates            | 16970         |
|    policy_gradient_loss | 2.43e-05      |
|    value_loss           | 88.5          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 95.2     |
|    ep_rew_mean          | -13.5    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1699     |
|    time_elapsed         | 5637     |
|    total_timesteps      | 217472   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0298  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 63       |
|    n_updates            | 16980    |
|    policy_gradient_loss | 1.37e-08 |
|    value_loss           | 87.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.9      |
|    ep_rew_mean          | -13.9     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1700      |
|    time_elapsed         | 5639      |
|    total_timesteps      | 217600    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0297   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.9      |
|    n_updates            | 16990     |
|    policy_gradient_loss | -1.91e-09 |
|    value_loss           | 91.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.6      |
|    ep_rew_mean          | -13.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1701      |
|    time_elapsed         | 5642      |
|    total_timesteps      | 217728    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0299   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 61        |
|    n_updates            | 17000     |
|    policy_gradient_loss | 2.42e-09  |
|    value_loss           | 125       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.6      |
|    ep_rew_mean          | -13.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1702      |
|    time_elapsed         | 5645      |
|    total_timesteps      | 217856    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0301   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 91.9      |
|    n_updates            | 17010     |
|    policy_gradient_loss | -1.86e-09 |
|    value_loss           | 227       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 95.7     |
|    ep_rew_mean          | -13.8    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1703     |
|    time_elapsed         | 5648     |
|    total_timesteps      | 217984   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0307  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 78.2     |
|    n_updates            | 17020    |
|    policy_gradient_loss | 3.26e-09 |
|    value_loss           | 123      |
--------------------------------------
Num timesteps: 218000
Best mean reward: -0.99 - Last mean reward per episode: -13.80
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.2          |
|    ep_rew_mean          | -13.3         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1704          |
|    time_elapsed         | 5651          |
|    total_timesteps      | 218112        |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0324       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 63.8          |
|    n_updates            | 17030         |
|    policy_gradient_loss | 3.12e-09      |
|    value_loss           | 124           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 94.2     |
|    ep_rew_mean          | -13.4    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1705     |
|    time_elapsed         | 5654     |
|    total_timesteps      | 218240   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0337  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 74.4     |
|    n_updates            | 17040    |
|    policy_gradient_loss | 3.42e-09 |
|    value_loss           | 121      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 94.4     |
|    ep_rew_mean          | -13.7    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1706     |
|    time_elapsed         | 5657     |
|    total_timesteps      | 218368   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0344  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 55.5     |
|    n_updates            | 17050    |
|    policy_gradient_loss | 1.26e-09 |
|    value_loss           | 117      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.1          |
|    ep_rew_mean          | -13.5         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1707          |
|    time_elapsed         | 5660          |
|    total_timesteps      | 218496        |
| train/                  |               |
|    approx_kl            | 1.6905833e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0347       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 58.2          |
|    n_updates            | 17060         |
|    policy_gradient_loss | -3.52e-05     |
|    value_loss           | 118           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94        |
|    ep_rew_mean          | -13.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1708      |
|    time_elapsed         | 5663      |
|    total_timesteps      | 218624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0342   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 82.4      |
|    n_updates            | 17070     |
|    policy_gradient_loss | -1.35e-09 |
|    value_loss           | 149       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.5      |
|    ep_rew_mean          | -13.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1709      |
|    time_elapsed         | 5666      |
|    total_timesteps      | 218752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0343   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 101       |
|    n_updates            | 17080     |
|    policy_gradient_loss | -6.98e-09 |
|    value_loss           | 196       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.4      |
|    ep_rew_mean          | -13.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1710      |
|    time_elapsed         | 5670      |
|    total_timesteps      | 218880    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0345   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 76.8      |
|    n_updates            | 17090     |
|    policy_gradient_loss | -4.47e-09 |
|    value_loss           | 144       |
---------------------------------------
Num timesteps: 219000
Best mean reward: -0.99 - Last mean reward per episode: -12.94
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 93.1     |
|    ep_rew_mean          | -13.2    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1711     |
|    time_elapsed         | 5673     |
|    total_timesteps      | 219008   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0349  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 76.6     |
|    n_updates            | 17100    |
|    policy_gradient_loss | 1.72e-09 |
|    value_loss           | 136      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.2      |
|    ep_rew_mean          | -13.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1712      |
|    time_elapsed         | 5676      |
|    total_timesteps      | 219136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0353   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.9      |
|    n_updates            | 17110     |
|    policy_gradient_loss | -2.79e-10 |
|    value_loss           | 84.6      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 93.2         |
|    ep_rew_mean          | -13.2        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1713         |
|    time_elapsed         | 5679         |
|    total_timesteps      | 219264       |
| train/                  |              |
|    approx_kl            | 6.747572e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0344      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 61.4         |
|    n_updates            | 17120        |
|    policy_gradient_loss | -3.06e-05    |
|    value_loss           | 104          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.1          |
|    ep_rew_mean          | -13.7         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1714          |
|    time_elapsed         | 5683          |
|    total_timesteps      | 219392        |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0296       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 26.2          |
|    n_updates            | 17130         |
|    policy_gradient_loss | -5.36e-08     |
|    value_loss           | 55            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.1          |
|    ep_rew_mean          | -13.6         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1715          |
|    time_elapsed         | 5687          |
|    total_timesteps      | 219520        |
| train/                  |               |
|    approx_kl            | 2.9802322e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0293       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 49.8          |
|    n_updates            | 17140         |
|    policy_gradient_loss | -3.73e-10     |
|    value_loss           | 104           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.1      |
|    ep_rew_mean          | -13.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1716      |
|    time_elapsed         | 5690      |
|    total_timesteps      | 219648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0311   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 76.7      |
|    n_updates            | 17150     |
|    policy_gradient_loss | -2.37e-09 |
|    value_loss           | 140       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 93.8         |
|    ep_rew_mean          | -13.3        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1717         |
|    time_elapsed         | 5693         |
|    total_timesteps      | 219776       |
| train/                  |              |
|    approx_kl            | 0.0005670204 |
|    clip_fraction        | 0.00313      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0361      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 49.2         |
|    n_updates            | 17160        |
|    policy_gradient_loss | -0.000595    |
|    value_loss           | 110          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 92.2          |
|    ep_rew_mean          | -12.3         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1718          |
|    time_elapsed         | 5696          |
|    total_timesteps      | 219904        |
| train/                  |               |
|    approx_kl            | 2.6787166e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0446       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 78.8          |
|    n_updates            | 17170         |
|    policy_gradient_loss | 3.47e-05      |
|    value_loss           | 160           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 220000
Best mean reward: -0.99 - Last mean reward per episode: -7.00
Eval num_timesteps=220000, episode_reward=-0.90 +/- 9.61
Episode length: 65.80 +/- 15.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 65.8         |
|    mean_reward          | -0.9         |
| time/                   |              |
|    total_timesteps      | 220000       |
| train/                  |              |
|    approx_kl            | 7.605506e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0439      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 88.2         |
|    n_updates            | 17180        |
|    policy_gradient_loss | -0.000129    |
|    value_loss           | 168          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 92.1     |
|    ep_rew_mean     | -12.2    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1719     |
|    time_elapsed    | 5700     |
|    total_timesteps | 220032   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 92.2          |
|    ep_rew_mean          | -12.4         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1720          |
|    time_elapsed         | 5703          |
|    total_timesteps      | 220160        |
| train/                  |               |
|    approx_kl            | 3.9915554e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0401       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 42.3          |
|    n_updates            | 17190         |
|    policy_gradient_loss | -0.000154     |
|    value_loss           | 73.6          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 91.4     |
|    ep_rew_mean          | -11.9    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1721     |
|    time_elapsed         | 5707     |
|    total_timesteps      | 220288   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0377  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 43.1     |
|    n_updates            | 17200    |
|    policy_gradient_loss | 1.02e-09 |
|    value_loss           | 71.8     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 91.5          |
|    ep_rew_mean          | -11.9         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1722          |
|    time_elapsed         | 5710          |
|    total_timesteps      | 220416        |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0386       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 53.9          |
|    n_updates            | 17210         |
|    policy_gradient_loss | 1.26e-09      |
|    value_loss           | 137           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 82.7          |
|    ep_rew_mean          | -7.04         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1723          |
|    time_elapsed         | 5713          |
|    total_timesteps      | 220544        |
| train/                  |               |
|    approx_kl            | 2.6368536e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0395       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 46.4          |
|    n_updates            | 17220         |
|    policy_gradient_loss | -0.000127     |
|    value_loss           | 79.1          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 82.4         |
|    ep_rew_mean          | -6.7         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1724         |
|    time_elapsed         | 5717         |
|    total_timesteps      | 220672       |
| train/                  |              |
|    approx_kl            | 6.557722e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0356      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 83.2         |
|    n_updates            | 17230        |
|    policy_gradient_loss | -0.000279    |
|    value_loss           | 180          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.5      |
|    ep_rew_mean          | -6.95     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1725      |
|    time_elapsed         | 5721      |
|    total_timesteps      | 220800    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.033    |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 73.9      |
|    n_updates            | 17240     |
|    policy_gradient_loss | -7.03e-09 |
|    value_loss           | 176       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.9     |
|    ep_rew_mean          | -7.17    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1726     |
|    time_elapsed         | 5725     |
|    total_timesteps      | 220928   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0328  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 112      |
|    n_updates            | 17250    |
|    policy_gradient_loss | 4.19e-10 |
|    value_loss           | 226      |
--------------------------------------
Num timesteps: 221000
Best mean reward: -0.99 - Last mean reward per episode: -3.47
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.2     |
|    ep_rew_mean          | -7.12    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1727     |
|    time_elapsed         | 5729     |
|    total_timesteps      | 221056   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.033   |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 39.5     |
|    n_updates            | 17260    |
|    policy_gradient_loss | 1.05e-09 |
|    value_loss           | 73.7     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.2      |
|    ep_rew_mean          | -7.09     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1728      |
|    time_elapsed         | 5732      |
|    total_timesteps      | 221184    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0334   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 97.6      |
|    n_updates            | 17270     |
|    policy_gradient_loss | -7.57e-09 |
|    value_loss           | 191       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 84.1         |
|    ep_rew_mean          | -6.93        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1729         |
|    time_elapsed         | 5735         |
|    total_timesteps      | 221312       |
| train/                  |              |
|    approx_kl            | 0.0004947698 |
|    clip_fraction        | 0.00391      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0316      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 46.3         |
|    n_updates            | 17280        |
|    policy_gradient_loss | -0.000869    |
|    value_loss           | 99           |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.2     |
|    ep_rew_mean          | -5.82    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1730     |
|    time_elapsed         | 5739     |
|    total_timesteps      | 221440   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0298  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 69.9     |
|    n_updates            | 17290    |
|    policy_gradient_loss | 4.1e-09  |
|    value_loss           | 182      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.8      |
|    ep_rew_mean          | -6.2      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1731      |
|    time_elapsed         | 5742      |
|    total_timesteps      | 221568    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0302   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 66        |
|    n_updates            | 17300     |
|    policy_gradient_loss | -3e-09    |
|    value_loss           | 169       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 82.9     |
|    ep_rew_mean          | -6.27    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1732     |
|    time_elapsed         | 5745     |
|    total_timesteps      | 221696   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0315  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 59.6     |
|    n_updates            | 17310    |
|    policy_gradient_loss | 5.31e-09 |
|    value_loss           | 130      |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.4         |
|    ep_rew_mean          | -3.68        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1733         |
|    time_elapsed         | 5748         |
|    total_timesteps      | 221824       |
| train/                  |              |
|    approx_kl            | 0.0011590398 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0392      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 35.6         |
|    n_updates            | 17320        |
|    policy_gradient_loss | -0.00361     |
|    value_loss           | 72.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.1         |
|    ep_rew_mean          | -3.23        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1734         |
|    time_elapsed         | 5751         |
|    total_timesteps      | 221952       |
| train/                  |              |
|    approx_kl            | 0.0004217755 |
|    clip_fraction        | 0.00313      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0543      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 39.7         |
|    n_updates            | 17330        |
|    policy_gradient_loss | -0.00141     |
|    value_loss           | 72.7         |
------------------------------------------
Num timesteps: 222000
Best mean reward: -0.99 - Last mean reward per episode: -3.77
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.2          |
|    ep_rew_mean          | -3.21         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1735          |
|    time_elapsed         | 5754          |
|    total_timesteps      | 222080        |
| train/                  |               |
|    approx_kl            | 0.00069272704 |
|    clip_fraction        | 0.00391       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0642       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 75.7          |
|    n_updates            | 17340         |
|    policy_gradient_loss | -0.000774     |
|    value_loss           | 223           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.2         |
|    ep_rew_mean          | -3.21        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1736         |
|    time_elapsed         | 5757         |
|    total_timesteps      | 222208       |
| train/                  |              |
|    approx_kl            | 0.0004591858 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0697      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 67.5         |
|    n_updates            | 17350        |
|    policy_gradient_loss | -0.000609    |
|    value_loss           | 132          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 78.3          |
|    ep_rew_mean          | -3.77         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1737          |
|    time_elapsed         | 5761          |
|    total_timesteps      | 222336        |
| train/                  |               |
|    approx_kl            | 2.1332875e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0566       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 27.4          |
|    n_updates            | 17360         |
|    policy_gradient_loss | 0.000905      |
|    value_loss           | 58.5          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 79.3         |
|    ep_rew_mean          | -4.44        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1738         |
|    time_elapsed         | 5763         |
|    total_timesteps      | 222464       |
| train/                  |              |
|    approx_kl            | 3.874302e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0606      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 43.2         |
|    n_updates            | 17370        |
|    policy_gradient_loss | -1.86e-10    |
|    value_loss           | 85           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 78.9         |
|    ep_rew_mean          | -4.45        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1739         |
|    time_elapsed         | 5766         |
|    total_timesteps      | 222592       |
| train/                  |              |
|    approx_kl            | 0.0020221486 |
|    clip_fraction        | 0.00937      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0736      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 37.1         |
|    n_updates            | 17380        |
|    policy_gradient_loss | -0.000261    |
|    value_loss           | 85.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 78.4          |
|    ep_rew_mean          | -4.01         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1740          |
|    time_elapsed         | 5769          |
|    total_timesteps      | 222720        |
| train/                  |               |
|    approx_kl            | 0.00039465912 |
|    clip_fraction        | 0.00156       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0717       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 66            |
|    n_updates            | 17390         |
|    policy_gradient_loss | -6.3e-05      |
|    value_loss           | 103           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 79           |
|    ep_rew_mean          | -4.41        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1741         |
|    time_elapsed         | 5773         |
|    total_timesteps      | 222848       |
| train/                  |              |
|    approx_kl            | 6.854534e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0749      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 68.8         |
|    n_updates            | 17400        |
|    policy_gradient_loss | 2.51e-09     |
|    value_loss           | 162          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 79.3         |
|    ep_rew_mean          | -4.56        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1742         |
|    time_elapsed         | 5776         |
|    total_timesteps      | 222976       |
| train/                  |              |
|    approx_kl            | 7.114373e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0795      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 77.2         |
|    n_updates            | 17410        |
|    policy_gradient_loss | 0.000146     |
|    value_loss           | 142          |
------------------------------------------
Num timesteps: 223000
Best mean reward: -0.99 - Last mean reward per episode: -4.49
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 79.3         |
|    ep_rew_mean          | -4.57        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1743         |
|    time_elapsed         | 5780         |
|    total_timesteps      | 223104       |
| train/                  |              |
|    approx_kl            | 0.0014770254 |
|    clip_fraction        | 0.00781      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0853      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 42.4         |
|    n_updates            | 17420        |
|    policy_gradient_loss | -0.00195     |
|    value_loss           | 102          |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 79.2          |
|    ep_rew_mean          | -4.41         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1744          |
|    time_elapsed         | 5782          |
|    total_timesteps      | 223232        |
| train/                  |               |
|    approx_kl            | 0.00015978236 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.108        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 42.6          |
|    n_updates            | 17430         |
|    policy_gradient_loss | 5.36e-05      |
|    value_loss           | 73.5          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 79.3        |
|    ep_rew_mean          | -4.45       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 1745        |
|    time_elapsed         | 5786        |
|    total_timesteps      | 223360      |
| train/                  |             |
|    approx_kl            | 0.011787107 |
|    clip_fraction        | 0.0336      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0727     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 38.5        |
|    n_updates            | 17440       |
|    policy_gradient_loss | -0.00404    |
|    value_loss           | 129         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 79.7         |
|    ep_rew_mean          | -5.06        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1746         |
|    time_elapsed         | 5789         |
|    total_timesteps      | 223488       |
| train/                  |              |
|    approx_kl            | 6.938446e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0518      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 36.3         |
|    n_updates            | 17450        |
|    policy_gradient_loss | 8.3e-05      |
|    value_loss           | 76.4         |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.8     |
|    ep_rew_mean          | -4.17    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1747     |
|    time_elapsed         | 5792     |
|    total_timesteps      | 223616   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0508  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 59.8     |
|    n_updates            | 17460    |
|    policy_gradient_loss | -1.4e-09 |
|    value_loss           | 107      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.8          |
|    ep_rew_mean          | -4.17         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1748          |
|    time_elapsed         | 5796          |
|    total_timesteps      | 223744        |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0527       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 80.2          |
|    n_updates            | 17470         |
|    policy_gradient_loss | -1.96e-09     |
|    value_loss           | 126           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.9          |
|    ep_rew_mean          | -4.25         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1749          |
|    time_elapsed         | 5799          |
|    total_timesteps      | 223872        |
| train/                  |               |
|    approx_kl            | 1.5613157e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0535       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 82.4          |
|    n_updates            | 17480         |
|    policy_gradient_loss | -0.000136     |
|    value_loss           | 184           |
-------------------------------------------
Num timesteps: 224000
Best mean reward: -0.99 - Last mean reward per episode: -4.42
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.5     |
|    ep_rew_mean          | -4.46    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1750     |
|    time_elapsed         | 5802     |
|    total_timesteps      | 224000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.051   |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 41.1     |
|    n_updates            | 17490    |
|    policy_gradient_loss | 9.92e-09 |
|    value_loss           | 76       |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.3     |
|    ep_rew_mean          | -4.54    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1751     |
|    time_elapsed         | 5806     |
|    total_timesteps      | 224128   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0506  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 105      |
|    n_updates            | 17500    |
|    policy_gradient_loss | 1.3e-09  |
|    value_loss           | 143      |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 78.3          |
|    ep_rew_mean          | -4.54         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1752          |
|    time_elapsed         | 5809          |
|    total_timesteps      | 224256        |
| train/                  |               |
|    approx_kl            | 3.4062192e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0495       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 62.5          |
|    n_updates            | 17510         |
|    policy_gradient_loss | -9.82e-05     |
|    value_loss           | 103           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 78.6          |
|    ep_rew_mean          | -4.7          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1753          |
|    time_elapsed         | 5812          |
|    total_timesteps      | 224384        |
| train/                  |               |
|    approx_kl            | 5.1162206e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0451       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 39.6          |
|    n_updates            | 17520         |
|    policy_gradient_loss | -8.19e-05     |
|    value_loss           | 72.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 78.7          |
|    ep_rew_mean          | -4.57         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1754          |
|    time_elapsed         | 5815          |
|    total_timesteps      | 224512        |
| train/                  |               |
|    approx_kl            | 1.7411541e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0426       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 71            |
|    n_updates            | 17530         |
|    policy_gradient_loss | -5.77e-05     |
|    value_loss           | 139           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -4.76     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1755      |
|    time_elapsed         | 5819      |
|    total_timesteps      | 224640    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0405   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 85.5      |
|    n_updates            | 17540     |
|    policy_gradient_loss | -7.92e-10 |
|    value_loss           | 184       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79       |
|    ep_rew_mean          | -4.92    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1756     |
|    time_elapsed         | 5822     |
|    total_timesteps      | 224768   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0401  |
|    explained_variance   | 2.38e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 39.6     |
|    n_updates            | 17550    |
|    policy_gradient_loss | 8.1e-09  |
|    value_loss           | 72.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79        |
|    ep_rew_mean          | -4.97     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1757      |
|    time_elapsed         | 5825      |
|    total_timesteps      | 224896    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0404   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 52.5      |
|    n_updates            | 17560     |
|    policy_gradient_loss | -1.12e-09 |
|    value_loss           | 95.3      |
---------------------------------------
Num timesteps: 225000
Best mean reward: -0.99 - Last mean reward per episode: -4.00
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=225000, episode_reward=5.30 +/- 7.39
Episode length: 69.40 +/- 15.04
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 69.4         |
|    mean_reward          | 5.3          |
| time/                   |              |
|    total_timesteps      | 225000       |
| train/                  |              |
|    approx_kl            | 0.0035298755 |
|    clip_fraction        | 0.0125       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0283      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 60.8         |
|    n_updates            | 17570        |
|    policy_gradient_loss | -0.00195     |
|    value_loss           | 136          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 78.8     |
|    ep_rew_mean     | -4.91    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1758     |
|    time_elapsed    | 5830     |
|    total_timesteps | 225024   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 78.1          |
|    ep_rew_mean          | -4.66         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1759          |
|    time_elapsed         | 5834          |
|    total_timesteps      | 225152        |
| train/                  |               |
|    approx_kl            | 5.4277014e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0204       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 39.3          |
|    n_updates            | 17580         |
|    policy_gradient_loss | -0.00012      |
|    value_loss           | 72.5          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 77.6        |
|    ep_rew_mean          | -4.41       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 1760        |
|    time_elapsed         | 5837        |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 3.18191e-05 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.019      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 66.4        |
|    n_updates            | 17590       |
|    policy_gradient_loss | -0.000181   |
|    value_loss           | 132         |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.2     |
|    ep_rew_mean          | -4.11    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1761     |
|    time_elapsed         | 5841     |
|    total_timesteps      | 225408   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0177  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.9     |
|    n_updates            | 17600    |
|    policy_gradient_loss | 1.86e-10 |
|    value_loss           | 71.7     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.2     |
|    ep_rew_mean          | -4.31    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1762     |
|    time_elapsed         | 5844     |
|    total_timesteps      | 225536   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0175  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 64.9     |
|    n_updates            | 17610    |
|    policy_gradient_loss | 1.16e-09 |
|    value_loss           | 137      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -4.31     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1763      |
|    time_elapsed         | 5847      |
|    total_timesteps      | 225664    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0176   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.8      |
|    n_updates            | 17620     |
|    policy_gradient_loss | -5.68e-09 |
|    value_loss           | 85.1      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.2     |
|    ep_rew_mean          | -4.31    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1764     |
|    time_elapsed         | 5850     |
|    total_timesteps      | 225792   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0176  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 28.1     |
|    n_updates            | 17630    |
|    policy_gradient_loss | 7.92e-09 |
|    value_loss           | 56.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -4.31     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1765      |
|    time_elapsed         | 5854      |
|    total_timesteps      | 225920    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0176   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 26.8      |
|    n_updates            | 17640     |
|    policy_gradient_loss | -3.21e-08 |
|    value_loss           | 55.5      |
---------------------------------------
Num timesteps: 226000
Best mean reward: -0.99 - Last mean reward per episode: -3.87
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.2     |
|    ep_rew_mean          | -4.31    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1766     |
|    time_elapsed         | 5857     |
|    total_timesteps      | 226048   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0177  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 25.5     |
|    n_updates            | 17650    |
|    policy_gradient_loss | 7.77e-08 |
|    value_loss           | 54.7     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.2          |
|    ep_rew_mean          | -4.31         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1767          |
|    time_elapsed         | 5860          |
|    total_timesteps      | 226176        |
| train/                  |               |
|    approx_kl            | 1.8347055e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0177       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 24.9          |
|    n_updates            | 17660         |
|    policy_gradient_loss | -7.2e-06      |
|    value_loss           | 53.9          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.2     |
|    ep_rew_mean          | -4.31    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1768     |
|    time_elapsed         | 5863     |
|    total_timesteps      | 226304   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0178  |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 26.5     |
|    n_updates            | 17670    |
|    policy_gradient_loss | 5.45e-08 |
|    value_loss           | 53.2     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 86.6          |
|    ep_rew_mean          | -9.32         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1769          |
|    time_elapsed         | 5867          |
|    total_timesteps      | 226432        |
| train/                  |               |
|    approx_kl            | 3.1664968e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0178       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 25.8          |
|    n_updates            | 17680         |
|    policy_gradient_loss | -1.09e-05     |
|    value_loss           | 52.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 86.6          |
|    ep_rew_mean          | -9.09         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1770          |
|    time_elapsed         | 5869          |
|    total_timesteps      | 226560        |
| train/                  |               |
|    approx_kl            | 1.7215498e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0176       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 23.7          |
|    n_updates            | 17690         |
|    policy_gradient_loss | -4.34e-05     |
|    value_loss           | 49.1          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.8     |
|    ep_rew_mean          | -9.2     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1771     |
|    time_elapsed         | 5873     |
|    total_timesteps      | 226688   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0173  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 80.6     |
|    n_updates            | 17700    |
|    policy_gradient_loss | -2.1e-09 |
|    value_loss           | 187      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.1     |
|    ep_rew_mean          | -9.36    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1772     |
|    time_elapsed         | 5876     |
|    total_timesteps      | 226816   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0172  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 22.8     |
|    n_updates            | 17710    |
|    policy_gradient_loss | 5.12e-10 |
|    value_loss           | 76       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87        |
|    ep_rew_mean          | -9.29     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1773      |
|    time_elapsed         | 5879      |
|    total_timesteps      | 226944    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0173   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 46.7      |
|    n_updates            | 17720     |
|    policy_gradient_loss | 3.57e-09  |
|    value_loss           | 110       |
---------------------------------------
Num timesteps: 227000
Best mean reward: -0.99 - Last mean reward per episode: -9.21
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.1     |
|    ep_rew_mean          | -9.33    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1774     |
|    time_elapsed         | 5882     |
|    total_timesteps      | 227072   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0173  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 54.1     |
|    n_updates            | 17730    |
|    policy_gradient_loss | 3.52e-09 |
|    value_loss           | 106      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.8     |
|    ep_rew_mean          | -9.19    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1775     |
|    time_elapsed         | 5885     |
|    total_timesteps      | 227200   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0174  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 54.7     |
|    n_updates            | 17740    |
|    policy_gradient_loss | -2.7e-09 |
|    value_loss           | 104      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.6     |
|    ep_rew_mean          | -9.22    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1776     |
|    time_elapsed         | 5888     |
|    total_timesteps      | 227328   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0174  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 43.4     |
|    n_updates            | 17750    |
|    policy_gradient_loss | 5.73e-09 |
|    value_loss           | 102      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.4     |
|    ep_rew_mean          | -9.79    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1777     |
|    time_elapsed         | 5891     |
|    total_timesteps      | 227456   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0175  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 44.6     |
|    n_updates            | 17760    |
|    policy_gradient_loss | 1.44e-09 |
|    value_loss           | 81.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.5      |
|    ep_rew_mean          | -9.83     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1778      |
|    time_elapsed         | 5893      |
|    total_timesteps      | 227584    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0176   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 60        |
|    n_updates            | 17770     |
|    policy_gradient_loss | 4.07e-09  |
|    value_loss           | 104       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.8      |
|    ep_rew_mean          | -9.8      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1779      |
|    time_elapsed         | 5896      |
|    total_timesteps      | 227712    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0177   |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 83.6      |
|    n_updates            | 17780     |
|    policy_gradient_loss | -3.91e-09 |
|    value_loss           | 138       |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 87.2        |
|    ep_rew_mean          | -9.43       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 1780        |
|    time_elapsed         | 5899        |
|    total_timesteps      | 227840      |
| train/                  |             |
|    approx_kl            | 0.005656275 |
|    clip_fraction        | 0.00469     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0278     |
|    explained_variance   | -2.38e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 72.6        |
|    n_updates            | 17790       |
|    policy_gradient_loss | -0.0034     |
|    value_loss           | 161         |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 85.9          |
|    ep_rew_mean          | -8.45         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1781          |
|    time_elapsed         | 5902          |
|    total_timesteps      | 227968        |
| train/                  |               |
|    approx_kl            | 1.6391277e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.048        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 70.8          |
|    n_updates            | 17800         |
|    policy_gradient_loss | 2.7e-09       |
|    value_loss           | 117           |
-------------------------------------------
Num timesteps: 228000
Best mean reward: -0.99 - Last mean reward per episode: -8.29
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 85.8           |
|    ep_rew_mean          | -8.41          |
| time/                   |                |
|    fps                  | 38             |
|    iterations           | 1782           |
|    time_elapsed         | 5907           |
|    total_timesteps      | 228096         |
| train/                  |                |
|    approx_kl            | 1.23037025e-05 |
|    clip_fraction        | 0              |
|    clip_range           | 0.2            |
|    entropy_loss         | -0.0513        |
|    explained_variance   | 0              |
|    learning_rate        | 0.0003         |
|    loss                 | 144            |
|    n_updates            | 17810          |
|    policy_gradient_loss | -9.14e-05      |
|    value_loss           | 218            |
--------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86       |
|    ep_rew_mean          | -8.51    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1783     |
|    time_elapsed         | 5910     |
|    total_timesteps      | 228224   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0491  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 31.7     |
|    n_updates            | 17820    |
|    policy_gradient_loss | 3.21e-09 |
|    value_loss           | 74.2     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 86.7          |
|    ep_rew_mean          | -8.86         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1784          |
|    time_elapsed         | 5913          |
|    total_timesteps      | 228352        |
| train/                  |               |
|    approx_kl            | 2.8276816e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0501       |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 81.5          |
|    n_updates            | 17830         |
|    policy_gradient_loss | -0.000441     |
|    value_loss           | 123           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 86.5         |
|    ep_rew_mean          | -8.85        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1785         |
|    time_elapsed         | 5916         |
|    total_timesteps      | 228480       |
| train/                  |              |
|    approx_kl            | 0.0005168114 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0623      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 47.2         |
|    n_updates            | 17840        |
|    policy_gradient_loss | -0.00293     |
|    value_loss           | 103          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 87.1          |
|    ep_rew_mean          | -9.24         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1786          |
|    time_elapsed         | 5919          |
|    total_timesteps      | 228608        |
| train/                  |               |
|    approx_kl            | 0.00091454573 |
|    clip_fraction        | 0.00469       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0763       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 57.2          |
|    n_updates            | 17850         |
|    policy_gradient_loss | -0.000736     |
|    value_loss           | 129           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 87.1          |
|    ep_rew_mean          | -9.34         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1787          |
|    time_elapsed         | 5923          |
|    total_timesteps      | 228736        |
| train/                  |               |
|    approx_kl            | 0.00011437526 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0965       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 31.1          |
|    n_updates            | 17860         |
|    policy_gradient_loss | 0.000606      |
|    value_loss           | 73.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 86.7          |
|    ep_rew_mean          | -9.16         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1788          |
|    time_elapsed         | 5925          |
|    total_timesteps      | 228864        |
| train/                  |               |
|    approx_kl            | 4.8328657e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.102        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 63            |
|    n_updates            | 17870         |
|    policy_gradient_loss | -6.9e-05      |
|    value_loss           | 104           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 87.2         |
|    ep_rew_mean          | -9.52        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1789         |
|    time_elapsed         | 5928         |
|    total_timesteps      | 228992       |
| train/                  |              |
|    approx_kl            | 9.536743e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.108       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 52.9         |
|    n_updates            | 17880        |
|    policy_gradient_loss | 7.45e-10     |
|    value_loss           | 103          |
------------------------------------------
Num timesteps: 229000
Best mean reward: -0.99 - Last mean reward per episode: -9.20
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 87.1         |
|    ep_rew_mean          | -9.46        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1790         |
|    time_elapsed         | 5931         |
|    total_timesteps      | 229120       |
| train/                  |              |
|    approx_kl            | 9.213667e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.11        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 35.5         |
|    n_updates            | 17890        |
|    policy_gradient_loss | -0.000195    |
|    value_loss           | 72.8         |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 86.5         |
|    ep_rew_mean          | -9.26        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1791         |
|    time_elapsed         | 5934         |
|    total_timesteps      | 229248       |
| train/                  |              |
|    approx_kl            | 0.0012198295 |
|    clip_fraction        | 0.00937      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0867      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 48.6         |
|    n_updates            | 17900        |
|    policy_gradient_loss | -0.00201     |
|    value_loss           | 105          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 85.7         |
|    ep_rew_mean          | -9.16        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1792         |
|    time_elapsed         | 5937         |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 4.182104e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0714      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 57.4         |
|    n_updates            | 17910        |
|    policy_gradient_loss | -0.000323    |
|    value_loss           | 141          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 85.4          |
|    ep_rew_mean          | -9.18         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1793          |
|    time_elapsed         | 5940          |
|    total_timesteps      | 229504        |
| train/                  |               |
|    approx_kl            | 2.8054696e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.069        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 48.1          |
|    n_updates            | 17920         |
|    policy_gradient_loss | -9.88e-05     |
|    value_loss           | 97.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 85.1         |
|    ep_rew_mean          | -9.14        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1794         |
|    time_elapsed         | 5943         |
|    total_timesteps      | 229632       |
| train/                  |              |
|    approx_kl            | 9.490177e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0727      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 49.3         |
|    n_updates            | 17930        |
|    policy_gradient_loss | 4.89e-05     |
|    value_loss           | 95.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 85.1         |
|    ep_rew_mean          | -9.05        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1795         |
|    time_elapsed         | 5946         |
|    total_timesteps      | 229760       |
| train/                  |              |
|    approx_kl            | 5.327724e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0721      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 90.2         |
|    n_updates            | 17940        |
|    policy_gradient_loss | -0.000192    |
|    value_loss           | 132          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 85.1         |
|    ep_rew_mean          | -9.25        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1796         |
|    time_elapsed         | 5948         |
|    total_timesteps      | 229888       |
| train/                  |              |
|    approx_kl            | 4.862435e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0737      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 78.9         |
|    n_updates            | 17950        |
|    policy_gradient_loss | 9.52e-05     |
|    value_loss           | 133          |
------------------------------------------
Num timesteps: 230000
Best mean reward: -0.99 - Last mean reward per episode: -8.46
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=230000, episode_reward=-6.90 +/- 9.54
Episode length: 77.80 +/- 26.79
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 77.8          |
|    mean_reward          | -6.9          |
| time/                   |               |
|    total_timesteps      | 230000        |
| train/                  |               |
|    approx_kl            | 5.0682575e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0677       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 41.2          |
|    n_updates            | 17960         |
|    policy_gradient_loss | -0.0001       |
|    value_loss           | 94.6          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 84.6     |
|    ep_rew_mean     | -9.01    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1797     |
|    time_elapsed    | 5954     |
|    total_timesteps | 230016   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 84.1          |
|    ep_rew_mean          | -8.83         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1798          |
|    time_elapsed         | 5958          |
|    total_timesteps      | 230144        |
| train/                  |               |
|    approx_kl            | 1.1920929e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0635       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 64.5          |
|    n_updates            | 17970         |
|    policy_gradient_loss | 1.05e-08      |
|    value_loss           | 168           |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.9     |
|    ep_rew_mean          | -8.54    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1799     |
|    time_elapsed         | 5961     |
|    total_timesteps      | 230272   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0629  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 52.8     |
|    n_updates            | 17980    |
|    policy_gradient_loss | 4.47e-09 |
|    value_loss           | 85.3     |
--------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 83.9           |
|    ep_rew_mean          | -8.87          |
| time/                   |                |
|    fps                  | 38             |
|    iterations           | 1800           |
|    time_elapsed         | 5965           |
|    total_timesteps      | 230400         |
| train/                  |                |
|    approx_kl            | 1.25113875e-05 |
|    clip_fraction        | 0              |
|    clip_range           | 0.2            |
|    entropy_loss         | -0.0623        |
|    explained_variance   | 0              |
|    learning_rate        | 0.0003         |
|    loss                 | 74.8           |
|    n_updates            | 17990          |
|    policy_gradient_loss | -3.5e-05       |
|    value_loss           | 148            |
--------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 84.5        |
|    ep_rew_mean          | -9.13       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 1801        |
|    time_elapsed         | 5968        |
|    total_timesteps      | 230528      |
| train/                  |             |
|    approx_kl            | 0.001363907 |
|    clip_fraction        | 0.00469     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0577     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 39.5        |
|    n_updates            | 18000       |
|    policy_gradient_loss | -0.000599   |
|    value_loss           | 85.4        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 85.2         |
|    ep_rew_mean          | -9.62        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1802         |
|    time_elapsed         | 5971         |
|    total_timesteps      | 230656       |
| train/                  |              |
|    approx_kl            | 3.001187e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0551      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 38.6         |
|    n_updates            | 18010        |
|    policy_gradient_loss | -5.14e-05    |
|    value_loss           | 69.2         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 83.6          |
|    ep_rew_mean          | -8.6          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1803          |
|    time_elapsed         | 5974          |
|    total_timesteps      | 230784        |
| train/                  |               |
|    approx_kl            | 3.6987476e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0536       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 30            |
|    n_updates            | 18020         |
|    policy_gradient_loss | -6.05e-05     |
|    value_loss           | 71.3          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.2     |
|    ep_rew_mean          | -8.4     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1804     |
|    time_elapsed         | 5977     |
|    total_timesteps      | 230912   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0525  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 109      |
|    n_updates            | 18030    |
|    policy_gradient_loss | 2.79e-10 |
|    value_loss           | 171      |
--------------------------------------
Num timesteps: 231000
Best mean reward: -0.99 - Last mean reward per episode: -8.47
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.8     |
|    ep_rew_mean          | -8.71    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1805     |
|    time_elapsed         | 5981     |
|    total_timesteps      | 231040   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0524  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.8     |
|    n_updates            | 18040    |
|    policy_gradient_loss | 8.57e-09 |
|    value_loss           | 80       |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 85          |
|    ep_rew_mean          | -9.28       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 1806        |
|    time_elapsed         | 5985        |
|    total_timesteps      | 231168      |
| train/                  |             |
|    approx_kl            | 4.31668e-07 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0523     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 32          |
|    n_updates            | 18050       |
|    policy_gradient_loss | -6.17e-06   |
|    value_loss           | 70.7        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85        |
|    ep_rew_mean          | -9.42     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1807      |
|    time_elapsed         | 5988      |
|    total_timesteps      | 231296    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0518   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 30.6      |
|    n_updates            | 18060     |
|    policy_gradient_loss | -3.63e-09 |
|    value_loss           | 70.9      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 84.8         |
|    ep_rew_mean          | -9.3         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1808         |
|    time_elapsed         | 5992         |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 9.536743e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0508      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 62.7         |
|    n_updates            | 18070        |
|    policy_gradient_loss | -9.74e-05    |
|    value_loss           | 112          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 84.7         |
|    ep_rew_mean          | -9.27        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1809         |
|    time_elapsed         | 5995         |
|    total_timesteps      | 231552       |
| train/                  |              |
|    approx_kl            | 6.681681e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0476      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 109          |
|    n_updates            | 18080        |
|    policy_gradient_loss | -0.000706    |
|    value_loss           | 159          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 84.7          |
|    ep_rew_mean          | -9.37         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1810          |
|    time_elapsed         | 5998          |
|    total_timesteps      | 231680        |
| train/                  |               |
|    approx_kl            | 1.9788276e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.044        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 34.8          |
|    n_updates            | 18090         |
|    policy_gradient_loss | -0.000207     |
|    value_loss           | 71.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 84.3          |
|    ep_rew_mean          | -8.94         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1811          |
|    time_elapsed         | 6001          |
|    total_timesteps      | 231808        |
| train/                  |               |
|    approx_kl            | 4.4303015e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0429       |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 39.7          |
|    n_updates            | 18100         |
|    policy_gradient_loss | -1.27e-05     |
|    value_loss           | 97.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 84.1          |
|    ep_rew_mean          | -8.86         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1812          |
|    time_elapsed         | 6004          |
|    total_timesteps      | 231936        |
| train/                  |               |
|    approx_kl            | 5.9604645e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0449       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 84.7          |
|    n_updates            | 18110         |
|    policy_gradient_loss | -1.86e-10     |
|    value_loss           | 186           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 232000
Best mean reward: -0.99 - Last mean reward per episode: -8.54
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 84.2          |
|    ep_rew_mean          | -8.98         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1813          |
|    time_elapsed         | 6007          |
|    total_timesteps      | 232064        |
| train/                  |               |
|    approx_kl            | 1.2183562e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0447       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 50.2          |
|    n_updates            | 18120         |
|    policy_gradient_loss | -0.000113     |
|    value_loss           | 86.1          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.1      |
|    ep_rew_mean          | -8.97     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1814      |
|    time_elapsed         | 6010      |
|    total_timesteps      | 232192    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0428   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 51.1      |
|    n_updates            | 18130     |
|    policy_gradient_loss | -4.66e-09 |
|    value_loss           | 93.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.4      |
|    ep_rew_mean          | -9.79     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1815      |
|    time_elapsed         | 6013      |
|    total_timesteps      | 232320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0431   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 26.8      |
|    n_updates            | 18140     |
|    policy_gradient_loss | 2.37e-09  |
|    value_loss           | 71.4      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 85.2          |
|    ep_rew_mean          | -9.72         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1816          |
|    time_elapsed         | 6017          |
|    total_timesteps      | 232448        |
| train/                  |               |
|    approx_kl            | 4.3488108e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0427       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 51.9          |
|    n_updates            | 18150         |
|    policy_gradient_loss | -6.76e-05     |
|    value_loss           | 76            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 85.2         |
|    ep_rew_mean          | -9.47        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1817         |
|    time_elapsed         | 6021         |
|    total_timesteps      | 232576       |
| train/                  |              |
|    approx_kl            | 7.448718e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0411      |
|    explained_variance   | 2.38e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 41.3         |
|    n_updates            | 18160        |
|    policy_gradient_loss | -6.66e-05    |
|    value_loss           | 73.8         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 85.2          |
|    ep_rew_mean          | -9.5          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1818          |
|    time_elapsed         | 6025          |
|    total_timesteps      | 232704        |
| train/                  |               |
|    approx_kl            | 1.4267862e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.04         |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 75            |
|    n_updates            | 18170         |
|    policy_gradient_loss | -7.66e-06     |
|    value_loss           | 142           |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85       |
|    ep_rew_mean          | -9.43    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1819     |
|    time_elapsed         | 6028     |
|    total_timesteps      | 232832   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0397  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 85.7     |
|    n_updates            | 18180    |
|    policy_gradient_loss | 5.17e-09 |
|    value_loss           | 168      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.1     |
|    ep_rew_mean          | -9.56    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1820     |
|    time_elapsed         | 6031     |
|    total_timesteps      | 232960   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0397  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 50.5     |
|    n_updates            | 18190    |
|    policy_gradient_loss | 4.8e-09  |
|    value_loss           | 74.3     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 233000
Best mean reward: -0.99 - Last mean reward per episode: -9.56
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.3      |
|    ep_rew_mean          | -9.85     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1821      |
|    time_elapsed         | 6034      |
|    total_timesteps      | 233088    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0399   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.7      |
|    n_updates            | 18200     |
|    policy_gradient_loss | -2.37e-09 |
|    value_loss           | 103       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 84.9         |
|    ep_rew_mean          | -9.55        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1822         |
|    time_elapsed         | 6037         |
|    total_timesteps      | 233216       |
| train/                  |              |
|    approx_kl            | 0.0003951816 |
|    clip_fraction        | 0.00391      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0345      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 63.1         |
|    n_updates            | 18210        |
|    policy_gradient_loss | -0.000502    |
|    value_loss           | 116          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 85           |
|    ep_rew_mean          | -9.39        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1823         |
|    time_elapsed         | 6040         |
|    total_timesteps      | 233344       |
| train/                  |              |
|    approx_kl            | 7.607695e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0286      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 59.5         |
|    n_updates            | 18220        |
|    policy_gradient_loss | -0.000244    |
|    value_loss           | 110          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 84.9          |
|    ep_rew_mean          | -9.44         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1824          |
|    time_elapsed         | 6044          |
|    total_timesteps      | 233472        |
| train/                  |               |
|    approx_kl            | 4.3668784e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0251       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 104           |
|    n_updates            | 18230         |
|    policy_gradient_loss | -0.000191     |
|    value_loss           | 187           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.8      |
|    ep_rew_mean          | -9.91     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1825      |
|    time_elapsed         | 6047      |
|    total_timesteps      | 233600    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.024    |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 59.2      |
|    n_updates            | 18240     |
|    policy_gradient_loss | -1.21e-09 |
|    value_loss           | 104       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 86           |
|    ep_rew_mean          | -10          |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1826         |
|    time_elapsed         | 6051         |
|    total_timesteps      | 233728       |
| train/                  |              |
|    approx_kl            | 5.523674e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0238      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 39.2         |
|    n_updates            | 18250        |
|    policy_gradient_loss | -4e-05       |
|    value_loss           | 78.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 85.5         |
|    ep_rew_mean          | -9.62        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1827         |
|    time_elapsed         | 6054         |
|    total_timesteps      | 233856       |
| train/                  |              |
|    approx_kl            | 9.865966e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0229      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 84.4         |
|    n_updates            | 18260        |
|    policy_gradient_loss | -9.37e-05    |
|    value_loss           | 136          |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.4     |
|    ep_rew_mean          | -9.48    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1828     |
|    time_elapsed         | 6057     |
|    total_timesteps      | 233984   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0218  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 71.7     |
|    n_updates            | 18270    |
|    policy_gradient_loss | 9.31e-11 |
|    value_loss           | 131      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 234000
Best mean reward: -0.99 - Last mean reward per episode: -4.72
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.8     |
|    ep_rew_mean          | -4.88    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1829     |
|    time_elapsed         | 6060     |
|    total_timesteps      | 234112   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0216  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 95.3     |
|    n_updates            | 18280    |
|    policy_gradient_loss | -7.5e-09 |
|    value_loss           | 181      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.8      |
|    ep_rew_mean          | -5.01     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1830      |
|    time_elapsed         | 6064      |
|    total_timesteps      | 234240    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0216   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.1      |
|    n_updates            | 18290     |
|    policy_gradient_loss | -1.63e-09 |
|    value_loss           | 83.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -5.31     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1831      |
|    time_elapsed         | 6067      |
|    total_timesteps      | 234368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0216   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 34.3      |
|    n_updates            | 18300     |
|    policy_gradient_loss | -3.73e-10 |
|    value_loss           | 70.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.6      |
|    ep_rew_mean          | -5.39     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1832      |
|    time_elapsed         | 6070      |
|    total_timesteps      | 234496    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0217   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 40.5      |
|    n_updates            | 18310     |
|    policy_gradient_loss | -7.36e-09 |
|    value_loss           | 78.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.5     |
|    ep_rew_mean          | -4.96    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1833     |
|    time_elapsed         | 6073     |
|    total_timesteps      | 234624   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0218  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 68.6     |
|    n_updates            | 18320    |
|    policy_gradient_loss | 8.54e-09 |
|    value_loss           | 137      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.7      |
|    ep_rew_mean          | -5.04     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1834      |
|    time_elapsed         | 6077      |
|    total_timesteps      | 234752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0218   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 102       |
|    n_updates            | 18330     |
|    policy_gradient_loss | -6.71e-09 |
|    value_loss           | 268       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.6     |
|    ep_rew_mean          | -4.8     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1835     |
|    time_elapsed         | 6081     |
|    total_timesteps      | 234880   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0219  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 31.7     |
|    n_updates            | 18340    |
|    policy_gradient_loss | 9.78e-09 |
|    value_loss           | 71.8     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 235000
Best mean reward: -0.99 - Last mean reward per episode: -5.04
Eval num_timesteps=235000, episode_reward=-4.00 +/- 16.05
Episode length: 84.00 +/- 39.68
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 84        |
|    mean_reward          | -4        |
| time/                   |           |
|    total_timesteps      | 235000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0219   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 27        |
|    n_updates            | 18350     |
|    policy_gradient_loss | -1.12e-09 |
|    value_loss           | 89.6      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 78.2     |
|    ep_rew_mean     | -4.99    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1836     |
|    time_elapsed    | 6087     |
|    total_timesteps | 235008   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.2      |
|    ep_rew_mean          | -4.89     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1837      |
|    time_elapsed         | 6090      |
|    total_timesteps      | 235136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.022    |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 69.9      |
|    n_updates            | 18360     |
|    policy_gradient_loss | -2.07e-09 |
|    value_loss           | 134       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.9          |
|    ep_rew_mean          | -4.54         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1838          |
|    time_elapsed         | 6094          |
|    total_timesteps      | 235264        |
| train/                  |               |
|    approx_kl            | 0.00018145051 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0207       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 40.7          |
|    n_updates            | 18370         |
|    policy_gradient_loss | -8.92e-05     |
|    value_loss           | 111           |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.9     |
|    ep_rew_mean          | -4.64    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1839     |
|    time_elapsed         | 6096     |
|    total_timesteps      | 235392   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0172  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 105      |
|    n_updates            | 18380    |
|    policy_gradient_loss | 1.16e-09 |
|    value_loss           | 174      |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.5         |
|    ep_rew_mean          | -4.67        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1840         |
|    time_elapsed         | 6099         |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 0.0002838662 |
|    clip_fraction        | 0.000781     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0154      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 44           |
|    n_updates            | 18390        |
|    policy_gradient_loss | -0.000576    |
|    value_loss           | 102          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.2      |
|    ep_rew_mean          | -5.01     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1841      |
|    time_elapsed         | 6102      |
|    total_timesteps      | 235648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0121   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.8      |
|    n_updates            | 18400     |
|    policy_gradient_loss | -3.07e-09 |
|    value_loss           | 84.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.6      |
|    ep_rew_mean          | -5.21     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1842      |
|    time_elapsed         | 6105      |
|    total_timesteps      | 235776    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0116   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 93.5      |
|    n_updates            | 18410     |
|    policy_gradient_loss | -2.24e-09 |
|    value_loss           | 182       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.5      |
|    ep_rew_mean          | -5.24     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1843      |
|    time_elapsed         | 6108      |
|    total_timesteps      | 235904    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0116   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 65.1      |
|    n_updates            | 18420     |
|    policy_gradient_loss | -2.72e-09 |
|    value_loss           | 130       |
---------------------------------------
Num timesteps: 236000
Best mean reward: -0.99 - Last mean reward per episode: -4.59
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.5      |
|    ep_rew_mean          | -4.84     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1844      |
|    time_elapsed         | 6110      |
|    total_timesteps      | 236032    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0116   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.2      |
|    n_updates            | 18430     |
|    policy_gradient_loss | -3.73e-10 |
|    value_loss           | 129       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.8     |
|    ep_rew_mean          | -5.11    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1845     |
|    time_elapsed         | 6113     |
|    total_timesteps      | 236160   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0116  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 49.1     |
|    n_updates            | 18440    |
|    policy_gradient_loss | -2e-09   |
|    value_loss           | 95.2     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.4     |
|    ep_rew_mean          | -4.91    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1846     |
|    time_elapsed         | 6116     |
|    total_timesteps      | 236288   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0117  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 50.5     |
|    n_updates            | 18450    |
|    policy_gradient_loss | 7.45e-10 |
|    value_loss           | 104      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.6     |
|    ep_rew_mean          | -4.98    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1847     |
|    time_elapsed         | 6119     |
|    total_timesteps      | 236416   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0118  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 25.6     |
|    n_updates            | 18460    |
|    policy_gradient_loss | 3.63e-09 |
|    value_loss           | 73.5     |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.7         |
|    ep_rew_mean          | -5.03        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1848         |
|    time_elapsed         | 6122         |
|    total_timesteps      | 236544       |
| train/                  |              |
|    approx_kl            | 0.0014005592 |
|    clip_fraction        | 0.00859      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00979     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 51.4         |
|    n_updates            | 18470        |
|    policy_gradient_loss | -0.00125     |
|    value_loss           | 100          |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.1     |
|    ep_rew_mean          | -4.73    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1849     |
|    time_elapsed         | 6125     |
|    total_timesteps      | 236672   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00756 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 47.2     |
|    n_updates            | 18480    |
|    policy_gradient_loss | -1.4e-10 |
|    value_loss           | 91.7     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.1          |
|    ep_rew_mean          | -4.66         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1850          |
|    time_elapsed         | 6128          |
|    total_timesteps      | 236800        |
| train/                  |               |
|    approx_kl            | 0.00058905734 |
|    clip_fraction        | 0.00391       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00862      |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 46.5          |
|    n_updates            | 18490         |
|    policy_gradient_loss | -0.000827     |
|    value_loss           | 88.2          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.1     |
|    ep_rew_mean          | -4.67    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1851     |
|    time_elapsed         | 6132     |
|    total_timesteps      | 236928   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0106  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 52.1     |
|    n_updates            | 18500    |
|    policy_gradient_loss | 2.33e-09 |
|    value_loss           | 105      |
--------------------------------------
Num timesteps: 237000
Best mean reward: -0.99 - Last mean reward per episode: -5.50
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.6      |
|    ep_rew_mean          | -4.88     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1852      |
|    time_elapsed         | 6135      |
|    total_timesteps      | 237056    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.011    |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.6      |
|    n_updates            | 18510     |
|    policy_gradient_loss | -2.75e-09 |
|    value_loss           | 90.3      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.4      |
|    ep_rew_mean          | -4.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1853      |
|    time_elapsed         | 6139      |
|    total_timesteps      | 237184    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0111   |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 71.8      |
|    n_updates            | 18520     |
|    policy_gradient_loss | -1.02e-09 |
|    value_loss           | 130       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.5      |
|    ep_rew_mean          | -4.85     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1854      |
|    time_elapsed         | 6142      |
|    total_timesteps      | 237312    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0112   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53.9      |
|    n_updates            | 18530     |
|    policy_gradient_loss | -5.59e-10 |
|    value_loss           | 87.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.6      |
|    ep_rew_mean          | -4.91     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1855      |
|    time_elapsed         | 6146      |
|    total_timesteps      | 237440    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0113   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55.6      |
|    n_updates            | 18540     |
|    policy_gradient_loss | -1.63e-09 |
|    value_loss           | 86.7      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.8     |
|    ep_rew_mean          | -4.98    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1856     |
|    time_elapsed         | 6149     |
|    total_timesteps      | 237568   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0113  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 71.8     |
|    n_updates            | 18550    |
|    policy_gradient_loss | 1.29e-08 |
|    value_loss           | 165      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.8     |
|    ep_rew_mean          | -4.98    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1857     |
|    time_elapsed         | 6152     |
|    total_timesteps      | 237696   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0114  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 41.9     |
|    n_updates            | 18560    |
|    policy_gradient_loss | 1.91e-09 |
|    value_loss           | 88.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.8      |
|    ep_rew_mean          | -4.98     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1858      |
|    time_elapsed         | 6157      |
|    total_timesteps      | 237824    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0115   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.5      |
|    n_updates            | 18570     |
|    policy_gradient_loss | -1.37e-08 |
|    value_loss           | 62.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.8      |
|    ep_rew_mean          | -4.98     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1859      |
|    time_elapsed         | 6162      |
|    total_timesteps      | 237952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0115   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 31.7      |
|    n_updates            | 18580     |
|    policy_gradient_loss | -2.08e-08 |
|    value_loss           | 60.6      |
---------------------------------------
Num timesteps: 238000
Best mean reward: -0.99 - Last mean reward per episode: -5.24
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.8     |
|    ep_rew_mean          | -4.98    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1860     |
|    time_elapsed         | 6166     |
|    total_timesteps      | 238080   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0115  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 30       |
|    n_updates            | 18590    |
|    policy_gradient_loss | 7.72e-08 |
|    value_loss           | 59.6     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.8      |
|    ep_rew_mean          | -4.98     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1861      |
|    time_elapsed         | 6171      |
|    total_timesteps      | 238208    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0115   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.5      |
|    n_updates            | 18600     |
|    policy_gradient_loss | -3.29e-08 |
|    value_loss           | 58.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.8     |
|    ep_rew_mean          | -4.98    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1862     |
|    time_elapsed         | 6176     |
|    total_timesteps      | 238336   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0115  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 28       |
|    n_updates            | 18610    |
|    policy_gradient_loss | 4.98e-09 |
|    value_loss           | 57.6     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.8          |
|    ep_rew_mean          | -4.98         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1863          |
|    time_elapsed         | 6180          |
|    total_timesteps      | 238464        |
| train/                  |               |
|    approx_kl            | 8.4517524e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0115       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 26.9          |
|    n_updates            | 18620         |
|    policy_gradient_loss | -2.41e-05     |
|    value_loss           | 56.7          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.2      |
|    ep_rew_mean          | -9.99     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1864      |
|    time_elapsed         | 6185      |
|    total_timesteps      | 238592    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0113   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 25.1      |
|    n_updates            | 18630     |
|    policy_gradient_loss | -3.68e-09 |
|    value_loss           | 55.8      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87       |
|    ep_rew_mean          | -9.88    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1865     |
|    time_elapsed         | 6189     |
|    total_timesteps      | 238720   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0113  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 22.2     |
|    n_updates            | 18640    |
|    policy_gradient_loss | 5.17e-09 |
|    value_loss           | 45.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.9      |
|    ep_rew_mean          | -9.87     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1866      |
|    time_elapsed         | 6192      |
|    total_timesteps      | 238848    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0113   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 91.3      |
|    n_updates            | 18650     |
|    policy_gradient_loss | -4.56e-09 |
|    value_loss           | 176       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.2      |
|    ep_rew_mean          | -9.71     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1867      |
|    time_elapsed         | 6195      |
|    total_timesteps      | 238976    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0113   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 44        |
|    n_updates            | 18660     |
|    policy_gradient_loss | -1.16e-09 |
|    value_loss           | 98        |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 239000
Best mean reward: -0.99 - Last mean reward per episode: -9.40
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.6      |
|    ep_rew_mean          | -9.31     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1868      |
|    time_elapsed         | 6198      |
|    total_timesteps      | 239104    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0114   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 36.2      |
|    n_updates            | 18670     |
|    policy_gradient_loss | -4.47e-09 |
|    value_loss           | 101       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.3     |
|    ep_rew_mean          | -9.33    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1869     |
|    time_elapsed         | 6201     |
|    total_timesteps      | 239232   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0115  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 81.4     |
|    n_updates            | 18680    |
|    policy_gradient_loss | 6.85e-09 |
|    value_loss           | 138      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.4      |
|    ep_rew_mean          | -9.3      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1870      |
|    time_elapsed         | 6204      |
|    total_timesteps      | 239360    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0115   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 56.4      |
|    n_updates            | 18690     |
|    policy_gradient_loss | -9.31e-10 |
|    value_loss           | 91.8      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.7     |
|    ep_rew_mean          | -8.93    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1871     |
|    time_elapsed         | 6207     |
|    total_timesteps      | 239488   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0116  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 51.1     |
|    n_updates            | 18700    |
|    policy_gradient_loss | 5.63e-09 |
|    value_loss           | 128      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.2     |
|    ep_rew_mean          | -8.47    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1872     |
|    time_elapsed         | 6210     |
|    total_timesteps      | 239616   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0117  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 34.8     |
|    n_updates            | 18710    |
|    policy_gradient_loss | 4.38e-09 |
|    value_loss           | 70.3     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.1      |
|    ep_rew_mean          | -8.65     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1873      |
|    time_elapsed         | 6213      |
|    total_timesteps      | 239744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0117   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 91.7      |
|    n_updates            | 18720     |
|    policy_gradient_loss | -2.84e-09 |
|    value_loss           | 152       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.5      |
|    ep_rew_mean          | -8.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1874      |
|    time_elapsed         | 6216      |
|    total_timesteps      | 239872    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0118   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 48.6      |
|    n_updates            | 18730     |
|    policy_gradient_loss | -2.03e-09 |
|    value_loss           | 92.4      |
---------------------------------------
Num timesteps: 240000
Best mean reward: -0.99 - Last mean reward per episode: -9.02
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=240000, episode_reward=-8.50 +/- 21.10
Episode length: 89.00 +/- 31.94
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 89       |
|    mean_reward          | -8.5     |
| time/                   |          |
|    total_timesteps      | 240000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0119  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 31.2     |
|    n_updates            | 18740    |
|    policy_gradient_loss | 9.69e-09 |
|    value_loss           | 70.3     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 84.6     |
|    ep_rew_mean     | -8.69    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1875     |
|    time_elapsed    | 6222     |
|    total_timesteps | 240000   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.3      |
|    ep_rew_mean          | -8.37     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1876      |
|    time_elapsed         | 6225      |
|    total_timesteps      | 240128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.012    |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 77.3      |
|    n_updates            | 18750     |
|    policy_gradient_loss | -6.05e-10 |
|    value_loss           | 181       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 84.5          |
|    ep_rew_mean          | -8.64         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1877          |
|    time_elapsed         | 6228          |
|    total_timesteps      | 240256        |
| train/                  |               |
|    approx_kl            | 6.7525543e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0118       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 90.2          |
|    n_updates            | 18760         |
|    policy_gradient_loss | -8.04e-05     |
|    value_loss           | 171           |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.1     |
|    ep_rew_mean          | -8.96    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1878     |
|    time_elapsed         | 6231     |
|    total_timesteps      | 240384   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0114  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 44       |
|    n_updates            | 18770    |
|    policy_gradient_loss | 6.52e-10 |
|    value_loss           | 90.2     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.5      |
|    ep_rew_mean          | -9.12     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1879      |
|    time_elapsed         | 6234      |
|    total_timesteps      | 240512    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0113   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 45.4      |
|    n_updates            | 18780     |
|    policy_gradient_loss | -1.2e-08  |
|    value_loss           | 74.6      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.5     |
|    ep_rew_mean          | -9.12    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1880     |
|    time_elapsed         | 6238     |
|    total_timesteps      | 240640   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0113  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 33.7     |
|    n_updates            | 18790    |
|    policy_gradient_loss | 5.42e-09 |
|    value_loss           | 71       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.4      |
|    ep_rew_mean          | -9.1      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1881      |
|    time_elapsed         | 6241      |
|    total_timesteps      | 240768    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0114   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 36        |
|    n_updates            | 18800     |
|    policy_gradient_loss | -6.43e-09 |
|    value_loss           | 87.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.1      |
|    ep_rew_mean          | -8.47     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1882      |
|    time_elapsed         | 6244      |
|    total_timesteps      | 240896    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0114   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 28.3      |
|    n_updates            | 18810     |
|    policy_gradient_loss | -4.84e-09 |
|    value_loss           | 70        |
---------------------------------------
Num timesteps: 241000
Best mean reward: -0.99 - Last mean reward per episode: -8.65
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.3      |
|    ep_rew_mean          | -8.23     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1883      |
|    time_elapsed         | 6247      |
|    total_timesteps      | 241024    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0115   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 32.5      |
|    n_updates            | 18820     |
|    policy_gradient_loss | -2.89e-09 |
|    value_loss           | 75.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 83.9          |
|    ep_rew_mean          | -8.46         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1884          |
|    time_elapsed         | 6250          |
|    total_timesteps      | 241152        |
| train/                  |               |
|    approx_kl            | 1.2735836e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0113       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 64.3          |
|    n_updates            | 18830         |
|    policy_gradient_loss | -7.31e-05     |
|    value_loss           | 107           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.8      |
|    ep_rew_mean          | -8.38     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1885      |
|    time_elapsed         | 6254      |
|    total_timesteps      | 241280    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0107   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 92.9      |
|    n_updates            | 18840     |
|    policy_gradient_loss | 1.63e-10  |
|    value_loss           | 158       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.3     |
|    ep_rew_mean          | -8.56    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1886     |
|    time_elapsed         | 6257     |
|    total_timesteps      | 241408   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0107  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 45.6     |
|    n_updates            | 18850    |
|    policy_gradient_loss | 3.07e-09 |
|    value_loss           | 95.1     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.8     |
|    ep_rew_mean          | -8.81    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1887     |
|    time_elapsed         | 6261     |
|    total_timesteps      | 241536   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0108  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 70.4     |
|    n_updates            | 18860    |
|    policy_gradient_loss | 2.33e-10 |
|    value_loss           | 110      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.3     |
|    ep_rew_mean          | -8.57    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1888     |
|    time_elapsed         | 6265     |
|    total_timesteps      | 241664   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0108  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 33.2     |
|    n_updates            | 18870    |
|    policy_gradient_loss | 3.54e-09 |
|    value_loss           | 71.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.9      |
|    ep_rew_mean          | -8.85     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1889      |
|    time_elapsed         | 6268      |
|    total_timesteps      | 241792    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0108   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41        |
|    n_updates            | 18880     |
|    policy_gradient_loss | -7.31e-09 |
|    value_loss           | 77.9      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.9     |
|    ep_rew_mean          | -8.85    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1890     |
|    time_elapsed         | 6271     |
|    total_timesteps      | 241920   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0109  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 64.7     |
|    n_updates            | 18890    |
|    policy_gradient_loss | 5.87e-09 |
|    value_loss           | 130      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 242000
Best mean reward: -0.99 - Last mean reward per episode: -9.51
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.9     |
|    ep_rew_mean          | -9.46    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1891     |
|    time_elapsed         | 6274     |
|    total_timesteps      | 242048   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.011   |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 27.3     |
|    n_updates            | 18900    |
|    policy_gradient_loss | 8.92e-08 |
|    value_loss           | 55.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.8     |
|    ep_rew_mean          | -8.82    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1892     |
|    time_elapsed         | 6277     |
|    total_timesteps      | 242176   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.011   |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 45.3     |
|    n_updates            | 18910    |
|    policy_gradient_loss | 1.91e-09 |
|    value_loss           | 143      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85       |
|    ep_rew_mean          | -8.98    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1893     |
|    time_elapsed         | 6280     |
|    total_timesteps      | 242304   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0111  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 97.5     |
|    n_updates            | 18920    |
|    policy_gradient_loss | 2.42e-09 |
|    value_loss           | 143      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85       |
|    ep_rew_mean          | -8.98    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1894     |
|    time_elapsed         | 6283     |
|    total_timesteps      | 242432   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0112  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 37.9     |
|    n_updates            | 18930    |
|    policy_gradient_loss | 7.08e-09 |
|    value_loss           | 84.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.4     |
|    ep_rew_mean          | -9.38    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1895     |
|    time_elapsed         | 6286     |
|    total_timesteps      | 242560   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0112  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 88.5     |
|    n_updates            | 18940    |
|    policy_gradient_loss | 1.58e-09 |
|    value_loss           | 141      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.6      |
|    ep_rew_mean          | -9.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1896      |
|    time_elapsed         | 6290      |
|    total_timesteps      | 242688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0113   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 36.5      |
|    n_updates            | 18950     |
|    policy_gradient_loss | -4.89e-09 |
|    value_loss           | 74.4      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.8     |
|    ep_rew_mean          | -9.41    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1897     |
|    time_elapsed         | 6294     |
|    total_timesteps      | 242816   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0113  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 109      |
|    n_updates            | 18960    |
|    policy_gradient_loss | 1.19e-09 |
|    value_loss           | 167      |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 86           |
|    ep_rew_mean          | -9.53        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1898         |
|    time_elapsed         | 6297         |
|    total_timesteps      | 242944       |
| train/                  |              |
|    approx_kl            | 8.156523e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0108      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 53.2         |
|    n_updates            | 18970        |
|    policy_gradient_loss | -0.000425    |
|    value_loss           | 97.8         |
------------------------------------------
Num timesteps: 243000
Best mean reward: -0.99 - Last mean reward per episode: -10.21
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 85.7          |
|    ep_rew_mean          | -9.37         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1899          |
|    time_elapsed         | 6300          |
|    total_timesteps      | 243072        |
| train/                  |               |
|    approx_kl            | 9.7933225e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0091       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 31.4          |
|    n_updates            | 18980         |
|    policy_gradient_loss | -0.000453     |
|    value_loss           | 76.1          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 85.7          |
|    ep_rew_mean          | -9.37         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1900          |
|    time_elapsed         | 6304          |
|    total_timesteps      | 243200        |
| train/                  |               |
|    approx_kl            | 0.00019426458 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00791      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 25.5          |
|    n_updates            | 18990         |
|    policy_gradient_loss | -0.0004       |
|    value_loss           | 73.3          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.6     |
|    ep_rew_mean          | -10.3    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1901     |
|    time_elapsed         | 6307     |
|    total_timesteps      | 243328   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00552 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 25.5     |
|    n_updates            | 19000    |
|    policy_gradient_loss | 7.59e-09 |
|    value_loss           | 53.9     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 86.5          |
|    ep_rew_mean          | -10.4         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1902          |
|    time_elapsed         | 6310          |
|    total_timesteps      | 243456        |
| train/                  |               |
|    approx_kl            | 2.1024607e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00483      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 69.4          |
|    n_updates            | 19010         |
|    policy_gradient_loss | 3.66e-05      |
|    value_loss           | 128           |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.9     |
|    ep_rew_mean          | -10      |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1903     |
|    time_elapsed         | 6312     |
|    total_timesteps      | 243584   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00484 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 52.9     |
|    n_updates            | 19020    |
|    policy_gradient_loss | 5.22e-09 |
|    value_loss           | 141      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.2     |
|    ep_rew_mean          | -10.3    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1904     |
|    time_elapsed         | 6315     |
|    total_timesteps      | 243712   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00486 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.3     |
|    n_updates            | 19030    |
|    policy_gradient_loss | 1.68e-09 |
|    value_loss           | 98.6     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.3      |
|    ep_rew_mean          | -10.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1905      |
|    time_elapsed         | 6318      |
|    total_timesteps      | 243840    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00487  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 34.4      |
|    n_updates            | 19040     |
|    policy_gradient_loss | -4.38e-09 |
|    value_loss           | 72.6      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 87           |
|    ep_rew_mean          | -10.9        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 1906         |
|    time_elapsed         | 6321         |
|    total_timesteps      | 243968       |
| train/                  |              |
|    approx_kl            | 7.063383e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00473     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 63.6         |
|    n_updates            | 19050        |
|    policy_gradient_loss | -8.1e-05     |
|    value_loss           | 141          |
------------------------------------------
Num timesteps: 244000
Best mean reward: -0.99 - Last mean reward per episode: -11.12
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.8      |
|    ep_rew_mean          | -10.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1907      |
|    time_elapsed         | 6324      |
|    total_timesteps      | 244096    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00391  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.1      |
|    n_updates            | 19060     |
|    policy_gradient_loss | -1.49e-09 |
|    value_loss           | 81.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.9     |
|    ep_rew_mean          | -10.9    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1908     |
|    time_elapsed         | 6327     |
|    total_timesteps      | 244224   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00368 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 55       |
|    n_updates            | 19070    |
|    policy_gradient_loss | 3.12e-09 |
|    value_loss           | 98       |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.9     |
|    ep_rew_mean          | -10.9    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1909     |
|    time_elapsed         | 6331     |
|    total_timesteps      | 244352   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00366 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 44.3     |
|    n_updates            | 19080    |
|    policy_gradient_loss | 6.8e-09  |
|    value_loss           | 74       |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.9     |
|    ep_rew_mean          | -10.9    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1910     |
|    time_elapsed         | 6336     |
|    total_timesteps      | 244480   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00366 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 26.5     |
|    n_updates            | 19090    |
|    policy_gradient_loss | 7.69e-08 |
|    value_loss           | 54.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.9      |
|    ep_rew_mean          | -10.9     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1911      |
|    time_elapsed         | 6341      |
|    total_timesteps      | 244608    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00366  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 25.7      |
|    n_updates            | 19100     |
|    policy_gradient_loss | -3.34e-08 |
|    value_loss           | 53        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.9      |
|    ep_rew_mean          | -10.9     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1912      |
|    time_elapsed         | 6346      |
|    total_timesteps      | 244736    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00366  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 24.2      |
|    n_updates            | 19110     |
|    policy_gradient_loss | -3.3e-08  |
|    value_loss           | 52.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.9     |
|    ep_rew_mean          | -10.9    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1913     |
|    time_elapsed         | 6350     |
|    total_timesteps      | 244864   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00366 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 24.5     |
|    n_updates            | 19120    |
|    policy_gradient_loss | 4.32e-08 |
|    value_loss           | 51.3     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.9      |
|    ep_rew_mean          | -10.9     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1914      |
|    time_elapsed         | 6355      |
|    total_timesteps      | 244992    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00366  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 22.8      |
|    n_updates            | 19130     |
|    policy_gradient_loss | -1.11e-08 |
|    value_loss           | 50.3      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 245000
Best mean reward: -0.99 - Last mean reward per episode: -11.20
Eval num_timesteps=245000, episode_reward=2.60 +/- 2.58
Episode length: 62.80 +/- 5.46
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 62.8      |
|    mean_reward          | 2.6       |
| time/                   |           |
|    total_timesteps      | 245000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00366  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 23.5      |
|    n_updates            | 19140     |
|    policy_gradient_loss | 9.08e-10  |
|    value_loss           | 48.3      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 86.3     |
|    ep_rew_mean     | -10.6    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1915     |
|    time_elapsed    | 6361     |
|    total_timesteps | 245120   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.4     |
|    ep_rew_mean          | -10.6    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1916     |
|    time_elapsed         | 6364     |
|    total_timesteps      | 245248   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00367 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 64.3     |
|    n_updates            | 19150    |
|    policy_gradient_loss | 8.27e-09 |
|    value_loss           | 160      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.5      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1917      |
|    time_elapsed         | 6368      |
|    total_timesteps      | 245376    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00367  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 59.1      |
|    n_updates            | 19160     |
|    policy_gradient_loss | -9.55e-10 |
|    value_loss           | 121       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.5      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1918      |
|    time_elapsed         | 6370      |
|    total_timesteps      | 245504    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00369  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 82        |
|    n_updates            | 19170     |
|    policy_gradient_loss | -7.64e-09 |
|    value_loss           | 158       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.9     |
|    ep_rew_mean          | -11      |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1919     |
|    time_elapsed         | 6373     |
|    total_timesteps      | 245632   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0037  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.4     |
|    n_updates            | 19180    |
|    policy_gradient_loss | 5.63e-09 |
|    value_loss           | 85.1     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 86.6          |
|    ep_rew_mean          | -10.6         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1920          |
|    time_elapsed         | 6376          |
|    total_timesteps      | 245760        |
| train/                  |               |
|    approx_kl            | 4.7204085e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00365      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 56            |
|    n_updates            | 19190         |
|    policy_gradient_loss | -6.45e-05     |
|    value_loss           | 154           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 86.4          |
|    ep_rew_mean          | -10.5         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 1921          |
|    time_elapsed         | 6379          |
|    total_timesteps      | 245888        |
| train/                  |               |
|    approx_kl            | 3.8105063e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00352      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 147           |
|    n_updates            | 19200         |
|    policy_gradient_loss | -2.22e-05     |
|    value_loss           | 208           |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 246000
Best mean reward: -0.99 - Last mean reward per episode: -10.34
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | -10.4     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1922      |
|    time_elapsed         | 6381      |
|    total_timesteps      | 246016    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00346  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.2      |
|    n_updates            | 19210     |
|    policy_gradient_loss | -1.63e-09 |
|    value_loss           | 77.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.7      |
|    ep_rew_mean          | -10.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1923      |
|    time_elapsed         | 6384      |
|    total_timesteps      | 246144    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00345  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 54.8      |
|    n_updates            | 19220     |
|    policy_gradient_loss | -5.59e-10 |
|    value_loss           | 90.8      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.8     |
|    ep_rew_mean          | -10.5    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1924     |
|    time_elapsed         | 6388     |
|    total_timesteps      | 246272   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00345 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 50.2     |
|    n_updates            | 19230    |
|    policy_gradient_loss | 2.05e-09 |
|    value_loss           | 109      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.3      |
|    ep_rew_mean          | -10.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1925      |
|    time_elapsed         | 6391      |
|    total_timesteps      | 246400    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00346  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 110       |
|    n_updates            | 19240     |
|    policy_gradient_loss | -8.38e-10 |
|    value_loss           | 202       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.5     |
|    ep_rew_mean          | -10.7    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1926     |
|    time_elapsed         | 6394     |
|    total_timesteps      | 246528   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00347 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 39       |
|    n_updates            | 19250    |
|    policy_gradient_loss | 3.03e-09 |
|    value_loss           | 77.8     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.2     |
|    ep_rew_mean          | -10.7    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1927     |
|    time_elapsed         | 6398     |
|    total_timesteps      | 246656   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00347 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 79.2     |
|    n_updates            | 19260    |
|    policy_gradient_loss | 4.47e-09 |
|    value_loss           | 213      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.5     |
|    ep_rew_mean          | -10.8    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1928     |
|    time_elapsed         | 6400     |
|    total_timesteps      | 246784   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00347 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 49.1     |
|    n_updates            | 19270    |
|    policy_gradient_loss | 3.73e-10 |
|    value_loss           | 114      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.1      |
|    ep_rew_mean          | -11.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1929      |
|    time_elapsed         | 6403      |
|    total_timesteps      | 246912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00348  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.8      |
|    n_updates            | 19280     |
|    policy_gradient_loss | -1.35e-09 |
|    value_loss           | 77.1      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 247000
Best mean reward: -0.99 - Last mean reward per episode: -6.18
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 88       |
|    ep_rew_mean          | -10.7    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1930     |
|    time_elapsed         | 6407     |
|    total_timesteps      | 247040   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00348 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 48       |
|    n_updates            | 19290    |
|    policy_gradient_loss | 6.78e-09 |
|    value_loss           | 76.7     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.1      |
|    ep_rew_mean          | -10.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1931      |
|    time_elapsed         | 6411      |
|    total_timesteps      | 247168    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00349  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 149       |
|    n_updates            | 19300     |
|    policy_gradient_loss | -2.33e-10 |
|    value_loss           | 297       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88        |
|    ep_rew_mean          | -10.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1932      |
|    time_elapsed         | 6414      |
|    total_timesteps      | 247296    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00349  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 65.4      |
|    n_updates            | 19310     |
|    policy_gradient_loss | -1.54e-09 |
|    value_loss           | 159       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.7      |
|    ep_rew_mean          | -5.95     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1933      |
|    time_elapsed         | 6416      |
|    total_timesteps      | 247424    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0035   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 49.6      |
|    n_updates            | 19320     |
|    policy_gradient_loss | 3.93e-09  |
|    value_loss           | 110       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.7     |
|    ep_rew_mean          | -5.97    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1934     |
|    time_elapsed         | 6420     |
|    total_timesteps      | 247552   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0035  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 49.4     |
|    n_updates            | 19330    |
|    policy_gradient_loss | 1.86e-10 |
|    value_loss           | 109      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.2      |
|    ep_rew_mean          | -6.12     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1935      |
|    time_elapsed         | 6423      |
|    total_timesteps      | 247680    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00351  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 94.7      |
|    n_updates            | 19340     |
|    policy_gradient_loss | -3.26e-09 |
|    value_loss           | 147       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.2     |
|    ep_rew_mean          | -6.01    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1936     |
|    time_elapsed         | 6426     |
|    total_timesteps      | 247808   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00351 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 54.3     |
|    n_updates            | 19350    |
|    policy_gradient_loss | 3.03e-10 |
|    value_loss           | 113      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.9      |
|    ep_rew_mean          | -6.46     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1937      |
|    time_elapsed         | 6430      |
|    total_timesteps      | 247936    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00353  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 54.8      |
|    n_updates            | 19360     |
|    policy_gradient_loss | -3.17e-09 |
|    value_loss           | 141       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 248000
Best mean reward: -0.99 - Last mean reward per episode: -6.02
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.1     |
|    ep_rew_mean          | -6.54    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1938     |
|    time_elapsed         | 6433     |
|    total_timesteps      | 248064   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00355 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 56.8     |
|    n_updates            | 19370    |
|    policy_gradient_loss | 2.31e-09 |
|    value_loss           | 108      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.1     |
|    ep_rew_mean          | -6.54    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1939     |
|    time_elapsed         | 6436     |
|    total_timesteps      | 248192   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00356 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 43.8     |
|    n_updates            | 19380    |
|    policy_gradient_loss | 8.7e-09  |
|    value_loss           | 82.6     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.2     |
|    ep_rew_mean          | -6.88    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1940     |
|    time_elapsed         | 6440     |
|    total_timesteps      | 248320   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00356 |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 25.5     |
|    n_updates            | 19390    |
|    policy_gradient_loss | 3.94e-08 |
|    value_loss           | 53.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.4      |
|    ep_rew_mean          | -6.9      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1941      |
|    time_elapsed         | 6443      |
|    total_timesteps      | 248448    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00357  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 87.4      |
|    n_updates            | 19400     |
|    policy_gradient_loss | -6.71e-09 |
|    value_loss           | 201       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.7      |
|    ep_rew_mean          | -6.74     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1942      |
|    time_elapsed         | 6447      |
|    total_timesteps      | 248576    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00358  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 62.1      |
|    n_updates            | 19410     |
|    policy_gradient_loss | -3.73e-09 |
|    value_loss           | 165       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.9      |
|    ep_rew_mean          | -6.16     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1943      |
|    time_elapsed         | 6450      |
|    total_timesteps      | 248704    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00359  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.5      |
|    n_updates            | 19420     |
|    policy_gradient_loss | -5.26e-09 |
|    value_loss           | 105       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.7     |
|    ep_rew_mean          | -6.27    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1944     |
|    time_elapsed         | 6453     |
|    total_timesteps      | 248832   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00361 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 71.5     |
|    n_updates            | 19430    |
|    policy_gradient_loss | 1.26e-09 |
|    value_loss           | 122      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.9      |
|    ep_rew_mean          | -6.24     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1945      |
|    time_elapsed         | 6456      |
|    total_timesteps      | 248960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00362  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 41.1      |
|    n_updates            | 19440     |
|    policy_gradient_loss | 5.26e-09  |
|    value_loss           | 75        |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 249000
Best mean reward: -0.99 - Last mean reward per episode: -5.67
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.5      |
|    ep_rew_mean          | -6.75     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1946      |
|    time_elapsed         | 6459      |
|    total_timesteps      | 249088    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00363  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 66.9      |
|    n_updates            | 19450     |
|    policy_gradient_loss | -3.45e-09 |
|    value_loss           | 126       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.8      |
|    ep_rew_mean          | -6.21     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1947      |
|    time_elapsed         | 6462      |
|    total_timesteps      | 249216    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00366  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 54.2      |
|    n_updates            | 19460     |
|    policy_gradient_loss | -7.92e-10 |
|    value_loss           | 102       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.7     |
|    ep_rew_mean          | -6.13    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1948     |
|    time_elapsed         | 6466     |
|    total_timesteps      | 249344   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00367 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 85.8     |
|    n_updates            | 19470    |
|    policy_gradient_loss | -4e-09   |
|    value_loss           | 189      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.7     |
|    ep_rew_mean          | -6.13    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1949     |
|    time_elapsed         | 6470     |
|    total_timesteps      | 249472   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00367 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 35.9     |
|    n_updates            | 19480    |
|    policy_gradient_loss | 2.65e-09 |
|    value_loss           | 73.7     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.3     |
|    ep_rew_mean          | -5.95    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1950     |
|    time_elapsed         | 6472     |
|    total_timesteps      | 249600   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00368 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 50.8     |
|    n_updates            | 19490    |
|    policy_gradient_loss | 4.66e-10 |
|    value_loss           | 105      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.4      |
|    ep_rew_mean          | -6.32     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1951      |
|    time_elapsed         | 6475      |
|    total_timesteps      | 249728    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00369  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 48.5      |
|    n_updates            | 19500     |
|    policy_gradient_loss | -9.78e-10 |
|    value_loss           | 89.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.3     |
|    ep_rew_mean          | -6.25    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1952     |
|    time_elapsed         | 6479     |
|    total_timesteps      | 249856   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0037  |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 95.5     |
|    n_updates            | 19510    |
|    policy_gradient_loss | 1.12e-09 |
|    value_loss           | 201      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.3     |
|    ep_rew_mean          | -6.25    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1953     |
|    time_elapsed         | 6482     |
|    total_timesteps      | 249984   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00371 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 41.3     |
|    n_updates            | 19520    |
|    policy_gradient_loss | 1.49e-08 |
|    value_loss           | 76.8     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 250000
Best mean reward: -0.99 - Last mean reward per episode: -5.92
Eval num_timesteps=250000, episode_reward=1.60 +/- 5.43
Episode length: 60.80 +/- 5.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 60.8      |
|    mean_reward          | 1.6       |
| time/                   |           |
|    total_timesteps      | 250000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00371  |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 25        |
|    n_updates            | 19530     |
|    policy_gradient_loss | 1.06e-07  |
|    value_loss           | 53.6      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80.3     |
|    ep_rew_mean     | -6.14    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1954     |
|    time_elapsed    | 6487     |
|    total_timesteps | 250112   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.8      |
|    ep_rew_mean          | -6.39     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1955      |
|    time_elapsed         | 6491      |
|    total_timesteps      | 250240    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00372  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 62.6      |
|    n_updates            | 19540     |
|    policy_gradient_loss | -8.38e-10 |
|    value_loss           | 112       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.5     |
|    ep_rew_mean          | -6.96    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1956     |
|    time_elapsed         | 6494     |
|    total_timesteps      | 250368   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00373 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 37.2     |
|    n_updates            | 19550    |
|    policy_gradient_loss | 2.19e-09 |
|    value_loss           | 75.9     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.3     |
|    ep_rew_mean          | -6.88    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1957     |
|    time_elapsed         | 6498     |
|    total_timesteps      | 250496   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00374 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 46       |
|    n_updates            | 19560    |
|    policy_gradient_loss | 4.19e-09 |
|    value_loss           | 81.9     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.4     |
|    ep_rew_mean          | -6.98    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1958     |
|    time_elapsed         | 6501     |
|    total_timesteps      | 250624   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00375 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 62       |
|    n_updates            | 19570    |
|    policy_gradient_loss | 8.85e-10 |
|    value_loss           | 109      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.8      |
|    ep_rew_mean          | -6.62     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1959      |
|    time_elapsed         | 6505      |
|    total_timesteps      | 250752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00375  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 47.1      |
|    n_updates            | 19580     |
|    policy_gradient_loss | 6.95e-09  |
|    value_loss           | 79        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.7     |
|    ep_rew_mean          | -6.55    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1960     |
|    time_elapsed         | 6509     |
|    total_timesteps      | 250880   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00376 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 86.5     |
|    n_updates            | 19590    |
|    policy_gradient_loss | -1.3e-09 |
|    value_loss           | 150      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 251000
Best mean reward: -0.99 - Last mean reward per episode: -5.16
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -5.89     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1961      |
|    time_elapsed         | 6512      |
|    total_timesteps      | 251008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00376  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.7      |
|    n_updates            | 19600     |
|    policy_gradient_loss | -3.98e-09 |
|    value_loss           | 77.4      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.5     |
|    ep_rew_mean          | -5.95    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1962     |
|    time_elapsed         | 6515     |
|    total_timesteps      | 251136   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00377 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 118      |
|    n_updates            | 19610    |
|    policy_gradient_loss | 3.31e-09 |
|    value_loss           | 208      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -5.95     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1963      |
|    time_elapsed         | 6518      |
|    total_timesteps      | 251264    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00377  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 47.7      |
|    n_updates            | 19620     |
|    policy_gradient_loss | 4.19e-10  |
|    value_loss           | 91.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.6      |
|    ep_rew_mean          | -7.08     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1964      |
|    time_elapsed         | 6522      |
|    total_timesteps      | 251392    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00378  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 25        |
|    n_updates            | 19630     |
|    policy_gradient_loss | -3.84e-08 |
|    value_loss           | 50.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.2      |
|    ep_rew_mean          | -6.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1965      |
|    time_elapsed         | 6525      |
|    total_timesteps      | 251520    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00378  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 72.8      |
|    n_updates            | 19640     |
|    policy_gradient_loss | -1.42e-09 |
|    value_loss           | 115       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.4      |
|    ep_rew_mean          | -7.08     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1966      |
|    time_elapsed         | 6528      |
|    total_timesteps      | 251648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0038   |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 74.8      |
|    n_updates            | 19650     |
|    policy_gradient_loss | -2.05e-09 |
|    value_loss           | 118       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.1      |
|    ep_rew_mean          | -7.27     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1967      |
|    time_elapsed         | 6532      |
|    total_timesteps      | 251776    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00383  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 60        |
|    n_updates            | 19660     |
|    policy_gradient_loss | -7.08e-09 |
|    value_loss           | 116       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.1      |
|    ep_rew_mean          | -7.27     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1968      |
|    time_elapsed         | 6536      |
|    total_timesteps      | 251904    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00387  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 97.6      |
|    n_updates            | 19670     |
|    policy_gradient_loss | -9.31e-10 |
|    value_loss           | 175       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 252000
Best mean reward: -0.99 - Last mean reward per episode: -6.05
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.8     |
|    ep_rew_mean          | -7.33    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1969     |
|    time_elapsed         | 6540     |
|    total_timesteps      | 252032   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00389 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 25.4     |
|    n_updates            | 19680    |
|    policy_gradient_loss | 2.4e-08  |
|    value_loss           | 52.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 81.3     |
|    ep_rew_mean          | -6.74    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1970     |
|    time_elapsed         | 6543     |
|    total_timesteps      | 252160   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0039  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 62.8     |
|    n_updates            | 19690    |
|    policy_gradient_loss | -1e-09   |
|    value_loss           | 115      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.9      |
|    ep_rew_mean          | -6.53     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1971      |
|    time_elapsed         | 6546      |
|    total_timesteps      | 252288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00392  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 128       |
|    n_updates            | 19700     |
|    policy_gradient_loss | -1.44e-09 |
|    value_loss           | 241       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.8     |
|    ep_rew_mean          | -6.5     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1972     |
|    time_elapsed         | 6549     |
|    total_timesteps      | 252416   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00393 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 29.4     |
|    n_updates            | 19710    |
|    policy_gradient_loss | 5.36e-09 |
|    value_loss           | 80.5     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.8      |
|    ep_rew_mean          | -6.29     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1973      |
|    time_elapsed         | 6553      |
|    total_timesteps      | 252544    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00394  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 64.8      |
|    n_updates            | 19720     |
|    policy_gradient_loss | -9.87e-09 |
|    value_loss           | 110       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.7     |
|    ep_rew_mean          | -6.26    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1974     |
|    time_elapsed         | 6556     |
|    total_timesteps      | 252672   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00395 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 80.9     |
|    n_updates            | 19730    |
|    policy_gradient_loss | 1.86e-09 |
|    value_loss           | 195      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.5      |
|    ep_rew_mean          | -6.17     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1975      |
|    time_elapsed         | 6562      |
|    total_timesteps      | 252800    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00395  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 54.2      |
|    n_updates            | 19740     |
|    policy_gradient_loss | -2.28e-09 |
|    value_loss           | 140       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.5      |
|    ep_rew_mean          | -6.17     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1976      |
|    time_elapsed         | 6566      |
|    total_timesteps      | 252928    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00396  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.8      |
|    n_updates            | 19750     |
|    policy_gradient_loss | -2.28e-09 |
|    value_loss           | 103       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 253000
Best mean reward: -0.99 - Last mean reward per episode: -5.67
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -5.7      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1977      |
|    time_elapsed         | 6570      |
|    total_timesteps      | 253056    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00397  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.9      |
|    n_updates            | 19760     |
|    policy_gradient_loss | -5.49e-09 |
|    value_loss           | 76.6      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.6     |
|    ep_rew_mean          | -5.7     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1978     |
|    time_elapsed         | 6573     |
|    total_timesteps      | 253184   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00398 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 111      |
|    n_updates            | 19770    |
|    policy_gradient_loss | 7.64e-09 |
|    value_loss           | 167      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80        |
|    ep_rew_mean          | -5.83     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1979      |
|    time_elapsed         | 6576      |
|    total_timesteps      | 253312    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00398  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 41.9      |
|    n_updates            | 19780     |
|    policy_gradient_loss | -5.82e-09 |
|    value_loss           | 74.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.8      |
|    ep_rew_mean          | -5.79     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1980      |
|    time_elapsed         | 6580      |
|    total_timesteps      | 253440    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00399  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 94.8      |
|    n_updates            | 19790     |
|    policy_gradient_loss | -2.05e-09 |
|    value_loss           | 138       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -5.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1981      |
|    time_elapsed         | 6582      |
|    total_timesteps      | 253568    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00399  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 70.9      |
|    n_updates            | 19800     |
|    policy_gradient_loss | 6.8e-09   |
|    value_loss           | 135       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.2      |
|    ep_rew_mean          | -5.59     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1982      |
|    time_elapsed         | 6585      |
|    total_timesteps      | 253696    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.004    |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 59.5      |
|    n_updates            | 19810     |
|    policy_gradient_loss | -3.86e-09 |
|    value_loss           | 95        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.3     |
|    ep_rew_mean          | -5.67    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1983     |
|    time_elapsed         | 6588     |
|    total_timesteps      | 253824   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00402 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 52.7     |
|    n_updates            | 19820    |
|    policy_gradient_loss | 3.12e-09 |
|    value_loss           | 96       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -5.73     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1984      |
|    time_elapsed         | 6591      |
|    total_timesteps      | 253952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00405  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 47.6      |
|    n_updates            | 19830     |
|    policy_gradient_loss | -7.92e-10 |
|    value_loss           | 99.5      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 254000
Best mean reward: -0.99 - Last mean reward per episode: -5.22
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.2      |
|    ep_rew_mean          | -5.49     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1985      |
|    time_elapsed         | 6593      |
|    total_timesteps      | 254080    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00409  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 95.4      |
|    n_updates            | 19840     |
|    policy_gradient_loss | -1.82e-09 |
|    value_loss           | 183       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.2     |
|    ep_rew_mean          | -5.47    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1986     |
|    time_elapsed         | 6596     |
|    total_timesteps      | 254208   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00411 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 71.7     |
|    n_updates            | 19850    |
|    policy_gradient_loss | 1.77e-09 |
|    value_loss           | 124      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79        |
|    ep_rew_mean          | -5.49     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1987      |
|    time_elapsed         | 6600      |
|    total_timesteps      | 254336    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00412  |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 29.9      |
|    n_updates            | 19860     |
|    policy_gradient_loss | -6.29e-10 |
|    value_loss           | 69.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.3      |
|    ep_rew_mean          | -5.78     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1988      |
|    time_elapsed         | 6603      |
|    total_timesteps      | 254464    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00414  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.6      |
|    n_updates            | 19870     |
|    policy_gradient_loss | -2.56e-09 |
|    value_loss           | 93.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.3      |
|    ep_rew_mean          | -5.78     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1989      |
|    time_elapsed         | 6607      |
|    total_timesteps      | 254592    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00419  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.8      |
|    n_updates            | 19880     |
|    policy_gradient_loss | -6.38e-09 |
|    value_loss           | 72.4      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.3     |
|    ep_rew_mean          | -6.26    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1990     |
|    time_elapsed         | 6612     |
|    total_timesteps      | 254720   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00421 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 27.7     |
|    n_updates            | 19890    |
|    policy_gradient_loss | 7.25e-08 |
|    value_loss           | 58.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.6      |
|    ep_rew_mean          | -6.38     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1991      |
|    time_elapsed         | 6615      |
|    total_timesteps      | 254848    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00421  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 82.8      |
|    n_updates            | 19900     |
|    policy_gradient_loss | -4.05e-09 |
|    value_loss           | 173       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.1     |
|    ep_rew_mean          | -6.13    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1992     |
|    time_elapsed         | 6618     |
|    total_timesteps      | 254976   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00422 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 31.2     |
|    n_updates            | 19910    |
|    policy_gradient_loss | -1.4e-10 |
|    value_loss           | 70.5     |
--------------------------------------
Num timesteps: 255000
Best mean reward: -0.99 - Last mean reward per episode: -6.15
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=255000, episode_reward=-2.70 +/- 7.40
Episode length: 65.40 +/- 14.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 65.4      |
|    mean_reward          | -2.7      |
| time/                   |           |
|    total_timesteps      | 255000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00423  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.4      |
|    n_updates            | 19920     |
|    policy_gradient_loss | -1.12e-09 |
|    value_loss           | 119       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79.5     |
|    ep_rew_mean     | -5.84    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 1993     |
|    time_elapsed    | 6622     |
|    total_timesteps | 255104   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.9     |
|    ep_rew_mean          | -6.24    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1994     |
|    time_elapsed         | 6627     |
|    total_timesteps      | 255232   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00424 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 33.9     |
|    n_updates            | 19930    |
|    policy_gradient_loss | 9.31e-10 |
|    value_loss           | 70.3     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.7      |
|    ep_rew_mean          | -6.26     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1995      |
|    time_elapsed         | 6630      |
|    total_timesteps      | 255360    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00424  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 77.3      |
|    n_updates            | 19940     |
|    policy_gradient_loss | -2.75e-09 |
|    value_loss           | 177       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.7      |
|    ep_rew_mean          | -6.14     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1996      |
|    time_elapsed         | 6634      |
|    total_timesteps      | 255488    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00427  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 32.5      |
|    n_updates            | 19950     |
|    policy_gradient_loss | -3.52e-09 |
|    value_loss           | 88.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -6.09     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1997      |
|    time_elapsed         | 6637      |
|    total_timesteps      | 255616    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00432  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 65.5      |
|    n_updates            | 19960     |
|    policy_gradient_loss | -5.59e-10 |
|    value_loss           | 123       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.2     |
|    ep_rew_mean          | -6.29    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 1998     |
|    time_elapsed         | 6641     |
|    total_timesteps      | 255744   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00434 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 41.2     |
|    n_updates            | 19970    |
|    policy_gradient_loss | 1.86e-09 |
|    value_loss           | 71.2     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.5      |
|    ep_rew_mean          | -6.53     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 1999      |
|    time_elapsed         | 6644      |
|    total_timesteps      | 255872    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00435  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 62.1      |
|    n_updates            | 19980     |
|    policy_gradient_loss | -7.82e-09 |
|    value_loss           | 107       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 256000
Best mean reward: -0.99 - Last mean reward per episode: -5.95
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.5     |
|    ep_rew_mean          | -6.64    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2000     |
|    time_elapsed         | 6646     |
|    total_timesteps      | 256000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00439 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 52.3     |
|    n_updates            | 19990    |
|    policy_gradient_loss | 1.14e-09 |
|    value_loss           | 96.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.8     |
|    ep_rew_mean          | -6.92    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2001     |
|    time_elapsed         | 6649     |
|    total_timesteps      | 256128   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00447 |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 47.5     |
|    n_updates            | 20000    |
|    policy_gradient_loss | 2.44e-09 |
|    value_loss           | 88.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80.5     |
|    ep_rew_mean          | -6.74    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2002     |
|    time_elapsed         | 6652     |
|    total_timesteps      | 256256   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00451 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 26.1     |
|    n_updates            | 20010    |
|    policy_gradient_loss | 3.17e-09 |
|    value_loss           | 69.7     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.9     |
|    ep_rew_mean          | -6.17    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2003     |
|    time_elapsed         | 6655     |
|    total_timesteps      | 256384   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00454 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 54.4     |
|    n_updates            | 20020    |
|    policy_gradient_loss | 1.86e-09 |
|    value_loss           | 99.1     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.4     |
|    ep_rew_mean          | -6.11    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2004     |
|    time_elapsed         | 6658     |
|    total_timesteps      | 256512   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00462 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 33.8     |
|    n_updates            | 20030    |
|    policy_gradient_loss | 0        |
|    value_loss           | 86.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.5      |
|    ep_rew_mean          | -5.93     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2005      |
|    time_elapsed         | 6661      |
|    total_timesteps      | 256640    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00469  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 36.1      |
|    n_updates            | 20040     |
|    policy_gradient_loss | 1.96e-09  |
|    value_loss           | 87        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.4     |
|    ep_rew_mean          | -6.11    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2006     |
|    time_elapsed         | 6665     |
|    total_timesteps      | 256768   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00473 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 100      |
|    n_updates            | 20050    |
|    policy_gradient_loss | 4.75e-09 |
|    value_loss           | 167      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.4      |
|    ep_rew_mean          | -6        |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2007      |
|    time_elapsed         | 6668      |
|    total_timesteps      | 256896    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00476  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.8      |
|    n_updates            | 20060     |
|    policy_gradient_loss | -2.65e-09 |
|    value_loss           | 85.6      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 257000
Best mean reward: -0.99 - Last mean reward per episode: -6.28
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.7     |
|    ep_rew_mean          | -6.54    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2008     |
|    time_elapsed         | 6671     |
|    total_timesteps      | 257024   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00481 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 50.4     |
|    n_updates            | 20070    |
|    policy_gradient_loss | 4.05e-09 |
|    value_loss           | 118      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.5     |
|    ep_rew_mean          | -6.38    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2009     |
|    time_elapsed         | 6675     |
|    total_timesteps      | 257152   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00484 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 51.2     |
|    n_updates            | 20080    |
|    policy_gradient_loss | 3.49e-09 |
|    value_loss           | 101      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -6.05     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2010      |
|    time_elapsed         | 6679      |
|    total_timesteps      | 257280    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00486  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 51.3      |
|    n_updates            | 20090     |
|    policy_gradient_loss | -3.73e-09 |
|    value_loss           | 175       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.4      |
|    ep_rew_mean          | -6.29     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2011      |
|    time_elapsed         | 6682      |
|    total_timesteps      | 257408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0049   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 67.5      |
|    n_updates            | 20100     |
|    policy_gradient_loss | -5.96e-09 |
|    value_loss           | 125       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.8      |
|    ep_rew_mean          | -6.01     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2012      |
|    time_elapsed         | 6686      |
|    total_timesteps      | 257536    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00495  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 62.1      |
|    n_updates            | 20110     |
|    policy_gradient_loss | -1.63e-09 |
|    value_loss           | 115       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.7      |
|    ep_rew_mean          | -6.45     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2013      |
|    time_elapsed         | 6689      |
|    total_timesteps      | 257664    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00501  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.2      |
|    n_updates            | 20120     |
|    policy_gradient_loss | -4.66e-11 |
|    value_loss           | 82        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.1     |
|    ep_rew_mean          | -6.03    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2014     |
|    time_elapsed         | 6692     |
|    total_timesteps      | 257792   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00507 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 38.2     |
|    n_updates            | 20130    |
|    policy_gradient_loss | 1.25e-08 |
|    value_loss           | 74.7     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.8      |
|    ep_rew_mean          | -6.08     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2015      |
|    time_elapsed         | 6695      |
|    total_timesteps      | 257920    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0051   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 58.4      |
|    n_updates            | 20140     |
|    policy_gradient_loss | -4.28e-09 |
|    value_loss           | 114       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 258000
Best mean reward: -0.99 - Last mean reward per episode: -5.09
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.3     |
|    ep_rew_mean          | -5.93    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2016     |
|    time_elapsed         | 6697     |
|    total_timesteps      | 258048   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00515 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 41.9     |
|    n_updates            | 20150    |
|    policy_gradient_loss | 1.77e-09 |
|    value_loss           | 80.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77        |
|    ep_rew_mean          | -5.1      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2017      |
|    time_elapsed         | 6700      |
|    total_timesteps      | 258176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00525  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 39.3      |
|    n_updates            | 20160     |
|    policy_gradient_loss | -3.24e-09 |
|    value_loss           | 79        |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 76.4          |
|    ep_rew_mean          | -4.8          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 2018          |
|    time_elapsed         | 6703          |
|    total_timesteps      | 258304        |
| train/                  |               |
|    approx_kl            | 0.00021759747 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00493      |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 57.6          |
|    n_updates            | 20170         |
|    policy_gradient_loss | -0.000464     |
|    value_loss           | 162           |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.8      |
|    ep_rew_mean          | -5.1      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2019      |
|    time_elapsed         | 6706      |
|    total_timesteps      | 258432    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00394  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 36.5      |
|    n_updates            | 20180     |
|    policy_gradient_loss | -4.89e-10 |
|    value_loss           | 76.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.7      |
|    ep_rew_mean          | -5.05     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2020      |
|    time_elapsed         | 6709      |
|    total_timesteps      | 258560    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00378  |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 40.6      |
|    n_updates            | 20190     |
|    policy_gradient_loss | 3.86e-09  |
|    value_loss           | 66.8      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 76.7     |
|    ep_rew_mean          | -5.13    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2021     |
|    time_elapsed         | 6712     |
|    total_timesteps      | 258688   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00378 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 44.3     |
|    n_updates            | 20200    |
|    policy_gradient_loss | 5.68e-09 |
|    value_loss           | 86.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.7      |
|    ep_rew_mean          | -4.16     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2022      |
|    time_elapsed         | 6715      |
|    total_timesteps      | 258816    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00381  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 60.9      |
|    n_updates            | 20210     |
|    policy_gradient_loss | -1.96e-09 |
|    value_loss           | 108       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.1      |
|    ep_rew_mean          | -4.24     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2023      |
|    time_elapsed         | 6718      |
|    total_timesteps      | 258944    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00385  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.6      |
|    n_updates            | 20220     |
|    policy_gradient_loss | -6.03e-09 |
|    value_loss           | 81.4      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 259000
Best mean reward: -0.99 - Last mean reward per episode: -3.40
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.9     |
|    ep_rew_mean          | -4.17    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2024     |
|    time_elapsed         | 6722     |
|    total_timesteps      | 259072   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00391 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 78       |
|    n_updates            | 20230    |
|    policy_gradient_loss | 4.26e-09 |
|    value_loss           | 119      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75       |
|    ep_rew_mean          | -4.21    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2025     |
|    time_elapsed         | 6725     |
|    total_timesteps      | 259200   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00397 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.2     |
|    n_updates            | 20240    |
|    policy_gradient_loss | 3.26e-10 |
|    value_loss           | 75.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.6      |
|    ep_rew_mean          | -4.21     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2026      |
|    time_elapsed         | 6728      |
|    total_timesteps      | 259328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00402  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.5      |
|    n_updates            | 20250     |
|    policy_gradient_loss | -3.73e-09 |
|    value_loss           | 68        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -3.78     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2027      |
|    time_elapsed         | 6731      |
|    total_timesteps      | 259456    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00404  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 36.8      |
|    n_updates            | 20260     |
|    policy_gradient_loss | -6.57e-09 |
|    value_loss           | 66.8      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.2     |
|    ep_rew_mean          | -3.99    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2028     |
|    time_elapsed         | 6734     |
|    total_timesteps      | 259584   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00406 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 51       |
|    n_updates            | 20270    |
|    policy_gradient_loss | 1.4e-10  |
|    value_loss           | 88.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.2     |
|    ep_rew_mean          | -4.17    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2029     |
|    time_elapsed         | 6738     |
|    total_timesteps      | 259712   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0041  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 39.5     |
|    n_updates            | 20280    |
|    policy_gradient_loss | 3.41e-09 |
|    value_loss           | 101      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.8     |
|    ep_rew_mean          | -3.81    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2030     |
|    time_elapsed         | 6741     |
|    total_timesteps      | 259840   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00413 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 28.6     |
|    n_updates            | 20290    |
|    policy_gradient_loss | 6.05e-10 |
|    value_loss           | 72.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -3.8      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2031      |
|    time_elapsed         | 6745      |
|    total_timesteps      | 259968    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00414  |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 89.3      |
|    n_updates            | 20300     |
|    policy_gradient_loss | -2.14e-09 |
|    value_loss           | 163       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 260000
Best mean reward: -0.99 - Last mean reward per episode: -4.34
Eval num_timesteps=260000, episode_reward=-0.70 +/- 3.66
Episode length: 69.40 +/- 10.54
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 69.4      |
|    mean_reward          | -0.7      |
| time/                   |           |
|    total_timesteps      | 260000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00415  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 31.9      |
|    n_updates            | 20310     |
|    policy_gradient_loss | -1.68e-09 |
|    value_loss           | 72.7      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 74.2     |
|    ep_rew_mean     | -3.98    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2032     |
|    time_elapsed    | 6750     |
|    total_timesteps | 260096   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.1      |
|    ep_rew_mean          | -4.04     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2033      |
|    time_elapsed         | 6753      |
|    total_timesteps      | 260224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00417  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 70.8      |
|    n_updates            | 20320     |
|    policy_gradient_loss | -4.05e-09 |
|    value_loss           | 168       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74       |
|    ep_rew_mean          | -4.03    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2034     |
|    time_elapsed         | 6756     |
|    total_timesteps      | 260352   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00423 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 46       |
|    n_updates            | 20330    |
|    policy_gradient_loss | 3.4e-09  |
|    value_loss           | 90.5     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.7      |
|    ep_rew_mean          | -3.96     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2035      |
|    time_elapsed         | 6759      |
|    total_timesteps      | 260480    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00433  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 41.6      |
|    n_updates            | 20340     |
|    policy_gradient_loss | 7.57e-10  |
|    value_loss           | 89.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -3.72     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2036      |
|    time_elapsed         | 6762      |
|    total_timesteps      | 260608    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00443  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 49.2      |
|    n_updates            | 20350     |
|    policy_gradient_loss | -9.31e-11 |
|    value_loss           | 92.3      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 73.8         |
|    ep_rew_mean          | -3.72        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 2037         |
|    time_elapsed         | 6765         |
|    total_timesteps      | 260736       |
| train/                  |              |
|    approx_kl            | 0.0009464482 |
|    clip_fraction        | 0.00391      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00372     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 89.6         |
|    n_updates            | 20360        |
|    policy_gradient_loss | -0.000679    |
|    value_loss           | 195          |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.8     |
|    ep_rew_mean          | -3.72    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2038     |
|    time_elapsed         | 6769     |
|    total_timesteps      | 260864   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00257 |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 31.7     |
|    n_updates            | 20370    |
|    policy_gradient_loss | 4.85e-08 |
|    value_loss           | 63.4     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.8     |
|    ep_rew_mean          | -3.72    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2039     |
|    time_elapsed         | 6772     |
|    total_timesteps      | 260992   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00243 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 28.6     |
|    n_updates            | 20380    |
|    policy_gradient_loss | 3.53e-08 |
|    value_loss           | 60.9     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 261000
Best mean reward: -0.99 - Last mean reward per episode: -3.71
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -3.72     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2040      |
|    time_elapsed         | 6775      |
|    total_timesteps      | 261120    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00241  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.3      |
|    n_updates            | 20390     |
|    policy_gradient_loss | -2.24e-09 |
|    value_loss           | 59.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -3.72     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2041      |
|    time_elapsed         | 6779      |
|    total_timesteps      | 261248    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00241  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 29.3      |
|    n_updates            | 20400     |
|    policy_gradient_loss | -3.37e-08 |
|    value_loss           | 58.9      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.8     |
|    ep_rew_mean          | -3.72    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2042     |
|    time_elapsed         | 6782     |
|    total_timesteps      | 261376   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00241 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 26.1     |
|    n_updates            | 20410    |
|    policy_gradient_loss | 2.17e-08 |
|    value_loss           | 58       |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.8     |
|    ep_rew_mean          | -3.72    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2043     |
|    time_elapsed         | 6786     |
|    total_timesteps      | 261504   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00241 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 26.1     |
|    n_updates            | 20420    |
|    policy_gradient_loss | 9.59e-09 |
|    value_loss           | 57       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.7      |
|    ep_rew_mean          | -8.56     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2044      |
|    time_elapsed         | 6789      |
|    total_timesteps      | 261632    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00241  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 25.6      |
|    n_updates            | 20430     |
|    policy_gradient_loss | -8.35e-09 |
|    value_loss           | 55.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.2      |
|    ep_rew_mean          | -8.5      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2045      |
|    time_elapsed         | 6793      |
|    total_timesteps      | 261760    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00242  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 19.4      |
|    n_updates            | 20440     |
|    policy_gradient_loss | -3.26e-09 |
|    value_loss           | 42.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.3      |
|    ep_rew_mean          | -8.47     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2046      |
|    time_elapsed         | 6797      |
|    total_timesteps      | 261888    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00242  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 111       |
|    n_updates            | 20450     |
|    policy_gradient_loss | -5.12e-10 |
|    value_loss           | 278       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 262000
Best mean reward: -0.99 - Last mean reward per episode: -8.84
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84        |
|    ep_rew_mean          | -8.79     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2047      |
|    time_elapsed         | 6800      |
|    total_timesteps      | 262016    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00242  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 51.7      |
|    n_updates            | 20460     |
|    policy_gradient_loss | 2.79e-10  |
|    value_loss           | 135       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.1     |
|    ep_rew_mean          | -8.65    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2048     |
|    time_elapsed         | 6804     |
|    total_timesteps      | 262144   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00242 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 31.6     |
|    n_updates            | 20470    |
|    policy_gradient_loss | 4.59e-09 |
|    value_loss           | 75       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84        |
|    ep_rew_mean          | -8.42     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2049      |
|    time_elapsed         | 6807      |
|    total_timesteps      | 262272    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00243  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 134       |
|    n_updates            | 20480     |
|    policy_gradient_loss | -6.66e-09 |
|    value_loss           | 184       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84       |
|    ep_rew_mean          | -8.42    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2050     |
|    time_elapsed         | 6811     |
|    total_timesteps      | 262400   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00243 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 62.4     |
|    n_updates            | 20490    |
|    policy_gradient_loss | 7.45e-10 |
|    value_loss           | 184      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84        |
|    ep_rew_mean          | -8.42     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2051      |
|    time_elapsed         | 6814      |
|    total_timesteps      | 262528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00243  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 97.4      |
|    n_updates            | 20500     |
|    policy_gradient_loss | -2.75e-09 |
|    value_loss           | 165       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.1      |
|    ep_rew_mean          | -8.87     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2052      |
|    time_elapsed         | 6818      |
|    total_timesteps      | 262656    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00244  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 46.4      |
|    n_updates            | 20510     |
|    policy_gradient_loss | -7.45e-10 |
|    value_loss           | 111       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.1     |
|    ep_rew_mean          | -8.87    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2053     |
|    time_elapsed         | 6821     |
|    total_timesteps      | 262784   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00245 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 49.3     |
|    n_updates            | 20520    |
|    policy_gradient_loss | 8.85e-10 |
|    value_loss           | 106      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.4      |
|    ep_rew_mean          | -8.88     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2054      |
|    time_elapsed         | 6824      |
|    total_timesteps      | 262912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00246  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.6      |
|    n_updates            | 20530     |
|    policy_gradient_loss | -2.79e-09 |
|    value_loss           | 70.7      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 263000
Best mean reward: -0.99 - Last mean reward per episode: -7.76
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.3     |
|    ep_rew_mean          | -7.87    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2055     |
|    time_elapsed         | 6828     |
|    total_timesteps      | 263040   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00247 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 86       |
|    n_updates            | 20540    |
|    policy_gradient_loss | 3.73e-10 |
|    value_loss           | 140      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.7     |
|    ep_rew_mean          | -8.06    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2056     |
|    time_elapsed         | 6832     |
|    total_timesteps      | 263168   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00248 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 85.6     |
|    n_updates            | 20550    |
|    policy_gradient_loss | 2.14e-09 |
|    value_loss           | 188      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.3      |
|    ep_rew_mean          | -7.84     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2057      |
|    time_elapsed         | 6834      |
|    total_timesteps      | 263296    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00248  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 35.6      |
|    n_updates            | 20560     |
|    policy_gradient_loss | 1.63e-09  |
|    value_loss           | 71.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.8      |
|    ep_rew_mean          | -7.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2058      |
|    time_elapsed         | 6837      |
|    total_timesteps      | 263424    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00249  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 34.3      |
|    n_updates            | 20570     |
|    policy_gradient_loss | -3.86e-09 |
|    value_loss           | 93.4      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.8     |
|    ep_rew_mean          | -7.99    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2059     |
|    time_elapsed         | 6841     |
|    total_timesteps      | 263552   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00251 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 114      |
|    n_updates            | 20580    |
|    policy_gradient_loss | 2.19e-09 |
|    value_loss           | 185      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.7     |
|    ep_rew_mean          | -7.84    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2060     |
|    time_elapsed         | 6845     |
|    total_timesteps      | 263680   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00251 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 80.5     |
|    n_updates            | 20590    |
|    policy_gradient_loss | 3.45e-09 |
|    value_loss           | 134      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.8      |
|    ep_rew_mean          | -7.88     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2061      |
|    time_elapsed         | 6848      |
|    total_timesteps      | 263808    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00252  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 59.5      |
|    n_updates            | 20600     |
|    policy_gradient_loss | -6.98e-10 |
|    value_loss           | 131       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.9      |
|    ep_rew_mean          | -7.87     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2062      |
|    time_elapsed         | 6852      |
|    total_timesteps      | 263936    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00253  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 44.4      |
|    n_updates            | 20610     |
|    policy_gradient_loss | -3.73e-09 |
|    value_loss           | 71.2      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 264000
Best mean reward: -0.99 - Last mean reward per episode: -7.31
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 83.4         |
|    ep_rew_mean          | -7.72        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 2063         |
|    time_elapsed         | 6855         |
|    total_timesteps      | 264064       |
| train/                  |              |
|    approx_kl            | 0.0001783031 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00234     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 84           |
|    n_updates            | 20620        |
|    policy_gradient_loss | -0.000537    |
|    value_loss           | 165          |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.2     |
|    ep_rew_mean          | -7.5     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2064     |
|    time_elapsed         | 6858     |
|    total_timesteps      | 264192   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00185 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.1     |
|    n_updates            | 20630    |
|    policy_gradient_loss | 2.84e-09 |
|    value_loss           | 92       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.1      |
|    ep_rew_mean          | -7.33     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2065      |
|    time_elapsed         | 6861      |
|    total_timesteps      | 264320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00175  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 59.4      |
|    n_updates            | 20640     |
|    policy_gradient_loss | -3.49e-09 |
|    value_loss           | 110       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.3     |
|    ep_rew_mean          | -7.87    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2066     |
|    time_elapsed         | 6865     |
|    total_timesteps      | 264448   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00174 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 86.4     |
|    n_updates            | 20650    |
|    policy_gradient_loss | -4.7e-09 |
|    value_loss           | 131      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84       |
|    ep_rew_mean          | -7.62    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2067     |
|    time_elapsed         | 6870     |
|    total_timesteps      | 264576   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00176 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 52.8     |
|    n_updates            | 20660    |
|    policy_gradient_loss | 3.49e-09 |
|    value_loss           | 116      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.5      |
|    ep_rew_mean          | -7.37     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2068      |
|    time_elapsed         | 6873      |
|    total_timesteps      | 264704    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00176  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 71.5      |
|    n_updates            | 20670     |
|    policy_gradient_loss | -6.52e-10 |
|    value_loss           | 128       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 83.7         |
|    ep_rew_mean          | -7.42        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 2069         |
|    time_elapsed         | 6876         |
|    total_timesteps      | 264832       |
| train/                  |              |
|    approx_kl            | 0.0026755687 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00153     |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 43.8         |
|    n_updates            | 20680        |
|    policy_gradient_loss | -0.00112     |
|    value_loss           | 88.9         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.8      |
|    ep_rew_mean          | -7.5      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2070      |
|    time_elapsed         | 6878      |
|    total_timesteps      | 264960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00129  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.3      |
|    n_updates            | 20690     |
|    policy_gradient_loss | -6.57e-09 |
|    value_loss           | 89.3      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 265000
Best mean reward: -0.99 - Last mean reward per episode: -7.25
Eval num_timesteps=265000, episode_reward=-10.90 +/- 8.22
Episode length: 93.80 +/- 22.17
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 93.8     |
|    mean_reward          | -10.9    |
| time/                   |          |
|    total_timesteps      | 265000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00126 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 30.1     |
|    n_updates            | 20700    |
|    policy_gradient_loss | 1.96e-09 |
|    value_loss           | 71.2     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 84       |
|    ep_rew_mean     | -7.67    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2071     |
|    time_elapsed    | 6884     |
|    total_timesteps | 265088   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.8      |
|    ep_rew_mean          | -7.99     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2072      |
|    time_elapsed         | 6887      |
|    total_timesteps      | 265216    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00126  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 59.4      |
|    n_updates            | 20710     |
|    policy_gradient_loss | 4.14e-09  |
|    value_loss           | 118       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.4      |
|    ep_rew_mean          | -8.12     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2073      |
|    time_elapsed         | 6890      |
|    total_timesteps      | 265344    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00126  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.7      |
|    n_updates            | 20720     |
|    policy_gradient_loss | -2.98e-09 |
|    value_loss           | 106       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.8     |
|    ep_rew_mean          | -8.29    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2074     |
|    time_elapsed         | 6894     |
|    total_timesteps      | 265472   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00127 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 97.8     |
|    n_updates            | 20730    |
|    policy_gradient_loss | 3.84e-09 |
|    value_loss           | 168      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.6     |
|    ep_rew_mean          | -8       |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2075     |
|    time_elapsed         | 6897     |
|    total_timesteps      | 265600   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00128 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 55       |
|    n_updates            | 20740    |
|    policy_gradient_loss | 1.26e-09 |
|    value_loss           | 106      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.6      |
|    ep_rew_mean          | -8.12     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2076      |
|    time_elapsed         | 6900      |
|    total_timesteps      | 265728    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00128  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 54.5      |
|    n_updates            | 20750     |
|    policy_gradient_loss | 2.35e-09  |
|    value_loss           | 97.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.6     |
|    ep_rew_mean          | -8.01    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2077     |
|    time_elapsed         | 6903     |
|    total_timesteps      | 265856   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00129 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 51.1     |
|    n_updates            | 20760    |
|    policy_gradient_loss | 9.31e-10 |
|    value_loss           | 101      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.7      |
|    ep_rew_mean          | -7.87     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2078      |
|    time_elapsed         | 6906      |
|    total_timesteps      | 265984    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0013   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 64.4      |
|    n_updates            | 20770     |
|    policy_gradient_loss | 2.61e-09  |
|    value_loss           | 137       |
---------------------------------------
Num timesteps: 266000
Best mean reward: -0.99 - Last mean reward per episode: -8.19
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.8     |
|    ep_rew_mean          | -7.92    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2079     |
|    time_elapsed         | 6910     |
|    total_timesteps      | 266112   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00131 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 90.8     |
|    n_updates            | 20780    |
|    policy_gradient_loss | 5.68e-09 |
|    value_loss           | 209      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.3      |
|    ep_rew_mean          | -7.65     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2080      |
|    time_elapsed         | 6913      |
|    total_timesteps      | 266240    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00131  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 42.9      |
|    n_updates            | 20790     |
|    policy_gradient_loss | -1.35e-09 |
|    value_loss           | 71.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85        |
|    ep_rew_mean          | -8.01     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2081      |
|    time_elapsed         | 6917      |
|    total_timesteps      | 266368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00131  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 41.3      |
|    n_updates            | 20800     |
|    policy_gradient_loss | 5.77e-09  |
|    value_loss           | 82.6      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85       |
|    ep_rew_mean          | -8.02    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2082     |
|    time_elapsed         | 6920     |
|    total_timesteps      | 266496   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00132 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 60.1     |
|    n_updates            | 20810    |
|    policy_gradient_loss | 2.19e-09 |
|    value_loss           | 128      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85       |
|    ep_rew_mean          | -8.02    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2083     |
|    time_elapsed         | 6923     |
|    total_timesteps      | 266624   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00132 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 52.6     |
|    n_updates            | 20820    |
|    policy_gradient_loss | 2.61e-09 |
|    value_loss           | 96.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.8      |
|    ep_rew_mean          | -8.12     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2084      |
|    time_elapsed         | 6927      |
|    total_timesteps      | 266752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00133  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.6      |
|    n_updates            | 20830     |
|    policy_gradient_loss | -2.14e-09 |
|    value_loss           | 95.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.1      |
|    ep_rew_mean          | -8.27     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2085      |
|    time_elapsed         | 6930      |
|    total_timesteps      | 266880    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00134  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 58        |
|    n_updates            | 20840     |
|    policy_gradient_loss | -2.33e-09 |
|    value_loss           | 97.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 267000
Best mean reward: -0.99 - Last mean reward per episode: -9.16
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.6      |
|    ep_rew_mean          | -9.02     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2086      |
|    time_elapsed         | 6933      |
|    total_timesteps      | 267008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00135  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 32.6      |
|    n_updates            | 20850     |
|    policy_gradient_loss | -5.59e-10 |
|    value_loss           | 79.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.2      |
|    ep_rew_mean          | -8.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2087      |
|    time_elapsed         | 6937      |
|    total_timesteps      | 267136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00136  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36        |
|    n_updates            | 20860     |
|    policy_gradient_loss | -3.12e-09 |
|    value_loss           | 73.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.7     |
|    ep_rew_mean          | -8.74    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2088     |
|    time_elapsed         | 6940     |
|    total_timesteps      | 267264   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00136 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 35       |
|    n_updates            | 20870    |
|    policy_gradient_loss | 2.84e-09 |
|    value_loss           | 75.9     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.3     |
|    ep_rew_mean          | -9.04    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2089     |
|    time_elapsed         | 6943     |
|    total_timesteps      | 267392   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00136 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 95.2     |
|    n_updates            | 20880    |
|    policy_gradient_loss | -3.4e-09 |
|    value_loss           | 222      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.3     |
|    ep_rew_mean          | -8.94    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2090     |
|    time_elapsed         | 6947     |
|    total_timesteps      | 267520   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00136 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 29.4     |
|    n_updates            | 20890    |
|    policy_gradient_loss | 4.66e-11 |
|    value_loss           | 78       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.7      |
|    ep_rew_mean          | -9.04     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2091      |
|    time_elapsed         | 6950      |
|    total_timesteps      | 267648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00137  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 72.7      |
|    n_updates            | 20900     |
|    policy_gradient_loss | -4.24e-09 |
|    value_loss           | 178       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.3     |
|    ep_rew_mean          | -8.86    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2092     |
|    time_elapsed         | 6953     |
|    total_timesteps      | 267776   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00137 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 75.5     |
|    n_updates            | 20910    |
|    policy_gradient_loss | 2.75e-09 |
|    value_loss           | 107      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.7      |
|    ep_rew_mean          | -8.96     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2093      |
|    time_elapsed         | 6956      |
|    total_timesteps      | 267904    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00138  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 89        |
|    n_updates            | 20920     |
|    policy_gradient_loss | -3.89e-09 |
|    value_loss           | 138       |
---------------------------------------
Num timesteps: 268000
Best mean reward: -0.99 - Last mean reward per episode: -8.70
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.1      |
|    ep_rew_mean          | -9.06     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2094      |
|    time_elapsed         | 6960      |
|    total_timesteps      | 268032    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00138  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 50.7      |
|    n_updates            | 20930     |
|    policy_gradient_loss | -4.66e-11 |
|    value_loss           | 128       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.7     |
|    ep_rew_mean          | -8.76    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2095     |
|    time_elapsed         | 6964     |
|    total_timesteps      | 268160   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00138 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 49.9     |
|    n_updates            | 20940    |
|    policy_gradient_loss | 1.07e-09 |
|    value_loss           | 106      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88        |
|    ep_rew_mean          | -8.88     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2096      |
|    time_elapsed         | 6967      |
|    total_timesteps      | 268288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00139  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 59.8      |
|    n_updates            | 20950     |
|    policy_gradient_loss | -2.84e-09 |
|    value_loss           | 108       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.5     |
|    ep_rew_mean          | -8.73    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2097     |
|    time_elapsed         | 6970     |
|    total_timesteps      | 268416   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0014  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 56.4     |
|    n_updates            | 20960    |
|    policy_gradient_loss | 8.38e-10 |
|    value_loss           | 101      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.2     |
|    ep_rew_mean          | -8.51    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2098     |
|    time_elapsed         | 6974     |
|    total_timesteps      | 268544   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00141 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 53.6     |
|    n_updates            | 20970    |
|    policy_gradient_loss | 2.33e-10 |
|    value_loss           | 100      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.3     |
|    ep_rew_mean          | -8.53    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2099     |
|    time_elapsed         | 6978     |
|    total_timesteps      | 268672   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00143 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 141      |
|    n_updates            | 20980    |
|    policy_gradient_loss | 7.92e-10 |
|    value_loss           | 220      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.9      |
|    ep_rew_mean          | -8.16     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2100      |
|    time_elapsed         | 6981      |
|    total_timesteps      | 268800    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00143  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47        |
|    n_updates            | 20990     |
|    policy_gradient_loss | -1.84e-09 |
|    value_loss           | 91.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.7     |
|    ep_rew_mean          | -8.72    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2101     |
|    time_elapsed         | 6985     |
|    total_timesteps      | 268928   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00144 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 70.7     |
|    n_updates            | 21000    |
|    policy_gradient_loss | 1.21e-09 |
|    value_loss           | 157      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 269000
Best mean reward: -0.99 - Last mean reward per episode: -9.29
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.7     |
|    ep_rew_mean          | -8.62    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2102     |
|    time_elapsed         | 6988     |
|    total_timesteps      | 269056   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00145 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 49.3     |
|    n_updates            | 21010    |
|    policy_gradient_loss | -2e-09   |
|    value_loss           | 92.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.7      |
|    ep_rew_mean          | -8.62     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2103      |
|    time_elapsed         | 6991      |
|    total_timesteps      | 269184    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00146  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 48.9      |
|    n_updates            | 21020     |
|    policy_gradient_loss | -2.14e-09 |
|    value_loss           | 111       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.7     |
|    ep_rew_mean          | -8.62    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2104     |
|    time_elapsed         | 6994     |
|    total_timesteps      | 269312   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00147 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 28.8     |
|    n_updates            | 21030    |
|    policy_gradient_loss | 2.89e-08 |
|    value_loss           | 58.5     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.7      |
|    ep_rew_mean          | -8.62     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2105      |
|    time_elapsed         | 6997      |
|    total_timesteps      | 269440    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00147  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 28.9      |
|    n_updates            | 21040     |
|    policy_gradient_loss | -7.19e-08 |
|    value_loss           | 57.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.7      |
|    ep_rew_mean          | -8.62     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2106      |
|    time_elapsed         | 7000      |
|    total_timesteps      | 269568    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00147  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 27.4      |
|    n_updates            | 21050     |
|    policy_gradient_loss | -5.68e-08 |
|    value_loss           | 56.8      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.7     |
|    ep_rew_mean          | -8.62    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2107     |
|    time_elapsed         | 7004     |
|    total_timesteps      | 269696   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00147 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 26.7     |
|    n_updates            | 21060    |
|    policy_gradient_loss | 6.04e-08 |
|    value_loss           | 56       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.7      |
|    ep_rew_mean          | -8.62     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2108      |
|    time_elapsed         | 7007      |
|    total_timesteps      | 269824    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00147  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 28.6      |
|    n_updates            | 21070     |
|    policy_gradient_loss | 5.82e-10  |
|    value_loss           | 55.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.7     |
|    ep_rew_mean          | -8.62    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2109     |
|    time_elapsed         | 7010     |
|    total_timesteps      | 269952   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00147 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 25.4     |
|    n_updates            | 21080    |
|    policy_gradient_loss | 3.13e-08 |
|    value_loss           | 54.4     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 270000
Best mean reward: -0.99 - Last mean reward per episode: -14.39
Eval num_timesteps=270000, episode_reward=-25.60 +/- 37.50
Episode length: 119.20 +/- 66.26
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 119      |
|    mean_reward          | -25.6    |
| time/                   |          |
|    total_timesteps      | 270000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00148 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 25.5     |
|    n_updates            | 21090    |
|    policy_gradient_loss | 5.03e-09 |
|    value_loss           | 53.7     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 96.9     |
|    ep_rew_mean     | -13.6    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2110     |
|    time_elapsed    | 7016     |
|    total_timesteps | 270080   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 97       |
|    ep_rew_mean          | -13.6    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2111     |
|    time_elapsed         | 7019     |
|    total_timesteps      | 270208   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00148 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.8     |
|    n_updates            | 21100    |
|    policy_gradient_loss | 2.35e-09 |
|    value_loss           | 69.7     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 97.1     |
|    ep_rew_mean          | -13.9    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2112     |
|    time_elapsed         | 7021     |
|    total_timesteps      | 270336   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00148 |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 48.5     |
|    n_updates            | 21110    |
|    policy_gradient_loss | 4.66e-11 |
|    value_loss           | 105      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.2      |
|    ep_rew_mean          | -8.8      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2113      |
|    time_elapsed         | 7024      |
|    total_timesteps      | 270464    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00149  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 57.3      |
|    n_updates            | 21120     |
|    policy_gradient_loss | -1.44e-09 |
|    value_loss           | 107       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.2     |
|    ep_rew_mean          | -8.89    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2114     |
|    time_elapsed         | 7026     |
|    total_timesteps      | 270592   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00149 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 64.9     |
|    n_updates            | 21130    |
|    policy_gradient_loss | 3.66e-09 |
|    value_loss           | 138      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.4      |
|    ep_rew_mean          | -8.4      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2115      |
|    time_elapsed         | 7029      |
|    total_timesteps      | 270720    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0015   |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 63.4      |
|    n_updates            | 21140     |
|    policy_gradient_loss | -7.31e-09 |
|    value_loss           | 136       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.7      |
|    ep_rew_mean          | -8.53     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2116      |
|    time_elapsed         | 7033      |
|    total_timesteps      | 270848    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0015   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 60.2      |
|    n_updates            | 21150     |
|    policy_gradient_loss | -4.66e-10 |
|    value_loss           | 183       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.1     |
|    ep_rew_mean          | -9.05    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2117     |
|    time_elapsed         | 7036     |
|    total_timesteps      | 270976   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0015  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 29.5     |
|    n_updates            | 21160    |
|    policy_gradient_loss | 3.54e-09 |
|    value_loss           | 73.4     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 271000
Best mean reward: -0.99 - Last mean reward per episode: -10.38
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.2      |
|    ep_rew_mean          | -9.18     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2118      |
|    time_elapsed         | 7040      |
|    total_timesteps      | 271104    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00151  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 82.7      |
|    n_updates            | 21170     |
|    policy_gradient_loss | -8.85e-10 |
|    value_loss           | 142       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.2     |
|    ep_rew_mean          | -9.2     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2119     |
|    time_elapsed         | 7043     |
|    total_timesteps      | 271232   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00152 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 49.2     |
|    n_updates            | 21180    |
|    policy_gradient_loss | 2.79e-10 |
|    value_loss           | 101      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.5      |
|    ep_rew_mean          | -8.86     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2120      |
|    time_elapsed         | 7048      |
|    total_timesteps      | 271360    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00153  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 57        |
|    n_updates            | 21190     |
|    policy_gradient_loss | 4.42e-09  |
|    value_loss           | 108       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | -8.47     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2121      |
|    time_elapsed         | 7051      |
|    total_timesteps      | 271488    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00155  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 95.3      |
|    n_updates            | 21200     |
|    policy_gradient_loss | -4.59e-09 |
|    value_loss           | 183       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | -8.43     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2122      |
|    time_elapsed         | 7055      |
|    total_timesteps      | 271616    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00156  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 135       |
|    n_updates            | 21210     |
|    policy_gradient_loss | -3.49e-11 |
|    value_loss           | 227       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.4      |
|    ep_rew_mean          | -8.3      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2123      |
|    time_elapsed         | 7058      |
|    total_timesteps      | 271744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00156  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.3      |
|    n_updates            | 21220     |
|    policy_gradient_loss | -4.52e-09 |
|    value_loss           | 90.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.3      |
|    ep_rew_mean          | -8.17     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2124      |
|    time_elapsed         | 7062      |
|    total_timesteps      | 271872    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00157  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.4      |
|    n_updates            | 21230     |
|    policy_gradient_loss | -1.82e-09 |
|    value_loss           | 88.8      |
---------------------------------------
Num timesteps: 272000
Best mean reward: -0.99 - Last mean reward per episode: -10.14
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.4      |
|    ep_rew_mean          | -8.21     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2125      |
|    time_elapsed         | 7065      |
|    total_timesteps      | 272000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00158  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.9      |
|    n_updates            | 21240     |
|    policy_gradient_loss | -2.37e-09 |
|    value_loss           | 125       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.8     |
|    ep_rew_mean          | -8.62    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2126     |
|    time_elapsed         | 7068     |
|    total_timesteps      | 272128   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00159 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 33.2     |
|    n_updates            | 21250    |
|    policy_gradient_loss | 3.98e-09 |
|    value_loss           | 70.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.7     |
|    ep_rew_mean          | -8.66    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2127     |
|    time_elapsed         | 7071     |
|    total_timesteps      | 272256   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0016  |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 53       |
|    n_updates            | 21260    |
|    policy_gradient_loss | 4.24e-09 |
|    value_loss           | 107      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.2      |
|    ep_rew_mean          | -8.78     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2128      |
|    time_elapsed         | 7075      |
|    total_timesteps      | 272384    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00161  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.7      |
|    n_updates            | 21270     |
|    policy_gradient_loss | -5.19e-09 |
|    value_loss           | 70.4      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.7     |
|    ep_rew_mean          | -8.54    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2129     |
|    time_elapsed         | 7078     |
|    total_timesteps      | 272512   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00162 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 114      |
|    n_updates            | 21280    |
|    policy_gradient_loss | 5.08e-09 |
|    value_loss           | 176      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.9      |
|    ep_rew_mean          | -8.65     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2130      |
|    time_elapsed         | 7081      |
|    total_timesteps      | 272640    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00162  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 58        |
|    n_updates            | 21290     |
|    policy_gradient_loss | -8.61e-10 |
|    value_loss           | 131       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86        |
|    ep_rew_mean          | -8.62     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2131      |
|    time_elapsed         | 7084      |
|    total_timesteps      | 272768    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00164  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63        |
|    n_updates            | 21300     |
|    policy_gradient_loss | -6.59e-09 |
|    value_loss           | 134       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.4      |
|    ep_rew_mean          | -8.78     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2132      |
|    time_elapsed         | 7088      |
|    total_timesteps      | 272896    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00166  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 45.8      |
|    n_updates            | 21310     |
|    policy_gradient_loss | 6.43e-09  |
|    value_loss           | 106       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 273000
Best mean reward: -0.99 - Last mean reward per episode: -9.90
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.5     |
|    ep_rew_mean          | -8.73    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2133     |
|    time_elapsed         | 7092     |
|    total_timesteps      | 273024   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00167 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 50.7     |
|    n_updates            | 21320    |
|    policy_gradient_loss | 1.44e-09 |
|    value_loss           | 112      |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 85.8         |
|    ep_rew_mean          | -8.59        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 2134         |
|    time_elapsed         | 7095         |
|    total_timesteps      | 273152       |
| train/                  |              |
|    approx_kl            | 0.0009739464 |
|    clip_fraction        | 0.00625      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00125     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 89.4         |
|    n_updates            | 21330        |
|    policy_gradient_loss | -0.00092     |
|    value_loss           | 171          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.3      |
|    ep_rew_mean          | -8.84     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2135      |
|    time_elapsed         | 7098      |
|    total_timesteps      | 273280    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000994 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.1      |
|    n_updates            | 21340     |
|    policy_gradient_loss | 1.54e-09  |
|    value_loss           | 91.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.3      |
|    ep_rew_mean          | -8.84     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2136      |
|    time_elapsed         | 7101      |
|    total_timesteps      | 273408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00097  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 31.4      |
|    n_updates            | 21350     |
|    policy_gradient_loss | -1.03e-08 |
|    value_loss           | 73.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.3      |
|    ep_rew_mean          | -9.36     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2137      |
|    time_elapsed         | 7105      |
|    total_timesteps      | 273536    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000969 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.3      |
|    n_updates            | 21360     |
|    policy_gradient_loss | 1.21e-09  |
|    value_loss           | 76.1      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87       |
|    ep_rew_mean          | -9.22    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2138     |
|    time_elapsed         | 7108     |
|    total_timesteps      | 273664   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00097 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 46       |
|    n_updates            | 21370    |
|    policy_gradient_loss | 2.56e-09 |
|    value_loss           | 96.5     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.5      |
|    ep_rew_mean          | -9.32     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2139      |
|    time_elapsed         | 7111      |
|    total_timesteps      | 273792    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000974 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.3      |
|    n_updates            | 21380     |
|    policy_gradient_loss | 1.58e-09  |
|    value_loss           | 91        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.3      |
|    ep_rew_mean          | -9.36     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2140      |
|    time_elapsed         | 7116      |
|    total_timesteps      | 273920    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000979 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 76.7      |
|    n_updates            | 21390     |
|    policy_gradient_loss | 2.75e-09  |
|    value_loss           | 158       |
---------------------------------------
Num timesteps: 274000
Best mean reward: -0.99 - Last mean reward per episode: -10.29
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.3      |
|    ep_rew_mean          | -9.35     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2141      |
|    time_elapsed         | 7119      |
|    total_timesteps      | 274048    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000986 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.7      |
|    n_updates            | 21400     |
|    policy_gradient_loss | 2.75e-09  |
|    value_loss           | 77        |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.7      |
|    ep_rew_mean          | -9.54     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2142      |
|    time_elapsed         | 7122      |
|    total_timesteps      | 274176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000993 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 98.1      |
|    n_updates            | 21410     |
|    policy_gradient_loss | -1.58e-09 |
|    value_loss           | 154       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.4      |
|    ep_rew_mean          | -9.41     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2143      |
|    time_elapsed         | 7125      |
|    total_timesteps      | 274304    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.001    |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 36.5      |
|    n_updates            | 21420     |
|    policy_gradient_loss | 1.16e-09  |
|    value_loss           | 70.6      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.7     |
|    ep_rew_mean          | -9.57    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2144     |
|    time_elapsed         | 7128     |
|    total_timesteps      | 274432   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.001   |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 67.4     |
|    n_updates            | 21430    |
|    policy_gradient_loss | 2.28e-09 |
|    value_loss           | 122      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.9     |
|    ep_rew_mean          | -9.44    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2145     |
|    time_elapsed         | 7132     |
|    total_timesteps      | 274560   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00101 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 37.3     |
|    n_updates            | 21440    |
|    policy_gradient_loss | 4.28e-09 |
|    value_loss           | 78.5     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.6      |
|    ep_rew_mean          | -9.19     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2146      |
|    time_elapsed         | 7135      |
|    total_timesteps      | 274688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00101  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26.5      |
|    n_updates            | 21450     |
|    policy_gradient_loss | -2.51e-09 |
|    value_loss           | 121       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.6     |
|    ep_rew_mean          | -9.31    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2147     |
|    time_elapsed         | 7138     |
|    total_timesteps      | 274816   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00101 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 105      |
|    n_updates            | 21460    |
|    policy_gradient_loss | 2.47e-09 |
|    value_loss           | 182      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.2      |
|    ep_rew_mean          | -9.12     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2148      |
|    time_elapsed         | 7141      |
|    total_timesteps      | 274944    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00102  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 89.3      |
|    n_updates            | 21470     |
|    policy_gradient_loss | 5.54e-09  |
|    value_loss           | 177       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 275000
Best mean reward: -0.99 - Last mean reward per episode: -10.08
Eval num_timesteps=275000, episode_reward=-14.00 +/- 12.68
Episode length: 92.00 +/- 32.54
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 92        |
|    mean_reward          | -14       |
| time/                   |           |
|    total_timesteps      | 275000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00103  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 54.6      |
|    n_updates            | 21480     |
|    policy_gradient_loss | -5.68e-09 |
|    value_loss           | 102       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 86.4     |
|    ep_rew_mean     | -8.81    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2149     |
|    time_elapsed    | 7146     |
|    total_timesteps | 275072   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.4      |
|    ep_rew_mean          | -8.81     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2150      |
|    time_elapsed         | 7149      |
|    total_timesteps      | 275200    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00104  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.8      |
|    n_updates            | 21490     |
|    policy_gradient_loss | -4.14e-09 |
|    value_loss           | 77.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.8      |
|    ep_rew_mean          | -9.01     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2151      |
|    time_elapsed         | 7152      |
|    total_timesteps      | 275328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00105  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.5      |
|    n_updates            | 21500     |
|    policy_gradient_loss | -5.36e-09 |
|    value_loss           | 98.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.8      |
|    ep_rew_mean          | -9.01     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2152      |
|    time_elapsed         | 7155      |
|    total_timesteps      | 275456    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00105  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.9      |
|    n_updates            | 21510     |
|    policy_gradient_loss | -3.06e-09 |
|    value_loss           | 73.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.3     |
|    ep_rew_mean          | -9.13    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2153     |
|    time_elapsed         | 7158     |
|    total_timesteps      | 275584   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00105 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 51.9     |
|    n_updates            | 21520    |
|    policy_gradient_loss | 6.05e-10 |
|    value_loss           | 108      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.6     |
|    ep_rew_mean          | -8.31    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2154     |
|    time_elapsed         | 7161     |
|    total_timesteps      | 275712   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00106 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 89.2     |
|    n_updates            | 21530    |
|    policy_gradient_loss | 1.91e-09 |
|    value_loss           | 135      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.2      |
|    ep_rew_mean          | -8.09     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2155      |
|    time_elapsed         | 7165      |
|    total_timesteps      | 275840    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00107  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 56.4      |
|    n_updates            | 21540     |
|    policy_gradient_loss | -1.26e-09 |
|    value_loss           | 96.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.2      |
|    ep_rew_mean          | -8.29     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2156      |
|    time_elapsed         | 7168      |
|    total_timesteps      | 275968    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00107  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 66.5      |
|    n_updates            | 21550     |
|    policy_gradient_loss | -1.02e-08 |
|    value_loss           | 131       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 276000
Best mean reward: -0.99 - Last mean reward per episode: -9.69
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.9      |
|    ep_rew_mean          | -7.93     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2157      |
|    time_elapsed         | 7171      |
|    total_timesteps      | 276096    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00107  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.5      |
|    n_updates            | 21560     |
|    policy_gradient_loss | -1.26e-09 |
|    value_loss           | 75        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.6      |
|    ep_rew_mean          | -8.09     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2158      |
|    time_elapsed         | 7174      |
|    total_timesteps      | 276224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00107  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 70.7      |
|    n_updates            | 21570     |
|    policy_gradient_loss | 1.63e-09  |
|    value_loss           | 168       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.4      |
|    ep_rew_mean          | -8.58     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2159      |
|    time_elapsed         | 7177      |
|    total_timesteps      | 276352    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00108  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 47.4      |
|    n_updates            | 21580     |
|    policy_gradient_loss | -2.21e-09 |
|    value_loss           | 92.7      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85       |
|    ep_rew_mean          | -8.31    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2160     |
|    time_elapsed         | 7180     |
|    total_timesteps      | 276480   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00108 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 32.8     |
|    n_updates            | 21590    |
|    policy_gradient_loss | 2.61e-09 |
|    value_loss           | 79.1     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85       |
|    ep_rew_mean          | -8.38    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2161     |
|    time_elapsed         | 7183     |
|    total_timesteps      | 276608   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00109 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 52.9     |
|    n_updates            | 21600    |
|    policy_gradient_loss | 2e-09    |
|    value_loss           | 127      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.1     |
|    ep_rew_mean          | -7.96    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2162     |
|    time_elapsed         | 7187     |
|    total_timesteps      | 276736   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00109 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42       |
|    n_updates            | 21610    |
|    policy_gradient_loss | 2.33e-09 |
|    value_loss           | 76.8     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84       |
|    ep_rew_mean          | -7.88    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2163     |
|    time_elapsed         | 7190     |
|    total_timesteps      | 276864   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00109 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 89.1     |
|    n_updates            | 21620    |
|    policy_gradient_loss | -1.4e-10 |
|    value_loss           | 186      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.8      |
|    ep_rew_mean          | -7.8      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2164      |
|    time_elapsed         | 7193      |
|    total_timesteps      | 276992    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00109  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 53.2      |
|    n_updates            | 21630     |
|    policy_gradient_loss | -2.31e-09 |
|    value_loss           | 90.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 277000
Best mean reward: -0.99 - Last mean reward per episode: -4.68
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.9     |
|    ep_rew_mean          | -8.14    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2165     |
|    time_elapsed         | 7197     |
|    total_timesteps      | 277120   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0011  |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 36.3     |
|    n_updates            | 21640    |
|    policy_gradient_loss | 5.02e-09 |
|    value_loss           | 75.1     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.8     |
|    ep_rew_mean          | -7.91    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2166     |
|    time_elapsed         | 7200     |
|    total_timesteps      | 277248   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00111 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 61.7     |
|    n_updates            | 21650    |
|    policy_gradient_loss | 1.16e-09 |
|    value_loss           | 100      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.9     |
|    ep_rew_mean          | -8.13    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2167     |
|    time_elapsed         | 7204     |
|    total_timesteps      | 277376   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00112 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 59.4     |
|    n_updates            | 21660    |
|    policy_gradient_loss | 2.79e-09 |
|    value_loss           | 140      |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.9     |
|    ep_rew_mean          | -8.27    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2168     |
|    time_elapsed         | 7207     |
|    total_timesteps      | 277504   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00113 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 36.9     |
|    n_updates            | 21670    |
|    policy_gradient_loss | 2.98e-09 |
|    value_loss           | 91.7     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.6      |
|    ep_rew_mean          | -3.1      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2169      |
|    time_elapsed         | 7209      |
|    total_timesteps      | 277632    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00114  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.5      |
|    n_updates            | 21680     |
|    policy_gradient_loss | -2.24e-09 |
|    value_loss           | 95.1      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.8     |
|    ep_rew_mean          | -3.1     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2170     |
|    time_elapsed         | 7213     |
|    total_timesteps      | 277760   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00115 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 54.4     |
|    n_updates            | 21690    |
|    policy_gradient_loss | 2.89e-09 |
|    value_loss           | 153      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.3      |
|    ep_rew_mean          | -3.37     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2171      |
|    time_elapsed         | 7217      |
|    total_timesteps      | 277888    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00117  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 65.9      |
|    n_updates            | 21700     |
|    policy_gradient_loss | -1.09e-09 |
|    value_loss           | 132       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 278000
Best mean reward: -0.99 - Last mean reward per episode: -4.38
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.9     |
|    ep_rew_mean          | -3.63    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2172     |
|    time_elapsed         | 7220     |
|    total_timesteps      | 278016   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00119 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 31.6     |
|    n_updates            | 21710    |
|    policy_gradient_loss | 1.61e-08 |
|    value_loss           | 70.4     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.9     |
|    ep_rew_mean          | -3.44    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2173     |
|    time_elapsed         | 7223     |
|    total_timesteps      | 278144   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00119 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 37.2     |
|    n_updates            | 21720    |
|    policy_gradient_loss | 1.3e-09  |
|    value_loss           | 93.5     |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 76.1         |
|    ep_rew_mean          | -3.46        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 2174         |
|    time_elapsed         | 7227         |
|    total_timesteps      | 278272       |
| train/                  |              |
|    approx_kl            | 0.0025225477 |
|    clip_fraction        | 0.00625      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.000767    |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 79.6         |
|    n_updates            | 21730        |
|    policy_gradient_loss | -0.000768    |
|    value_loss           | 152          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.2      |
|    ep_rew_mean          | -3.52     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2175      |
|    time_elapsed         | 7231      |
|    total_timesteps      | 278400    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000473 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 69.5      |
|    n_updates            | 21740     |
|    policy_gradient_loss | -2.33e-10 |
|    value_loss           | 158       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.2      |
|    ep_rew_mean          | -3.69     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2176      |
|    time_elapsed         | 7234      |
|    total_timesteps      | 278528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000449 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 83.5      |
|    n_updates            | 21750     |
|    policy_gradient_loss | 8.48e-09  |
|    value_loss           | 124       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -3.59     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2177      |
|    time_elapsed         | 7237      |
|    total_timesteps      | 278656    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000447 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.4      |
|    n_updates            | 21760     |
|    policy_gradient_loss | -2.14e-09 |
|    value_loss           | 93.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.5      |
|    ep_rew_mean          | -3.73     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2178      |
|    time_elapsed         | 7240      |
|    total_timesteps      | 278784    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000447 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 40.6      |
|    n_updates            | 21770     |
|    policy_gradient_loss | -2.91e-09 |
|    value_loss           | 74.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.1      |
|    ep_rew_mean          | -3.43     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2179      |
|    time_elapsed         | 7243      |
|    total_timesteps      | 278912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000447 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 58.9      |
|    n_updates            | 21780     |
|    policy_gradient_loss | 1.12e-09  |
|    value_loss           | 169       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 279000
Best mean reward: -0.99 - Last mean reward per episode: -4.26
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.7      |
|    ep_rew_mean          | -3.43     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2180      |
|    time_elapsed         | 7246      |
|    total_timesteps      | 279040    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000448 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 120       |
|    n_updates            | 21790     |
|    policy_gradient_loss | 8.03e-09  |
|    value_loss           | 170       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.7      |
|    ep_rew_mean          | -3.63     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2181      |
|    time_elapsed         | 7249      |
|    total_timesteps      | 279168    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000448 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 52.6      |
|    n_updates            | 21800     |
|    policy_gradient_loss | -1.63e-10 |
|    value_loss           | 89        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -3.88     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2182      |
|    time_elapsed         | 7252      |
|    total_timesteps      | 279296    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000449 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.7      |
|    n_updates            | 21810     |
|    policy_gradient_loss | 2.97e-09  |
|    value_loss           | 86        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.3      |
|    ep_rew_mean          | -4.07     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2183      |
|    time_elapsed         | 7255      |
|    total_timesteps      | 279424    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00045  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.8      |
|    n_updates            | 21820     |
|    policy_gradient_loss | -1.56e-09 |
|    value_loss           | 92.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.3      |
|    ep_rew_mean          | -4.07     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2184      |
|    time_elapsed         | 7258      |
|    total_timesteps      | 279552    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000452 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47        |
|    n_updates            | 21830     |
|    policy_gradient_loss | -7.92e-10 |
|    value_loss           | 93.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.1      |
|    ep_rew_mean          | -4.47     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2185      |
|    time_elapsed         | 7262      |
|    total_timesteps      | 279680    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000453 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.4      |
|    n_updates            | 21840     |
|    policy_gradient_loss | 8.15e-09  |
|    value_loss           | 76.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.7      |
|    ep_rew_mean          | -4.26     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2186      |
|    time_elapsed         | 7264      |
|    total_timesteps      | 279808    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000454 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 52.4      |
|    n_updates            | 21850     |
|    policy_gradient_loss | 2.42e-09  |
|    value_loss           | 115       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.4      |
|    ep_rew_mean          | -3.89     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2187      |
|    time_elapsed         | 7267      |
|    total_timesteps      | 279936    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000455 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.6      |
|    n_updates            | 21860     |
|    policy_gradient_loss | 1.14e-08  |
|    value_loss           | 77.2      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 280000
Best mean reward: -0.99 - Last mean reward per episode: -5.04
Eval num_timesteps=280000, episode_reward=-12.80 +/- 23.55
Episode length: 93.60 +/- 52.92
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 93.6      |
|    mean_reward          | -12.8     |
| time/                   |           |
|    total_timesteps      | 280000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000456 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 85.8      |
|    n_updates            | 21870     |
|    policy_gradient_loss | -1.86e-09 |
|    value_loss           | 178       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 76.9     |
|    ep_rew_mean     | -4.16    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2188     |
|    time_elapsed    | 7273     |
|    total_timesteps | 280064   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.7      |
|    ep_rew_mean          | -4.26     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2189      |
|    time_elapsed         | 7276      |
|    total_timesteps      | 280192    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000456 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.7      |
|    n_updates            | 21880     |
|    policy_gradient_loss | -7.64e-09 |
|    value_loss           | 72.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.1      |
|    ep_rew_mean          | -4.54     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2190      |
|    time_elapsed         | 7279      |
|    total_timesteps      | 280320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000457 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.8      |
|    n_updates            | 21890     |
|    policy_gradient_loss | -3.19e-09 |
|    value_loss           | 93.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.3      |
|    ep_rew_mean          | -4.74     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2191      |
|    time_elapsed         | 7282      |
|    total_timesteps      | 280448    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000458 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 58.4      |
|    n_updates            | 21900     |
|    policy_gradient_loss | -3.68e-09 |
|    value_loss           | 103       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.9      |
|    ep_rew_mean          | -4.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2192      |
|    time_elapsed         | 7285      |
|    total_timesteps      | 280576    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000461 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 28.5      |
|    n_updates            | 21910     |
|    policy_gradient_loss | 2e-09     |
|    value_loss           | 71.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.8      |
|    ep_rew_mean          | -4.5      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2193      |
|    time_elapsed         | 7289      |
|    total_timesteps      | 280704    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000462 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 40.8      |
|    n_updates            | 21920     |
|    policy_gradient_loss | -2.47e-09 |
|    value_loss           | 91        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77        |
|    ep_rew_mean          | -4.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2194      |
|    time_elapsed         | 7292      |
|    total_timesteps      | 280832    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000464 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 126       |
|    n_updates            | 21930     |
|    policy_gradient_loss | -2.42e-09 |
|    value_loss           | 170       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77        |
|    ep_rew_mean          | -4.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2195      |
|    time_elapsed         | 7295      |
|    total_timesteps      | 280960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000465 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49        |
|    n_updates            | 21940     |
|    policy_gradient_loss | -5.77e-09 |
|    value_loss           | 105       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 281000
Best mean reward: -0.99 - Last mean reward per episode: -4.64
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77        |
|    ep_rew_mean          | -4.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2196      |
|    time_elapsed         | 7300      |
|    total_timesteps      | 281088    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000466 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 28.6      |
|    n_updates            | 21950     |
|    policy_gradient_loss | 6.89e-08  |
|    value_loss           | 57        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80        |
|    ep_rew_mean          | -6.1      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2197      |
|    time_elapsed         | 7305      |
|    total_timesteps      | 281216    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000467 |
|    explained_variance   | 2.38e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 26.3      |
|    n_updates            | 21960     |
|    policy_gradient_loss | -2.02e-08 |
|    value_loss           | 54.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -5.86     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2198      |
|    time_elapsed         | 7310      |
|    total_timesteps      | 281344    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000467 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 76.7      |
|    n_updates            | 21970     |
|    policy_gradient_loss | 3.63e-09  |
|    value_loss           | 168       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.5     |
|    ep_rew_mean          | -5.17    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2199     |
|    time_elapsed         | 7313     |
|    total_timesteps      | 281472   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00047 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 47.6     |
|    n_updates            | 21980    |
|    policy_gradient_loss | 2.33e-10 |
|    value_loss           | 100      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.9      |
|    ep_rew_mean          | -5.25     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2200      |
|    time_elapsed         | 7316      |
|    total_timesteps      | 281600    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000472 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 104       |
|    n_updates            | 21990     |
|    policy_gradient_loss | -3.26e-10 |
|    value_loss           | 185       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -5.37     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2201      |
|    time_elapsed         | 7320      |
|    total_timesteps      | 281728    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000472 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 66.1      |
|    n_updates            | 22000     |
|    policy_gradient_loss | 5.33e-09  |
|    value_loss           | 109       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.8      |
|    ep_rew_mean          | -4.8      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2202      |
|    time_elapsed         | 7323      |
|    total_timesteps      | 281856    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000474 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.4      |
|    n_updates            | 22010     |
|    policy_gradient_loss | 1.58e-09  |
|    value_loss           | 101       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.9      |
|    ep_rew_mean          | -4.43     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2203      |
|    time_elapsed         | 7326      |
|    total_timesteps      | 281984    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000475 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 67.2      |
|    n_updates            | 22020     |
|    policy_gradient_loss | 6.52e-09  |
|    value_loss           | 142       |
---------------------------------------
Num timesteps: 282000
Best mean reward: -0.99 - Last mean reward per episode: -6.00
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.9      |
|    ep_rew_mean          | -4.56     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2204      |
|    time_elapsed         | 7328      |
|    total_timesteps      | 282112    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000476 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 64.5      |
|    n_updates            | 22030     |
|    policy_gradient_loss | 5.63e-09  |
|    value_loss           | 142       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.9      |
|    ep_rew_mean          | -4.47     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2205      |
|    time_elapsed         | 7331      |
|    total_timesteps      | 282240    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000476 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.7      |
|    n_updates            | 22040     |
|    policy_gradient_loss | 1.14e-09  |
|    value_loss           | 83.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.8      |
|    ep_rew_mean          | -4.39     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2206      |
|    time_elapsed         | 7334      |
|    total_timesteps      | 282368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000477 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 62.4      |
|    n_updates            | 22050     |
|    policy_gradient_loss | 4.1e-09   |
|    value_loss           | 141       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.9      |
|    ep_rew_mean          | -4.64     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2207      |
|    time_elapsed         | 7337      |
|    total_timesteps      | 282496    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000478 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 106       |
|    n_updates            | 22060     |
|    policy_gradient_loss | -6.52e-10 |
|    value_loss           | 170       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.7      |
|    ep_rew_mean          | -4.66     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2208      |
|    time_elapsed         | 7340      |
|    total_timesteps      | 282624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000481 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.4      |
|    n_updates            | 22070     |
|    policy_gradient_loss | -3.73e-09 |
|    value_loss           | 94.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -4.91     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2209      |
|    time_elapsed         | 7343      |
|    total_timesteps      | 282752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000483 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 72.6      |
|    n_updates            | 22080     |
|    policy_gradient_loss | 2.56e-09  |
|    value_loss           | 126       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.3      |
|    ep_rew_mean          | -4.86     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2210      |
|    time_elapsed         | 7347      |
|    total_timesteps      | 282880    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000485 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 51.7      |
|    n_updates            | 22090     |
|    policy_gradient_loss | -2.79e-09 |
|    value_loss           | 96        |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 283000
Best mean reward: -0.99 - Last mean reward per episode: -5.12
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.4      |
|    ep_rew_mean          | -4.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2211      |
|    time_elapsed         | 7350      |
|    total_timesteps      | 283008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000486 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 68.5      |
|    n_updates            | 22100     |
|    policy_gradient_loss | 5.42e-09  |
|    value_loss           | 130       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.3      |
|    ep_rew_mean          | -5.26     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2212      |
|    time_elapsed         | 7353      |
|    total_timesteps      | 283136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000487 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 51.1      |
|    n_updates            | 22110     |
|    policy_gradient_loss | -5.59e-10 |
|    value_loss           | 109       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.9      |
|    ep_rew_mean          | -5.45     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2213      |
|    time_elapsed         | 7356      |
|    total_timesteps      | 283264    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000488 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 36.4      |
|    n_updates            | 22120     |
|    policy_gradient_loss | 1.07e-09  |
|    value_loss           | 81.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.4      |
|    ep_rew_mean          | -5.12     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2214      |
|    time_elapsed         | 7360      |
|    total_timesteps      | 283392    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000488 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.1      |
|    n_updates            | 22130     |
|    policy_gradient_loss | 2.14e-09  |
|    value_loss           | 112       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.4     |
|    ep_rew_mean          | -5.09    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2215     |
|    time_elapsed         | 7363     |
|    total_timesteps      | 283520   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00049 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 112      |
|    n_updates            | 22140    |
|    policy_gradient_loss | 2.33e-09 |
|    value_loss           | 186      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.7      |
|    ep_rew_mean          | -5.24     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2216      |
|    time_elapsed         | 7366      |
|    total_timesteps      | 283648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000491 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 48.3      |
|    n_updates            | 22150     |
|    policy_gradient_loss | -3.68e-09 |
|    value_loss           | 100       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.6      |
|    ep_rew_mean          | -5.08     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2217      |
|    time_elapsed         | 7369      |
|    total_timesteps      | 283776    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000492 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.4      |
|    n_updates            | 22160     |
|    policy_gradient_loss | 1.26e-09  |
|    value_loss           | 97.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78        |
|    ep_rew_mean          | -4.8      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2218      |
|    time_elapsed         | 7372      |
|    total_timesteps      | 283904    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000493 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 95.8      |
|    n_updates            | 22170     |
|    policy_gradient_loss | 2.84e-09  |
|    value_loss           | 177       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 284000
Best mean reward: -0.99 - Last mean reward per episode: -5.13
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.9      |
|    ep_rew_mean          | -4.74     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2219      |
|    time_elapsed         | 7375      |
|    total_timesteps      | 284032    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000493 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 94.6      |
|    n_updates            | 22180     |
|    policy_gradient_loss | -9.08e-10 |
|    value_loss           | 175       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.7      |
|    ep_rew_mean          | -4.42     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2220      |
|    time_elapsed         | 7378      |
|    total_timesteps      | 284160    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000494 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 61.7      |
|    n_updates            | 22190     |
|    policy_gradient_loss | -8.5e-10  |
|    value_loss           | 88.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.7      |
|    ep_rew_mean          | -4.57     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2221      |
|    time_elapsed         | 7381      |
|    total_timesteps      | 284288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000495 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.6      |
|    n_updates            | 22200     |
|    policy_gradient_loss | -4.05e-09 |
|    value_loss           | 152       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.2      |
|    ep_rew_mean          | -4.79     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2222      |
|    time_elapsed         | 7384      |
|    total_timesteps      | 284416    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000497 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.2      |
|    n_updates            | 22210     |
|    policy_gradient_loss | 1.77e-09  |
|    value_loss           | 78.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.5      |
|    ep_rew_mean          | -4.96     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2223      |
|    time_elapsed         | 7389      |
|    total_timesteps      | 284544    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000498 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.7      |
|    n_updates            | 22220     |
|    policy_gradient_loss | -2.08e-08 |
|    value_loss           | 78.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.7      |
|    ep_rew_mean          | -4.96     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2224      |
|    time_elapsed         | 7392      |
|    total_timesteps      | 284672    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000499 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 69.7      |
|    n_updates            | 22230     |
|    policy_gradient_loss | -2.97e-09 |
|    value_loss           | 165       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.7      |
|    ep_rew_mean          | -4.96     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2225      |
|    time_elapsed         | 7394      |
|    total_timesteps      | 284800    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000502 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 71.6      |
|    n_updates            | 22240     |
|    policy_gradient_loss | -9.78e-10 |
|    value_loss           | 135       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.9      |
|    ep_rew_mean          | -5.05     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2226      |
|    time_elapsed         | 7397      |
|    total_timesteps      | 284928    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000505 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 51.5      |
|    n_updates            | 22250     |
|    policy_gradient_loss | 6.85e-09  |
|    value_loss           | 92.1      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 285000
Best mean reward: -0.99 - Last mean reward per episode: -5.41
Eval num_timesteps=285000, episode_reward=-6.90 +/- 19.02
Episode length: 81.80 +/- 28.46
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 81.8      |
|    mean_reward          | -6.9      |
| time/                   |           |
|    total_timesteps      | 285000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000507 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 42.6      |
|    n_updates            | 22260     |
|    policy_gradient_loss | -4.28e-09 |
|    value_loss           | 86.5      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 78.9     |
|    ep_rew_mean     | -5.05    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2227     |
|    time_elapsed    | 7404     |
|    total_timesteps | 285056   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.6      |
|    ep_rew_mean          | -4.9      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2228      |
|    time_elapsed         | 7408      |
|    total_timesteps      | 285184    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000507 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 25.6      |
|    n_updates            | 22270     |
|    policy_gradient_loss | 1.73e-08  |
|    value_loss           | 56.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.2      |
|    ep_rew_mean          | -5.42     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2229      |
|    time_elapsed         | 7411      |
|    total_timesteps      | 285312    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000507 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 44.1      |
|    n_updates            | 22280     |
|    policy_gradient_loss | -1.12e-08 |
|    value_loss           | 86.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -5.26     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2230      |
|    time_elapsed         | 7414      |
|    total_timesteps      | 285440    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000509 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 56.2      |
|    n_updates            | 22290     |
|    policy_gradient_loss | -7.17e-09 |
|    value_loss           | 105       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -5.26     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2231      |
|    time_elapsed         | 7418      |
|    total_timesteps      | 285568    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000512 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 70.1      |
|    n_updates            | 22300     |
|    policy_gradient_loss | 3.98e-09  |
|    value_loss           | 137       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79        |
|    ep_rew_mean          | -5.29     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2232      |
|    time_elapsed         | 7421      |
|    total_timesteps      | 285696    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000513 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.1      |
|    n_updates            | 22310     |
|    policy_gradient_loss | -4.47e-09 |
|    value_loss           | 95.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.8      |
|    ep_rew_mean          | -5.29     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2233      |
|    time_elapsed         | 7424      |
|    total_timesteps      | 285824    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000514 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45.8      |
|    n_updates            | 22320     |
|    policy_gradient_loss | -2.71e-09 |
|    value_loss           | 130       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.7      |
|    ep_rew_mean          | -5.23     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2234      |
|    time_elapsed         | 7427      |
|    total_timesteps      | 285952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000515 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 27.6      |
|    n_updates            | 22330     |
|    policy_gradient_loss | -2.28e-09 |
|    value_loss           | 79.8      |
---------------------------------------
Num timesteps: 286000
Best mean reward: -0.99 - Last mean reward per episode: -5.99
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.7      |
|    ep_rew_mean          | -5.23     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2235      |
|    time_elapsed         | 7430      |
|    total_timesteps      | 286080    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000517 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50        |
|    n_updates            | 22340     |
|    policy_gradient_loss | -3.73e-09 |
|    value_loss           | 101       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.7      |
|    ep_rew_mean          | -5.23     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2236      |
|    time_elapsed         | 7434      |
|    total_timesteps      | 286208    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000521 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 25.5      |
|    n_updates            | 22350     |
|    policy_gradient_loss | 1.05e-08  |
|    value_loss           | 56.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.7      |
|    ep_rew_mean          | -5.23     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2237      |
|    time_elapsed         | 7437      |
|    total_timesteps      | 286336    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000522 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26.2      |
|    n_updates            | 22360     |
|    policy_gradient_loss | -3.95e-08 |
|    value_loss           | 55        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.1      |
|    ep_rew_mean          | -7.46     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2238      |
|    time_elapsed         | 7441      |
|    total_timesteps      | 286464    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000523 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 25.4      |
|    n_updates            | 22370     |
|    policy_gradient_loss | -5.78e-08 |
|    value_loss           | 54        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.8      |
|    ep_rew_mean          | -7.52     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2239      |
|    time_elapsed         | 7445      |
|    total_timesteps      | 286592    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000523 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.9      |
|    n_updates            | 22380     |
|    policy_gradient_loss | -1.09e-09 |
|    value_loss           | 80.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.8      |
|    ep_rew_mean          | -7.52     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2240      |
|    time_elapsed         | 7448      |
|    total_timesteps      | 286720    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000524 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 51.4      |
|    n_updates            | 22390     |
|    policy_gradient_loss | -7.45e-10 |
|    value_loss           | 102       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.6      |
|    ep_rew_mean          | -8.12     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2241      |
|    time_elapsed         | 7451      |
|    total_timesteps      | 286848    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000524 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.6      |
|    n_updates            | 22400     |
|    policy_gradient_loss | 5.68e-09  |
|    value_loss           | 79.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.8      |
|    ep_rew_mean          | -8.31     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2242      |
|    time_elapsed         | 7454      |
|    total_timesteps      | 286976    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000525 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.4      |
|    n_updates            | 22410     |
|    policy_gradient_loss | 4.66e-09  |
|    value_loss           | 74        |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 287000
Best mean reward: -0.99 - Last mean reward per episode: -9.26
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.9      |
|    ep_rew_mean          | -8.36     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2243      |
|    time_elapsed         | 7457      |
|    total_timesteps      | 287104    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000526 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 66.9      |
|    n_updates            | 22420     |
|    policy_gradient_loss | -6.38e-09 |
|    value_loss           | 110       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.2      |
|    ep_rew_mean          | -8.4      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2244      |
|    time_elapsed         | 7461      |
|    total_timesteps      | 287232    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000526 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.5      |
|    n_updates            | 22430     |
|    policy_gradient_loss | -3.89e-09 |
|    value_loss           | 78.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.7      |
|    ep_rew_mean          | -8.35     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2245      |
|    time_elapsed         | 7464      |
|    total_timesteps      | 287360    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000528 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 81.4      |
|    n_updates            | 22440     |
|    policy_gradient_loss | 1.16e-09  |
|    value_loss           | 150       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.8      |
|    ep_rew_mean          | -8.6      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2246      |
|    time_elapsed         | 7467      |
|    total_timesteps      | 287488    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000531 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 66.6      |
|    n_updates            | 22450     |
|    policy_gradient_loss | -5.36e-10 |
|    value_loss           | 114       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.8      |
|    ep_rew_mean          | -8.59     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2247      |
|    time_elapsed         | 7469      |
|    total_timesteps      | 287616    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000533 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.9      |
|    n_updates            | 22460     |
|    policy_gradient_loss | 3.82e-09  |
|    value_loss           | 101       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.2      |
|    ep_rew_mean          | -8.7      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2248      |
|    time_elapsed         | 7473      |
|    total_timesteps      | 287744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000534 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.1      |
|    n_updates            | 22470     |
|    policy_gradient_loss | 2.79e-10  |
|    value_loss           | 82.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.8      |
|    ep_rew_mean          | -8.31     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2249      |
|    time_elapsed         | 7476      |
|    total_timesteps      | 287872    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000535 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 53.3      |
|    n_updates            | 22480     |
|    policy_gradient_loss | 2.61e-09  |
|    value_loss           | 114       |
---------------------------------------
Num timesteps: 288000
Best mean reward: -0.99 - Last mean reward per episode: -8.64
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.9     |
|    ep_rew_mean          | -8.24    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2250     |
|    time_elapsed         | 7480     |
|    total_timesteps      | 288000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00054 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 86.8     |
|    n_updates            | 22490    |
|    policy_gradient_loss | 1.89e-09 |
|    value_loss           | 152      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.5      |
|    ep_rew_mean          | -8.17     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2251      |
|    time_elapsed         | 7484      |
|    total_timesteps      | 288128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000544 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 77.4      |
|    n_updates            | 22500     |
|    policy_gradient_loss | -6.24e-09 |
|    value_loss           | 144       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.2      |
|    ep_rew_mean          | -7.98     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2252      |
|    time_elapsed         | 7487      |
|    total_timesteps      | 288256    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000545 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 46.6      |
|    n_updates            | 22510     |
|    policy_gradient_loss | 6.98e-11  |
|    value_loss           | 101       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.1      |
|    ep_rew_mean          | -8.13     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2253      |
|    time_elapsed         | 7490      |
|    total_timesteps      | 288384    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000546 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.4      |
|    n_updates            | 22520     |
|    policy_gradient_loss | 2.49e-09  |
|    value_loss           | 77        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.4      |
|    ep_rew_mean          | -7.71     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2254      |
|    time_elapsed         | 7492      |
|    total_timesteps      | 288512    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000548 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 61.4      |
|    n_updates            | 22530     |
|    policy_gradient_loss | -5.59e-10 |
|    value_loss           | 124       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.3      |
|    ep_rew_mean          | -7.54     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2255      |
|    time_elapsed         | 7495      |
|    total_timesteps      | 288640    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000549 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 68        |
|    n_updates            | 22540     |
|    policy_gradient_loss | -1.77e-09 |
|    value_loss           | 135       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.7      |
|    ep_rew_mean          | -7.26     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2256      |
|    time_elapsed         | 7498      |
|    total_timesteps      | 288768    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000549 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 68.5      |
|    n_updates            | 22550     |
|    policy_gradient_loss | -6.52e-09 |
|    value_loss           | 134       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.6      |
|    ep_rew_mean          | -7.18     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2257      |
|    time_elapsed         | 7500      |
|    total_timesteps      | 288896    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00055  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 47.3      |
|    n_updates            | 22560     |
|    policy_gradient_loss | -4.19e-10 |
|    value_loss           | 93.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 289000
Best mean reward: -0.99 - Last mean reward per episode: -5.83
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.8      |
|    ep_rew_mean          | -7.42     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2258      |
|    time_elapsed         | 7504      |
|    total_timesteps      | 289024    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000551 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 35.2      |
|    n_updates            | 22570     |
|    policy_gradient_loss | 5.82e-09  |
|    value_loss           | 81.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.5      |
|    ep_rew_mean          | -7.28     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2259      |
|    time_elapsed         | 7507      |
|    total_timesteps      | 289152    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000552 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 66.5      |
|    n_updates            | 22580     |
|    policy_gradient_loss | -2.26e-09 |
|    value_loss           | 136       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 78.1         |
|    ep_rew_mean          | -5.74        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 2260         |
|    time_elapsed         | 7510         |
|    total_timesteps      | 289280       |
| train/                  |              |
|    approx_kl            | 0.0023671794 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.000364    |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 49.5         |
|    n_updates            | 22590        |
|    policy_gradient_loss | -0.000928    |
|    value_loss           | 106          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.2      |
|    ep_rew_mean          | -5.58     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2261      |
|    time_elapsed         | 7513      |
|    total_timesteps      | 289408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000226 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53.9      |
|    n_updates            | 22600     |
|    policy_gradient_loss | -3.86e-09 |
|    value_loss           | 95        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.7      |
|    ep_rew_mean          | -5.86     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2262      |
|    time_elapsed         | 7517      |
|    total_timesteps      | 289536    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000213 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 89.9      |
|    n_updates            | 22610     |
|    policy_gradient_loss | 5.03e-09  |
|    value_loss           | 157       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.7      |
|    ep_rew_mean          | -5.75     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2263      |
|    time_elapsed         | 7521      |
|    total_timesteps      | 289664    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000212 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 73.4      |
|    n_updates            | 22620     |
|    policy_gradient_loss | -6.01e-09 |
|    value_loss           | 177       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.5      |
|    ep_rew_mean          | -5.66     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2264      |
|    time_elapsed         | 7525      |
|    total_timesteps      | 289792    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000213 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 74.7      |
|    n_updates            | 22630     |
|    policy_gradient_loss | 2.7e-09   |
|    value_loss           | 154       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.8      |
|    ep_rew_mean          | -5.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2265      |
|    time_elapsed         | 7528      |
|    total_timesteps      | 289920    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000213 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.5      |
|    n_updates            | 22640     |
|    policy_gradient_loss | -4.77e-10 |
|    value_loss           | 95.7      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 290000
Best mean reward: -0.99 - Last mean reward per episode: -6.14
Eval num_timesteps=290000, episode_reward=-3.50 +/- 14.69
Episode length: 79.00 +/- 18.95
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 79        |
|    mean_reward          | -3.5      |
| time/                   |           |
|    total_timesteps      | 290000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000214 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 62.5      |
|    n_updates            | 22650     |
|    policy_gradient_loss | 3.86e-09  |
|    value_loss           | 136       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79       |
|    ep_rew_mean     | -5.78    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2266     |
|    time_elapsed    | 7534     |
|    total_timesteps | 290048   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.9      |
|    ep_rew_mean          | -5.84     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2267      |
|    time_elapsed         | 7538      |
|    total_timesteps      | 290176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000214 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.4      |
|    n_updates            | 22660     |
|    policy_gradient_loss | -4.75e-09 |
|    value_loss           | 114       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.8      |
|    ep_rew_mean          | -5.61     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2268      |
|    time_elapsed         | 7541      |
|    total_timesteps      | 290304    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000214 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.9      |
|    n_updates            | 22670     |
|    policy_gradient_loss | -6.52e-10 |
|    value_loss           | 85.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79        |
|    ep_rew_mean          | -5.8      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2269      |
|    time_elapsed         | 7544      |
|    total_timesteps      | 290432    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000214 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 74.6      |
|    n_updates            | 22680     |
|    policy_gradient_loss | 2.89e-09  |
|    value_loss           | 129       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.9      |
|    ep_rew_mean          | -6.25     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2270      |
|    time_elapsed         | 7548      |
|    total_timesteps      | 290560    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000215 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49        |
|    n_updates            | 22690     |
|    policy_gradient_loss | 4.19e-09  |
|    value_loss           | 84.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.8      |
|    ep_rew_mean          | -6.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2271      |
|    time_elapsed         | 7551      |
|    total_timesteps      | 290688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000215 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 92.3      |
|    n_updates            | 22700     |
|    policy_gradient_loss | -9.78e-10 |
|    value_loss           | 168       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.6      |
|    ep_rew_mean          | -6.61     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2272      |
|    time_elapsed         | 7554      |
|    total_timesteps      | 290816    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000216 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.5      |
|    n_updates            | 22710     |
|    policy_gradient_loss | 9.78e-10  |
|    value_loss           | 108       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.1      |
|    ep_rew_mean          | -6.95     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2273      |
|    time_elapsed         | 7557      |
|    total_timesteps      | 290944    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000216 |
|    explained_variance   | 2.38e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 44.7      |
|    n_updates            | 22720     |
|    policy_gradient_loss | 2.56e-09  |
|    value_loss           | 75.5      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 291000
Best mean reward: -0.99 - Last mean reward per episode: -6.51
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.8      |
|    ep_rew_mean          | -6.69     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2274      |
|    time_elapsed         | 7560      |
|    total_timesteps      | 291072    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000217 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 52.6      |
|    n_updates            | 22730     |
|    policy_gradient_loss | -6.57e-09 |
|    value_loss           | 103       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.9      |
|    ep_rew_mean          | -6.44     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2275      |
|    time_elapsed         | 7564      |
|    total_timesteps      | 291200    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000218 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 80.2      |
|    n_updates            | 22740     |
|    policy_gradient_loss | 4.1e-09   |
|    value_loss           | 143       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.8      |
|    ep_rew_mean          | -6.48     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2276      |
|    time_elapsed         | 7567      |
|    total_timesteps      | 291328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000218 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 112       |
|    n_updates            | 22750     |
|    policy_gradient_loss | -4.47e-09 |
|    value_loss           | 267       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.3      |
|    ep_rew_mean          | -5.77     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2277      |
|    time_elapsed         | 7570      |
|    total_timesteps      | 291456    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000218 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.4      |
|    n_updates            | 22760     |
|    policy_gradient_loss | -1.72e-09 |
|    value_loss           | 77        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.3      |
|    ep_rew_mean          | -5.97     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2278      |
|    time_elapsed         | 7573      |
|    total_timesteps      | 291584    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000218 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 66.5      |
|    n_updates            | 22770     |
|    policy_gradient_loss | -5.08e-09 |
|    value_loss           | 137       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.2      |
|    ep_rew_mean          | -5.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2279      |
|    time_elapsed         | 7575      |
|    total_timesteps      | 291712    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000218 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.5      |
|    n_updates            | 22780     |
|    policy_gradient_loss | -4.66e-09 |
|    value_loss           | 103       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.2      |
|    ep_rew_mean          | -5.58     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2280      |
|    time_elapsed         | 7578      |
|    total_timesteps      | 291840    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000219 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 60.1      |
|    n_updates            | 22790     |
|    policy_gradient_loss | -3.82e-09 |
|    value_loss           | 83.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.3      |
|    ep_rew_mean          | -5.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2281      |
|    time_elapsed         | 7581      |
|    total_timesteps      | 291968    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000219 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 83.6      |
|    n_updates            | 22800     |
|    policy_gradient_loss | -1.82e-09 |
|    value_loss           | 168       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 292000
Best mean reward: -0.99 - Last mean reward per episode: -5.87
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80        |
|    ep_rew_mean          | -6        |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2282      |
|    time_elapsed         | 7585      |
|    total_timesteps      | 292096    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00022  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 97.1      |
|    n_updates            | 22810     |
|    policy_gradient_loss | 4.66e-09  |
|    value_loss           | 187       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.1      |
|    ep_rew_mean          | -6.16     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2283      |
|    time_elapsed         | 7588      |
|    total_timesteps      | 292224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00022  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.8      |
|    n_updates            | 22820     |
|    policy_gradient_loss | -5.03e-09 |
|    value_loss           | 71.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.7      |
|    ep_rew_mean          | -6.33     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2284      |
|    time_elapsed         | 7591      |
|    total_timesteps      | 292352    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000221 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 51.5      |
|    n_updates            | 22830     |
|    policy_gradient_loss | 3.26e-09  |
|    value_loss           | 118       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.8      |
|    ep_rew_mean          | -6.51     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2285      |
|    time_elapsed         | 7594      |
|    total_timesteps      | 292480    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000221 |
|    explained_variance   | 2.38e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 79.4      |
|    n_updates            | 22840     |
|    policy_gradient_loss | -9.31e-10 |
|    value_loss           | 137       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.3      |
|    ep_rew_mean          | -6.15     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2286      |
|    time_elapsed         | 7597      |
|    total_timesteps      | 292608    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000221 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.5      |
|    n_updates            | 22850     |
|    policy_gradient_loss | 4.89e-09  |
|    value_loss           | 108       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.7      |
|    ep_rew_mean          | -6.07     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2287      |
|    time_elapsed         | 7600      |
|    total_timesteps      | 292736    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000222 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 71.9      |
|    n_updates            | 22860     |
|    policy_gradient_loss | -1.82e-09 |
|    value_loss           | 142       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.7      |
|    ep_rew_mean          | -6.14     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2288      |
|    time_elapsed         | 7603      |
|    total_timesteps      | 292864    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000223 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 38.3      |
|    n_updates            | 22870     |
|    policy_gradient_loss | 8.85e-10  |
|    value_loss           | 92        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.4      |
|    ep_rew_mean          | -6.08     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2289      |
|    time_elapsed         | 7606      |
|    total_timesteps      | 292992    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000223 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.4      |
|    n_updates            | 22880     |
|    policy_gradient_loss | 5.08e-09  |
|    value_loss           | 84.1      |
---------------------------------------
Num timesteps: 293000
Best mean reward: -0.99 - Last mean reward per episode: -5.82
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.5      |
|    ep_rew_mean          | -6.04     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2290      |
|    time_elapsed         | 7610      |
|    total_timesteps      | 293120    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000223 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 140       |
|    n_updates            | 22890     |
|    policy_gradient_loss | 4.66e-11  |
|    value_loss           | 255       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80        |
|    ep_rew_mean          | -5.72     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2291      |
|    time_elapsed         | 7613      |
|    total_timesteps      | 293248    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000224 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 57.2      |
|    n_updates            | 22900     |
|    policy_gradient_loss | 8.38e-10  |
|    value_loss           | 140       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.7      |
|    ep_rew_mean          | -5.47     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2292      |
|    time_elapsed         | 7616      |
|    total_timesteps      | 293376    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000224 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 72.2      |
|    n_updates            | 22910     |
|    policy_gradient_loss | -8.85e-10 |
|    value_loss           | 136       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.8      |
|    ep_rew_mean          | -5.49     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2293      |
|    time_elapsed         | 7619      |
|    total_timesteps      | 293504    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000224 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 58.3      |
|    n_updates            | 22920     |
|    policy_gradient_loss | 2.89e-09  |
|    value_loss           | 131       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.3      |
|    ep_rew_mean          | -5.78     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2294      |
|    time_elapsed         | 7622      |
|    total_timesteps      | 293632    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000224 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.8      |
|    n_updates            | 22930     |
|    policy_gradient_loss | 8.85e-10  |
|    value_loss           | 107       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.3      |
|    ep_rew_mean          | -5.86     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2295      |
|    time_elapsed         | 7624      |
|    total_timesteps      | 293760    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000225 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 60.7      |
|    n_updates            | 22940     |
|    policy_gradient_loss | -4.77e-09 |
|    value_loss           | 99.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.7      |
|    ep_rew_mean          | -6.04     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2296      |
|    time_elapsed         | 7627      |
|    total_timesteps      | 293888    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000225 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.3      |
|    n_updates            | 22950     |
|    policy_gradient_loss | 1.02e-09  |
|    value_loss           | 72.7      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 294000
Best mean reward: -0.99 - Last mean reward per episode: -2.95
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.3      |
|    ep_rew_mean          | -5.83     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2297      |
|    time_elapsed         | 7630      |
|    total_timesteps      | 294016    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000226 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 61.5      |
|    n_updates            | 22960     |
|    policy_gradient_loss | -2e-09    |
|    value_loss           | 102       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.3      |
|    ep_rew_mean          | -3.17     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2298      |
|    time_elapsed         | 7633      |
|    total_timesteps      | 294144    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000228 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45.9      |
|    n_updates            | 22970     |
|    policy_gradient_loss | -3.07e-09 |
|    value_loss           | 102       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.7      |
|    ep_rew_mean          | -3.35     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2299      |
|    time_elapsed         | 7635      |
|    total_timesteps      | 294272    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000228 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 87.5      |
|    n_updates            | 22980     |
|    policy_gradient_loss | 1.37e-09  |
|    value_loss           | 177       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.4      |
|    ep_rew_mean          | -2.71     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2300      |
|    time_elapsed         | 7638      |
|    total_timesteps      | 294400    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000229 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 45        |
|    n_updates            | 22990     |
|    policy_gradient_loss | 3.96e-09  |
|    value_loss           | 95.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.6      |
|    ep_rew_mean          | -2.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2301      |
|    time_elapsed         | 7641      |
|    total_timesteps      | 294528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00023  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.5      |
|    n_updates            | 23000     |
|    policy_gradient_loss | -2.89e-09 |
|    value_loss           | 92        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.6     |
|    ep_rew_mean          | -2.69    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2302     |
|    time_elapsed         | 7645     |
|    total_timesteps      | 294656   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00023 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 27.8     |
|    n_updates            | 23010    |
|    policy_gradient_loss | 3.96e-09 |
|    value_loss           | 70.8     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.6      |
|    ep_rew_mean          | -2.69     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2303      |
|    time_elapsed         | 7649      |
|    total_timesteps      | 294784    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000231 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 62.7      |
|    n_updates            | 23020     |
|    policy_gradient_loss | -2.84e-09 |
|    value_loss           | 129       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.6      |
|    ep_rew_mean          | -2.69     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2304      |
|    time_elapsed         | 7652      |
|    total_timesteps      | 294912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000231 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.9      |
|    n_updates            | 23030     |
|    policy_gradient_loss | 1.1e-08   |
|    value_loss           | 60.4      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 295000
Best mean reward: -0.99 - Last mean reward per episode: -3.96
Eval num_timesteps=295000, episode_reward=-96.00 +/- 202.18
Episode length: 252.00 +/- 374.04
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 252       |
|    mean_reward          | -96       |
| time/                   |           |
|    total_timesteps      | 295000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000231 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26.4      |
|    n_updates            | 23040     |
|    policy_gradient_loss | -1.94e-08 |
|    value_loss           | 57.9      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 77.1     |
|    ep_rew_mean     | -4.03    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2305     |
|    time_elapsed    | 7663     |
|    total_timesteps | 295040   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.8      |
|    ep_rew_mean          | -3.88     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2306      |
|    time_elapsed         | 7666      |
|    total_timesteps      | 295168    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000231 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 45.2      |
|    n_updates            | 23050     |
|    policy_gradient_loss | 2.24e-09  |
|    value_loss           | 94.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77        |
|    ep_rew_mean          | -3.88     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2307      |
|    time_elapsed         | 7669      |
|    total_timesteps      | 295296    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000232 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.3      |
|    n_updates            | 23060     |
|    policy_gradient_loss | 1.07e-09  |
|    value_loss           | 95.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.8      |
|    ep_rew_mean          | -3.9      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2308      |
|    time_elapsed         | 7672      |
|    total_timesteps      | 295424    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000233 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 57.8      |
|    n_updates            | 23070     |
|    policy_gradient_loss | -2.89e-09 |
|    value_loss           | 132       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.6      |
|    ep_rew_mean          | -4.29     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2309      |
|    time_elapsed         | 7675      |
|    total_timesteps      | 295552    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000233 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.1      |
|    n_updates            | 23080     |
|    policy_gradient_loss | -7.92e-10 |
|    value_loss           | 72.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.9      |
|    ep_rew_mean          | -4.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2310      |
|    time_elapsed         | 7678      |
|    total_timesteps      | 295680    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000234 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 32.7      |
|    n_updates            | 23090     |
|    policy_gradient_loss | 4.8e-09   |
|    value_loss           | 70.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.5      |
|    ep_rew_mean          | -4.54     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2311      |
|    time_elapsed         | 7681      |
|    total_timesteps      | 295808    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000234 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 43.7      |
|    n_updates            | 23100     |
|    policy_gradient_loss | -1.65e-09 |
|    value_loss           | 92.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78        |
|    ep_rew_mean          | -4.8      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2312      |
|    time_elapsed         | 7684      |
|    total_timesteps      | 295936    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000234 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 61.6      |
|    n_updates            | 23110     |
|    policy_gradient_loss | 2.37e-09  |
|    value_loss           | 89.2      |
---------------------------------------
Num timesteps: 296000
Best mean reward: -0.99 - Last mean reward per episode: -9.85
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.2      |
|    ep_rew_mean          | -4.79     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2313      |
|    time_elapsed         | 7687      |
|    total_timesteps      | 296064    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000235 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.2      |
|    n_updates            | 23120     |
|    policy_gradient_loss | 4.09e-09  |
|    value_loss           | 70.5      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.5      |
|    ep_rew_mean          | -4.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2314      |
|    time_elapsed         | 7690      |
|    total_timesteps      | 296192    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000235 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 81.6      |
|    n_updates            | 23130     |
|    policy_gradient_loss | -1.86e-09 |
|    value_loss           | 124       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.8      |
|    ep_rew_mean          | -5.01     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2315      |
|    time_elapsed         | 7693      |
|    total_timesteps      | 296320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000235 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26.8      |
|    n_updates            | 23140     |
|    policy_gradient_loss | -1.89e-09 |
|    value_loss           | 70.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -5.17     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2316      |
|    time_elapsed         | 7696      |
|    total_timesteps      | 296448    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000235 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53.8      |
|    n_updates            | 23150     |
|    policy_gradient_loss | 9.31e-11  |
|    value_loss           | 106       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -5.58     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2317      |
|    time_elapsed         | 7699      |
|    total_timesteps      | 296576    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000236 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 52.5      |
|    n_updates            | 23160     |
|    policy_gradient_loss | 2.93e-09  |
|    value_loss           | 99.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -5.58     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2318      |
|    time_elapsed         | 7702      |
|    total_timesteps      | 296704    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000237 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45.9      |
|    n_updates            | 23170     |
|    policy_gradient_loss | 1.72e-09  |
|    value_loss           | 93.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.8      |
|    ep_rew_mean          | -5.72     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2319      |
|    time_elapsed         | 7705      |
|    total_timesteps      | 296832    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000238 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.9      |
|    n_updates            | 23180     |
|    policy_gradient_loss | -7.12e-09 |
|    value_loss           | 88.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -5.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2320      |
|    time_elapsed         | 7708      |
|    total_timesteps      | 296960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000239 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 51.2      |
|    n_updates            | 23190     |
|    policy_gradient_loss | -9.55e-10 |
|    value_loss           | 90.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 297000
Best mean reward: -0.99 - Last mean reward per episode: -10.49
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -5.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2321      |
|    time_elapsed         | 7711      |
|    total_timesteps      | 297088    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00024  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.9      |
|    n_updates            | 23200     |
|    policy_gradient_loss | -2.91e-09 |
|    value_loss           | 69.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.8      |
|    ep_rew_mean          | -5.7      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2322      |
|    time_elapsed         | 7714      |
|    total_timesteps      | 297216    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00024  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 52.5      |
|    n_updates            | 23210     |
|    policy_gradient_loss | -3.26e-09 |
|    value_loss           | 85        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 80       |
|    ep_rew_mean          | -5.82    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2323     |
|    time_elapsed         | 7717     |
|    total_timesteps      | 297344   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00024 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 63.3     |
|    n_updates            | 23220    |
|    policy_gradient_loss | 6.05e-10 |
|    value_loss           | 132      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -5.54     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2324      |
|    time_elapsed         | 7720      |
|    total_timesteps      | 297472    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000241 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39        |
|    n_updates            | 23230     |
|    policy_gradient_loss | 5.54e-09  |
|    value_loss           | 77.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -5.63     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2325      |
|    time_elapsed         | 7724      |
|    total_timesteps      | 297600    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000241 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 143       |
|    n_updates            | 23240     |
|    policy_gradient_loss | 8.15e-09  |
|    value_loss           | 263       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -5.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2326      |
|    time_elapsed         | 7727      |
|    total_timesteps      | 297728    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000242 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 68.9      |
|    n_updates            | 23250     |
|    policy_gradient_loss | -4.19e-10 |
|    value_loss           | 129       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -5.37     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2327      |
|    time_elapsed         | 7730      |
|    total_timesteps      | 297856    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000242 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.1      |
|    n_updates            | 23260     |
|    policy_gradient_loss | -2.84e-09 |
|    value_loss           | 93        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.2      |
|    ep_rew_mean          | -5.5      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2328      |
|    time_elapsed         | 7733      |
|    total_timesteps      | 297984    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000243 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 80.4      |
|    n_updates            | 23270     |
|    policy_gradient_loss | 1.02e-08  |
|    value_loss           | 168       |
---------------------------------------
Num timesteps: 298000
Best mean reward: -0.99 - Last mean reward per episode: -9.55
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.7      |
|    ep_rew_mean          | -5.43     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2329      |
|    time_elapsed         | 7736      |
|    total_timesteps      | 298112    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000243 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 58.6      |
|    n_updates            | 23280     |
|    policy_gradient_loss | 4.1e-09   |
|    value_loss           | 90.3      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.7      |
|    ep_rew_mean          | -5.13     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2330      |
|    time_elapsed         | 7739      |
|    total_timesteps      | 298240    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000244 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55.2      |
|    n_updates            | 23290     |
|    policy_gradient_loss | 4e-09     |
|    value_loss           | 85.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.7      |
|    ep_rew_mean          | -5.13     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2331      |
|    time_elapsed         | 7742      |
|    total_timesteps      | 298368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000246 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 47.8      |
|    n_updates            | 23300     |
|    policy_gradient_loss | -3.26e-10 |
|    value_loss           | 86.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.6      |
|    ep_rew_mean          | -5.01     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2332      |
|    time_elapsed         | 7745      |
|    total_timesteps      | 298496    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000247 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 30.8      |
|    n_updates            | 23310     |
|    policy_gradient_loss | 4.19e-08  |
|    value_loss           | 63.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -4.83     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2333      |
|    time_elapsed         | 7749      |
|    total_timesteps      | 298624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000248 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 53.9      |
|    n_updates            | 23320     |
|    policy_gradient_loss | 3.35e-09  |
|    value_loss           | 126       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.7      |
|    ep_rew_mean          | -5.06     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2334      |
|    time_elapsed         | 7751      |
|    total_timesteps      | 298752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000249 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 37.8      |
|    n_updates            | 23330     |
|    policy_gradient_loss | 1.63e-09  |
|    value_loss           | 84.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78       |
|    ep_rew_mean          | -5.18    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2335     |
|    time_elapsed         | 7754     |
|    total_timesteps      | 298880   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00025 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 56.7     |
|    n_updates            | 23340    |
|    policy_gradient_loss | 4.56e-09 |
|    value_loss           | 128      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 299000
Best mean reward: -0.99 - Last mean reward per episode: -10.22
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.9      |
|    ep_rew_mean          | -5.55     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2336      |
|    time_elapsed         | 7756      |
|    total_timesteps      | 299008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000251 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.3      |
|    n_updates            | 23350     |
|    policy_gradient_loss | 6.05e-10  |
|    value_loss           | 69.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.6      |
|    ep_rew_mean          | -5.91     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2337      |
|    time_elapsed         | 7760      |
|    total_timesteps      | 299136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000252 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 40.1      |
|    n_updates            | 23360     |
|    policy_gradient_loss | 1.51e-09  |
|    value_loss           | 85.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.2      |
|    ep_rew_mean          | -5.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2338      |
|    time_elapsed         | 7763      |
|    total_timesteps      | 299264    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000253 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.1      |
|    n_updates            | 23370     |
|    policy_gradient_loss | 9.31e-11  |
|    value_loss           | 69.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.2      |
|    ep_rew_mean          | -5.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2339      |
|    time_elapsed         | 7766      |
|    total_timesteps      | 299392    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000253 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.4      |
|    n_updates            | 23380     |
|    policy_gradient_loss | -1.4e-10  |
|    value_loss           | 85.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.3      |
|    ep_rew_mean          | -5.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2340      |
|    time_elapsed         | 7769      |
|    total_timesteps      | 299520    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000254 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.5      |
|    n_updates            | 23390     |
|    policy_gradient_loss | -3.68e-09 |
|    value_loss           | 87.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.1      |
|    ep_rew_mean          | -5.87     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2341      |
|    time_elapsed         | 7772      |
|    total_timesteps      | 299648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000255 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 87.8      |
|    n_updates            | 23400     |
|    policy_gradient_loss | 3e-09     |
|    value_loss           | 169       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -5.61     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2342      |
|    time_elapsed         | 7775      |
|    total_timesteps      | 299776    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000256 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 48.4      |
|    n_updates            | 23410     |
|    policy_gradient_loss | -2.14e-09 |
|    value_loss           | 92        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.6      |
|    ep_rew_mean          | -5.5      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2343      |
|    time_elapsed         | 7778      |
|    total_timesteps      | 299904    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000258 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 61.4      |
|    n_updates            | 23420     |
|    policy_gradient_loss | 1.49e-09  |
|    value_loss           | 95.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 300000
Best mean reward: -0.99 - Last mean reward per episode: -10.04
Eval num_timesteps=300000, episode_reward=-11.60 +/- 8.85
Episode length: 99.20 +/- 25.03
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 99.2      |
|    mean_reward          | -11.6     |
| time/                   |           |
|    total_timesteps      | 300000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000261 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.5      |
|    n_updates            | 23430     |
|    policy_gradient_loss | -1.77e-09 |
|    value_loss           | 83.3      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 76.5     |
|    ep_rew_mean     | -5.43    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2344     |
|    time_elapsed    | 7783     |
|    total_timesteps | 300032   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.1      |
|    ep_rew_mean          | -5.25     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2345      |
|    time_elapsed         | 7786      |
|    total_timesteps      | 300160    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000263 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.9      |
|    n_updates            | 23440     |
|    policy_gradient_loss | 6.73e-09  |
|    value_loss           | 69.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.1      |
|    ep_rew_mean          | -5.25     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2346      |
|    time_elapsed         | 7789      |
|    total_timesteps      | 300288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000263 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 96.3      |
|    n_updates            | 23450     |
|    policy_gradient_loss | -2.14e-09 |
|    value_loss           | 161       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.6      |
|    ep_rew_mean          | -5.88     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2347      |
|    time_elapsed         | 7793      |
|    total_timesteps      | 300416    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000263 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 31.8      |
|    n_updates            | 23460     |
|    policy_gradient_loss | 3.93e-08  |
|    value_loss           | 64.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.3      |
|    ep_rew_mean          | -5.76     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2348      |
|    time_elapsed         | 7796      |
|    total_timesteps      | 300544    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000264 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.4      |
|    n_updates            | 23470     |
|    policy_gradient_loss | -2.84e-09 |
|    value_loss           | 118       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.6      |
|    ep_rew_mean          | -5.72     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2349      |
|    time_elapsed         | 7799      |
|    total_timesteps      | 300672    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000265 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 46.6      |
|    n_updates            | 23480     |
|    policy_gradient_loss | 4e-09     |
|    value_loss           | 83.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.7      |
|    ep_rew_mean          | -5.86     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2350      |
|    time_elapsed         | 7802      |
|    total_timesteps      | 300800    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000266 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.5      |
|    n_updates            | 23490     |
|    policy_gradient_loss | 1.4e-09   |
|    value_loss           | 111       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77        |
|    ep_rew_mean          | -5.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2351      |
|    time_elapsed         | 7805      |
|    total_timesteps      | 300928    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000267 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33        |
|    n_updates            | 23500     |
|    policy_gradient_loss | 7.96e-09  |
|    value_loss           | 67.8      |
---------------------------------------
Num timesteps: 301000
Best mean reward: -0.99 - Last mean reward per episode: -11.03
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.1      |
|    ep_rew_mean          | -6.05     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2352      |
|    time_elapsed         | 7808      |
|    total_timesteps      | 301056    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000268 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 60.8      |
|    n_updates            | 23510     |
|    policy_gradient_loss | -4e-09    |
|    value_loss           | 124       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.3      |
|    ep_rew_mean          | -6.16     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2353      |
|    time_elapsed         | 7810      |
|    total_timesteps      | 301184    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00027  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 32.5      |
|    n_updates            | 23520     |
|    policy_gradient_loss | -4.45e-09 |
|    value_loss           | 67.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.9      |
|    ep_rew_mean          | -6.66     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2354      |
|    time_elapsed         | 7814      |
|    total_timesteps      | 301312    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000271 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.8      |
|    n_updates            | 23530     |
|    policy_gradient_loss | 1.31e-08  |
|    value_loss           | 77.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.3      |
|    ep_rew_mean          | -6.34     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2355      |
|    time_elapsed         | 7817      |
|    total_timesteps      | 301440    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000271 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.8      |
|    n_updates            | 23540     |
|    policy_gradient_loss | -7.68e-10 |
|    value_loss           | 84.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.8      |
|    ep_rew_mean          | -6.62     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2356      |
|    time_elapsed         | 7820      |
|    total_timesteps      | 301568    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000272 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.1      |
|    n_updates            | 23550     |
|    policy_gradient_loss | -7.61e-09 |
|    value_loss           | 89.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.8      |
|    ep_rew_mean          | -6.49     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2357      |
|    time_elapsed         | 7823      |
|    total_timesteps      | 301696    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000274 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 32.4      |
|    n_updates            | 23560     |
|    policy_gradient_loss | -2.65e-09 |
|    value_loss           | 68.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.8      |
|    ep_rew_mean          | -6.5      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2358      |
|    time_elapsed         | 7827      |
|    total_timesteps      | 301824    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000274 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.4      |
|    n_updates            | 23570     |
|    policy_gradient_loss | 1.82e-09  |
|    value_loss           | 126       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.1      |
|    ep_rew_mean          | -6.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2359      |
|    time_elapsed         | 7831      |
|    total_timesteps      | 301952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000276 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 31.9      |
|    n_updates            | 23580     |
|    policy_gradient_loss | -1.75e-09 |
|    value_loss           | 85.3      |
---------------------------------------
Num timesteps: 302000
Best mean reward: -0.99 - Last mean reward per episode: -10.45
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78        |
|    ep_rew_mean          | -6.8      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2360      |
|    time_elapsed         | 7834      |
|    total_timesteps      | 302080    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000278 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.3      |
|    n_updates            | 23590     |
|    policy_gradient_loss | 4.42e-09  |
|    value_loss           | 69.7      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.5      |
|    ep_rew_mean          | -7.03     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2361      |
|    time_elapsed         | 7837      |
|    total_timesteps      | 302208    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000278 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 39.3      |
|    n_updates            | 23600     |
|    policy_gradient_loss | 4.52e-09  |
|    value_loss           | 73.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79        |
|    ep_rew_mean          | -7.3      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2362      |
|    time_elapsed         | 7840      |
|    total_timesteps      | 302336    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000279 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 28.9      |
|    n_updates            | 23610     |
|    policy_gradient_loss | 7.1e-09   |
|    value_loss           | 69.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.8     |
|    ep_rew_mean          | -7.19    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2363     |
|    time_elapsed         | 7843     |
|    total_timesteps      | 302464   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00028 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 36.6     |
|    n_updates            | 23620    |
|    policy_gradient_loss | 4.35e-09 |
|    value_loss           | 90       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.4      |
|    ep_rew_mean          | -7.61     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2364      |
|    time_elapsed         | 7846      |
|    total_timesteps      | 302592    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000281 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.6      |
|    n_updates            | 23630     |
|    policy_gradient_loss | -9.31e-10 |
|    value_loss           | 72.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.7      |
|    ep_rew_mean          | -5.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2365      |
|    time_elapsed         | 7849      |
|    total_timesteps      | 302720    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000282 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 33.1      |
|    n_updates            | 23640     |
|    policy_gradient_loss | 8.8e-09   |
|    value_loss           | 69        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.8      |
|    ep_rew_mean          | -5.62     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2366      |
|    time_elapsed         | 7852      |
|    total_timesteps      | 302848    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000282 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 141       |
|    n_updates            | 23650     |
|    policy_gradient_loss | 3.4e-09   |
|    value_loss           | 356       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.9      |
|    ep_rew_mean          | -5.54     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2367      |
|    time_elapsed         | 7855      |
|    total_timesteps      | 302976    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000282 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.3      |
|    n_updates            | 23660     |
|    policy_gradient_loss | -3.03e-09 |
|    value_loss           | 104       |
---------------------------------------
Num timesteps: 303000
Best mean reward: -0.99 - Last mean reward per episode: -5.20
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.9      |
|    ep_rew_mean          | -5.54     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2368      |
|    time_elapsed         | 7859      |
|    total_timesteps      | 303104    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000283 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 107       |
|    n_updates            | 23670     |
|    policy_gradient_loss | 1.21e-09  |
|    value_loss           | 181       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.9      |
|    ep_rew_mean          | -5.97     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2369      |
|    time_elapsed         | 7862      |
|    total_timesteps      | 303232    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000284 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 30        |
|    n_updates            | 23680     |
|    policy_gradient_loss | 5.37e-08  |
|    value_loss           | 60.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -5.51     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2370      |
|    time_elapsed         | 7866      |
|    total_timesteps      | 303360    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000284 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41        |
|    n_updates            | 23690     |
|    policy_gradient_loss | 4.24e-09  |
|    value_loss           | 90.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78        |
|    ep_rew_mean          | -5.78     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2371      |
|    time_elapsed         | 7870      |
|    total_timesteps      | 303488    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000285 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 58.6      |
|    n_updates            | 23700     |
|    policy_gradient_loss | 3.96e-10  |
|    value_loss           | 122       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.2      |
|    ep_rew_mean          | -5.68     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2372      |
|    time_elapsed         | 7874      |
|    total_timesteps      | 303616    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000286 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.6      |
|    n_updates            | 23710     |
|    policy_gradient_loss | 4.66e-10  |
|    value_loss           | 107       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.4      |
|    ep_rew_mean          | -6.19     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2373      |
|    time_elapsed         | 7878      |
|    total_timesteps      | 303744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000288 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 101       |
|    n_updates            | 23720     |
|    policy_gradient_loss | -4.98e-09 |
|    value_loss           | 165       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -6.06     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2374      |
|    time_elapsed         | 7881      |
|    total_timesteps      | 303872    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000291 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55.6      |
|    n_updates            | 23730     |
|    policy_gradient_loss | -2.56e-09 |
|    value_loss           | 109       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 304000
Best mean reward: -0.99 - Last mean reward per episode: -6.01
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.9      |
|    ep_rew_mean          | -5.93     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2375      |
|    time_elapsed         | 7885      |
|    total_timesteps      | 304000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000294 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 31.1      |
|    n_updates            | 23740     |
|    policy_gradient_loss | -3.03e-09 |
|    value_loss           | 97.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -5.96     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2376      |
|    time_elapsed         | 7888      |
|    total_timesteps      | 304128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000295 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 61.9      |
|    n_updates            | 23750     |
|    policy_gradient_loss | 2.7e-09   |
|    value_loss           | 117       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -6.14     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2377      |
|    time_elapsed         | 7892      |
|    total_timesteps      | 304256    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000296 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 57.7      |
|    n_updates            | 23760     |
|    policy_gradient_loss | -2.33e-10 |
|    value_loss           | 134       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.7      |
|    ep_rew_mean          | -6.24     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2378      |
|    time_elapsed         | 7896      |
|    total_timesteps      | 304384    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000297 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 62.3      |
|    n_updates            | 23770     |
|    policy_gradient_loss | -2.65e-09 |
|    value_loss           | 113       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80        |
|    ep_rew_mean          | -6.3      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2379      |
|    time_elapsed         | 7899      |
|    total_timesteps      | 304512    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000297 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.8      |
|    n_updates            | 23780     |
|    policy_gradient_loss | -2.51e-09 |
|    value_loss           | 73.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.2      |
|    ep_rew_mean          | -6.32     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2380      |
|    time_elapsed         | 7903      |
|    total_timesteps      | 304640    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000298 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 45.6      |
|    n_updates            | 23790     |
|    policy_gradient_loss | 2.51e-09  |
|    value_loss           | 112       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.9      |
|    ep_rew_mean          | -6.63     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2381      |
|    time_elapsed         | 7905      |
|    total_timesteps      | 304768    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000301 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 71        |
|    n_updates            | 23800     |
|    policy_gradient_loss | 2.24e-09  |
|    value_loss           | 142       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.9      |
|    ep_rew_mean          | -6.63     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2382      |
|    time_elapsed         | 7908      |
|    total_timesteps      | 304896    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000302 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.7      |
|    n_updates            | 23810     |
|    policy_gradient_loss | 6.98e-10  |
|    value_loss           | 79.2      |
---------------------------------------
Num timesteps: 305000
Best mean reward: -0.99 - Last mean reward per episode: -6.78
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=305000, episode_reward=3.50 +/- 9.31
Episode length: 65.00 +/- 8.63
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 65        |
|    mean_reward          | 3.5       |
| time/                   |           |
|    total_timesteps      | 305000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000302 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.4      |
|    n_updates            | 23820     |
|    policy_gradient_loss | 1.4e-10   |
|    value_loss           | 77.6      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81.1     |
|    ep_rew_mean     | -6.57    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2383     |
|    time_elapsed    | 7914     |
|    total_timesteps | 305024   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.8      |
|    ep_rew_mean          | -6.28     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2384      |
|    time_elapsed         | 7918      |
|    total_timesteps      | 305152    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000303 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 108       |
|    n_updates            | 23830     |
|    policy_gradient_loss | 4.1e-09   |
|    value_loss           | 189       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.2      |
|    ep_rew_mean          | -6.48     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2385      |
|    time_elapsed         | 7921      |
|    total_timesteps      | 305280    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000304 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 59.7      |
|    n_updates            | 23840     |
|    policy_gradient_loss | -3.03e-10 |
|    value_loss           | 122       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.2      |
|    ep_rew_mean          | -6.3      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2386      |
|    time_elapsed         | 7926      |
|    total_timesteps      | 305408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000305 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 41.8      |
|    n_updates            | 23850     |
|    policy_gradient_loss | -1.81e-08 |
|    value_loss           | 74.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.8      |
|    ep_rew_mean          | -6.3      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2387      |
|    time_elapsed         | 7929      |
|    total_timesteps      | 305536    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000305 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 136       |
|    n_updates            | 23860     |
|    policy_gradient_loss | 2.33e-09  |
|    value_loss           | 225       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.6      |
|    ep_rew_mean          | -6.29     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2388      |
|    time_elapsed         | 7931      |
|    total_timesteps      | 305664    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000305 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.5      |
|    n_updates            | 23870     |
|    policy_gradient_loss | -1.4e-09  |
|    value_loss           | 105       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.6      |
|    ep_rew_mean          | -6.09     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2389      |
|    time_elapsed         | 7934      |
|    total_timesteps      | 305792    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000306 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 82.6      |
|    n_updates            | 23880     |
|    policy_gradient_loss | 4e-09     |
|    value_loss           | 195       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.8      |
|    ep_rew_mean          | -6.22     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2390      |
|    time_elapsed         | 7937      |
|    total_timesteps      | 305920    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000307 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 83        |
|    n_updates            | 23890     |
|    policy_gradient_loss | 5.12e-10  |
|    value_loss           | 166       |
---------------------------------------
Num timesteps: 306000
Best mean reward: -0.99 - Last mean reward per episode: -6.53
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.2      |
|    ep_rew_mean          | -6.39     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2391      |
|    time_elapsed         | 7940      |
|    total_timesteps      | 306048    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000312 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 73.9      |
|    n_updates            | 23900     |
|    policy_gradient_loss | 2.28e-09  |
|    value_loss           | 106       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.6      |
|    ep_rew_mean          | -6.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2392      |
|    time_elapsed         | 7943      |
|    total_timesteps      | 306176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000315 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.5      |
|    n_updates            | 23910     |
|    policy_gradient_loss | -1.47e-09 |
|    value_loss           | 76.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.4      |
|    ep_rew_mean          | -6.59     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2393      |
|    time_elapsed         | 7947      |
|    total_timesteps      | 306304    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000317 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.7      |
|    n_updates            | 23920     |
|    policy_gradient_loss | 2.1e-10   |
|    value_loss           | 107       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.2      |
|    ep_rew_mean          | -6.51     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2394      |
|    time_elapsed         | 7950      |
|    total_timesteps      | 306432    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000321 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 66.9      |
|    n_updates            | 23930     |
|    policy_gradient_loss | 4.47e-09  |
|    value_loss           | 176       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.8      |
|    ep_rew_mean          | -6.29     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2395      |
|    time_elapsed         | 7953      |
|    total_timesteps      | 306560    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000323 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.4      |
|    n_updates            | 23940     |
|    policy_gradient_loss | 1.86e-09  |
|    value_loss           | 74.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81        |
|    ep_rew_mean          | -6.39     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2396      |
|    time_elapsed         | 7957      |
|    total_timesteps      | 306688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000324 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 95.6      |
|    n_updates            | 23950     |
|    policy_gradient_loss | -1.91e-09 |
|    value_loss           | 138       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.8      |
|    ep_rew_mean          | -6.3      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2397      |
|    time_elapsed         | 7960      |
|    total_timesteps      | 306816    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000327 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 70.5      |
|    n_updates            | 23960     |
|    policy_gradient_loss | 5.68e-09  |
|    value_loss           | 107       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.9     |
|    ep_rew_mean          | -5.97    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2398     |
|    time_elapsed         | 7964     |
|    total_timesteps      | 306944   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00033 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 51.3     |
|    n_updates            | 23970    |
|    policy_gradient_loss | 3.31e-09 |
|    value_loss           | 101      |
--------------------------------------
Num timesteps: 307000
Best mean reward: -0.99 - Last mean reward per episode: -6.12
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.8      |
|    ep_rew_mean          | -5.9      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2399      |
|    time_elapsed         | 7967      |
|    total_timesteps      | 307072    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000333 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.7      |
|    n_updates            | 23980     |
|    policy_gradient_loss | -1.3e-09  |
|    value_loss           | 101       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.9      |
|    ep_rew_mean          | -5.46     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2400      |
|    time_elapsed         | 7970      |
|    total_timesteps      | 307200    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000335 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 47.2      |
|    n_updates            | 23990     |
|    policy_gradient_loss | -2.51e-09 |
|    value_loss           | 104       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79        |
|    ep_rew_mean          | -5.51     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2401      |
|    time_elapsed         | 7972      |
|    total_timesteps      | 307328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000336 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 61.9      |
|    n_updates            | 24000     |
|    policy_gradient_loss | 4.7e-09   |
|    value_loss           | 106       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.9      |
|    ep_rew_mean          | -5.66     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2402      |
|    time_elapsed         | 7975      |
|    total_timesteps      | 307456    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000338 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 45.9      |
|    n_updates            | 24010     |
|    policy_gradient_loss | 1.51e-09  |
|    value_loss           | 93.4      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.9     |
|    ep_rew_mean          | -5.66    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2403     |
|    time_elapsed         | 7977     |
|    total_timesteps      | 307584   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00034 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 51.2     |
|    n_updates            | 24020    |
|    policy_gradient_loss | 9.31e-11 |
|    value_loss           | 89.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -5.73     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2404      |
|    time_elapsed         | 7980      |
|    total_timesteps      | 307712    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000344 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 49        |
|    n_updates            | 24030     |
|    policy_gradient_loss | 2.33e-09  |
|    value_loss           | 90        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -5.73     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2405      |
|    time_elapsed         | 7984      |
|    total_timesteps      | 307840    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000346 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.8      |
|    n_updates            | 24040     |
|    policy_gradient_loss | -1.51e-09 |
|    value_loss           | 76.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -5.73     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2406      |
|    time_elapsed         | 7987      |
|    total_timesteps      | 307968    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000346 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 30        |
|    n_updates            | 24050     |
|    policy_gradient_loss | -9.02e-08 |
|    value_loss           | 58.5      |
---------------------------------------
Num timesteps: 308000
Best mean reward: -0.99 - Last mean reward per episode: -5.54
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -5.73     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2407      |
|    time_elapsed         | 7991      |
|    total_timesteps      | 308096    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000347 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 27.6      |
|    n_updates            | 24060     |
|    policy_gradient_loss | -8.41e-08 |
|    value_loss           | 57.4      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.1      |
|    ep_rew_mean          | -8.23     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2408      |
|    time_elapsed         | 7994      |
|    total_timesteps      | 308224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000347 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 28.6      |
|    n_updates            | 24070     |
|    policy_gradient_loss | 1.78e-08  |
|    value_loss           | 56.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.5      |
|    ep_rew_mean          | -8.26     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2409      |
|    time_elapsed         | 7998      |
|    total_timesteps      | 308352    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000347 |
|    explained_variance   | 2.38e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 27        |
|    n_updates            | 24080     |
|    policy_gradient_loss | -4.66e-11 |
|    value_loss           | 71        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.6      |
|    ep_rew_mean          | -8.3      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2410      |
|    time_elapsed         | 8001      |
|    total_timesteps      | 308480    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000348 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 122       |
|    n_updates            | 24090     |
|    policy_gradient_loss | -3.49e-09 |
|    value_loss           | 188       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.5      |
|    ep_rew_mean          | -8.27     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2411      |
|    time_elapsed         | 8004      |
|    total_timesteps      | 308608    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000349 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 43.3      |
|    n_updates            | 24100     |
|    policy_gradient_loss | 1.58e-09  |
|    value_loss           | 99.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83        |
|    ep_rew_mean          | -7.58     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2412      |
|    time_elapsed         | 8008      |
|    total_timesteps      | 308736    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000351 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.8      |
|    n_updates            | 24110     |
|    policy_gradient_loss | 5.59e-10  |
|    value_loss           | 71.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.1      |
|    ep_rew_mean          | -7.66     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2413      |
|    time_elapsed         | 8011      |
|    total_timesteps      | 308864    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000353 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 48.4      |
|    n_updates            | 24120     |
|    policy_gradient_loss | 3.68e-09  |
|    value_loss           | 110       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.7      |
|    ep_rew_mean          | -7.93     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2414      |
|    time_elapsed         | 8014      |
|    total_timesteps      | 308992    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000357 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 87.2      |
|    n_updates            | 24130     |
|    policy_gradient_loss | -6.24e-09 |
|    value_loss           | 136       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 309000
Best mean reward: -0.99 - Last mean reward per episode: -7.58
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.3      |
|    ep_rew_mean          | -8.03     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2415      |
|    time_elapsed         | 8018      |
|    total_timesteps      | 309120    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000362 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.6      |
|    n_updates            | 24140     |
|    policy_gradient_loss | 6.57e-09  |
|    value_loss           | 73.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84        |
|    ep_rew_mean          | -7.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2416      |
|    time_elapsed         | 8022      |
|    total_timesteps      | 309248    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000365 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 91.2      |
|    n_updates            | 24150     |
|    policy_gradient_loss | 6.29e-10  |
|    value_loss           | 223       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84        |
|    ep_rew_mean          | -7.92     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2417      |
|    time_elapsed         | 8025      |
|    total_timesteps      | 309376    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000365 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 81.5      |
|    n_updates            | 24160     |
|    policy_gradient_loss | 6.52e-10  |
|    value_loss           | 139       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.9      |
|    ep_rew_mean          | -8.23     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2418      |
|    time_elapsed         | 8030      |
|    total_timesteps      | 309504    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000367 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 27.9      |
|    n_updates            | 24170     |
|    policy_gradient_loss | -1.02e-07 |
|    value_loss           | 57.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.8      |
|    ep_rew_mean          | -7.71     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2419      |
|    time_elapsed         | 8033      |
|    total_timesteps      | 309632    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000367 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 80.9      |
|    n_updates            | 24180     |
|    policy_gradient_loss | 1.84e-09  |
|    value_loss           | 139       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.8      |
|    ep_rew_mean          | -7.71     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2420      |
|    time_elapsed         | 8035      |
|    total_timesteps      | 309760    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000368 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.3      |
|    n_updates            | 24190     |
|    policy_gradient_loss | -2.29e-09 |
|    value_loss           | 95.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.2     |
|    ep_rew_mean          | -7.28    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2421     |
|    time_elapsed         | 8038     |
|    total_timesteps      | 309888   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00037 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 54.7     |
|    n_updates            | 24200    |
|    policy_gradient_loss | 2.51e-09 |
|    value_loss           | 92.2     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 310000
Best mean reward: -0.99 - Last mean reward per episode: -6.62
Eval num_timesteps=310000, episode_reward=-2.40 +/- 15.09
Episode length: 72.80 +/- 20.46
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 72.8      |
|    mean_reward          | -2.4      |
| time/                   |           |
|    total_timesteps      | 310000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000373 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 58.2      |
|    n_updates            | 24210     |
|    policy_gradient_loss | 3.26e-10  |
|    value_loss           | 128       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 83       |
|    ep_rew_mean     | -7.11    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2422     |
|    time_elapsed    | 8043     |
|    total_timesteps | 310016   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83        |
|    ep_rew_mean          | -7        |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2423      |
|    time_elapsed         | 8046      |
|    total_timesteps      | 310144    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000374 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 61        |
|    n_updates            | 24220     |
|    policy_gradient_loss | -9.31e-10 |
|    value_loss           | 170       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.2      |
|    ep_rew_mean          | -7.09     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2424      |
|    time_elapsed         | 8050      |
|    total_timesteps      | 310272    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000376 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 79.6      |
|    n_updates            | 24230     |
|    policy_gradient_loss | 3.91e-09  |
|    value_loss           | 129       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83        |
|    ep_rew_mean          | -7        |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2425      |
|    time_elapsed         | 8052      |
|    total_timesteps      | 310400    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000377 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.3      |
|    n_updates            | 24240     |
|    policy_gradient_loss | -4.1e-09  |
|    value_loss           | 70.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.7      |
|    ep_rew_mean          | -6.83     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2426      |
|    time_elapsed         | 8056      |
|    total_timesteps      | 310528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000378 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 31.8      |
|    n_updates            | 24250     |
|    policy_gradient_loss | -4.98e-09 |
|    value_loss           | 76.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 82.4      |
|    ep_rew_mean          | -6.58     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2427      |
|    time_elapsed         | 8059      |
|    total_timesteps      | 310656    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000379 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.2      |
|    n_updates            | 24260     |
|    policy_gradient_loss | -4.38e-09 |
|    value_loss           | 91.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.2      |
|    ep_rew_mean          | -5.99     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2428      |
|    time_elapsed         | 8063      |
|    total_timesteps      | 310784    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000381 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 69.4      |
|    n_updates            | 24270     |
|    policy_gradient_loss | -7.78e-09 |
|    value_loss           | 130       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.2      |
|    ep_rew_mean          | -6.38     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2429      |
|    time_elapsed         | 8066      |
|    total_timesteps      | 310912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000384 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47        |
|    n_updates            | 24280     |
|    policy_gradient_loss | 3.73e-09  |
|    value_loss           | 89.4      |
---------------------------------------
Num timesteps: 311000
Best mean reward: -0.99 - Last mean reward per episode: -5.18
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.4      |
|    ep_rew_mean          | -6.68     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2430      |
|    time_elapsed         | 8069      |
|    total_timesteps      | 311040    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000388 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 42.3      |
|    n_updates            | 24290     |
|    policy_gradient_loss | -3.49e-11 |
|    value_loss           | 86.6      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 81.8      |
|    ep_rew_mean          | -6.99     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2431      |
|    time_elapsed         | 8072      |
|    total_timesteps      | 311168    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000392 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 28.4      |
|    n_updates            | 24300     |
|    policy_gradient_loss | -1.54e-09 |
|    value_loss           | 71.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.7      |
|    ep_rew_mean          | -6.53     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2432      |
|    time_elapsed         | 8076      |
|    total_timesteps      | 311296    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000396 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 45.9      |
|    n_updates            | 24310     |
|    policy_gradient_loss | -1.49e-09 |
|    value_loss           | 96.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.6      |
|    ep_rew_mean          | -6.58     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2433      |
|    time_elapsed         | 8079      |
|    total_timesteps      | 311424    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000404 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 103       |
|    n_updates            | 24320     |
|    policy_gradient_loss | -2.21e-09 |
|    value_loss           | 168       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -5.93     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2434      |
|    time_elapsed         | 8082      |
|    total_timesteps      | 311552    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000409 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 44.9      |
|    n_updates            | 24330     |
|    policy_gradient_loss | 2.47e-09  |
|    value_loss           | 86.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.1      |
|    ep_rew_mean          | -5.56     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2435      |
|    time_elapsed         | 8085      |
|    total_timesteps      | 311680    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000417 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 71.4      |
|    n_updates            | 24340     |
|    policy_gradient_loss | -5.54e-09 |
|    value_loss           | 165       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.1     |
|    ep_rew_mean          | -5.44    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2436     |
|    time_elapsed         | 8088     |
|    total_timesteps      | 311808   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00042 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 28.3     |
|    n_updates            | 24350    |
|    policy_gradient_loss | 2.33e-09 |
|    value_loss           | 68.5     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.5      |
|    ep_rew_mean          | -5.05     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2437      |
|    time_elapsed         | 8093      |
|    total_timesteps      | 311936    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000424 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.7      |
|    n_updates            | 24360     |
|    policy_gradient_loss | -4.94e-09 |
|    value_loss           | 123       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 312000
Best mean reward: -0.99 - Last mean reward per episode: -3.75
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77       |
|    ep_rew_mean          | -4.89    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2438     |
|    time_elapsed         | 8096     |
|    total_timesteps      | 312064   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00043 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 51.4     |
|    n_updates            | 24370    |
|    policy_gradient_loss | 4.66e-09 |
|    value_loss           | 167      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.6      |
|    ep_rew_mean          | -4.69     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2439      |
|    time_elapsed         | 8099      |
|    total_timesteps      | 312192    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000434 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 60.8      |
|    n_updates            | 24380     |
|    policy_gradient_loss | -4.56e-09 |
|    value_loss           | 121       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -5.11     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2440      |
|    time_elapsed         | 8103      |
|    total_timesteps      | 312320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000438 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 38.5      |
|    n_updates            | 24390     |
|    policy_gradient_loss | -5.26e-09 |
|    value_loss           | 69.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.7      |
|    ep_rew_mean          | -4.93     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2441      |
|    time_elapsed         | 8106      |
|    total_timesteps      | 312448    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000439 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 31.1      |
|    n_updates            | 24400     |
|    policy_gradient_loss | -9.31e-09 |
|    value_loss           | 67.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.2      |
|    ep_rew_mean          | -4.38     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2442      |
|    time_elapsed         | 8109      |
|    total_timesteps      | 312576    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000443 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.3      |
|    n_updates            | 24410     |
|    policy_gradient_loss | 4.87e-09  |
|    value_loss           | 89.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -4.41     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2443      |
|    time_elapsed         | 8112      |
|    total_timesteps      | 312704    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000448 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 105       |
|    n_updates            | 24420     |
|    policy_gradient_loss | 3.49e-10  |
|    value_loss           | 199       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -4.41     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2444      |
|    time_elapsed         | 8116      |
|    total_timesteps      | 312832    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00045  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 28.8      |
|    n_updates            | 24430     |
|    policy_gradient_loss | -9.08e-09 |
|    value_loss           | 71.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78        |
|    ep_rew_mean          | -5.59     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2445      |
|    time_elapsed         | 8120      |
|    total_timesteps      | 312960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000452 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 29.4      |
|    n_updates            | 24440     |
|    policy_gradient_loss | -1.21e-08 |
|    value_loss           | 61        |
---------------------------------------
Num timesteps: 313000
Best mean reward: -0.99 - Last mean reward per episode: -5.50
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.7      |
|    ep_rew_mean          | -5.46     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2446      |
|    time_elapsed         | 8127      |
|    total_timesteps      | 313088    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000454 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 51.4      |
|    n_updates            | 24450     |
|    policy_gradient_loss | 1.86e-09  |
|    value_loss           | 97.6      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.3      |
|    ep_rew_mean          | -5.55     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2447      |
|    time_elapsed         | 8131      |
|    total_timesteps      | 313216    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000462 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.5      |
|    n_updates            | 24460     |
|    policy_gradient_loss | -1.14e-09 |
|    value_loss           | 69.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.4      |
|    ep_rew_mean          | -5.5      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2448      |
|    time_elapsed         | 8134      |
|    total_timesteps      | 313344    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000467 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 60.8      |
|    n_updates            | 24470     |
|    policy_gradient_loss | -4.61e-09 |
|    value_loss           | 94.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.3      |
|    ep_rew_mean          | -5.47     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2449      |
|    time_elapsed         | 8137      |
|    total_timesteps      | 313472    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000474 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 58.3      |
|    n_updates            | 24480     |
|    policy_gradient_loss | 4.42e-09  |
|    value_loss           | 130       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.3      |
|    ep_rew_mean          | -5.64     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2450      |
|    time_elapsed         | 8140      |
|    total_timesteps      | 313600    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000478 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 81.8      |
|    n_updates            | 24490     |
|    policy_gradient_loss | -2e-09    |
|    value_loss           | 188       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77       |
|    ep_rew_mean          | -5.21    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2451     |
|    time_elapsed         | 8144     |
|    total_timesteps      | 313728   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00048 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 26.7     |
|    n_updates            | 24500    |
|    policy_gradient_loss | 1.63e-10 |
|    value_loss           | 69.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.1      |
|    ep_rew_mean          | -5.13     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2452      |
|    time_elapsed         | 8147      |
|    total_timesteps      | 313856    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000482 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 78.9      |
|    n_updates            | 24510     |
|    policy_gradient_loss | 1.86e-10  |
|    value_loss           | 204       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.1      |
|    ep_rew_mean          | -5.14     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2453      |
|    time_elapsed         | 8151      |
|    total_timesteps      | 313984    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000485 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 69.8      |
|    n_updates            | 24520     |
|    policy_gradient_loss | 1.21e-09  |
|    value_loss           | 122       |
---------------------------------------
Num timesteps: 314000
Best mean reward: -0.99 - Last mean reward per episode: -5.24
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -5.22     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2454      |
|    time_elapsed         | 8154      |
|    total_timesteps      | 314112    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000488 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 35.8      |
|    n_updates            | 24530     |
|    policy_gradient_loss | 1.3e-09   |
|    value_loss           | 68.7      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.4      |
|    ep_rew_mean          | -5.18     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2455      |
|    time_elapsed         | 8157      |
|    total_timesteps      | 314240    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000494 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 58.2      |
|    n_updates            | 24540     |
|    policy_gradient_loss | 4.66e-10  |
|    value_loss           | 126       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.1      |
|    ep_rew_mean          | -5.37     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2456      |
|    time_elapsed         | 8161      |
|    total_timesteps      | 314368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000502 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55.2      |
|    n_updates            | 24550     |
|    policy_gradient_loss | 1.02e-09  |
|    value_loss           | 118       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77.8     |
|    ep_rew_mean          | -5.33    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2457     |
|    time_elapsed         | 8166     |
|    total_timesteps      | 314496   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00051 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 83.8     |
|    n_updates            | 24560    |
|    policy_gradient_loss | 3.61e-09 |
|    value_loss           | 155      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.7      |
|    ep_rew_mean          | -5.07     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2458      |
|    time_elapsed         | 8169      |
|    total_timesteps      | 314624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000528 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45        |
|    n_updates            | 24570     |
|    policy_gradient_loss | -2.48e-09 |
|    value_loss           | 86.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.7      |
|    ep_rew_mean          | -4.95     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2459      |
|    time_elapsed         | 8172      |
|    total_timesteps      | 314752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000543 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 52.4      |
|    n_updates            | 24580     |
|    policy_gradient_loss | -2.79e-10 |
|    value_loss           | 173       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 78.8     |
|    ep_rew_mean          | -5.39    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2460     |
|    time_elapsed         | 8176     |
|    total_timesteps      | 314880   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00055 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 70.8     |
|    n_updates            | 24590    |
|    policy_gradient_loss | 6.01e-09 |
|    value_loss           | 118      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 315000
Best mean reward: -0.99 - Last mean reward per episode: -5.76
Eval num_timesteps=315000, episode_reward=-5.00 +/- 9.23
Episode length: 82.00 +/- 15.13
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 82        |
|    mean_reward          | -5        |
| time/                   |           |
|    total_timesteps      | 315000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000553 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 62.4      |
|    n_updates            | 24600     |
|    policy_gradient_loss | -5.59e-10 |
|    value_loss           | 102       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79.2     |
|    ep_rew_mean     | -5.59    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2461     |
|    time_elapsed    | 8182     |
|    total_timesteps | 315008   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.4      |
|    ep_rew_mean          | -5.6      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2462      |
|    time_elapsed         | 8186      |
|    total_timesteps      | 315136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000558 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.6      |
|    n_updates            | 24610     |
|    policy_gradient_loss | -1.3e-09  |
|    value_loss           | 77.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -5.7      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2463      |
|    time_elapsed         | 8189      |
|    total_timesteps      | 315264    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000561 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 67.2      |
|    n_updates            | 24620     |
|    policy_gradient_loss | -2.33e-10 |
|    value_loss           | 103       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -5.72     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2464      |
|    time_elapsed         | 8193      |
|    total_timesteps      | 315392    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000569 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.2      |
|    n_updates            | 24630     |
|    policy_gradient_loss | -9.31e-11 |
|    value_loss           | 95.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.8      |
|    ep_rew_mean          | -5.72     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2465      |
|    time_elapsed         | 8196      |
|    total_timesteps      | 315520    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000595 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.1      |
|    n_updates            | 24640     |
|    policy_gradient_loss | -2.28e-09 |
|    value_loss           | 98.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80        |
|    ep_rew_mean          | -5.79     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2466      |
|    time_elapsed         | 8199      |
|    total_timesteps      | 315648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000617 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 67.4      |
|    n_updates            | 24650     |
|    policy_gradient_loss | 1.4e-10   |
|    value_loss           | 124       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.3      |
|    ep_rew_mean          | -5.97     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2467      |
|    time_elapsed         | 8202      |
|    total_timesteps      | 315776    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000627 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.3      |
|    n_updates            | 24660     |
|    policy_gradient_loss | 6.98e-10  |
|    value_loss           | 88        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -3.4      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2468      |
|    time_elapsed         | 8205      |
|    total_timesteps      | 315904    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000644 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.2      |
|    n_updates            | 24670     |
|    policy_gradient_loss | 3.26e-09  |
|    value_loss           | 93.1      |
---------------------------------------
Num timesteps: 316000
Best mean reward: -0.99 - Last mean reward per episode: -3.26
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.9      |
|    ep_rew_mean          | -3.43     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2469      |
|    time_elapsed         | 8208      |
|    total_timesteps      | 316032    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000671 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 47.4      |
|    n_updates            | 24680     |
|    policy_gradient_loss | -3.24e-09 |
|    value_loss           | 83.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.9      |
|    ep_rew_mean          | -3.17     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2470      |
|    time_elapsed         | 8211      |
|    total_timesteps      | 316160    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000696 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 37.5      |
|    n_updates            | 24690     |
|    policy_gradient_loss | 3.14e-09  |
|    value_loss           | 75.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75        |
|    ep_rew_mean          | -3.18     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2471      |
|    time_elapsed         | 8215      |
|    total_timesteps      | 316288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000705 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 106       |
|    n_updates            | 24700     |
|    policy_gradient_loss | -1.4e-10  |
|    value_loss           | 205       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.4      |
|    ep_rew_mean          | -3.5      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2472      |
|    time_elapsed         | 8218      |
|    total_timesteps      | 316416    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000708 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 28.5      |
|    n_updates            | 24710     |
|    policy_gradient_loss | 1.29e-08  |
|    value_loss           | 69.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.9      |
|    ep_rew_mean          | -3.75     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2473      |
|    time_elapsed         | 8221      |
|    total_timesteps      | 316544    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000712 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.3      |
|    n_updates            | 24720     |
|    policy_gradient_loss | -4.56e-09 |
|    value_loss           | 71.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.5      |
|    ep_rew_mean          | -4.13     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2474      |
|    time_elapsed         | 8224      |
|    total_timesteps      | 316672    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000718 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 42.6      |
|    n_updates            | 24730     |
|    policy_gradient_loss | -1.26e-09 |
|    value_loss           | 86.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.6      |
|    ep_rew_mean          | -3.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2475      |
|    time_elapsed         | 8228      |
|    total_timesteps      | 316800    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000732 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 34.8      |
|    n_updates            | 24740     |
|    policy_gradient_loss | -5.33e-09 |
|    value_loss           | 69.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.1      |
|    ep_rew_mean          | -4.14     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2476      |
|    time_elapsed         | 8231      |
|    total_timesteps      | 316928    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000748 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 52.6      |
|    n_updates            | 24750     |
|    policy_gradient_loss | -1.86e-10 |
|    value_loss           | 99.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 317000
Best mean reward: -0.99 - Last mean reward per episode: -4.22
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.2      |
|    ep_rew_mean          | -4.19     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2477      |
|    time_elapsed         | 8235      |
|    total_timesteps      | 317056    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000793 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 59.4      |
|    n_updates            | 24760     |
|    policy_gradient_loss | -3.96e-09 |
|    value_loss           | 104       |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 75.3        |
|    ep_rew_mean          | -3.85       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 2478        |
|    time_elapsed         | 8238        |
|    total_timesteps      | 317184      |
| train/                  |             |
|    approx_kl            | 0.002094566 |
|    clip_fraction        | 0.00625     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.000542   |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 68.1        |
|    n_updates            | 24770       |
|    policy_gradient_loss | -0.000706   |
|    value_loss           | 127         |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -3.81     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2479      |
|    time_elapsed         | 8242      |
|    total_timesteps      | 317312    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000355 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 23.8      |
|    n_updates            | 24780     |
|    policy_gradient_loss | -3.17e-09 |
|    value_loss           | 70.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.3      |
|    ep_rew_mean          | -3.86     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2480      |
|    time_elapsed         | 8245      |
|    total_timesteps      | 317440    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000339 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.4      |
|    n_updates            | 24790     |
|    policy_gradient_loss | 3.45e-09  |
|    value_loss           | 98.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.3      |
|    ep_rew_mean          | -3.86     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2481      |
|    time_elapsed         | 8248      |
|    total_timesteps      | 317568    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000341 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 56.2      |
|    n_updates            | 24800     |
|    policy_gradient_loss | -2.75e-09 |
|    value_loss           | 98.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.3      |
|    ep_rew_mean          | -3.86     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2482      |
|    time_elapsed         | 8252      |
|    total_timesteps      | 317696    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000344 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 27.2      |
|    n_updates            | 24810     |
|    policy_gradient_loss | 1.48e-08  |
|    value_loss           | 58.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.3      |
|    ep_rew_mean          | -3.86     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2483      |
|    time_elapsed         | 8256      |
|    total_timesteps      | 317824    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000345 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 26.1      |
|    n_updates            | 24820     |
|    policy_gradient_loss | 8.26e-08  |
|    value_loss           | 56.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.3      |
|    ep_rew_mean          | -3.86     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2484      |
|    time_elapsed         | 8260      |
|    total_timesteps      | 317952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000345 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 27.3      |
|    n_updates            | 24830     |
|    policy_gradient_loss | 2.34e-08  |
|    value_loss           | 55.9      |
---------------------------------------
Num timesteps: 318000
Best mean reward: -0.99 - Last mean reward per episode: -4.54
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.3      |
|    ep_rew_mean          | -3.86     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2485      |
|    time_elapsed         | 8264      |
|    total_timesteps      | 318080    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000345 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 25.8      |
|    n_updates            | 24840     |
|    policy_gradient_loss | -6.4e-09  |
|    value_loss           | 55        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.3      |
|    ep_rew_mean          | -3.86     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2486      |
|    time_elapsed         | 8268      |
|    total_timesteps      | 318208    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000346 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26.5      |
|    n_updates            | 24850     |
|    policy_gradient_loss | 3.4e-08   |
|    value_loss           | 54        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.3      |
|    ep_rew_mean          | -3.86     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2487      |
|    time_elapsed         | 8272      |
|    total_timesteps      | 318336    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000346 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 24.9      |
|    n_updates            | 24860     |
|    policy_gradient_loss | 3.11e-08  |
|    value_loss           | 53.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.7      |
|    ep_rew_mean          | -8.87     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2488      |
|    time_elapsed         | 8275      |
|    total_timesteps      | 318464    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000346 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 23.9      |
|    n_updates            | 24870     |
|    policy_gradient_loss | -7.74e-08 |
|    value_loss           | 52.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.1      |
|    ep_rew_mean          | -8.96     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2489      |
|    time_elapsed         | 8280      |
|    total_timesteps      | 318592    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000346 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 19.8      |
|    n_updates            | 24880     |
|    policy_gradient_loss | -7.17e-09 |
|    value_loss           | 38.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.1      |
|    ep_rew_mean          | -9.06     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2490      |
|    time_elapsed         | 8283      |
|    total_timesteps      | 318720    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000347 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 101       |
|    n_updates            | 24890     |
|    policy_gradient_loss | -8.1e-09  |
|    value_loss           | 207       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.2      |
|    ep_rew_mean          | -9.68     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2491      |
|    time_elapsed         | 8287      |
|    total_timesteps      | 318848    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000347 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 74.3      |
|    n_updates            | 24900     |
|    policy_gradient_loss | -8.99e-09 |
|    value_loss           | 124       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.2      |
|    ep_rew_mean          | -9.68     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2492      |
|    time_elapsed         | 8290      |
|    total_timesteps      | 318976    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000347 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37        |
|    n_updates            | 24910     |
|    policy_gradient_loss | 6.19e-09  |
|    value_loss           | 78.3      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 319000
Best mean reward: -0.99 - Last mean reward per episode: -9.46
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.7      |
|    ep_rew_mean          | -10.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2493      |
|    time_elapsed         | 8293      |
|    total_timesteps      | 319104    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000348 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 23.7      |
|    n_updates            | 24920     |
|    policy_gradient_loss | 4.66e-11  |
|    value_loss           | 49.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.4      |
|    ep_rew_mean          | -10.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2494      |
|    time_elapsed         | 8296      |
|    total_timesteps      | 319232    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000349 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.4      |
|    n_updates            | 24930     |
|    policy_gradient_loss | -3.86e-09 |
|    value_loss           | 114       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.4      |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2495      |
|    time_elapsed         | 8300      |
|    total_timesteps      | 319360    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000349 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.1      |
|    n_updates            | 24940     |
|    policy_gradient_loss | -2.33e-10 |
|    value_loss           | 113       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.3     |
|    ep_rew_mean          | -10.1    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2496     |
|    time_elapsed         | 8303     |
|    total_timesteps      | 319488   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00035 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 90       |
|    n_updates            | 24950    |
|    policy_gradient_loss | 4.47e-09 |
|    value_loss           | 212      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.3      |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2497      |
|    time_elapsed         | 8306      |
|    total_timesteps      | 319616    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000351 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 39.3      |
|    n_updates            | 24960     |
|    policy_gradient_loss | 4.66e-10  |
|    value_loss           | 106       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.3      |
|    ep_rew_mean          | -10       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2498      |
|    time_elapsed         | 8310      |
|    total_timesteps      | 319744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000353 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 61.2      |
|    n_updates            | 24970     |
|    policy_gradient_loss | -1.58e-09 |
|    value_loss           | 103       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.9      |
|    ep_rew_mean          | -10.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2499      |
|    time_elapsed         | 8313      |
|    total_timesteps      | 319872    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000353 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 62.2      |
|    n_updates            | 24980     |
|    policy_gradient_loss | 5.59e-10  |
|    value_loss           | 144       |
---------------------------------------
Num timesteps: 320000
Best mean reward: -0.99 - Last mean reward per episode: -10.30
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=320000, episode_reward=1.50 +/- 16.15
Episode length: 77.00 +/- 19.88
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 77        |
|    mean_reward          | 1.5       |
| time/                   |           |
|    total_timesteps      | 320000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000355 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 64.3      |
|    n_updates            | 24990     |
|    policy_gradient_loss | -4.8e-09  |
|    value_loss           | 163       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 87.6     |
|    ep_rew_mean     | -9.99    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2500     |
|    time_elapsed    | 8322     |
|    total_timesteps | 320000   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.6      |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2501      |
|    time_elapsed         | 8325      |
|    total_timesteps      | 320128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000359 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 55.4      |
|    n_updates            | 25000     |
|    policy_gradient_loss | 8.38e-10  |
|    value_loss           | 107       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.9      |
|    ep_rew_mean          | -10.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2502      |
|    time_elapsed         | 8329      |
|    total_timesteps      | 320256    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000364 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 70.9      |
|    n_updates            | 25010     |
|    policy_gradient_loss | 1.02e-09  |
|    value_loss           | 110       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.1      |
|    ep_rew_mean          | -10.4     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2503      |
|    time_elapsed         | 8332      |
|    total_timesteps      | 320384    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000367 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 39.2      |
|    n_updates            | 25020     |
|    policy_gradient_loss | -2.44e-09 |
|    value_loss           | 98.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.7      |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2504      |
|    time_elapsed         | 8335      |
|    total_timesteps      | 320512    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000369 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 54.4      |
|    n_updates            | 25030     |
|    policy_gradient_loss | -5.63e-09 |
|    value_loss           | 99.7      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.8     |
|    ep_rew_mean          | -10.2    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2505     |
|    time_elapsed         | 8338     |
|    total_timesteps      | 320640   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00037 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 95.8     |
|    n_updates            | 25040    |
|    policy_gradient_loss | 3.28e-09 |
|    value_loss           | 180      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88        |
|    ep_rew_mean          | -10.4     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2506      |
|    time_elapsed         | 8342      |
|    total_timesteps      | 320768    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000371 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38        |
|    n_updates            | 25050     |
|    policy_gradient_loss | 3.73e-09  |
|    value_loss           | 73.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.9      |
|    ep_rew_mean          | -10.4     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2507      |
|    time_elapsed         | 8345      |
|    total_timesteps      | 320896    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000373 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 76.8      |
|    n_updates            | 25060     |
|    policy_gradient_loss | 2.1e-09   |
|    value_loss           | 166       |
---------------------------------------
Num timesteps: 321000
Best mean reward: -0.99 - Last mean reward per episode: -8.72
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.6      |
|    ep_rew_mean          | -10.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2508      |
|    time_elapsed         | 8349      |
|    total_timesteps      | 321024    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000376 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.6      |
|    n_updates            | 25070     |
|    policy_gradient_loss | 1.96e-09  |
|    value_loss           | 131       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.6      |
|    ep_rew_mean          | -9.62     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2509      |
|    time_elapsed         | 8353      |
|    total_timesteps      | 321152    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000378 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.8      |
|    n_updates            | 25080     |
|    policy_gradient_loss | 6.98e-11  |
|    value_loss           | 99.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.4      |
|    ep_rew_mean          | -9.41     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2510      |
|    time_elapsed         | 8356      |
|    total_timesteps      | 321280    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000383 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 43        |
|    n_updates            | 25090     |
|    policy_gradient_loss | 1.3e-09   |
|    value_loss           | 121       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.4      |
|    ep_rew_mean          | -9.6      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2511      |
|    time_elapsed         | 8360      |
|    total_timesteps      | 321408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000389 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 96.3      |
|    n_updates            | 25100     |
|    policy_gradient_loss | 5.22e-09  |
|    value_loss           | 182       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.9      |
|    ep_rew_mean          | -8.84     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2512      |
|    time_elapsed         | 8363      |
|    total_timesteps      | 321536    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000393 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.4      |
|    n_updates            | 25110     |
|    policy_gradient_loss | -2.19e-09 |
|    value_loss           | 97        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.5      |
|    ep_rew_mean          | -8.63     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2513      |
|    time_elapsed         | 8366      |
|    total_timesteps      | 321664    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000398 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.6      |
|    n_updates            | 25120     |
|    policy_gradient_loss | -2.84e-09 |
|    value_loss           | 91.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.5      |
|    ep_rew_mean          | -8.65     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2514      |
|    time_elapsed         | 8370      |
|    total_timesteps      | 321792    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000404 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 41.8      |
|    n_updates            | 25130     |
|    policy_gradient_loss | 6.57e-09  |
|    value_loss           | 87.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.6      |
|    ep_rew_mean          | -8.72     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2515      |
|    time_elapsed         | 8373      |
|    total_timesteps      | 321920    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000407 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.3      |
|    n_updates            | 25140     |
|    policy_gradient_loss | 2.27e-09  |
|    value_loss           | 86.1      |
---------------------------------------
Num timesteps: 322000
Best mean reward: -0.99 - Last mean reward per episode: -9.21
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.9      |
|    ep_rew_mean          | -9.06     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2516      |
|    time_elapsed         | 8376      |
|    total_timesteps      | 322048    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000412 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.7      |
|    n_updates            | 25150     |
|    policy_gradient_loss | -8.85e-10 |
|    value_loss           | 103       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.9      |
|    ep_rew_mean          | -9.06     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2517      |
|    time_elapsed         | 8379      |
|    total_timesteps      | 322176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000417 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.2      |
|    n_updates            | 25160     |
|    policy_gradient_loss | -4.89e-10 |
|    value_loss           | 90.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.1      |
|    ep_rew_mean          | -9.23     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2518      |
|    time_elapsed         | 8382      |
|    total_timesteps      | 322304    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000424 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.8      |
|    n_updates            | 25170     |
|    policy_gradient_loss | -2.05e-09 |
|    value_loss           | 94.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.6      |
|    ep_rew_mean          | -9.71     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2519      |
|    time_elapsed         | 8385      |
|    total_timesteps      | 322432    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000431 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 38.4      |
|    n_updates            | 25180     |
|    policy_gradient_loss | 1.09e-08  |
|    value_loss           | 74.5      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 85.5         |
|    ep_rew_mean          | -9.74        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 2520         |
|    time_elapsed         | 8388         |
|    total_timesteps      | 322560       |
| train/                  |              |
|    approx_kl            | 0.0008582943 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00035     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 46.3         |
|    n_updates            | 25190        |
|    policy_gradient_loss | -0.000499    |
|    value_loss           | 81.6         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.9      |
|    ep_rew_mean          | -9.85     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2521      |
|    time_elapsed         | 8391      |
|    total_timesteps      | 322688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000261 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 53.9      |
|    n_updates            | 25200     |
|    policy_gradient_loss | 1.63e-09  |
|    value_loss           | 97.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.7      |
|    ep_rew_mean          | -9.87     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2522      |
|    time_elapsed         | 8395      |
|    total_timesteps      | 322816    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000252 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 127       |
|    n_updates            | 25210     |
|    policy_gradient_loss | -2.93e-09 |
|    value_loss           | 177       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.2      |
|    ep_rew_mean          | -9.61     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2523      |
|    time_elapsed         | 8398      |
|    total_timesteps      | 322944    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000252 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.9      |
|    n_updates            | 25220     |
|    policy_gradient_loss | -2.65e-09 |
|    value_loss           | 88.1      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 323000
Best mean reward: -0.99 - Last mean reward per episode: -9.36
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.9      |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2524      |
|    time_elapsed         | 8401      |
|    total_timesteps      | 323072    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000253 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.7      |
|    n_updates            | 25230     |
|    policy_gradient_loss | 1.53e-08  |
|    value_loss           | 73.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | -10.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2525      |
|    time_elapsed         | 8405      |
|    total_timesteps      | 323200    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000254 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.5      |
|    n_updates            | 25240     |
|    policy_gradient_loss | -2.47e-09 |
|    value_loss           | 104       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.3      |
|    ep_rew_mean          | -10.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2526      |
|    time_elapsed         | 8409      |
|    total_timesteps      | 323328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000255 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 42.5      |
|    n_updates            | 25250     |
|    policy_gradient_loss | -5.1e-09  |
|    value_loss           | 89.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.7      |
|    ep_rew_mean          | -10.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2527      |
|    time_elapsed         | 8412      |
|    total_timesteps      | 323456    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000257 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 90        |
|    n_updates            | 25260     |
|    policy_gradient_loss | -1.4e-09  |
|    value_loss           | 156       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88        |
|    ep_rew_mean          | -11.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2528      |
|    time_elapsed         | 8415      |
|    total_timesteps      | 323584    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000258 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.2      |
|    n_updates            | 25270     |
|    policy_gradient_loss | -8.43e-09 |
|    value_loss           | 79.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.9      |
|    ep_rew_mean          | -10.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2529      |
|    time_elapsed         | 8419      |
|    total_timesteps      | 323712    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000259 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45.7      |
|    n_updates            | 25280     |
|    policy_gradient_loss | 5.03e-09  |
|    value_loss           | 105       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.8      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2530      |
|    time_elapsed         | 8422      |
|    total_timesteps      | 323840    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000261 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.1      |
|    n_updates            | 25290     |
|    policy_gradient_loss | 3.14e-09  |
|    value_loss           | 96.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.9      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2531      |
|    time_elapsed         | 8426      |
|    total_timesteps      | 323968    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000262 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30.1      |
|    n_updates            | 25300     |
|    policy_gradient_loss | -1.82e-09 |
|    value_loss           | 72.8      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 324000
Best mean reward: -0.99 - Last mean reward per episode: -10.90
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.7      |
|    ep_rew_mean          | -10.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2532      |
|    time_elapsed         | 8430      |
|    total_timesteps      | 324096    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000263 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 38.8      |
|    n_updates            | 25310     |
|    policy_gradient_loss | 8.38e-10  |
|    value_loss           | 86.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.8      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2533      |
|    time_elapsed         | 8434      |
|    total_timesteps      | 324224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000263 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 100       |
|    n_updates            | 25320     |
|    policy_gradient_loss | -7.47e-09 |
|    value_loss           | 223       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.6      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2534      |
|    time_elapsed         | 8437      |
|    total_timesteps      | 324352    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000263 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 71.3      |
|    n_updates            | 25330     |
|    policy_gradient_loss | 5.87e-09  |
|    value_loss           | 165       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.3      |
|    ep_rew_mean          | -10.9     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2535      |
|    time_elapsed         | 8440      |
|    total_timesteps      | 324480    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000264 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.2      |
|    n_updates            | 25340     |
|    policy_gradient_loss | 3.54e-09  |
|    value_loss           | 92        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.9      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2536      |
|    time_elapsed         | 8445      |
|    total_timesteps      | 324608    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000266 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 58        |
|    n_updates            | 25350     |
|    policy_gradient_loss | -2e-09    |
|    value_loss           | 106       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88        |
|    ep_rew_mean          | -10.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2537      |
|    time_elapsed         | 8448      |
|    total_timesteps      | 324736    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000267 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.6      |
|    n_updates            | 25360     |
|    policy_gradient_loss | 7.12e-09  |
|    value_loss           | 131       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.1      |
|    ep_rew_mean          | -10.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2538      |
|    time_elapsed         | 8451      |
|    total_timesteps      | 324864    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000268 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 61.2      |
|    n_updates            | 25370     |
|    policy_gradient_loss | 2.56e-09  |
|    value_loss           | 134       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.3      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2539      |
|    time_elapsed         | 8454      |
|    total_timesteps      | 324992    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000271 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.8      |
|    n_updates            | 25380     |
|    policy_gradient_loss | -5.17e-09 |
|    value_loss           | 90.7      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 325000
Best mean reward: -0.99 - Last mean reward per episode: -9.78
Eval num_timesteps=325000, episode_reward=-2.70 +/- 4.64
Episode length: 69.40 +/- 9.54
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 69.4      |
|    mean_reward          | -2.7      |
| time/                   |           |
|    total_timesteps      | 325000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000274 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 89.7      |
|    n_updates            | 25390     |
|    policy_gradient_loss | -4.19e-10 |
|    value_loss           | 204       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 88.2     |
|    ep_rew_mean     | -10.7    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2540     |
|    time_elapsed    | 8459     |
|    total_timesteps | 325120   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.2      |
|    ep_rew_mean          | -10.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2541      |
|    time_elapsed         | 8463      |
|    total_timesteps      | 325248    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000274 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.8      |
|    n_updates            | 25400     |
|    policy_gradient_loss | -6.05e-10 |
|    value_loss           | 69.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88        |
|    ep_rew_mean          | -10.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2542      |
|    time_elapsed         | 8465      |
|    total_timesteps      | 325376    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000276 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 42.3      |
|    n_updates            | 25410     |
|    policy_gradient_loss | -4.38e-09 |
|    value_loss           | 96        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 87.6     |
|    ep_rew_mean          | -10.3    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2543     |
|    time_elapsed         | 8469     |
|    total_timesteps      | 325504   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00028 |
|    explained_variance   | 5.96e-08 |
|    learning_rate        | 0.0003   |
|    loss                 | 29.2     |
|    n_updates            | 25420    |
|    policy_gradient_loss | 3.14e-09 |
|    value_loss           | 69.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.2      |
|    ep_rew_mean          | -10.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2544      |
|    time_elapsed         | 8472      |
|    total_timesteps      | 325632    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000282 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 55.8      |
|    n_updates            | 25430     |
|    policy_gradient_loss | 9.31e-11  |
|    value_loss           | 114       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88        |
|    ep_rew_mean          | -10.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2545      |
|    time_elapsed         | 8477      |
|    total_timesteps      | 325760    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000283 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 81.2      |
|    n_updates            | 25440     |
|    policy_gradient_loss | 6.15e-09  |
|    value_loss           | 127       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.2      |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2546      |
|    time_elapsed         | 8481      |
|    total_timesteps      | 325888    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000283 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 34.4      |
|    n_updates            | 25450     |
|    policy_gradient_loss | 1.51e-09  |
|    value_loss           | 70.5      |
---------------------------------------
Num timesteps: 326000
Best mean reward: -0.99 - Last mean reward per episode: -3.85
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.3      |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2547      |
|    time_elapsed         | 8485      |
|    total_timesteps      | 326016    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000284 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 80.6      |
|    n_updates            | 25460     |
|    policy_gradient_loss | 2.47e-09  |
|    value_loss           | 132       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.2      |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2548      |
|    time_elapsed         | 8488      |
|    total_timesteps      | 326144    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000285 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.4      |
|    n_updates            | 25470     |
|    policy_gradient_loss | 2.19e-09  |
|    value_loss           | 94.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.6      |
|    ep_rew_mean          | -5.09     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2549      |
|    time_elapsed         | 8490      |
|    total_timesteps      | 326272    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000288 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 38.3      |
|    n_updates            | 25480     |
|    policy_gradient_loss | -1.33e-09 |
|    value_loss           | 87.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.6      |
|    ep_rew_mean          | -5.09     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2550      |
|    time_elapsed         | 8494      |
|    total_timesteps      | 326400    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000291 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 61.3      |
|    n_updates            | 25490     |
|    policy_gradient_loss | 7.61e-09  |
|    value_loss           | 122       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.9      |
|    ep_rew_mean          | -3.64     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2551      |
|    time_elapsed         | 8498      |
|    total_timesteps      | 326528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000293 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.6      |
|    n_updates            | 25500     |
|    policy_gradient_loss | -9.36e-09 |
|    value_loss           | 71        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75        |
|    ep_rew_mean          | -3.49     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2552      |
|    time_elapsed         | 8501      |
|    total_timesteps      | 326656    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000293 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 60.8      |
|    n_updates            | 25510     |
|    policy_gradient_loss | -5.26e-09 |
|    value_loss           | 177       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75        |
|    ep_rew_mean          | -3.4      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2553      |
|    time_elapsed         | 8505      |
|    total_timesteps      | 326784    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000294 |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 83.9      |
|    n_updates            | 25520     |
|    policy_gradient_loss | -1.49e-09 |
|    value_loss           | 169       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.8      |
|    ep_rew_mean          | -3.49     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2554      |
|    time_elapsed         | 8509      |
|    total_timesteps      | 326912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000294 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 59.5      |
|    n_updates            | 25530     |
|    policy_gradient_loss | 2.77e-09  |
|    value_loss           | 102       |
---------------------------------------
Num timesteps: 327000
Best mean reward: -0.99 - Last mean reward per episode: -3.38
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.9      |
|    ep_rew_mean          | -3.56     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2555      |
|    time_elapsed         | 8513      |
|    total_timesteps      | 327040    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000295 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.6      |
|    n_updates            | 25540     |
|    policy_gradient_loss | 6.05e-10  |
|    value_loss           | 98.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -3.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2556      |
|    time_elapsed         | 8516      |
|    total_timesteps      | 327168    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000298 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.9      |
|    n_updates            | 25550     |
|    policy_gradient_loss | -3.45e-09 |
|    value_loss           | 68.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -3.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2557      |
|    time_elapsed         | 8520      |
|    total_timesteps      | 327296    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000301 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 45.8      |
|    n_updates            | 25560     |
|    policy_gradient_loss | -7.68e-10 |
|    value_loss           | 94        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -3.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2558      |
|    time_elapsed         | 8524      |
|    total_timesteps      | 327424    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000304 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 28.4      |
|    n_updates            | 25570     |
|    policy_gradient_loss | 1.4e-10   |
|    value_loss           | 60.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -3.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2559      |
|    time_elapsed         | 8529      |
|    total_timesteps      | 327552    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000305 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26.5      |
|    n_updates            | 25580     |
|    policy_gradient_loss | 2.88e-08  |
|    value_loss           | 59        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -3.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2560      |
|    time_elapsed         | 8533      |
|    total_timesteps      | 327680    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000306 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 28.8      |
|    n_updates            | 25590     |
|    policy_gradient_loss | 7.12e-08  |
|    value_loss           | 58        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -3.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2561      |
|    time_elapsed         | 8538      |
|    total_timesteps      | 327808    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000306 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26        |
|    n_updates            | 25600     |
|    policy_gradient_loss | -3.82e-08 |
|    value_loss           | 57.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -3.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2562      |
|    time_elapsed         | 8542      |
|    total_timesteps      | 327936    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000306 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 27.3      |
|    n_updates            | 25610     |
|    policy_gradient_loss | 5.31e-08  |
|    value_loss           | 56.3      |
---------------------------------------
Num timesteps: 328000
Best mean reward: -0.99 - Last mean reward per episode: -3.58
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -3.67     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2563      |
|    time_elapsed         | 8547      |
|    total_timesteps      | 328064    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000306 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 25.6      |
|    n_updates            | 25620     |
|    policy_gradient_loss | 6.52e-10  |
|    value_loss           | 55.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.6      |
|    ep_rew_mean          | -8.79     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2564      |
|    time_elapsed         | 8551      |
|    total_timesteps      | 328192    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000307 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 26.1      |
|    n_updates            | 25630     |
|    policy_gradient_loss | -2.96e-08 |
|    value_loss           | 54.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.8      |
|    ep_rew_mean          | -8.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2565      |
|    time_elapsed         | 8555      |
|    total_timesteps      | 328320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000307 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 18.8      |
|    n_updates            | 25640     |
|    policy_gradient_loss | -7.15e-09 |
|    value_loss           | 41.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.1      |
|    ep_rew_mean          | -9.04     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2566      |
|    time_elapsed         | 8560      |
|    total_timesteps      | 328448    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000307 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.4      |
|    n_updates            | 25650     |
|    policy_gradient_loss | 5.45e-09  |
|    value_loss           | 126       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.4      |
|    ep_rew_mean          | -8.98     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2567      |
|    time_elapsed         | 8563      |
|    total_timesteps      | 328576    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000308 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.7      |
|    n_updates            | 25660     |
|    policy_gradient_loss | 7.45e-10  |
|    value_loss           | 115       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85        |
|    ep_rew_mean          | -8.9      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2568      |
|    time_elapsed         | 8566      |
|    total_timesteps      | 328704    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000311 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 112       |
|    n_updates            | 25670     |
|    policy_gradient_loss | -6.5e-09  |
|    value_loss           | 197       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.9      |
|    ep_rew_mean          | -8.57     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2569      |
|    time_elapsed         | 8569      |
|    total_timesteps      | 328832    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000313 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 63        |
|    n_updates            | 25680     |
|    policy_gradient_loss | -2.82e-09 |
|    value_loss           | 114       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.1      |
|    ep_rew_mean          | -8.64     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2570      |
|    time_elapsed         | 8572      |
|    total_timesteps      | 328960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000314 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 167       |
|    n_updates            | 25690     |
|    policy_gradient_loss | -6.38e-09 |
|    value_loss           | 233       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 329000
Best mean reward: -0.99 - Last mean reward per episode: -8.87
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.5      |
|    ep_rew_mean          | -9.07     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2571      |
|    time_elapsed         | 8576      |
|    total_timesteps      | 329088    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000315 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.9      |
|    n_updates            | 25700     |
|    policy_gradient_loss | -3.73e-10 |
|    value_loss           | 74.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.7      |
|    ep_rew_mean          | -9.56     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2572      |
|    time_elapsed         | 8580      |
|    total_timesteps      | 329216    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000316 |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 44.1      |
|    n_updates            | 25710     |
|    policy_gradient_loss | 1.35e-09  |
|    value_loss           | 76.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.3      |
|    ep_rew_mean          | -9.77     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2573      |
|    time_elapsed         | 8584      |
|    total_timesteps      | 329344    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000318 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 61.6      |
|    n_updates            | 25720     |
|    policy_gradient_loss | -2.77e-09 |
|    value_loss           | 113       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87        |
|    ep_rew_mean          | -9.53     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2574      |
|    time_elapsed         | 8587      |
|    total_timesteps      | 329472    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000324 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 71.8      |
|    n_updates            | 25730     |
|    policy_gradient_loss | 4.66e-10  |
|    value_loss           | 115       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.4      |
|    ep_rew_mean          | -9.81     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2575      |
|    time_elapsed         | 8590      |
|    total_timesteps      | 329600    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000329 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 108       |
|    n_updates            | 25740     |
|    policy_gradient_loss | -2.84e-09 |
|    value_loss           | 182       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.6      |
|    ep_rew_mean          | -9.98     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2576      |
|    time_elapsed         | 8593      |
|    total_timesteps      | 329728    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000333 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 49.1      |
|    n_updates            | 25750     |
|    policy_gradient_loss | -3.4e-09  |
|    value_loss           | 113       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.6      |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2577      |
|    time_elapsed         | 8596      |
|    total_timesteps      | 329856    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000336 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.5      |
|    n_updates            | 25760     |
|    policy_gradient_loss | 4.68e-09  |
|    value_loss           | 111       |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 87.9        |
|    ep_rew_mean          | -10.1       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 2578        |
|    time_elapsed         | 8599        |
|    total_timesteps      | 329984      |
| train/                  |             |
|    approx_kl            | 0.002385146 |
|    clip_fraction        | 0.00547     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.000226   |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 73.6        |
|    n_updates            | 25770       |
|    policy_gradient_loss | -0.000312   |
|    value_loss           | 113         |
-----------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 330000
Best mean reward: -0.99 - Last mean reward per episode: -10.13
Eval num_timesteps=330000, episode_reward=-9.70 +/- 10.34
Episode length: 91.40 +/- 24.53
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 91.4      |
|    mean_reward          | -9.7      |
| time/                   |           |
|    total_timesteps      | 330000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000142 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 68.3      |
|    n_updates            | 25780     |
|    policy_gradient_loss | 5.36e-10  |
|    value_loss           | 140       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 88.1     |
|    ep_rew_mean     | -10.3    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2579     |
|    time_elapsed    | 8604     |
|    total_timesteps | 330112   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.8      |
|    ep_rew_mean          | -10.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2580      |
|    time_elapsed         | 8607      |
|    total_timesteps      | 330240    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000134 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 60.9      |
|    n_updates            | 25790     |
|    policy_gradient_loss | 2.42e-09  |
|    value_loss           | 112       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.4      |
|    ep_rew_mean          | -9.79     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2581      |
|    time_elapsed         | 8610      |
|    total_timesteps      | 330368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000134 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.8      |
|    n_updates            | 25800     |
|    policy_gradient_loss | 1.14e-09  |
|    value_loss           | 107       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.5      |
|    ep_rew_mean          | -9.87     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2582      |
|    time_elapsed         | 8614      |
|    total_timesteps      | 330496    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000134 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 97.2      |
|    n_updates            | 25810     |
|    policy_gradient_loss | 2.61e-09  |
|    value_loss           | 196       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.5      |
|    ep_rew_mean          | -9.75     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2583      |
|    time_elapsed         | 8617      |
|    total_timesteps      | 330624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000134 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 60.2      |
|    n_updates            | 25820     |
|    policy_gradient_loss | 3.73e-10  |
|    value_loss           | 105       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.3      |
|    ep_rew_mean          | -9.73     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2584      |
|    time_elapsed         | 8621      |
|    total_timesteps      | 330752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000135 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 57.8      |
|    n_updates            | 25830     |
|    policy_gradient_loss | -6.75e-10 |
|    value_loss           | 141       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.5      |
|    ep_rew_mean          | -9.54     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2585      |
|    time_elapsed         | 8624      |
|    total_timesteps      | 330880    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000135 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.1      |
|    n_updates            | 25840     |
|    policy_gradient_loss | 1.75e-09  |
|    value_loss           | 97.2      |
---------------------------------------
Num timesteps: 331000
Best mean reward: -0.99 - Last mean reward per episode: -8.82
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.2      |
|    ep_rew_mean          | -9.4      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2586      |
|    time_elapsed         | 8627      |
|    total_timesteps      | 331008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000135 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 106       |
|    n_updates            | 25850     |
|    policy_gradient_loss | -3.4e-09  |
|    value_loss           | 218       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.2      |
|    ep_rew_mean          | -9.4      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2587      |
|    time_elapsed         | 8630      |
|    total_timesteps      | 331136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000136 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 52.3      |
|    n_updates            | 25860     |
|    policy_gradient_loss | -4.7e-09  |
|    value_loss           | 92.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.2      |
|    ep_rew_mean          | -9.3      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2588      |
|    time_elapsed         | 8634      |
|    total_timesteps      | 331264    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000136 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30.1      |
|    n_updates            | 25870     |
|    policy_gradient_loss | -2.65e-08 |
|    value_loss           | 59.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.9      |
|    ep_rew_mean          | -9.04     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2589      |
|    time_elapsed         | 8637      |
|    total_timesteps      | 331392    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000136 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55.2      |
|    n_updates            | 25880     |
|    policy_gradient_loss | -3.63e-09 |
|    value_loss           | 81.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.1      |
|    ep_rew_mean          | -9.36     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2590      |
|    time_elapsed         | 8641      |
|    total_timesteps      | 331520    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000136 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 76.5      |
|    n_updates            | 25890     |
|    policy_gradient_loss | 3.31e-09  |
|    value_loss           | 137       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.3      |
|    ep_rew_mean          | -9.45     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2591      |
|    time_elapsed         | 8644      |
|    total_timesteps      | 331648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000136 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 52.1      |
|    n_updates            | 25900     |
|    policy_gradient_loss | 1.16e-09  |
|    value_loss           | 92.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.4      |
|    ep_rew_mean          | -9.11     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2592      |
|    time_elapsed         | 8647      |
|    total_timesteps      | 331776    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000136 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 53.6      |
|    n_updates            | 25910     |
|    policy_gradient_loss | 2.24e-09  |
|    value_loss           | 94.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.3      |
|    ep_rew_mean          | -8.97     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2593      |
|    time_elapsed         | 8650      |
|    total_timesteps      | 331904    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000137 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.4      |
|    n_updates            | 25920     |
|    policy_gradient_loss | -6.22e-09 |
|    value_loss           | 70.7      |
---------------------------------------
Num timesteps: 332000
Best mean reward: -0.99 - Last mean reward per episode: -8.57
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.8      |
|    ep_rew_mean          | -8.89     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2594      |
|    time_elapsed         | 8655      |
|    total_timesteps      | 332032    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000137 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 71        |
|    n_updates            | 25930     |
|    policy_gradient_loss | -4.91e-09 |
|    value_loss           | 135       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.8      |
|    ep_rew_mean          | -8.48     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2595      |
|    time_elapsed         | 8658      |
|    total_timesteps      | 332160    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000137 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.5      |
|    n_updates            | 25940     |
|    policy_gradient_loss | -1.12e-09 |
|    value_loss           | 96.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.4      |
|    ep_rew_mean          | -8.31     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2596      |
|    time_elapsed         | 8662      |
|    total_timesteps      | 332288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000138 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.2      |
|    n_updates            | 25950     |
|    policy_gradient_loss | -2.93e-09 |
|    value_loss           | 87.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.5      |
|    ep_rew_mean          | -7.95     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2597      |
|    time_elapsed         | 8667      |
|    total_timesteps      | 332416    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000138 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 41.7      |
|    n_updates            | 25960     |
|    policy_gradient_loss | -3.8e-09  |
|    value_loss           | 87        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.2      |
|    ep_rew_mean          | -8.02     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2598      |
|    time_elapsed         | 8671      |
|    total_timesteps      | 332544    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000139 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53        |
|    n_updates            | 25970     |
|    policy_gradient_loss | -2.61e-09 |
|    value_loss           | 92.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.2      |
|    ep_rew_mean          | -8.02     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2599      |
|    time_elapsed         | 8674      |
|    total_timesteps      | 332672    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000139 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 45.2      |
|    n_updates            | 25980     |
|    policy_gradient_loss | -3.96e-09 |
|    value_loss           | 119       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.6     |
|    ep_rew_mean          | -8.8     |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2600     |
|    time_elapsed         | 8678     |
|    total_timesteps      | 332800   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00014 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 31.2     |
|    n_updates            | 25990    |
|    policy_gradient_loss | 1.29e-07 |
|    value_loss           | 63.3     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.2     |
|    ep_rew_mean          | -8.71    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2601     |
|    time_elapsed         | 8681     |
|    total_timesteps      | 332928   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00014 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 37.9     |
|    n_updates            | 26000    |
|    policy_gradient_loss | 3.31e-09 |
|    value_loss           | 88.6     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 333000
Best mean reward: -0.99 - Last mean reward per episode: -9.36
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 84.2     |
|    ep_rew_mean          | -8.79    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2602     |
|    time_elapsed         | 8684     |
|    total_timesteps      | 333056   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00014 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 48.5     |
|    n_updates            | 26010    |
|    policy_gradient_loss | 9.31e-11 |
|    value_loss           | 85.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.3      |
|    ep_rew_mean          | -8.83     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2603      |
|    time_elapsed         | 8687      |
|    total_timesteps      | 333184    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000141 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.4      |
|    n_updates            | 26020     |
|    policy_gradient_loss | 5.12e-10  |
|    value_loss           | 83.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.1      |
|    ep_rew_mean          | -8.65     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2604      |
|    time_elapsed         | 8692      |
|    total_timesteps      | 333312    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000142 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 31        |
|    n_updates            | 26030     |
|    policy_gradient_loss | 7.36e-09  |
|    value_loss           | 73.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.3      |
|    ep_rew_mean          | -8.78     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2605      |
|    time_elapsed         | 8695      |
|    total_timesteps      | 333440    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000143 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 84.2      |
|    n_updates            | 26040     |
|    policy_gradient_loss | -3.47e-09 |
|    value_loss           | 160       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.3      |
|    ep_rew_mean          | -8.88     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2606      |
|    time_elapsed         | 8699      |
|    total_timesteps      | 333568    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000143 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 86.1      |
|    n_updates            | 26050     |
|    policy_gradient_loss | 2.19e-09  |
|    value_loss           | 148       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.2      |
|    ep_rew_mean          | -9.31     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2607      |
|    time_elapsed         | 8702      |
|    total_timesteps      | 333696    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000143 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.8      |
|    n_updates            | 26060     |
|    policy_gradient_loss | -9.73e-09 |
|    value_loss           | 77.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | -9.77     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2608      |
|    time_elapsed         | 8706      |
|    total_timesteps      | 333824    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000143 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 25.2      |
|    n_updates            | 26070     |
|    policy_gradient_loss | -2.33e-10 |
|    value_loss           | 68.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.3      |
|    ep_rew_mean          | -8.97     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2609      |
|    time_elapsed         | 8710      |
|    total_timesteps      | 333952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000143 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.5      |
|    n_updates            | 26080     |
|    policy_gradient_loss | 1.4e-10   |
|    value_loss           | 68.4      |
---------------------------------------
Num timesteps: 334000
Best mean reward: -0.99 - Last mean reward per episode: -9.01
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.3      |
|    ep_rew_mean          | -8.97     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2610      |
|    time_elapsed         | 8714      |
|    total_timesteps      | 334080    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000143 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 112       |
|    n_updates            | 26090     |
|    policy_gradient_loss | -1.19e-09 |
|    value_loss           | 256       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.7      |
|    ep_rew_mean          | -9.16     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2611      |
|    time_elapsed         | 8718      |
|    total_timesteps      | 334208    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000143 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 30.3      |
|    n_updates            | 26100     |
|    policy_gradient_loss | 2.53e-08  |
|    value_loss           | 62        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.9      |
|    ep_rew_mean          | -9.36     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2612      |
|    time_elapsed         | 8721      |
|    total_timesteps      | 334336    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000143 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 61.6      |
|    n_updates            | 26110     |
|    policy_gradient_loss | -4.52e-09 |
|    value_loss           | 121       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.9      |
|    ep_rew_mean          | -9.26     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2613      |
|    time_elapsed         | 8726      |
|    total_timesteps      | 334464    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000144 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48        |
|    n_updates            | 26120     |
|    policy_gradient_loss | -8.38e-10 |
|    value_loss           | 93.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.5      |
|    ep_rew_mean          | -9.63     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2614      |
|    time_elapsed         | 8730      |
|    total_timesteps      | 334592    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000144 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 35.9      |
|    n_updates            | 26130     |
|    policy_gradient_loss | -3.21e-09 |
|    value_loss           | 104       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.2      |
|    ep_rew_mean          | -9.53     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2615      |
|    time_elapsed         | 8733      |
|    total_timesteps      | 334720    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000145 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37        |
|    n_updates            | 26140     |
|    policy_gradient_loss | -3.17e-09 |
|    value_loss           | 85.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.4      |
|    ep_rew_mean          | -9.6      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2616      |
|    time_elapsed         | 8738      |
|    total_timesteps      | 334848    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000146 |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 61.8      |
|    n_updates            | 26150     |
|    policy_gradient_loss | -4.26e-09 |
|    value_loss           | 89.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.5      |
|    ep_rew_mean          | -9.66     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2617      |
|    time_elapsed         | 8741      |
|    total_timesteps      | 334976    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000147 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 49.8      |
|    n_updates            | 26160     |
|    policy_gradient_loss | 1.3e-09   |
|    value_loss           | 94        |
---------------------------------------
Num timesteps: 335000
Best mean reward: -0.99 - Last mean reward per episode: -10.35
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=335000, episode_reward=2.30 +/- 12.53
Episode length: 79.40 +/- 12.03
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 79.4      |
|    mean_reward          | 2.3       |
| time/                   |           |
|    total_timesteps      | 335000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000148 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.4      |
|    n_updates            | 26170     |
|    policy_gradient_loss | 5.03e-09  |
|    value_loss           | 73.4      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 86.5     |
|    ep_rew_mean     | -9.66    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2618     |
|    time_elapsed    | 8746     |
|    total_timesteps | 335104   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.4      |
|    ep_rew_mean          | -10.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2619      |
|    time_elapsed         | 8750      |
|    total_timesteps      | 335232    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000148 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 28.6      |
|    n_updates            | 26180     |
|    policy_gradient_loss | 4.13e-08  |
|    value_loss           | 59.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.3      |
|    ep_rew_mean          | -9.96     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2620      |
|    time_elapsed         | 8753      |
|    total_timesteps      | 335360    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000148 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55        |
|    n_updates            | 26190     |
|    policy_gradient_loss | 5.12e-10  |
|    value_loss           | 100       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.6      |
|    ep_rew_mean          | -10.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2621      |
|    time_elapsed         | 8756      |
|    total_timesteps      | 335488    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000149 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 65.9      |
|    n_updates            | 26200     |
|    policy_gradient_loss | -1.11e-08 |
|    value_loss           | 170       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.9      |
|    ep_rew_mean          | -10.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2622      |
|    time_elapsed         | 8759      |
|    total_timesteps      | 335616    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000149 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 28.5      |
|    n_updates            | 26210     |
|    policy_gradient_loss | -7.17e-09 |
|    value_loss           | 69.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.9      |
|    ep_rew_mean          | -10.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2623      |
|    time_elapsed         | 8764      |
|    total_timesteps      | 335744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000149 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 133       |
|    n_updates            | 26220     |
|    policy_gradient_loss | 1.72e-09  |
|    value_loss           | 252       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 88.5     |
|    ep_rew_mean          | -10.6    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2624     |
|    time_elapsed         | 8768     |
|    total_timesteps      | 335872   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00015 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 38.3     |
|    n_updates            | 26230    |
|    policy_gradient_loss | 2.28e-09 |
|    value_loss           | 88.1     |
--------------------------------------
Num timesteps: 336000
Best mean reward: -0.99 - Last mean reward per episode: -5.47
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.1      |
|    ep_rew_mean          | -10.9     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2625      |
|    time_elapsed         | 8772      |
|    total_timesteps      | 336000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00015  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 42.8      |
|    n_updates            | 26240     |
|    policy_gradient_loss | -1.96e-09 |
|    value_loss           | 72.1      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.4      |
|    ep_rew_mean          | -11.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2626      |
|    time_elapsed         | 8776      |
|    total_timesteps      | 336128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000151 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 40.4      |
|    n_updates            | 26250     |
|    policy_gradient_loss | 5.61e-09  |
|    value_loss           | 70        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.4      |
|    ep_rew_mean          | -11.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2627      |
|    time_elapsed         | 8780      |
|    total_timesteps      | 336256    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000151 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.4      |
|    n_updates            | 26260     |
|    policy_gradient_loss | 2.17e-09  |
|    value_loss           | 69.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.9      |
|    ep_rew_mean          | -6.13     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2628      |
|    time_elapsed         | 8783      |
|    total_timesteps      | 336384    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000151 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.1      |
|    n_updates            | 26270     |
|    policy_gradient_loss | -3.91e-09 |
|    value_loss           | 94.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.1      |
|    ep_rew_mean          | -5.84     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2629      |
|    time_elapsed         | 8787      |
|    total_timesteps      | 336512    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000152 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.8      |
|    n_updates            | 26280     |
|    policy_gradient_loss | -3.05e-09 |
|    value_loss           | 92.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.9      |
|    ep_rew_mean          | -5.93     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2630      |
|    time_elapsed         | 8790      |
|    total_timesteps      | 336640    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000152 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 43.2      |
|    n_updates            | 26290     |
|    policy_gradient_loss | 2.42e-09  |
|    value_loss           | 73.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.4      |
|    ep_rew_mean          | -5.59     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2631      |
|    time_elapsed         | 8793      |
|    total_timesteps      | 336768    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000154 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.3      |
|    n_updates            | 26300     |
|    policy_gradient_loss | -3.4e-09  |
|    value_loss           | 98.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.6      |
|    ep_rew_mean          | -5.88     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2632      |
|    time_elapsed         | 8796      |
|    total_timesteps      | 336896    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000154 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 73.4      |
|    n_updates            | 26310     |
|    policy_gradient_loss | -5.98e-09 |
|    value_loss           | 188       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 337000
Best mean reward: -0.99 - Last mean reward per episode: -5.08
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.6      |
|    ep_rew_mean          | -5.88     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2633      |
|    time_elapsed         | 8800      |
|    total_timesteps      | 337024    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000154 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 32.4      |
|    n_updates            | 26320     |
|    policy_gradient_loss | -6.1e-09  |
|    value_loss           | 70.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.8      |
|    ep_rew_mean          | -6.53     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2634      |
|    time_elapsed         | 8804      |
|    total_timesteps      | 337152    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000155 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 26.8      |
|    n_updates            | 26330     |
|    policy_gradient_loss | 2.24e-08  |
|    value_loss           | 58        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.9      |
|    ep_rew_mean          | -6.14     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2635      |
|    time_elapsed         | 8808      |
|    total_timesteps      | 337280    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000155 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 46.7      |
|    n_updates            | 26340     |
|    policy_gradient_loss | 2.89e-09  |
|    value_loss           | 91.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.4      |
|    ep_rew_mean          | -6.3      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2636      |
|    time_elapsed         | 8812      |
|    total_timesteps      | 337408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000155 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.4      |
|    n_updates            | 26350     |
|    policy_gradient_loss | -4.17e-09 |
|    value_loss           | 70.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.7      |
|    ep_rew_mean          | -6.04     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2637      |
|    time_elapsed         | 8818      |
|    total_timesteps      | 337536    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000155 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 110       |
|    n_updates            | 26360     |
|    policy_gradient_loss | 1.21e-09  |
|    value_loss           | 161       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.8      |
|    ep_rew_mean          | -6        |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2638      |
|    time_elapsed         | 8821      |
|    total_timesteps      | 337664    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000156 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 66.9      |
|    n_updates            | 26370     |
|    policy_gradient_loss | 1.36e-09  |
|    value_loss           | 127       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.9      |
|    ep_rew_mean          | -6.07     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2639      |
|    time_elapsed         | 8825      |
|    total_timesteps      | 337792    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000156 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 55.9      |
|    n_updates            | 26380     |
|    policy_gradient_loss | 1.82e-09  |
|    value_loss           | 127       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.5      |
|    ep_rew_mean          | -5.94     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2640      |
|    time_elapsed         | 8829      |
|    total_timesteps      | 337920    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000157 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.9      |
|    n_updates            | 26390     |
|    policy_gradient_loss | -9.78e-10 |
|    value_loss           | 91.7      |
---------------------------------------
Num timesteps: 338000
Best mean reward: -0.99 - Last mean reward per episode: -6.03
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.5      |
|    ep_rew_mean          | -5.94     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2641      |
|    time_elapsed         | 8832      |
|    total_timesteps      | 338048    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000157 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.2      |
|    n_updates            | 26400     |
|    policy_gradient_loss | 1.4e-10   |
|    value_loss           | 86.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.2      |
|    ep_rew_mean          | -6.38     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2642      |
|    time_elapsed         | 8837      |
|    total_timesteps      | 338176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000158 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 38.4      |
|    n_updates            | 26410     |
|    policy_gradient_loss | 7.02e-09  |
|    value_loss           | 74.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.7      |
|    ep_rew_mean          | -6.63     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2643      |
|    time_elapsed         | 8841      |
|    total_timesteps      | 338304    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000158 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.8      |
|    n_updates            | 26420     |
|    policy_gradient_loss | -1.05e-08 |
|    value_loss           | 69.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.9      |
|    ep_rew_mean          | -6.93     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2644      |
|    time_elapsed         | 8845      |
|    total_timesteps      | 338432    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000158 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 57.9      |
|    n_updates            | 26430     |
|    policy_gradient_loss | 8.85e-10  |
|    value_loss           | 98.6      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.7     |
|    ep_rew_mean          | -6.83    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2645     |
|    time_elapsed         | 8848     |
|    total_timesteps      | 338560   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00016 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 56.4     |
|    n_updates            | 26440    |
|    policy_gradient_loss | 9.31e-11 |
|    value_loss           | 98.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80        |
|    ep_rew_mean          | -6.99     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2646      |
|    time_elapsed         | 8852      |
|    total_timesteps      | 338688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000161 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.8      |
|    n_updates            | 26450     |
|    policy_gradient_loss | -6.05e-10 |
|    value_loss           | 87.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.9      |
|    ep_rew_mean          | -6.96     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2647      |
|    time_elapsed         | 8855      |
|    total_timesteps      | 338816    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000162 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 53.6      |
|    n_updates            | 26460     |
|    policy_gradient_loss | -7.45e-10 |
|    value_loss           | 133       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.2      |
|    ep_rew_mean          | -7.19     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2648      |
|    time_elapsed         | 8858      |
|    total_timesteps      | 338944    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000163 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.3      |
|    n_updates            | 26470     |
|    policy_gradient_loss | -6.05e-09 |
|    value_loss           | 69.5      |
---------------------------------------
Num timesteps: 339000
Best mean reward: -0.99 - Last mean reward per episode: -6.70
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80        |
|    ep_rew_mean          | -7.3      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2649      |
|    time_elapsed         | 8861      |
|    total_timesteps      | 339072    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000163 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.8      |
|    n_updates            | 26480     |
|    policy_gradient_loss | -2.24e-09 |
|    value_loss           | 95.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 80.2      |
|    ep_rew_mean          | -7.4      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2650      |
|    time_elapsed         | 8865      |
|    total_timesteps      | 339200    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000165 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 42.6      |
|    n_updates            | 26490     |
|    policy_gradient_loss | -1.09e-09 |
|    value_loss           | 88.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.7      |
|    ep_rew_mean          | -7.07     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2651      |
|    time_elapsed         | 8868      |
|    total_timesteps      | 339328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000166 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.9      |
|    n_updates            | 26500     |
|    policy_gradient_loss | 5.08e-09  |
|    value_loss           | 73.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -7.1      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2652      |
|    time_elapsed         | 8872      |
|    total_timesteps      | 339456    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000166 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 75.7      |
|    n_updates            | 26510     |
|    policy_gradient_loss | 9.83e-09  |
|    value_loss           | 168       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -7.06     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2653      |
|    time_elapsed         | 8875      |
|    total_timesteps      | 339584    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000166 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53.7      |
|    n_updates            | 26520     |
|    policy_gradient_loss | -1.82e-09 |
|    value_loss           | 89.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -7.06     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2654      |
|    time_elapsed         | 8880      |
|    total_timesteps      | 339712    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000168 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 52        |
|    n_updates            | 26530     |
|    policy_gradient_loss | -7.96e-09 |
|    value_loss           | 99        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.5      |
|    ep_rew_mean          | -6.95     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2655      |
|    time_elapsed         | 8883      |
|    total_timesteps      | 339840    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000169 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 43.3      |
|    n_updates            | 26540     |
|    policy_gradient_loss | 5.56e-09  |
|    value_loss           | 72.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 79.3     |
|    ep_rew_mean          | -6.95    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2656     |
|    time_elapsed         | 8886     |
|    total_timesteps      | 339968   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00017 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 65.5     |
|    n_updates            | 26550    |
|    policy_gradient_loss | 1.49e-09 |
|    value_loss           | 130      |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 340000
Best mean reward: -0.99 - Last mean reward per episode: -6.68
Eval num_timesteps=340000, episode_reward=2.50 +/- 12.24
Episode length: 67.00 +/- 11.28
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 67        |
|    mean_reward          | 2.5       |
| time/                   |           |
|    total_timesteps      | 340000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000171 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 44.7      |
|    n_updates            | 26560     |
|    policy_gradient_loss | -7.22e-10 |
|    value_loss           | 108       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79.4     |
|    ep_rew_mean     | -6.9     |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2657     |
|    time_elapsed    | 8891     |
|    total_timesteps | 340096   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79        |
|    ep_rew_mean          | -6.51     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2658      |
|    time_elapsed         | 8896      |
|    total_timesteps      | 340224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000172 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 57.8      |
|    n_updates            | 26570     |
|    policy_gradient_loss | 4.42e-09  |
|    value_loss           | 104       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.2      |
|    ep_rew_mean          | -6.59     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2659      |
|    time_elapsed         | 8901      |
|    total_timesteps      | 340352    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000172 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 72.7      |
|    n_updates            | 26580     |
|    policy_gradient_loss | 1.19e-08  |
|    value_loss           | 167       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -6.61     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2660      |
|    time_elapsed         | 8906      |
|    total_timesteps      | 340480    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000173 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 31.2      |
|    n_updates            | 26590     |
|    policy_gradient_loss | -9.08e-10 |
|    value_loss           | 75.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -6.61     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2661      |
|    time_elapsed         | 8910      |
|    total_timesteps      | 340608    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000173 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 76.3      |
|    n_updates            | 26600     |
|    policy_gradient_loss | -1.11e-08 |
|    value_loss           | 153       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -6.61     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2662      |
|    time_elapsed         | 8915      |
|    total_timesteps      | 340736    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000173 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 29        |
|    n_updates            | 26610     |
|    policy_gradient_loss | -4.8e-08  |
|    value_loss           | 59        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -6.61     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2663      |
|    time_elapsed         | 8919      |
|    total_timesteps      | 340864    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000173 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 27.5      |
|    n_updates            | 26620     |
|    policy_gradient_loss | 2.54e-08  |
|    value_loss           | 58.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -6.61     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2664      |
|    time_elapsed         | 8923      |
|    total_timesteps      | 340992    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000173 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 28.1      |
|    n_updates            | 26630     |
|    policy_gradient_loss | 2.61e-08  |
|    value_loss           | 57.2      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 341000
Best mean reward: -0.99 - Last mean reward per episode: -5.59
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -6.61     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2665      |
|    time_elapsed         | 8927      |
|    total_timesteps      | 341120    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000173 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 27.3      |
|    n_updates            | 26640     |
|    policy_gradient_loss | -5.31e-09 |
|    value_loss           | 56.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 79.6      |
|    ep_rew_mean          | -6.61     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2666      |
|    time_elapsed         | 8931      |
|    total_timesteps      | 341248    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000173 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 26.4      |
|    n_updates            | 26650     |
|    policy_gradient_loss | 3.91e-09  |
|    value_loss           | 55.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89        |
|    ep_rew_mean          | -11.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2667      |
|    time_elapsed         | 8935      |
|    total_timesteps      | 341376    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000173 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26.1      |
|    n_updates            | 26660     |
|    policy_gradient_loss | -7.78e-08 |
|    value_loss           | 54.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.2      |
|    ep_rew_mean          | -11.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2668      |
|    time_elapsed         | 8939      |
|    total_timesteps      | 341504    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000174 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 20.9      |
|    n_updates            | 26670     |
|    policy_gradient_loss | -1.6e-08  |
|    value_loss           | 46.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.5      |
|    ep_rew_mean          | -11.9     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2669      |
|    time_elapsed         | 8942      |
|    total_timesteps      | 341632    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000174 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.4      |
|    n_updates            | 26680     |
|    policy_gradient_loss | -1.54e-09 |
|    value_loss           | 73.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.7      |
|    ep_rew_mean          | -11.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2670      |
|    time_elapsed         | 8945      |
|    total_timesteps      | 341760    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000175 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.2      |
|    n_updates            | 26690     |
|    policy_gradient_loss | 1.93e-09  |
|    value_loss           | 113       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.2      |
|    ep_rew_mean          | -11.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2671      |
|    time_elapsed         | 8950      |
|    total_timesteps      | 341888    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000176 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.3      |
|    n_updates            | 26700     |
|    policy_gradient_loss | -5.87e-09 |
|    value_loss           | 75.7      |
---------------------------------------
Num timesteps: 342000
Best mean reward: -0.99 - Last mean reward per episode: -10.44
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.9      |
|    ep_rew_mean          | -11.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2672      |
|    time_elapsed         | 8954      |
|    total_timesteps      | 342016    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000177 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.2      |
|    n_updates            | 26710     |
|    policy_gradient_loss | -2.75e-09 |
|    value_loss           | 102       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.4      |
|    ep_rew_mean          | -11.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2673      |
|    time_elapsed         | 8959      |
|    total_timesteps      | 342144    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000178 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 78.7      |
|    n_updates            | 26720     |
|    policy_gradient_loss | -5.96e-09 |
|    value_loss           | 147       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.9      |
|    ep_rew_mean          | -11.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2674      |
|    time_elapsed         | 8963      |
|    total_timesteps      | 342272    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000179 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30.7      |
|    n_updates            | 26730     |
|    policy_gradient_loss | -2.14e-09 |
|    value_loss           | 77.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.5      |
|    ep_rew_mean          | -12.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2675      |
|    time_elapsed         | 8967      |
|    total_timesteps      | 342400    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000179 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 52.2      |
|    n_updates            | 26740     |
|    policy_gradient_loss | 4.19e-09  |
|    value_loss           | 108       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.5      |
|    ep_rew_mean          | -12.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2676      |
|    time_elapsed         | 8971      |
|    total_timesteps      | 342528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000179 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 24.2      |
|    n_updates            | 26750     |
|    policy_gradient_loss | 1.07e-09  |
|    value_loss           | 75.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.5      |
|    ep_rew_mean          | -12.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2677      |
|    time_elapsed         | 8976      |
|    total_timesteps      | 342656    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00018  |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 22.9      |
|    n_updates            | 26760     |
|    policy_gradient_loss | -2.23e-08 |
|    value_loss           | 51.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.5     |
|    ep_rew_mean          | -12.1    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2678     |
|    time_elapsed         | 8981     |
|    total_timesteps      | 342784   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00018 |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 24.3     |
|    n_updates            | 26770    |
|    policy_gradient_loss | 5.65e-08 |
|    value_loss           | 50.3     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.5      |
|    ep_rew_mean          | -12.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2679      |
|    time_elapsed         | 8986      |
|    total_timesteps      | 342912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00018  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 23.7      |
|    n_updates            | 26780     |
|    policy_gradient_loss | -1.74e-08 |
|    value_loss           | 49.5      |
---------------------------------------
Num timesteps: 343000
Best mean reward: -0.99 - Last mean reward per episode: -10.60
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.5     |
|    ep_rew_mean          | -12.1    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2680     |
|    time_elapsed         | 8991     |
|    total_timesteps      | 343040   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00018 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 22       |
|    n_updates            | 26790    |
|    policy_gradient_loss | 7.78e-09 |
|    value_loss           | 48.7     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.5     |
|    ep_rew_mean          | -12.1    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2681     |
|    time_elapsed         | 8996     |
|    total_timesteps      | 343168   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00018 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 22       |
|    n_updates            | 26800    |
|    policy_gradient_loss | 3.21e-09 |
|    value_loss           | 47.8     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 89.5     |
|    ep_rew_mean          | -12.1    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2682     |
|    time_elapsed         | 9001     |
|    total_timesteps      | 343296   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00018 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 23.2     |
|    n_updates            | 26810    |
|    policy_gradient_loss | 2.09e-08 |
|    value_loss           | 47       |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 98.5      |
|    ep_rew_mean          | -17.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2683      |
|    time_elapsed         | 9005      |
|    total_timesteps      | 343424    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00018  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 21.7      |
|    n_updates            | 26820     |
|    policy_gradient_loss | -5.48e-08 |
|    value_loss           | 46.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 98.5      |
|    ep_rew_mean          | -17.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2684      |
|    time_elapsed         | 9009      |
|    total_timesteps      | 343552    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000181 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 39        |
|    n_updates            | 26830     |
|    policy_gradient_loss | 1.21e-09  |
|    value_loss           | 75.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 97.5      |
|    ep_rew_mean          | -16.4     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2685      |
|    time_elapsed         | 9013      |
|    total_timesteps      | 343680    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000183 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 32.3      |
|    n_updates            | 26840     |
|    policy_gradient_loss | -4.19e-10 |
|    value_loss           | 86.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 98        |
|    ep_rew_mean          | -16.9     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2686      |
|    time_elapsed         | 9018      |
|    total_timesteps      | 343808    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000184 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 82.4      |
|    n_updates            | 26850     |
|    policy_gradient_loss | 1.26e-09  |
|    value_loss           | 175       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 96.4      |
|    ep_rew_mean          | -16.4     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2687      |
|    time_elapsed         | 9022      |
|    total_timesteps      | 343936    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000184 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 43.7      |
|    n_updates            | 26860     |
|    policy_gradient_loss | -1.35e-09 |
|    value_loss           | 85.3      |
---------------------------------------
Num timesteps: 344000
Best mean reward: -0.99 - Last mean reward per episode: -15.82
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 97.1      |
|    ep_rew_mean          | -16.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2688      |
|    time_elapsed         | 9026      |
|    total_timesteps      | 344064    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000186 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 47.2      |
|    n_updates            | 26870     |
|    policy_gradient_loss | -6.05e-10 |
|    value_loss           | 129       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 96.8      |
|    ep_rew_mean          | -16.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2689      |
|    time_elapsed         | 9030      |
|    total_timesteps      | 344192    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000187 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53.3      |
|    n_updates            | 26880     |
|    policy_gradient_loss | -4.19e-10 |
|    value_loss           | 83.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 96.3      |
|    ep_rew_mean          | -16.4     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2690      |
|    time_elapsed         | 9034      |
|    total_timesteps      | 344320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000187 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 116       |
|    n_updates            | 26890     |
|    policy_gradient_loss | -3.61e-09 |
|    value_loss           | 177       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 96.5      |
|    ep_rew_mean          | -16.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2691      |
|    time_elapsed         | 9037      |
|    total_timesteps      | 344448    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000188 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 87.6      |
|    n_updates            | 26900     |
|    policy_gradient_loss | -4.52e-09 |
|    value_loss           | 131       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 96.6      |
|    ep_rew_mean          | -16.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2692      |
|    time_elapsed         | 9040      |
|    total_timesteps      | 344576    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000188 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 54.4      |
|    n_updates            | 26910     |
|    policy_gradient_loss | -1.82e-09 |
|    value_loss           | 125       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 96.5      |
|    ep_rew_mean          | -16.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2693      |
|    time_elapsed         | 9044      |
|    total_timesteps      | 344704    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000188 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 119       |
|    n_updates            | 26920     |
|    policy_gradient_loss | -3.82e-09 |
|    value_loss           | 223       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 96.4      |
|    ep_rew_mean          | -16.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2694      |
|    time_elapsed         | 9048      |
|    total_timesteps      | 344832    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000189 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55        |
|    n_updates            | 26930     |
|    policy_gradient_loss | -3.07e-09 |
|    value_loss           | 118       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 96.1      |
|    ep_rew_mean          | -16.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2695      |
|    time_elapsed         | 9051      |
|    total_timesteps      | 344960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000189 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 27.8      |
|    n_updates            | 26940     |
|    policy_gradient_loss | -3.73e-10 |
|    value_loss           | 79.3      |
---------------------------------------
Num timesteps: 345000
Best mean reward: -0.99 - Last mean reward per episode: -16.19
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=345000, episode_reward=0.50 +/- 2.10
Episode length: 71.00 +/- 13.62
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 71        |
|    mean_reward          | 0.5       |
| time/                   |           |
|    total_timesteps      | 345000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00019  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 59.1      |
|    n_updates            | 26950     |
|    policy_gradient_loss | -3.26e-10 |
|    value_loss           | 123       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 96.1     |
|    ep_rew_mean     | -16.3    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2696     |
|    time_elapsed    | 9056     |
|    total_timesteps | 345088   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.9      |
|    ep_rew_mean          | -16.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2697      |
|    time_elapsed         | 9061      |
|    total_timesteps      | 345216    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000191 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 25.9      |
|    n_updates            | 26960     |
|    policy_gradient_loss | -5.24e-09 |
|    value_loss           | 80        |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 96.1         |
|    ep_rew_mean          | -16.6        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 2698         |
|    time_elapsed         | 9064         |
|    total_timesteps      | 345344       |
| train/                  |              |
|    approx_kl            | 0.0012097144 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.000143    |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 95.1         |
|    n_updates            | 26970        |
|    policy_gradient_loss | -0.00051     |
|    value_loss           | 161          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 96.5      |
|    ep_rew_mean          | -16.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2699      |
|    time_elapsed         | 9067      |
|    total_timesteps      | 345472    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000106 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.3      |
|    n_updates            | 26980     |
|    policy_gradient_loss | 8.61e-10  |
|    value_loss           | 79.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.2      |
|    ep_rew_mean          | -15.9     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2700      |
|    time_elapsed         | 9070      |
|    total_timesteps      | 345600    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000102 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 98.3      |
|    n_updates            | 26990     |
|    policy_gradient_loss | -3.31e-09 |
|    value_loss           | 216       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95        |
|    ep_rew_mean          | -15.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2701      |
|    time_elapsed         | 9074      |
|    total_timesteps      | 345728    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000102 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.7      |
|    n_updates            | 27000     |
|    policy_gradient_loss | -5.77e-09 |
|    value_loss           | 114       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.8      |
|    ep_rew_mean          | -15.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2702      |
|    time_elapsed         | 9078      |
|    total_timesteps      | 345856    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000102 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 63        |
|    n_updates            | 27010     |
|    policy_gradient_loss | 2.98e-09  |
|    value_loss           | 118       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.5      |
|    ep_rew_mean          | -15.9     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2703      |
|    time_elapsed         | 9081      |
|    total_timesteps      | 345984    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000103 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 23.2      |
|    n_updates            | 27020     |
|    policy_gradient_loss | -2.54e-08 |
|    value_loss           | 86        |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 346000
Best mean reward: -0.99 - Last mean reward per episode: -14.62
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.2      |
|    ep_rew_mean          | -15.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2704      |
|    time_elapsed         | 9083      |
|    total_timesteps      | 346112    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000103 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 51.4      |
|    n_updates            | 27030     |
|    policy_gradient_loss | 6.26e-09  |
|    value_loss           | 120       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.1      |
|    ep_rew_mean          | -15.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2705      |
|    time_elapsed         | 9088      |
|    total_timesteps      | 346240    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000103 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 67.1      |
|    n_updates            | 27040     |
|    policy_gradient_loss | -1.4e-09  |
|    value_loss           | 121       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.5      |
|    ep_rew_mean          | -15.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2706      |
|    time_elapsed         | 9091      |
|    total_timesteps      | 346368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000104 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 66.4      |
|    n_updates            | 27050     |
|    policy_gradient_loss | 2.24e-09  |
|    value_loss           | 125       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.7      |
|    ep_rew_mean          | -16       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2707      |
|    time_elapsed         | 9094      |
|    total_timesteps      | 346496    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000104 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 75.3      |
|    n_updates            | 27060     |
|    policy_gradient_loss | 2.28e-09  |
|    value_loss           | 158       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.9      |
|    ep_rew_mean          | -14.9     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2708      |
|    time_elapsed         | 9099      |
|    total_timesteps      | 346624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000105 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.3      |
|    n_updates            | 27070     |
|    policy_gradient_loss | 9.03e-09  |
|    value_loss           | 78        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.3      |
|    ep_rew_mean          | -15       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2709      |
|    time_elapsed         | 9103      |
|    total_timesteps      | 346752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000105 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 89.1      |
|    n_updates            | 27080     |
|    policy_gradient_loss | -6.98e-10 |
|    value_loss           | 211       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.6      |
|    ep_rew_mean          | -14.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2710      |
|    time_elapsed         | 9109      |
|    total_timesteps      | 346880    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000105 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 116       |
|    n_updates            | 27090     |
|    policy_gradient_loss | 6.66e-09  |
|    value_loss           | 173       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 347000
Best mean reward: -0.99 - Last mean reward per episode: -14.21
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.8      |
|    ep_rew_mean          | -14.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2711      |
|    time_elapsed         | 9113      |
|    total_timesteps      | 347008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000106 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 79.3      |
|    n_updates            | 27100     |
|    policy_gradient_loss | -6.98e-10 |
|    value_loss           | 153       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94        |
|    ep_rew_mean          | -14.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2712      |
|    time_elapsed         | 9117      |
|    total_timesteps      | 347136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000106 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 23.1      |
|    n_updates            | 27110     |
|    policy_gradient_loss | -3.17e-09 |
|    value_loss           | 76.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.1      |
|    ep_rew_mean          | -14.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2713      |
|    time_elapsed         | 9121      |
|    total_timesteps      | 347264    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000106 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 115       |
|    n_updates            | 27120     |
|    policy_gradient_loss | 4.19e-09  |
|    value_loss           | 206       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.1      |
|    ep_rew_mean          | -14.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2714      |
|    time_elapsed         | 9125      |
|    total_timesteps      | 347392    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000106 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 49.3      |
|    n_updates            | 27130     |
|    policy_gradient_loss | -6.98e-11 |
|    value_loss           | 144       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.1      |
|    ep_rew_mean          | -14.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2715      |
|    time_elapsed         | 9128      |
|    total_timesteps      | 347520    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000106 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.4      |
|    n_updates            | 27140     |
|    policy_gradient_loss | -2.19e-09 |
|    value_loss           | 106       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.4      |
|    ep_rew_mean          | -15.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2716      |
|    time_elapsed         | 9132      |
|    total_timesteps      | 347648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000106 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 27.5      |
|    n_updates            | 27150     |
|    policy_gradient_loss | -2.65e-08 |
|    value_loss           | 55.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.8      |
|    ep_rew_mean          | -15.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2717      |
|    time_elapsed         | 9137      |
|    total_timesteps      | 347776    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000106 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 59.3      |
|    n_updates            | 27160     |
|    policy_gradient_loss | 4.94e-09  |
|    value_loss           | 108       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.6      |
|    ep_rew_mean          | -15.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2718      |
|    time_elapsed         | 9141      |
|    total_timesteps      | 347904    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000107 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 64.2      |
|    n_updates            | 27170     |
|    policy_gradient_loss | -9.78e-10 |
|    value_loss           | 120       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 348000
Best mean reward: -0.99 - Last mean reward per episode: -14.51
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.5      |
|    ep_rew_mean          | -15       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2719      |
|    time_elapsed         | 9146      |
|    total_timesteps      | 348032    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000107 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26.1      |
|    n_updates            | 27180     |
|    policy_gradient_loss | 4.66e-11  |
|    value_loss           | 74.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.6      |
|    ep_rew_mean          | -15.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2720      |
|    time_elapsed         | 9150      |
|    total_timesteps      | 348160    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000108 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 51.9      |
|    n_updates            | 27190     |
|    policy_gradient_loss | -3.45e-09 |
|    value_loss           | 105       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.7      |
|    ep_rew_mean          | -15       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2721      |
|    time_elapsed         | 9154      |
|    total_timesteps      | 348288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000109 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.3      |
|    n_updates            | 27200     |
|    policy_gradient_loss | 4.1e-09   |
|    value_loss           | 110       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.3      |
|    ep_rew_mean          | -15.4     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2722      |
|    time_elapsed         | 9157      |
|    total_timesteps      | 348416    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00011  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 93.1      |
|    n_updates            | 27210     |
|    policy_gradient_loss | -5.59e-09 |
|    value_loss           | 197       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95        |
|    ep_rew_mean          | -15.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2723      |
|    time_elapsed         | 9161      |
|    total_timesteps      | 348544    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00011  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.5      |
|    n_updates            | 27220     |
|    policy_gradient_loss | -9.31e-09 |
|    value_loss           | 80.1      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 95.1     |
|    ep_rew_mean          | -15.3    |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2724     |
|    time_elapsed         | 9164     |
|    total_timesteps      | 348672   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00011 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 41.7     |
|    n_updates            | 27230    |
|    policy_gradient_loss | 2.61e-09 |
|    value_loss           | 103      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.3      |
|    ep_rew_mean          | -14.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2725      |
|    time_elapsed         | 9168      |
|    total_timesteps      | 348800    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000111 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 45.6      |
|    n_updates            | 27240     |
|    policy_gradient_loss | -1.49e-09 |
|    value_loss           | 107       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.4      |
|    ep_rew_mean          | -15       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2726      |
|    time_elapsed         | 9171      |
|    total_timesteps      | 348928    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000111 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 79.5      |
|    n_updates            | 27250     |
|    policy_gradient_loss | -1.96e-09 |
|    value_loss           | 137       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 349000
Best mean reward: -0.99 - Last mean reward per episode: -14.55
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.7      |
|    ep_rew_mean          | -15.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2727      |
|    time_elapsed         | 9175      |
|    total_timesteps      | 349056    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000111 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.9      |
|    n_updates            | 27260     |
|    policy_gradient_loss | -3.45e-09 |
|    value_loss           | 79.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95        |
|    ep_rew_mean          | -15.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2728      |
|    time_elapsed         | 9178      |
|    total_timesteps      | 349184    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000111 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 41.9      |
|    n_updates            | 27270     |
|    policy_gradient_loss | 1.72e-09  |
|    value_loss           | 95        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95        |
|    ep_rew_mean          | -15.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2729      |
|    time_elapsed         | 9182      |
|    total_timesteps      | 349312    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000111 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 40.2      |
|    n_updates            | 27280     |
|    policy_gradient_loss | -4.66e-10 |
|    value_loss           | 114       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94.9      |
|    ep_rew_mean          | -15       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2730      |
|    time_elapsed         | 9185      |
|    total_timesteps      | 349440    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000112 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 86.1      |
|    n_updates            | 27290     |
|    policy_gradient_loss | -2.79e-10 |
|    value_loss           | 169       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.1      |
|    ep_rew_mean          | -15.1     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2731      |
|    time_elapsed         | 9190      |
|    total_timesteps      | 349568    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000113 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 72.4      |
|    n_updates            | 27300     |
|    policy_gradient_loss | 9.31e-10  |
|    value_loss           | 143       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.2      |
|    ep_rew_mean          | -15.2     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2732      |
|    time_elapsed         | 9193      |
|    total_timesteps      | 349696    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000113 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.3      |
|    n_updates            | 27310     |
|    policy_gradient_loss | -2.63e-09 |
|    value_loss           | 80.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.5      |
|    ep_rew_mean          | -15.3     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2733      |
|    time_elapsed         | 9197      |
|    total_timesteps      | 349824    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000113 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 66.8      |
|    n_updates            | 27320     |
|    policy_gradient_loss | -4.77e-09 |
|    value_loss           | 149       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 95.1      |
|    ep_rew_mean          | -15.5     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2734      |
|    time_elapsed         | 9201      |
|    total_timesteps      | 349952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000114 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53.1      |
|    n_updates            | 27330     |
|    policy_gradient_loss | -2.31e-09 |
|    value_loss           | 113       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 350000
Best mean reward: -0.99 - Last mean reward per episode: -9.99
Eval num_timesteps=350000, episode_reward=8.20 +/- 6.27
Episode length: 59.60 +/- 3.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 59.6      |
|    mean_reward          | 8.2       |
| time/                   |           |
|    total_timesteps      | 350000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000114 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 64.1      |
|    n_updates            | 27340     |
|    policy_gradient_loss | 5.12e-10  |
|    value_loss           | 126       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 85.9     |
|    ep_rew_mean     | -10.6    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 2735     |
|    time_elapsed    | 9205     |
|    total_timesteps | 350080   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.9      |
|    ep_rew_mean          | -10.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2736      |
|    time_elapsed         | 9208      |
|    total_timesteps      | 350208    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000114 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.3      |
|    n_updates            | 27350     |
|    policy_gradient_loss | 9.31e-10  |
|    value_loss           | 85.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.6      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2737      |
|    time_elapsed         | 9212      |
|    total_timesteps      | 350336    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000114 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 28.9      |
|    n_updates            | 27360     |
|    policy_gradient_loss | -2.19e-09 |
|    value_loss           | 75.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.2      |
|    ep_rew_mean          | -10.4     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2738      |
|    time_elapsed         | 9217      |
|    total_timesteps      | 350464    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000115 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 83.1      |
|    n_updates            | 27370     |
|    policy_gradient_loss | -3.35e-09 |
|    value_loss           | 167       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | -10.4     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2739      |
|    time_elapsed         | 9220      |
|    total_timesteps      | 350592    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000115 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 75.4      |
|    n_updates            | 27380     |
|    policy_gradient_loss | -3.91e-09 |
|    value_loss           | 143       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.5      |
|    ep_rew_mean          | -10       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2740      |
|    time_elapsed         | 9223      |
|    total_timesteps      | 350720    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000115 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 74.2      |
|    n_updates            | 27390     |
|    policy_gradient_loss | -2.1e-09  |
|    value_loss           | 103       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.8      |
|    ep_rew_mean          | -10.8     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2741      |
|    time_elapsed         | 9227      |
|    total_timesteps      | 350848    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000115 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.3      |
|    n_updates            | 27400     |
|    policy_gradient_loss | -4.28e-09 |
|    value_loss           | 84.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.7      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2742      |
|    time_elapsed         | 9231      |
|    total_timesteps      | 350976    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000116 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.9      |
|    n_updates            | 27410     |
|    policy_gradient_loss | 2.44e-09  |
|    value_loss           | 74.2      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 351000
Best mean reward: -0.99 - Last mean reward per episode: -4.48
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.9      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2743      |
|    time_elapsed         | 9234      |
|    total_timesteps      | 351104    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000116 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.7      |
|    n_updates            | 27420     |
|    policy_gradient_loss | -7.17e-09 |
|    value_loss           | 107       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77        |
|    ep_rew_mean          | -5.08     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2744      |
|    time_elapsed         | 9238      |
|    total_timesteps      | 351232    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000116 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 90.7      |
|    n_updates            | 27430     |
|    policy_gradient_loss | -1.26e-09 |
|    value_loss           | 165       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.5      |
|    ep_rew_mean          | -5.36     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2745      |
|    time_elapsed         | 9241      |
|    total_timesteps      | 351360    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000116 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 113       |
|    n_updates            | 27440     |
|    policy_gradient_loss | -3.21e-09 |
|    value_loss           | 233       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.8      |
|    ep_rew_mean          | -5.08     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2746      |
|    time_elapsed         | 9245      |
|    total_timesteps      | 351488    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000116 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 64.5      |
|    n_updates            | 27450     |
|    policy_gradient_loss | 1.24e-08  |
|    value_loss           | 91.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.3      |
|    ep_rew_mean          | -4.74     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2747      |
|    time_elapsed         | 9247      |
|    total_timesteps      | 351616    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000117 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 72.8      |
|    n_updates            | 27460     |
|    policy_gradient_loss | -5.22e-09 |
|    value_loss           | 104       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.9      |
|    ep_rew_mean          | -4.54     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2748      |
|    time_elapsed         | 9251      |
|    total_timesteps      | 351744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000117 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 60.4      |
|    n_updates            | 27470     |
|    policy_gradient_loss | -2.65e-09 |
|    value_loss           | 137       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -4.49     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2749      |
|    time_elapsed         | 9254      |
|    total_timesteps      | 351872    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000117 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 54.7      |
|    n_updates            | 27480     |
|    policy_gradient_loss | 6.89e-09  |
|    value_loss           | 102       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 352000
Best mean reward: -0.99 - Last mean reward per episode: -3.77
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -4.58     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2750      |
|    time_elapsed         | 9258      |
|    total_timesteps      | 352000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000117 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 51.3      |
|    n_updates            | 27490     |
|    policy_gradient_loss | 7.45e-10  |
|    value_loss           | 133       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.8      |
|    ep_rew_mean          | -4.5      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2751      |
|    time_elapsed         | 9261      |
|    total_timesteps      | 352128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000118 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.4      |
|    n_updates            | 27500     |
|    policy_gradient_loss | -7.03e-09 |
|    value_loss           | 72.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.5      |
|    ep_rew_mean          | -4.77     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2752      |
|    time_elapsed         | 9265      |
|    total_timesteps      | 352256    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000118 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.1      |
|    n_updates            | 27510     |
|    policy_gradient_loss | 4.94e-09  |
|    value_loss           | 84        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.8      |
|    ep_rew_mean          | -5.12     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2753      |
|    time_elapsed         | 9269      |
|    total_timesteps      | 352384    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000118 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 72.2      |
|    n_updates            | 27520     |
|    policy_gradient_loss | 3.91e-09  |
|    value_loss           | 150       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.7      |
|    ep_rew_mean          | -5.03     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2754      |
|    time_elapsed         | 9272      |
|    total_timesteps      | 352512    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000119 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.4      |
|    n_updates            | 27530     |
|    policy_gradient_loss | -2.1e-09  |
|    value_loss           | 73.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 77       |
|    ep_rew_mean          | -5       |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 2755     |
|    time_elapsed         | 9275     |
|    total_timesteps      | 352640   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00012 |
|    explained_variance   | 1.79e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 47.3     |
|    n_updates            | 27540    |
|    policy_gradient_loss | 1.49e-09 |
|    value_loss           | 101      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77        |
|    ep_rew_mean          | -4.97     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2756      |
|    time_elapsed         | 9279      |
|    total_timesteps      | 352768    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000121 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 67.3      |
|    n_updates            | 27550     |
|    policy_gradient_loss | 6.98e-10  |
|    value_loss           | 162       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -5.11     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2757      |
|    time_elapsed         | 9282      |
|    total_timesteps      | 352896    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000121 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53.3      |
|    n_updates            | 27560     |
|    policy_gradient_loss | 1.56e-09  |
|    value_loss           | 95.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 353000
Best mean reward: -0.99 - Last mean reward per episode: -4.43
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.4      |
|    ep_rew_mean          | -4.82     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2758      |
|    time_elapsed         | 9285      |
|    total_timesteps      | 353024    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000121 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.2      |
|    n_updates            | 27570     |
|    policy_gradient_loss | 1.86e-09  |
|    value_loss           | 103       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.3      |
|    ep_rew_mean          | -4.64     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2759      |
|    time_elapsed         | 9288      |
|    total_timesteps      | 353152    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000122 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 54.7      |
|    n_updates            | 27580     |
|    policy_gradient_loss | 4.17e-09  |
|    value_loss           | 93.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.5      |
|    ep_rew_mean          | -4.87     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2760      |
|    time_elapsed         | 9291      |
|    total_timesteps      | 353280    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000122 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.3      |
|    n_updates            | 27590     |
|    policy_gradient_loss | -7.92e-10 |
|    value_loss           | 107       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.7      |
|    ep_rew_mean          | -4.87     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2761      |
|    time_elapsed         | 9295      |
|    total_timesteps      | 353408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000123 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 67.5      |
|    n_updates            | 27600     |
|    policy_gradient_loss | -7.17e-09 |
|    value_loss           | 131       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -5.03     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2762      |
|    time_elapsed         | 9299      |
|    total_timesteps      | 353536    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000123 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 91.8      |
|    n_updates            | 27610     |
|    policy_gradient_loss | 2.56e-09  |
|    value_loss           | 180       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.6      |
|    ep_rew_mean          | -4.68     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2763      |
|    time_elapsed         | 9303      |
|    total_timesteps      | 353664    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000123 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 65.6      |
|    n_updates            | 27620     |
|    policy_gradient_loss | -4.7e-09  |
|    value_loss           | 109       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.4      |
|    ep_rew_mean          | -5.11     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2764      |
|    time_elapsed         | 9306      |
|    total_timesteps      | 353792    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000124 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30.7      |
|    n_updates            | 27630     |
|    policy_gradient_loss | -1.9e-09  |
|    value_loss           | 70.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.2      |
|    ep_rew_mean          | -5.47     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2765      |
|    time_elapsed         | 9309      |
|    total_timesteps      | 353920    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000124 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 32.7      |
|    n_updates            | 27640     |
|    policy_gradient_loss | -1.82e-09 |
|    value_loss           | 70.4      |
---------------------------------------
Num timesteps: 354000
Best mean reward: -0.99 - Last mean reward per episode: -4.90
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.5      |
|    ep_rew_mean          | -5.54     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2766      |
|    time_elapsed         | 9312      |
|    total_timesteps      | 354048    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000124 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.1      |
|    n_updates            | 27650     |
|    policy_gradient_loss | 8.61e-10  |
|    value_loss           | 71        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.3      |
|    ep_rew_mean          | -5.57     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2767      |
|    time_elapsed         | 9315      |
|    total_timesteps      | 354176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000124 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 57.2      |
|    n_updates            | 27660     |
|    policy_gradient_loss | -3.4e-09  |
|    value_loss           | 135       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.9      |
|    ep_rew_mean          | -5.34     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2768      |
|    time_elapsed         | 9319      |
|    total_timesteps      | 354304    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000125 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 56.4      |
|    n_updates            | 27670     |
|    policy_gradient_loss | 4.89e-09  |
|    value_loss           | 139       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.9      |
|    ep_rew_mean          | -5.54     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2769      |
|    time_elapsed         | 9323      |
|    total_timesteps      | 354432    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000125 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 65.8      |
|    n_updates            | 27680     |
|    policy_gradient_loss | -4.75e-09 |
|    value_loss           | 101       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.8      |
|    ep_rew_mean          | -5.7      |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2770      |
|    time_elapsed         | 9327      |
|    total_timesteps      | 354560    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000126 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 69.6      |
|    n_updates            | 27690     |
|    policy_gradient_loss | -4.12e-09 |
|    value_loss           | 102       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.7      |
|    ep_rew_mean          | -5.74     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2771      |
|    time_elapsed         | 9330      |
|    total_timesteps      | 354688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000126 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.1      |
|    n_updates            | 27700     |
|    policy_gradient_loss | -1.4e-09  |
|    value_loss           | 71.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.7      |
|    ep_rew_mean          | -5.74     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2772      |
|    time_elapsed         | 9334      |
|    total_timesteps      | 354816    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000127 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 56.4      |
|    n_updates            | 27710     |
|    policy_gradient_loss | 6.43e-09  |
|    value_loss           | 97.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.4      |
|    ep_rew_mean          | -5.89     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2773      |
|    time_elapsed         | 9339      |
|    total_timesteps      | 354944    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000127 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26.4      |
|    n_updates            | 27720     |
|    policy_gradient_loss | -4.37e-08 |
|    value_loss           | 58.4      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 355000
Best mean reward: -0.99 - Last mean reward per episode: -5.62
Eval num_timesteps=355000, episode_reward=5.60 +/- 6.31
Episode length: 60.80 +/- 3.49
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 60.8      |
|    mean_reward          | 5.6       |
| time/                   |           |
|    total_timesteps      | 355000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000127 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 90.1      |
|    n_updates            | 27730     |
|    policy_gradient_loss | 3.26e-09  |
|    value_loss           | 180       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 78.2     |
|    ep_rew_mean     | -6       |
| time/              |          |
|    fps             | 37       |
|    iterations      | 2774     |
|    time_elapsed    | 9344     |
|    total_timesteps | 355072   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78        |
|    ep_rew_mean          | -6.02     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2775      |
|    time_elapsed         | 9348      |
|    total_timesteps      | 355200    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000127 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.2      |
|    n_updates            | 27740     |
|    policy_gradient_loss | 4.07e-09  |
|    value_loss           | 76.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 78.4      |
|    ep_rew_mean          | -6.22     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2776      |
|    time_elapsed         | 9350      |
|    total_timesteps      | 355328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000127 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 40.6      |
|    n_updates            | 27750     |
|    policy_gradient_loss | 4.1e-09   |
|    value_loss           | 92.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.3      |
|    ep_rew_mean          | -5.66     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2777      |
|    time_elapsed         | 9354      |
|    total_timesteps      | 355456    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000128 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 30.3      |
|    n_updates            | 27760     |
|    policy_gradient_loss | 8.24e-09  |
|    value_loss           | 71.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.4      |
|    ep_rew_mean          | -5.6      |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2778      |
|    time_elapsed         | 9357      |
|    total_timesteps      | 355584    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000128 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48        |
|    n_updates            | 27770     |
|    policy_gradient_loss | -5.15e-09 |
|    value_loss           | 96.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.9      |
|    ep_rew_mean          | -5.23     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2779      |
|    time_elapsed         | 9360      |
|    total_timesteps      | 355712    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000128 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 54.3      |
|    n_updates            | 27780     |
|    policy_gradient_loss | 1.21e-09  |
|    value_loss           | 132       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.3      |
|    ep_rew_mean          | -5.47     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2780      |
|    time_elapsed         | 9363      |
|    total_timesteps      | 355840    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000129 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 82.3      |
|    n_updates            | 27790     |
|    policy_gradient_loss | -3.26e-10 |
|    value_loss           | 134       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.2      |
|    ep_rew_mean          | -5.41     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2781      |
|    time_elapsed         | 9367      |
|    total_timesteps      | 355968    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000129 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 25.6      |
|    n_updates            | 27800     |
|    policy_gradient_loss | 1.19e-09  |
|    value_loss           | 70.3      |
---------------------------------------
Num timesteps: 356000
Best mean reward: -0.99 - Last mean reward per episode: -4.32
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.8      |
|    ep_rew_mean          | -5.38     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2782      |
|    time_elapsed         | 9370      |
|    total_timesteps      | 356096    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000129 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 64        |
|    n_updates            | 27810     |
|    policy_gradient_loss | -7.45e-09 |
|    value_loss           | 113       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.6      |
|    ep_rew_mean          | -5.19     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2783      |
|    time_elapsed         | 9375      |
|    total_timesteps      | 356224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000129 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 31.6      |
|    n_updates            | 27820     |
|    policy_gradient_loss | -1.33e-09 |
|    value_loss           | 72.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.8      |
|    ep_rew_mean          | -5.12     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2784      |
|    time_elapsed         | 9381      |
|    total_timesteps      | 356352    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00013  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 51.9      |
|    n_updates            | 27830     |
|    policy_gradient_loss | -7.08e-09 |
|    value_loss           | 124       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.8      |
|    ep_rew_mean          | -5.03     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2785      |
|    time_elapsed         | 9385      |
|    total_timesteps      | 356480    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00013  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 86.9      |
|    n_updates            | 27840     |
|    policy_gradient_loss | -9.31e-11 |
|    value_loss           | 176       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.4      |
|    ep_rew_mean          | -5.29     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2786      |
|    time_elapsed         | 9389      |
|    total_timesteps      | 356608    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00013  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.9      |
|    n_updates            | 27850     |
|    policy_gradient_loss | -4.49e-09 |
|    value_loss           | 106       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.3      |
|    ep_rew_mean          | -5.38     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2787      |
|    time_elapsed         | 9392      |
|    total_timesteps      | 356736    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00013  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.2      |
|    n_updates            | 27860     |
|    policy_gradient_loss | -2.84e-09 |
|    value_loss           | 81.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77.1      |
|    ep_rew_mean          | -5.26     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2788      |
|    time_elapsed         | 9395      |
|    total_timesteps      | 356864    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000131 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 45.1      |
|    n_updates            | 27870     |
|    policy_gradient_loss | 1.26e-09  |
|    value_loss           | 88.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.5      |
|    ep_rew_mean          | -4.64     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2789      |
|    time_elapsed         | 9398      |
|    total_timesteps      | 356992    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000132 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 31.8      |
|    n_updates            | 27880     |
|    policy_gradient_loss | 3.12e-09  |
|    value_loss           | 87.8      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 357000
Best mean reward: -0.99 - Last mean reward per episode: -3.88
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.2      |
|    ep_rew_mean          | -4.68     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2790      |
|    time_elapsed         | 9402      |
|    total_timesteps      | 357120    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000132 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 95.1      |
|    n_updates            | 27890     |
|    policy_gradient_loss | 2.65e-09  |
|    value_loss           | 203       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.3      |
|    ep_rew_mean          | -4.84     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2791      |
|    time_elapsed         | 9405      |
|    total_timesteps      | 357248    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000133 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 46.1      |
|    n_updates            | 27900     |
|    policy_gradient_loss | 4.61e-09  |
|    value_loss           | 90.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.2      |
|    ep_rew_mean          | -4.67     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2792      |
|    time_elapsed         | 9408      |
|    total_timesteps      | 357376    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000134 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.6      |
|    n_updates            | 27910     |
|    policy_gradient_loss | 5.73e-09  |
|    value_loss           | 89.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 77        |
|    ep_rew_mean          | -5.08     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2793      |
|    time_elapsed         | 9412      |
|    total_timesteps      | 357504    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000135 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 55.8      |
|    n_updates            | 27920     |
|    policy_gradient_loss | -1.54e-09 |
|    value_loss           | 118       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.6      |
|    ep_rew_mean          | -4.98     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2794      |
|    time_elapsed         | 9415      |
|    total_timesteps      | 357632    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000136 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.6      |
|    n_updates            | 27930     |
|    policy_gradient_loss | -5.1e-09  |
|    value_loss           | 71.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.9      |
|    ep_rew_mean          | -4.93     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2795      |
|    time_elapsed         | 9418      |
|    total_timesteps      | 357760    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000136 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 63.3      |
|    n_updates            | 27940     |
|    policy_gradient_loss | 3.73e-09  |
|    value_loss           | 127       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.7      |
|    ep_rew_mean          | -4.83     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2796      |
|    time_elapsed         | 9421      |
|    total_timesteps      | 357888    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000136 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 78.4      |
|    n_updates            | 27950     |
|    policy_gradient_loss | -1.4e-09  |
|    value_loss           | 149       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 358000
Best mean reward: -0.99 - Last mean reward per episode: -4.44
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -4.7      |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2797      |
|    time_elapsed         | 9425      |
|    total_timesteps      | 358016    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000137 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 62.8      |
|    n_updates            | 27960     |
|    policy_gradient_loss | 4.1e-09   |
|    value_loss           | 95.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76        |
|    ep_rew_mean          | -4.7      |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2798      |
|    time_elapsed         | 9429      |
|    total_timesteps      | 358144    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000138 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 34.6      |
|    n_updates            | 27970     |
|    policy_gradient_loss | 3e-09     |
|    value_loss           | 86.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.4      |
|    ep_rew_mean          | -4.92     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2799      |
|    time_elapsed         | 9432      |
|    total_timesteps      | 358272    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000139 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 41.5      |
|    n_updates            | 27980     |
|    policy_gradient_loss | 1.08e-08  |
|    value_loss           | 72.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 76.6      |
|    ep_rew_mean          | -4.79     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2800      |
|    time_elapsed         | 9435      |
|    total_timesteps      | 358400    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000139 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 55.8      |
|    n_updates            | 27990     |
|    policy_gradient_loss | -2.28e-09 |
|    value_loss           | 121       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.2     |
|    ep_rew_mean          | -3.69    |
| time/                   |          |
|    fps                  | 37       |
|    iterations           | 2801     |
|    time_elapsed         | 9439     |
|    total_timesteps      | 358528   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00014 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 66.4     |
|    n_updates            | 28000    |
|    policy_gradient_loss | 1.7e-09  |
|    value_loss           | 165      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.9      |
|    ep_rew_mean          | -3.75     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2802      |
|    time_elapsed         | 9443      |
|    total_timesteps      | 358656    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00014  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 89.4      |
|    n_updates            | 28010     |
|    policy_gradient_loss | 5.73e-09  |
|    value_loss           | 240       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 75.1     |
|    ep_rew_mean          | -4.06    |
| time/                   |          |
|    fps                  | 37       |
|    iterations           | 2803     |
|    time_elapsed         | 9446     |
|    total_timesteps      | 358784   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00014 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 35.1     |
|    n_updates            | 28020    |
|    policy_gradient_loss | 2.24e-09 |
|    value_loss           | 80.2     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.7      |
|    ep_rew_mean          | -4.46     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2804      |
|    time_elapsed         | 9449      |
|    total_timesteps      | 358912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000141 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.5      |
|    n_updates            | 28030     |
|    policy_gradient_loss | -3.31e-09 |
|    value_loss           | 68.7      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 359000
Best mean reward: -0.99 - Last mean reward per episode: -3.95
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.1      |
|    ep_rew_mean          | -4.16     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2805      |
|    time_elapsed         | 9452      |
|    total_timesteps      | 359040    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000142 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.5      |
|    n_updates            | 28040     |
|    policy_gradient_loss | 3.82e-09  |
|    value_loss           | 81        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.3      |
|    ep_rew_mean          | -4.07     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2806      |
|    time_elapsed         | 9456      |
|    total_timesteps      | 359168    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000144 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 32.5      |
|    n_updates            | 28050     |
|    policy_gradient_loss | -1.89e-09 |
|    value_loss           | 79.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -4.02     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2807      |
|    time_elapsed         | 9460      |
|    total_timesteps      | 359296    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000145 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 93.3      |
|    n_updates            | 28060     |
|    policy_gradient_loss | 1.58e-09  |
|    value_loss           | 156       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.3      |
|    ep_rew_mean          | -4.06     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2808      |
|    time_elapsed         | 9463      |
|    total_timesteps      | 359424    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000145 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 57        |
|    n_updates            | 28070     |
|    policy_gradient_loss | -6.59e-09 |
|    value_loss           | 108       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.7      |
|    ep_rew_mean          | -4.13     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2809      |
|    time_elapsed         | 9467      |
|    total_timesteps      | 359552    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000146 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36        |
|    n_updates            | 28080     |
|    policy_gradient_loss | -8.38e-10 |
|    value_loss           | 67.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.5      |
|    ep_rew_mean          | -3.88     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2810      |
|    time_elapsed         | 9473      |
|    total_timesteps      | 359680    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000146 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 89.1      |
|    n_updates            | 28090     |
|    policy_gradient_loss | -3.73e-10 |
|    value_loss           | 154       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.4      |
|    ep_rew_mean          | -3.79     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2811      |
|    time_elapsed         | 9476      |
|    total_timesteps      | 359808    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000147 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 85.6      |
|    n_updates            | 28100     |
|    policy_gradient_loss | -2.1e-09  |
|    value_loss           | 160       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.7      |
|    ep_rew_mean          | -3.54     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2812      |
|    time_elapsed         | 9479      |
|    total_timesteps      | 359936    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000148 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35        |
|    n_updates            | 28110     |
|    policy_gradient_loss | -3.35e-09 |
|    value_loss           | 82.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 360000
Best mean reward: -0.99 - Last mean reward per episode: -2.94
Eval num_timesteps=360000, episode_reward=6.00 +/- 6.32
Episode length: 64.00 +/- 8.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 64        |
|    mean_reward          | 6         |
| time/                   |           |
|    total_timesteps      | 360000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00015  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.1      |
|    n_updates            | 28120     |
|    policy_gradient_loss | -3.93e-09 |
|    value_loss           | 86.2      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 74.6     |
|    ep_rew_mean     | -3.5     |
| time/              |          |
|    fps             | 37       |
|    iterations      | 2813     |
|    time_elapsed    | 9485     |
|    total_timesteps | 360064   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.7      |
|    ep_rew_mean          | -3.56     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2814      |
|    time_elapsed         | 9489      |
|    total_timesteps      | 360192    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00015  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.7      |
|    n_updates            | 28130     |
|    policy_gradient_loss | -4.19e-09 |
|    value_loss           | 75.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.9      |
|    ep_rew_mean          | -3.15     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2815      |
|    time_elapsed         | 9492      |
|    total_timesteps      | 360320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000151 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 36.5      |
|    n_updates            | 28140     |
|    policy_gradient_loss | 7.68e-10  |
|    value_loss           | 66.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.9      |
|    ep_rew_mean          | -3.16     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2816      |
|    time_elapsed         | 9495      |
|    total_timesteps      | 360448    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000151 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 97        |
|    n_updates            | 28150     |
|    policy_gradient_loss | -5.66e-09 |
|    value_loss           | 152       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.3      |
|    ep_rew_mean          | -3.25     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2817      |
|    time_elapsed         | 9498      |
|    total_timesteps      | 360576    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000152 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 47.7      |
|    n_updates            | 28160     |
|    policy_gradient_loss | 4.89e-09  |
|    value_loss           | 85.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.7      |
|    ep_rew_mean          | -3.44     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2818      |
|    time_elapsed         | 9502      |
|    total_timesteps      | 360704    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000152 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 58.1      |
|    n_updates            | 28170     |
|    policy_gradient_loss | 1.72e-09  |
|    value_loss           | 114       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.5      |
|    ep_rew_mean          | -3.84     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2819      |
|    time_elapsed         | 9505      |
|    total_timesteps      | 360832    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000152 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34        |
|    n_updates            | 28180     |
|    policy_gradient_loss | -5.91e-09 |
|    value_loss           | 76.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.5      |
|    ep_rew_mean          | -3.87     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2820      |
|    time_elapsed         | 9509      |
|    total_timesteps      | 360960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000154 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 59.8      |
|    n_updates            | 28190     |
|    policy_gradient_loss | 2.47e-09  |
|    value_loss           | 118       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 361000
Best mean reward: -0.99 - Last mean reward per episode: -2.38
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 75.2      |
|    ep_rew_mean          | -4        |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2821      |
|    time_elapsed         | 9512      |
|    total_timesteps      | 361088    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000155 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 35.8      |
|    n_updates            | 28200     |
|    policy_gradient_loss | -9.73e-09 |
|    value_loss           | 68.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.8      |
|    ep_rew_mean          | -3.69     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2822      |
|    time_elapsed         | 9515      |
|    total_timesteps      | 361216    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000155 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.2      |
|    n_updates            | 28210     |
|    policy_gradient_loss | 5.31e-09  |
|    value_loss           | 91.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -2.9      |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2823      |
|    time_elapsed         | 9519      |
|    total_timesteps      | 361344    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000157 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63        |
|    n_updates            | 28220     |
|    policy_gradient_loss | -4.38e-09 |
|    value_loss           | 169       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.4      |
|    ep_rew_mean          | -2.69     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2824      |
|    time_elapsed         | 9523      |
|    total_timesteps      | 361472    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000158 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 108       |
|    n_updates            | 28230     |
|    policy_gradient_loss | 4.24e-09  |
|    value_loss           | 199       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73        |
|    ep_rew_mean          | -2.52     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2825      |
|    time_elapsed         | 9526      |
|    total_timesteps      | 361600    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000158 |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 39.6      |
|    n_updates            | 28240     |
|    policy_gradient_loss | 3.26e-10  |
|    value_loss           | 83.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73        |
|    ep_rew_mean          | -2.52     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2826      |
|    time_elapsed         | 9529      |
|    total_timesteps      | 361728    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000159 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 75        |
|    n_updates            | 28250     |
|    policy_gradient_loss | -4.38e-09 |
|    value_loss           | 159       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 74.5     |
|    ep_rew_mean          | -3.23    |
| time/                   |          |
|    fps                  | 37       |
|    iterations           | 2827     |
|    time_elapsed         | 9532     |
|    total_timesteps      | 361856   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00016 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 32.4     |
|    n_updates            | 28260    |
|    policy_gradient_loss | 1.06e-08 |
|    value_loss           | 65.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.4      |
|    ep_rew_mean          | -3.11     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2828      |
|    time_elapsed         | 9535      |
|    total_timesteps      | 361984    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00016  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 48.4      |
|    n_updates            | 28270     |
|    policy_gradient_loss | 4.1e-09   |
|    value_loss           | 85.1      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 362000
Best mean reward: -0.99 - Last mean reward per episode: -1.88
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.1      |
|    ep_rew_mean          | -2.96     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2829      |
|    time_elapsed         | 9538      |
|    total_timesteps      | 362112    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000162 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.6      |
|    n_updates            | 28280     |
|    policy_gradient_loss | -4.05e-09 |
|    value_loss           | 112       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.2      |
|    ep_rew_mean          | -2.99     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2830      |
|    time_elapsed         | 9541      |
|    total_timesteps      | 362240    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000163 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 31.9      |
|    n_updates            | 28290     |
|    policy_gradient_loss | -3.38e-09 |
|    value_loss           | 76.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73        |
|    ep_rew_mean          | -2.41     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2831      |
|    time_elapsed         | 9544      |
|    total_timesteps      | 362368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000163 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 36.8      |
|    n_updates            | 28300     |
|    policy_gradient_loss | -4.54e-09 |
|    value_loss           | 77.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.2      |
|    ep_rew_mean          | -2.28     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2832      |
|    time_elapsed         | 9547      |
|    total_timesteps      | 362496    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000165 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.7      |
|    n_updates            | 28310     |
|    policy_gradient_loss | 3.54e-09  |
|    value_loss           | 152       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.3      |
|    ep_rew_mean          | -2.34     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2833      |
|    time_elapsed         | 9550      |
|    total_timesteps      | 362624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000165 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 60.1      |
|    n_updates            | 28320     |
|    policy_gradient_loss | 3.91e-09  |
|    value_loss           | 137       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.6      |
|    ep_rew_mean          | -2.28     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2834      |
|    time_elapsed         | 9554      |
|    total_timesteps      | 362752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000166 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 40.7      |
|    n_updates            | 28330     |
|    policy_gradient_loss | 4.75e-09  |
|    value_loss           | 68.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.4      |
|    ep_rew_mean          | -2.18     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2835      |
|    time_elapsed         | 9557      |
|    total_timesteps      | 362880    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000166 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 80.8      |
|    n_updates            | 28340     |
|    policy_gradient_loss | -3.21e-09 |
|    value_loss           | 150       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 363000
Best mean reward: -0.99 - Last mean reward per episode: -1.62
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.2      |
|    ep_rew_mean          | -2.12     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2836      |
|    time_elapsed         | 9559      |
|    total_timesteps      | 363008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000167 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.9      |
|    n_updates            | 28350     |
|    policy_gradient_loss | 1.16e-09  |
|    value_loss           | 74.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 74.1      |
|    ep_rew_mean          | -2.53     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2837      |
|    time_elapsed         | 9563      |
|    total_timesteps      | 363136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000168 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55.9      |
|    n_updates            | 28360     |
|    policy_gradient_loss | -1.51e-09 |
|    value_loss           | 107       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.6     |
|    ep_rew_mean          | -2.39    |
| time/                   |          |
|    fps                  | 37       |
|    iterations           | 2838     |
|    time_elapsed         | 9567     |
|    total_timesteps      | 363264   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00017 |
|    explained_variance   | 1.19e-07 |
|    learning_rate        | 0.0003   |
|    loss                 | 40.4     |
|    n_updates            | 28370    |
|    policy_gradient_loss | 4.49e-09 |
|    value_loss           | 82.5     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -2.41     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2839      |
|    time_elapsed         | 9570      |
|    total_timesteps      | 363392    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000172 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.3      |
|    n_updates            | 28380     |
|    policy_gradient_loss | 9.78e-10  |
|    value_loss           | 75.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -2.41     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2840      |
|    time_elapsed         | 9574      |
|    total_timesteps      | 363520    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000174 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.3      |
|    n_updates            | 28390     |
|    policy_gradient_loss | 6.29e-10  |
|    value_loss           | 111       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -2.49     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2841      |
|    time_elapsed         | 9577      |
|    total_timesteps      | 363648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000177 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 37        |
|    n_updates            | 28400     |
|    policy_gradient_loss | -1.4e-10  |
|    value_loss           | 68.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -2.49     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2842      |
|    time_elapsed         | 9580      |
|    total_timesteps      | 363776    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000178 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.7      |
|    n_updates            | 28410     |
|    policy_gradient_loss | 3.4e-09   |
|    value_loss           | 82.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -2.49     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2843      |
|    time_elapsed         | 9584      |
|    total_timesteps      | 363904    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000179 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 32.2      |
|    n_updates            | 28420     |
|    policy_gradient_loss | 2.28e-08  |
|    value_loss           | 65.6      |
---------------------------------------
Num timesteps: 364000
Best mean reward: -0.99 - Last mean reward per episode: -2.31
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -2.49     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2844      |
|    time_elapsed         | 9589      |
|    total_timesteps      | 364032    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000179 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 32.2      |
|    n_updates            | 28430     |
|    policy_gradient_loss | 7.72e-08  |
|    value_loss           | 63.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -2.49     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2845      |
|    time_elapsed         | 9593      |
|    total_timesteps      | 364160    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000179 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.4      |
|    n_updates            | 28440     |
|    policy_gradient_loss | 8.03e-08  |
|    value_loss           | 62.9      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.8     |
|    ep_rew_mean          | -2.49    |
| time/                   |          |
|    fps                  | 37       |
|    iterations           | 2846     |
|    time_elapsed         | 9597     |
|    total_timesteps      | 364288   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00018 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 29.2     |
|    n_updates            | 28450    |
|    policy_gradient_loss | 5.32e-08 |
|    value_loss           | 61.9     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 73.8      |
|    ep_rew_mean          | -2.49     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2847      |
|    time_elapsed         | 9602      |
|    total_timesteps      | 364416    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00018  |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 30        |
|    n_updates            | 28460     |
|    policy_gradient_loss | -3.34e-08 |
|    value_loss           | 61        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 73.8     |
|    ep_rew_mean          | -2.49    |
| time/                   |          |
|    fps                  | 37       |
|    iterations           | 2848     |
|    time_elapsed         | 9606     |
|    total_timesteps      | 364544   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00018 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 29.7     |
|    n_updates            | 28470    |
|    policy_gradient_loss | 4.52e-09 |
|    value_loss           | 60.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.2      |
|    ep_rew_mean          | -7.5      |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2849      |
|    time_elapsed         | 9610      |
|    total_timesteps      | 364672    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00018  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 27.2      |
|    n_updates            | 28480     |
|    policy_gradient_loss | -2.67e-08 |
|    value_loss           | 59.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.3      |
|    ep_rew_mean          | -7.77     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2850      |
|    time_elapsed         | 9614      |
|    total_timesteps      | 364800    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00018  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 22        |
|    n_updates            | 28490     |
|    policy_gradient_loss | -7.05e-08 |
|    value_loss           | 47.5      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 83.8     |
|    ep_rew_mean          | -7.98    |
| time/                   |          |
|    fps                  | 37       |
|    iterations           | 2851     |
|    time_elapsed         | 9617     |
|    total_timesteps      | 364928   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00018 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 48.9     |
|    n_updates            | 28500    |
|    policy_gradient_loss | 7.26e-09 |
|    value_loss           | 98.9     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 365000
Best mean reward: -0.99 - Last mean reward per episode: -7.26
Eval num_timesteps=365000, episode_reward=-19.10 +/- 35.16
Episode length: 102.20 +/- 67.29
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 102       |
|    mean_reward          | -19.1     |
| time/                   |           |
|    total_timesteps      | 365000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000182 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 34.9      |
|    n_updates            | 28510     |
|    policy_gradient_loss | 3.93e-09  |
|    value_loss           | 105       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 83.6     |
|    ep_rew_mean     | -7.88    |
| time/              |          |
|    fps             | 37       |
|    iterations      | 2852     |
|    time_elapsed    | 9623     |
|    total_timesteps | 365056   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.6      |
|    ep_rew_mean          | -7.88     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2853      |
|    time_elapsed         | 9627      |
|    total_timesteps      | 365184    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000183 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 34.6      |
|    n_updates            | 28520     |
|    policy_gradient_loss | 3.1e-09   |
|    value_loss           | 85        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.5      |
|    ep_rew_mean          | -8.28     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2854      |
|    time_elapsed         | 9631      |
|    total_timesteps      | 365312    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000183 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 27.9      |
|    n_updates            | 28530     |
|    policy_gradient_loss | 1.28e-08  |
|    value_loss           | 55.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.9      |
|    ep_rew_mean          | -8.25     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2855      |
|    time_elapsed         | 9634      |
|    total_timesteps      | 365440    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000183 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 83.7      |
|    n_updates            | 28540     |
|    policy_gradient_loss | 6.29e-09  |
|    value_loss           | 138       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.9      |
|    ep_rew_mean          | -8.25     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2856      |
|    time_elapsed         | 9637      |
|    total_timesteps      | 365568    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000184 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 95.7      |
|    n_updates            | 28550     |
|    policy_gradient_loss | -3.63e-09 |
|    value_loss           | 188       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86        |
|    ep_rew_mean          | -8.81     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2857      |
|    time_elapsed         | 9642      |
|    total_timesteps      | 365696    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000184 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 29        |
|    n_updates            | 28560     |
|    policy_gradient_loss | 6.73e-08  |
|    value_loss           | 58.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.2      |
|    ep_rew_mean          | -8.9      |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2858      |
|    time_elapsed         | 9649      |
|    total_timesteps      | 365824    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000184 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 69.2      |
|    n_updates            | 28570     |
|    policy_gradient_loss | 4.35e-09  |
|    value_loss           | 139       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.1      |
|    ep_rew_mean          | -9.36     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2859      |
|    time_elapsed         | 9653      |
|    total_timesteps      | 365952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000184 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 104       |
|    n_updates            | 28580     |
|    policy_gradient_loss | -1.16e-09 |
|    value_loss           | 165       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 366000
Best mean reward: -0.99 - Last mean reward per episode: -9.64
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.2      |
|    ep_rew_mean          | -9.28     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2860      |
|    time_elapsed         | 9656      |
|    total_timesteps      | 366080    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000185 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35        |
|    n_updates            | 28590     |
|    policy_gradient_loss | -8.45e-09 |
|    value_loss           | 82.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 87.1      |
|    ep_rew_mean          | -9.37     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2861      |
|    time_elapsed         | 9659      |
|    total_timesteps      | 366208    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000185 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 67.9      |
|    n_updates            | 28600     |
|    policy_gradient_loss | -5.54e-09 |
|    value_loss           | 107       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.5      |
|    ep_rew_mean          | -9.05     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2862      |
|    time_elapsed         | 9662      |
|    total_timesteps      | 366336    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000187 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 32.4      |
|    n_updates            | 28610     |
|    policy_gradient_loss | -2.47e-09 |
|    value_loss           | 77.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.7      |
|    ep_rew_mean          | -9.27     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2863      |
|    time_elapsed         | 9666      |
|    total_timesteps      | 366464    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000188 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.1      |
|    n_updates            | 28620     |
|    policy_gradient_loss | -5.73e-09 |
|    value_loss           | 97.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.9      |
|    ep_rew_mean          | -9.55     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2864      |
|    time_elapsed         | 9670      |
|    total_timesteps      | 366592    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000189 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 56        |
|    n_updates            | 28630     |
|    policy_gradient_loss | 3.86e-09  |
|    value_loss           | 103       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.9     |
|    ep_rew_mean          | -9.45    |
| time/                   |          |
|    fps                  | 37       |
|    iterations           | 2865     |
|    time_elapsed         | 9672     |
|    total_timesteps      | 366720   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00019 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 43.9     |
|    n_updates            | 28640    |
|    policy_gradient_loss | 1.77e-09 |
|    value_loss           | 74.3     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.9      |
|    ep_rew_mean          | -9.47     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2866      |
|    time_elapsed         | 9676      |
|    total_timesteps      | 366848    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000191 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 76.7      |
|    n_updates            | 28650     |
|    policy_gradient_loss | 2.47e-09  |
|    value_loss           | 117       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.2      |
|    ep_rew_mean          | -9.12     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2867      |
|    time_elapsed         | 9679      |
|    total_timesteps      | 366976    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000193 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 62.8      |
|    n_updates            | 28660     |
|    policy_gradient_loss | 2e-09     |
|    value_loss           | 134       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 367000
Best mean reward: -0.99 - Last mean reward per episode: -9.90
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.5      |
|    ep_rew_mean          | -9.25     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2868      |
|    time_elapsed         | 9682      |
|    total_timesteps      | 367104    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000194 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45.1      |
|    n_updates            | 28670     |
|    policy_gradient_loss | -3.68e-09 |
|    value_loss           | 96.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.6      |
|    ep_rew_mean          | -9.28     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2869      |
|    time_elapsed         | 9687      |
|    total_timesteps      | 367232    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000195 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 55.8      |
|    n_updates            | 28680     |
|    policy_gradient_loss | 1.91e-09  |
|    value_loss           | 108       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.6      |
|    ep_rew_mean          | -9.4      |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2870      |
|    time_elapsed         | 9690      |
|    total_timesteps      | 367360    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000197 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 110       |
|    n_updates            | 28690     |
|    policy_gradient_loss | 1.77e-09  |
|    value_loss           | 189       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.7      |
|    ep_rew_mean          | -9.45     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2871      |
|    time_elapsed         | 9694      |
|    total_timesteps      | 367488    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000198 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 91.4      |
|    n_updates            | 28700     |
|    policy_gradient_loss | -3.66e-09 |
|    value_loss           | 206       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.9      |
|    ep_rew_mean          | -9.55     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2872      |
|    time_elapsed         | 9698      |
|    total_timesteps      | 367616    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000199 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.5      |
|    n_updates            | 28710     |
|    policy_gradient_loss | -1.12e-09 |
|    value_loss           | 91        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.9      |
|    ep_rew_mean          | -9.55     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2873      |
|    time_elapsed         | 9702      |
|    total_timesteps      | 367744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0002   |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29.6      |
|    n_updates            | 28720     |
|    policy_gradient_loss | -5.36e-09 |
|    value_loss           | 70.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.1      |
|    ep_rew_mean          | -9.97     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2874      |
|    time_elapsed         | 9707      |
|    total_timesteps      | 367872    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000201 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 29        |
|    n_updates            | 28730     |
|    policy_gradient_loss | 1.71e-08  |
|    value_loss           | 57.1      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 368000
Best mean reward: -0.99 - Last mean reward per episode: -10.96
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.4      |
|    ep_rew_mean          | -10       |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2875      |
|    time_elapsed         | 9711      |
|    total_timesteps      | 368000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000201 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 83.6      |
|    n_updates            | 28740     |
|    policy_gradient_loss | 4.89e-10  |
|    value_loss           | 158       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.3      |
|    ep_rew_mean          | -9.83     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2876      |
|    time_elapsed         | 9715      |
|    total_timesteps      | 368128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000203 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 80.7      |
|    n_updates            | 28750     |
|    policy_gradient_loss | 4.19e-10  |
|    value_loss           | 132       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.2      |
|    ep_rew_mean          | -9.99     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2877      |
|    time_elapsed         | 9718      |
|    total_timesteps      | 368256    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000204 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 64.3      |
|    n_updates            | 28760     |
|    policy_gradient_loss | -3.12e-09 |
|    value_loss           | 136       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.6      |
|    ep_rew_mean          | -10.3     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2878      |
|    time_elapsed         | 9721      |
|    total_timesteps      | 368384    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000206 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 48.4      |
|    n_updates            | 28770     |
|    policy_gradient_loss | 6.4e-09   |
|    value_loss           | 100       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.5      |
|    ep_rew_mean          | -9.96     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2879      |
|    time_elapsed         | 9724      |
|    total_timesteps      | 368512    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000207 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.8      |
|    n_updates            | 28780     |
|    policy_gradient_loss | 2.86e-09  |
|    value_loss           | 72.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.6      |
|    ep_rew_mean          | -10.4     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2880      |
|    time_elapsed         | 9728      |
|    total_timesteps      | 368640    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000208 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 131       |
|    n_updates            | 28790     |
|    policy_gradient_loss | 1.07e-08  |
|    value_loss           | 218       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 88.6     |
|    ep_rew_mean          | -10.4    |
| time/                   |          |
|    fps                  | 37       |
|    iterations           | 2881     |
|    time_elapsed         | 9731     |
|    total_timesteps      | 368768   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00021 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 42.6     |
|    n_updates            | 28800    |
|    policy_gradient_loss | 2.63e-09 |
|    value_loss           | 101      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.8      |
|    ep_rew_mean          | -11       |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2882      |
|    time_elapsed         | 9734      |
|    total_timesteps      | 368896    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000213 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 35.3      |
|    n_updates            | 28810     |
|    policy_gradient_loss | -3.82e-09 |
|    value_loss           | 81.4      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 369000
Best mean reward: -0.99 - Last mean reward per episode: -11.61
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.6      |
|    ep_rew_mean          | -10.6     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2883      |
|    time_elapsed         | 9738      |
|    total_timesteps      | 369024    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000214 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 35.9      |
|    n_updates            | 28820     |
|    policy_gradient_loss | 7.05e-09  |
|    value_loss           | 70.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.6      |
|    ep_rew_mean          | -10.6     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2884      |
|    time_elapsed         | 9742      |
|    total_timesteps      | 369152    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000214 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 123       |
|    n_updates            | 28830     |
|    policy_gradient_loss | 3.56e-09  |
|    value_loss           | 225       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.7      |
|    ep_rew_mean          | -10.5     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2885      |
|    time_elapsed         | 9746      |
|    total_timesteps      | 369280    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000215 |
|    explained_variance   | -2.38e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 34.1      |
|    n_updates            | 28840     |
|    policy_gradient_loss | -2.05e-09 |
|    value_loss           | 73.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 90        |
|    ep_rew_mean          | -10.8     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2886      |
|    time_elapsed         | 9749      |
|    total_timesteps      | 369408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000215 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 104       |
|    n_updates            | 28850     |
|    policy_gradient_loss | -4.31e-09 |
|    value_loss           | 185       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.3      |
|    ep_rew_mean          | -10.6     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2887      |
|    time_elapsed         | 9753      |
|    total_timesteps      | 369536    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000216 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.8      |
|    n_updates            | 28860     |
|    policy_gradient_loss | -6.15e-09 |
|    value_loss           | 93.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.2      |
|    ep_rew_mean          | -9.78     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2888      |
|    time_elapsed         | 9755      |
|    total_timesteps      | 369664    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000217 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 49.9      |
|    n_updates            | 28870     |
|    policy_gradient_loss | 5.59e-10  |
|    value_loss           | 91.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.7      |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2889      |
|    time_elapsed         | 9759      |
|    total_timesteps      | 369792    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000219 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 105       |
|    n_updates            | 28880     |
|    policy_gradient_loss | -3.73e-09 |
|    value_loss           | 179       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 88.5     |
|    ep_rew_mean          | -10.1    |
| time/                   |          |
|    fps                  | 37       |
|    iterations           | 2890     |
|    time_elapsed         | 9762     |
|    total_timesteps      | 369920   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00022 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.1     |
|    n_updates            | 28890    |
|    policy_gradient_loss | 3.12e-09 |
|    value_loss           | 70.1     |
--------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 370000
Best mean reward: -0.99 - Last mean reward per episode: -11.31
Eval num_timesteps=370000, episode_reward=-11.20 +/- 21.71
Episode length: 86.40 +/- 39.93
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 86.4      |
|    mean_reward          | -11.2     |
| time/                   |           |
|    total_timesteps      | 370000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000223 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 46.5      |
|    n_updates            | 28900     |
|    policy_gradient_loss | 4.03e-09  |
|    value_loss           | 99        |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 88.4     |
|    ep_rew_mean     | -9.99    |
| time/              |          |
|    fps             | 37       |
|    iterations      | 2891     |
|    time_elapsed    | 9768     |
|    total_timesteps | 370048   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.8      |
|    ep_rew_mean          | -10.2     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2892      |
|    time_elapsed         | 9771      |
|    total_timesteps      | 370176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000226 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 34.2      |
|    n_updates            | 28910     |
|    policy_gradient_loss | -2.14e-09 |
|    value_loss           | 78.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.8      |
|    ep_rew_mean          | -10.5     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2893      |
|    time_elapsed         | 9775      |
|    total_timesteps      | 370304    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000228 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 107       |
|    n_updates            | 28920     |
|    policy_gradient_loss | 7.45e-10  |
|    value_loss           | 181       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.6      |
|    ep_rew_mean          | -10.4     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2894      |
|    time_elapsed         | 9778      |
|    total_timesteps      | 370432    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000229 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 45.3      |
|    n_updates            | 28930     |
|    policy_gradient_loss | -7.45e-10 |
|    value_loss           | 90.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.9      |
|    ep_rew_mean          | -10.6     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2895      |
|    time_elapsed         | 9783      |
|    total_timesteps      | 370560    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000231 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 37.4      |
|    n_updates            | 28940     |
|    policy_gradient_loss | 5.59e-09  |
|    value_loss           | 74.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.2      |
|    ep_rew_mean          | -10.8     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2896      |
|    time_elapsed         | 9787      |
|    total_timesteps      | 370688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000232 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 75.5      |
|    n_updates            | 28950     |
|    policy_gradient_loss | -1.86e-09 |
|    value_loss           | 133       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.2      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2897      |
|    time_elapsed         | 9792      |
|    total_timesteps      | 370816    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000235 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 45.3      |
|    n_updates            | 28960     |
|    policy_gradient_loss | 2.24e-09  |
|    value_loss           | 75.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89        |
|    ep_rew_mean          | -10.6     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2898      |
|    time_elapsed         | 9796      |
|    total_timesteps      | 370944    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000237 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 50.9      |
|    n_updates            | 28970     |
|    policy_gradient_loss | 3.21e-09  |
|    value_loss           | 106       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 371000
Best mean reward: -0.99 - Last mean reward per episode: -11.89
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89        |
|    ep_rew_mean          | -10.6     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2899      |
|    time_elapsed         | 9799      |
|    total_timesteps      | 371072    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00024  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40        |
|    n_updates            | 28980     |
|    policy_gradient_loss | -3.91e-09 |
|    value_loss           | 95        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 88.7      |
|    ep_rew_mean          | -10.4     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2900      |
|    time_elapsed         | 9803      |
|    total_timesteps      | 371200    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000243 |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 48.6      |
|    n_updates            | 28990     |
|    policy_gradient_loss | -2.72e-09 |
|    value_loss           | 134       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.3      |
|    ep_rew_mean          | -10.7     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2901      |
|    time_elapsed         | 9806      |
|    total_timesteps      | 371328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000246 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.1      |
|    n_updates            | 29000     |
|    policy_gradient_loss | -1.68e-09 |
|    value_loss           | 70.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.3      |
|    ep_rew_mean          | -11       |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2902      |
|    time_elapsed         | 9809      |
|    total_timesteps      | 371456    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000247 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.3      |
|    n_updates            | 29010     |
|    policy_gradient_loss | -5.3e-09  |
|    value_loss           | 70.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.5      |
|    ep_rew_mean          | -11.3     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2903      |
|    time_elapsed         | 9813      |
|    total_timesteps      | 371584    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000248 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42        |
|    n_updates            | 29020     |
|    policy_gradient_loss | -3.59e-09 |
|    value_loss           | 86.6      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 90.2     |
|    ep_rew_mean          | -11.4    |
| time/                   |          |
|    fps                  | 37       |
|    iterations           | 2904     |
|    time_elapsed         | 9817     |
|    total_timesteps      | 371712   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00025 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 44.1     |
|    n_updates            | 29030    |
|    policy_gradient_loss | 2.89e-09 |
|    value_loss           | 82.4     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.8      |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2905      |
|    time_elapsed         | 9821      |
|    total_timesteps      | 371840    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000254 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 96.4      |
|    n_updates            | 29040     |
|    policy_gradient_loss | -1.72e-09 |
|    value_loss           | 160       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.8      |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2906      |
|    time_elapsed         | 9825      |
|    total_timesteps      | 371968    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000257 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 31.9      |
|    n_updates            | 29050     |
|    policy_gradient_loss | 1.7e-09   |
|    value_loss           | 76.9      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 372000
Best mean reward: -0.99 - Last mean reward per episode: -12.49
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 89.8      |
|    ep_rew_mean          | -11.2     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2907      |
|    time_elapsed         | 9829      |
|    total_timesteps      | 372096    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000258 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 26        |
|    n_updates            | 29060     |
|    policy_gradient_loss | -6.97e-08 |
|    value_loss           | 54.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 92.9      |
|    ep_rew_mean          | -12.9     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2908      |
|    time_elapsed         | 9834      |
|    total_timesteps      | 372224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000258 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 25.6      |
|    n_updates            | 29070     |
|    policy_gradient_loss | -3.16e-08 |
|    value_loss           | 53.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 92.9      |
|    ep_rew_mean          | -12.9     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2909      |
|    time_elapsed         | 9837      |
|    total_timesteps      | 372352    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000259 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55.9      |
|    n_updates            | 29080     |
|    policy_gradient_loss | 7.68e-10  |
|    value_loss           | 146       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 94        |
|    ep_rew_mean          | -13.5     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2910      |
|    time_elapsed         | 9840      |
|    total_timesteps      | 372480    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00026  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49        |
|    n_updates            | 29090     |
|    policy_gradient_loss | -1.35e-08 |
|    value_loss           | 83.2      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 93.5     |
|    ep_rew_mean          | -13.2    |
| time/                   |          |
|    fps                  | 37       |
|    iterations           | 2911     |
|    time_elapsed         | 9843     |
|    total_timesteps      | 372608   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00026 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 38.7     |
|    n_updates            | 29100    |
|    policy_gradient_loss | 2.37e-09 |
|    value_loss           | 74.3     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.3      |
|    ep_rew_mean          | -13.1     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2912      |
|    time_elapsed         | 9846      |
|    total_timesteps      | 372736    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000263 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 44.2      |
|    n_updates            | 29110     |
|    policy_gradient_loss | -2.19e-09 |
|    value_loss           | 113       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.4      |
|    ep_rew_mean          | -13.3     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2913      |
|    time_elapsed         | 9848      |
|    total_timesteps      | 372864    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000266 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 61.4      |
|    n_updates            | 29120     |
|    policy_gradient_loss | -2.33e-10 |
|    value_loss           | 113       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.1      |
|    ep_rew_mean          | -13.1     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2914      |
|    time_elapsed         | 9851      |
|    total_timesteps      | 372992    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000272 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.4      |
|    n_updates            | 29130     |
|    policy_gradient_loss | -2.1e-09  |
|    value_loss           | 113       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 373000
Best mean reward: -0.99 - Last mean reward per episode: -8.33
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 93.8      |
|    ep_rew_mean          | -13.5     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2915      |
|    time_elapsed         | 9854      |
|    total_timesteps      | 373120    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000278 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.4      |
|    n_updates            | 29140     |
|    policy_gradient_loss | -1.54e-09 |
|    value_loss           | 102       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.7      |
|    ep_rew_mean          | -8.65     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2916      |
|    time_elapsed         | 9858      |
|    total_timesteps      | 373248    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00028  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45.4      |
|    n_updates            | 29150     |
|    policy_gradient_loss | -1.49e-09 |
|    value_loss           | 84.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.7      |
|    ep_rew_mean          | -8.65     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2917      |
|    time_elapsed         | 9860      |
|    total_timesteps      | 373376    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000281 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 45        |
|    n_updates            | 29160     |
|    policy_gradient_loss | 4.82e-09  |
|    value_loss           | 73.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.9      |
|    ep_rew_mean          | -9.23     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2918      |
|    time_elapsed         | 9864      |
|    total_timesteps      | 373504    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000283 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 25.4      |
|    n_updates            | 29170     |
|    policy_gradient_loss | 4.7e-08   |
|    value_loss           | 51.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.5      |
|    ep_rew_mean          | -9.07     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2919      |
|    time_elapsed         | 9868      |
|    total_timesteps      | 373632    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000284 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.1      |
|    n_updates            | 29180     |
|    policy_gradient_loss | 1.68e-09  |
|    value_loss           | 106       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.6      |
|    ep_rew_mean          | -8.72     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2920      |
|    time_elapsed         | 9871      |
|    total_timesteps      | 373760    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000285 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 79.3      |
|    n_updates            | 29190     |
|    policy_gradient_loss | -4.61e-09 |
|    value_loss           | 120       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.1      |
|    ep_rew_mean          | -8.96     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2921      |
|    time_elapsed         | 9874      |
|    total_timesteps      | 373888    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00029  |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 55.7      |
|    n_updates            | 29200     |
|    policy_gradient_loss | -1.79e-09 |
|    value_loss           | 111       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 374000
Best mean reward: -0.99 - Last mean reward per episode: -8.73
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.7      |
|    ep_rew_mean          | -8.94     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2922      |
|    time_elapsed         | 9877      |
|    total_timesteps      | 374016    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000293 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 39.1      |
|    n_updates            | 29210     |
|    policy_gradient_loss | 1.72e-09  |
|    value_loss           | 75.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.6      |
|    ep_rew_mean          | -8.52     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2923      |
|    time_elapsed         | 9880      |
|    total_timesteps      | 374144    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000296 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.8      |
|    n_updates            | 29220     |
|    policy_gradient_loss | -4e-09    |
|    value_loss           | 102       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.2      |
|    ep_rew_mean          | -8.98     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2924      |
|    time_elapsed         | 9882      |
|    total_timesteps      | 374272    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000303 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 55.4      |
|    n_updates            | 29230     |
|    policy_gradient_loss | 3.17e-09  |
|    value_loss           | 103       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84        |
|    ep_rew_mean          | -8.88     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2925      |
|    time_elapsed         | 9886      |
|    total_timesteps      | 374400    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00031  |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 58.8      |
|    n_updates            | 29240     |
|    policy_gradient_loss | 5.94e-09  |
|    value_loss           | 91.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.1      |
|    ep_rew_mean          | -8.95     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2926      |
|    time_elapsed         | 9889      |
|    total_timesteps      | 374528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000313 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 40.1      |
|    n_updates            | 29250     |
|    policy_gradient_loss | -7.66e-09 |
|    value_loss           | 85.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.1      |
|    ep_rew_mean          | -8.95     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2927      |
|    time_elapsed         | 9892      |
|    total_timesteps      | 374656    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000317 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 62.1      |
|    n_updates            | 29260     |
|    policy_gradient_loss | -3.77e-09 |
|    value_loss           | 119       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 84.7      |
|    ep_rew_mean          | -9.26     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2928      |
|    time_elapsed         | 9896      |
|    total_timesteps      | 374784    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000322 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 28.6      |
|    n_updates            | 29270     |
|    policy_gradient_loss | -8.48e-09 |
|    value_loss           | 91.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.1      |
|    ep_rew_mean          | -9.46     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2929      |
|    time_elapsed         | 9899      |
|    total_timesteps      | 374912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000325 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 53.6      |
|    n_updates            | 29280     |
|    policy_gradient_loss | 2.14e-09  |
|    value_loss           | 129       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 375000
Best mean reward: -0.99 - Last mean reward per episode: -9.46
Eval num_timesteps=375000, episode_reward=-12.20 +/- 29.76
Episode length: 88.40 +/- 56.88
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 88.4      |
|    mean_reward          | -12.2     |
| time/                   |           |
|    total_timesteps      | 375000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000329 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46        |
|    n_updates            | 29290     |
|    policy_gradient_loss | 3.03e-09  |
|    value_loss           | 80.2      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 85.3     |
|    ep_rew_mean     | -9.36    |
| time/              |          |
|    fps             | 37       |
|    iterations      | 2930     |
|    time_elapsed    | 9904     |
|    total_timesteps | 375040   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.3      |
|    ep_rew_mean          | -9.37     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2931      |
|    time_elapsed         | 9907      |
|    total_timesteps      | 375168    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000334 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 112       |
|    n_updates            | 29300     |
|    policy_gradient_loss | 1.12e-09  |
|    value_loss           | 182       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.5      |
|    ep_rew_mean          | -9.47     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2932      |
|    time_elapsed         | 9910      |
|    total_timesteps      | 375296    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000342 |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 36.5      |
|    n_updates            | 29310     |
|    policy_gradient_loss | -1.72e-09 |
|    value_loss           | 83        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.1      |
|    ep_rew_mean          | -9.13     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2933      |
|    time_elapsed         | 9913      |
|    total_timesteps      | 375424    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000348 |
|    explained_variance   | 2.38e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 86.4      |
|    n_updates            | 29320     |
|    policy_gradient_loss | 1.47e-09  |
|    value_loss           | 161       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.5      |
|    ep_rew_mean          | -9.16     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2934      |
|    time_elapsed         | 9916      |
|    total_timesteps      | 375552    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00035  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 95.1      |
|    n_updates            | 29330     |
|    policy_gradient_loss | -2.05e-09 |
|    value_loss           | 163       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.3      |
|    ep_rew_mean          | -9.04     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2935      |
|    time_elapsed         | 9920      |
|    total_timesteps      | 375680    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000351 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 101       |
|    n_updates            | 29340     |
|    policy_gradient_loss | -1.58e-09 |
|    value_loss           | 219       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.2      |
|    ep_rew_mean          | -9.22     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2936      |
|    time_elapsed         | 9923      |
|    total_timesteps      | 375808    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000352 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 95.3      |
|    n_updates            | 29350     |
|    policy_gradient_loss | 7.64e-09  |
|    value_loss           | 153       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.4      |
|    ep_rew_mean          | -9.48     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2937      |
|    time_elapsed         | 9927      |
|    total_timesteps      | 375936    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000353 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 66.5      |
|    n_updates            | 29360     |
|    policy_gradient_loss | -2.98e-09 |
|    value_loss           | 111       |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 376000
Best mean reward: -0.99 - Last mean reward per episode: -9.66
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.8      |
|    ep_rew_mean          | -9.81     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2938      |
|    time_elapsed         | 9930      |
|    total_timesteps      | 376064    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000356 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.8      |
|    n_updates            | 29370     |
|    policy_gradient_loss | 5.15e-09  |
|    value_loss           | 77.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.7      |
|    ep_rew_mean          | -9.56     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2939      |
|    time_elapsed         | 9934      |
|    total_timesteps      | 376192    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000358 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 33.7      |
|    n_updates            | 29380     |
|    policy_gradient_loss | 3.73e-09  |
|    value_loss           | 76.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.7      |
|    ep_rew_mean          | -8.67     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2940      |
|    time_elapsed         | 9937      |
|    total_timesteps      | 376320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000361 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 126       |
|    n_updates            | 29390     |
|    policy_gradient_loss | -1.26e-09 |
|    value_loss           | 208       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.3      |
|    ep_rew_mean          | -8.45     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2941      |
|    time_elapsed         | 9940      |
|    total_timesteps      | 376448    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000364 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 60.4      |
|    n_updates            | 29400     |
|    policy_gradient_loss | -1.86e-10 |
|    value_loss           | 148       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83.3      |
|    ep_rew_mean          | -8.45     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2942      |
|    time_elapsed         | 9945      |
|    total_timesteps      | 376576    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000371 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 41.6      |
|    n_updates            | 29410     |
|    policy_gradient_loss | 1.35e-08  |
|    value_loss           | 79.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.3      |
|    ep_rew_mean          | -9.54     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2943      |
|    time_elapsed         | 9949      |
|    total_timesteps      | 376704    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000374 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 24.3      |
|    n_updates            | 29420     |
|    policy_gradient_loss | -8.86e-08 |
|    value_loss           | 50.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.3      |
|    ep_rew_mean          | -9.46     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2944      |
|    time_elapsed         | 9951      |
|    total_timesteps      | 376832    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000375 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 101       |
|    n_updates            | 29430     |
|    policy_gradient_loss | 3.21e-09  |
|    value_loss           | 188       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.3      |
|    ep_rew_mean          | -9.46     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2945      |
|    time_elapsed         | 9955      |
|    total_timesteps      | 376960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000376 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 107       |
|    n_updates            | 29440     |
|    policy_gradient_loss | -2.86e-09 |
|    value_loss           | 151       |
---------------------------------------
Num timesteps: 377000
Best mean reward: -0.99 - Last mean reward per episode: -10.11
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 86.6        |
|    ep_rew_mean          | -10.1       |
| time/                   |             |
|    fps                  | 37          |
|    iterations           | 2946        |
|    time_elapsed         | 9958        |
|    total_timesteps      | 377088      |
| train/                  |             |
|    approx_kl            | 0.003071053 |
|    clip_fraction        | 0.00625     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.000583   |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 26.9        |
|    n_updates            | 29450       |
|    policy_gradient_loss | -0.0022     |
|    value_loss           | 52.8        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | -10.2     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2947      |
|    time_elapsed         | 9961      |
|    total_timesteps      | 377216    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000798 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.5      |
|    n_updates            | 29460     |
|    policy_gradient_loss | 2.65e-09  |
|    value_loss           | 77.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86        |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2948      |
|    time_elapsed         | 9965      |
|    total_timesteps      | 377344    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000838 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 58.3      |
|    n_updates            | 29470     |
|    policy_gradient_loss | 2.37e-09  |
|    value_loss           | 116       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 85.2     |
|    ep_rew_mean          | -9.62    |
| time/                   |          |
|    fps                  | 37       |
|    iterations           | 2949     |
|    time_elapsed         | 9968     |
|    total_timesteps      | 377472   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00085 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 59.4     |
|    n_updates            | 29480    |
|    policy_gradient_loss | 3.86e-09 |
|    value_loss           | 119      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.3      |
|    ep_rew_mean          | -9.74     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2950      |
|    time_elapsed         | 9971      |
|    total_timesteps      | 377600    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000863 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 93.4      |
|    n_updates            | 29490     |
|    policy_gradient_loss | 7.45e-09  |
|    value_loss           | 160       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 85.5      |
|    ep_rew_mean          | -9.82     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2951      |
|    time_elapsed         | 9975      |
|    total_timesteps      | 377728    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000875 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 107       |
|    n_updates            | 29500     |
|    policy_gradient_loss | 6.47e-09  |
|    value_loss           | 185       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.2      |
|    ep_rew_mean          | -10.2     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2952      |
|    time_elapsed         | 9978      |
|    total_timesteps      | 377856    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000881 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.8      |
|    n_updates            | 29510     |
|    policy_gradient_loss | 4.19e-09  |
|    value_loss           | 76.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86        |
|    ep_rew_mean          | -10.1     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2953      |
|    time_elapsed         | 9982      |
|    total_timesteps      | 377984    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000888 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 37.3      |
|    n_updates            | 29520     |
|    policy_gradient_loss | -4.45e-09 |
|    value_loss           | 75.4      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 378000
Best mean reward: -0.99 - Last mean reward per episode: -11.10
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.5      |
|    ep_rew_mean          | -10.2     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2954      |
|    time_elapsed         | 9987      |
|    total_timesteps      | 378112    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000896 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 31.9      |
|    n_updates            | 29530     |
|    policy_gradient_loss | 4.47e-09  |
|    value_loss           | 89.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.8      |
|    ep_rew_mean          | -10.3     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2955      |
|    time_elapsed         | 9991      |
|    total_timesteps      | 378240    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000901 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 205       |
|    n_updates            | 29540     |
|    policy_gradient_loss | 4.84e-09  |
|    value_loss           | 304       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.9      |
|    ep_rew_mean          | -10.4     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2956      |
|    time_elapsed         | 9994      |
|    total_timesteps      | 378368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000905 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 53.9      |
|    n_updates            | 29550     |
|    policy_gradient_loss | 2.05e-09  |
|    value_loss           | 108       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 86.2     |
|    ep_rew_mean          | -10.1    |
| time/                   |          |
|    fps                  | 37       |
|    iterations           | 2957     |
|    time_elapsed         | 9998     |
|    total_timesteps      | 378496   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00091 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 45.7     |
|    n_updates            | 29560    |
|    policy_gradient_loss | 2.72e-09 |
|    value_loss           | 145      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | -10       |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2958      |
|    time_elapsed         | 10002     |
|    total_timesteps      | 378624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000917 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 64.3      |
|    n_updates            | 29570     |
|    policy_gradient_loss | -2.84e-09 |
|    value_loss           | 107       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | -10       |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2959      |
|    time_elapsed         | 10006     |
|    total_timesteps      | 378752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000929 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 76.5      |
|    n_updates            | 29580     |
|    policy_gradient_loss | 6.33e-09  |
|    value_loss           | 102       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | -10       |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2960      |
|    time_elapsed         | 10009     |
|    total_timesteps      | 378880    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000946 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 39.9      |
|    n_updates            | 29590     |
|    policy_gradient_loss | 2.14e-09  |
|    value_loss           | 84.8      |
---------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 379000
Best mean reward: -0.99 - Last mean reward per episode: -10.61
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | -10       |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2961      |
|    time_elapsed         | 10013     |
|    total_timesteps      | 379008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000956 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 25.3      |
|    n_updates            | 29600     |
|    policy_gradient_loss | 2.24e-08  |
|    value_loss           | 53.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | -10       |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2962      |
|    time_elapsed         | 10017     |
|    total_timesteps      | 379136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000959 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 25.4      |
|    n_updates            | 29610     |
|    policy_gradient_loss | -4.66e-11 |
|    value_loss           | 52.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | -10       |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2963      |
|    time_elapsed         | 10021     |
|    total_timesteps      | 379264    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000962 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 24.4      |
|    n_updates            | 29620     |
|    policy_gradient_loss | 3.32e-08  |
|    value_loss           | 51.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | -10       |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2964      |
|    time_elapsed         | 10024     |
|    total_timesteps      | 379392    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000964 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 24.4      |
|    n_updates            | 29630     |
|    policy_gradient_loss | -6.04e-08 |
|    value_loss           | 50.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 92.7      |
|    ep_rew_mean          | -13.6     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2965      |
|    time_elapsed         | 10028     |
|    total_timesteps      | 379520    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000967 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 23.3      |
|    n_updates            | 29640     |
|    policy_gradient_loss | -8.1e-09  |
|    value_loss           | 49.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 92.8      |
|    ep_rew_mean          | -13.6     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2966      |
|    time_elapsed         | 10031     |
|    total_timesteps      | 379648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000971 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 63.7      |
|    n_updates            | 29650     |
|    policy_gradient_loss | -3e-09    |
|    value_loss           | 115       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 92.8      |
|    ep_rew_mean          | -13.4     |
| time/                   |           |
|    fps                  | 37        |
|    iterations           | 2967      |
|    time_elapsed         | 10035     |
|    total_timesteps      | 379776    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000977 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 59.3      |
|    n_updates            | 29660     |
|    policy_gradient_loss | 1.16e-09  |
|    value_loss           | 114       |
---------------------------------------
Traceback (most recent call last):
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/freeway/run_supervised_gnn.py", line 118, in <module>
    main()
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/freeway/run_supervised_gnn.py", line 112, in main
    model.learn(total_timesteps=1000000, callback=[WandbCallback(), save_best_callback, eval_callback])
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 315, in learn
    return super().learn(
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 313, in learn
    self.train()
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 279, in train
    loss.backward()
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt