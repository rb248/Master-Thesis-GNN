/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.
  logger.warn(
Using cpu device
----------------------------
| time/              |     |
|    fps             | 191 |
|    iterations      | 1   |
|    time_elapsed    | 0   |
|    total_timesteps | 128 |
----------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 67           |
|    iterations           | 2            |
|    time_elapsed         | 3            |
|    total_timesteps      | 256          |
| train/                  |              |
|    approx_kl            | 0.0022338605 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.00307     |
|    learning_rate        | 0.0003       |
|    loss                 | 5.07         |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00207     |
|    value_loss           | 20           |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 54            |
|    iterations           | 3             |
|    time_elapsed         | 7             |
|    total_timesteps      | 384           |
| train/                  |               |
|    approx_kl            | 0.00089554535 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.09         |
|    explained_variance   | 0.000302      |
|    learning_rate        | 0.0003        |
|    loss                 | 17            |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.000978     |
|    value_loss           | 40.1          |
-------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 4           |
|    time_elapsed         | 10          |
|    total_timesteps      | 512         |
| train/                  |             |
|    approx_kl            | 0.012549705 |
|    clip_fraction        | 0.0211      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 0.000293    |
|    learning_rate        | 0.0003      |
|    loss                 | 17.4        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0138     |
|    value_loss           | 39.8        |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 47           |
|    iterations           | 5            |
|    time_elapsed         | 13           |
|    total_timesteps      | 640          |
| train/                  |              |
|    approx_kl            | 0.0019325903 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.08        |
|    explained_variance   | -0.00013     |
|    learning_rate        | 0.0003       |
|    loss                 | 17.7         |
|    n_updates            | 40           |
|    policy_gradient_loss | 0.00165      |
|    value_loss           | 39.2         |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 6           |
|    time_elapsed         | 16          |
|    total_timesteps      | 768         |
| train/                  |             |
|    approx_kl            | 0.005016223 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | -9.89e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 17.2        |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00382    |
|    value_loss           | 38.6        |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 45           |
|    iterations           | 7            |
|    time_elapsed         | 19           |
|    total_timesteps      | 896          |
| train/                  |              |
|    approx_kl            | 0.0044355136 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.09        |
|    explained_variance   | 1.98e-05     |
|    learning_rate        | 0.0003       |
|    loss                 | 17.5         |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00138     |
|    value_loss           | 37.9         |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 1000
Best mean reward: -inf - Last mean reward per episode: -805.61
Saving new best model at 113000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 44           |
|    iterations           | 8            |
|    time_elapsed         | 22           |
|    total_timesteps      | 1024         |
| train/                  |              |
|    approx_kl            | 0.0033401432 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.09        |
|    explained_variance   | -2.21e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 17           |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00224     |
|    value_loss           | 37.2         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 43          |
|    iterations           | 9           |
|    time_elapsed         | 26          |
|    total_timesteps      | 1152        |
| train/                  |             |
|    approx_kl            | 0.009016329 |
|    clip_fraction        | 0.0391      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 0.000651    |
|    learning_rate        | 0.0003      |
|    loss                 | 12.7        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00557    |
|    value_loss           | 27.8        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 41           |
|    iterations           | 10           |
|    time_elapsed         | 30           |
|    total_timesteps      | 1280         |
| train/                  |              |
|    approx_kl            | 0.0031998805 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.09        |
|    explained_variance   | -0.000193    |
|    learning_rate        | 0.0003       |
|    loss                 | 15.8         |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00283     |
|    value_loss           | 35.6         |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -500       |
| time/                   |            |
|    fps                  | 39         |
|    iterations           | 11         |
|    time_elapsed         | 35         |
|    total_timesteps      | 1408       |
| train/                  |            |
|    approx_kl            | 0.00790238 |
|    clip_fraction        | 0          |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.07      |
|    explained_variance   | 1.27e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 16.2       |
|    n_updates            | 100        |
|    policy_gradient_loss | -0.00476   |
|    value_loss           | 34.9       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 12          |
|    time_elapsed         | 39          |
|    total_timesteps      | 1536        |
| train/                  |             |
|    approx_kl            | 0.006354375 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.04       |
|    explained_variance   | -1.79e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 17          |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00417    |
|    value_loss           | 34.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 37          |
|    iterations           | 13          |
|    time_elapsed         | 44          |
|    total_timesteps      | 1664        |
| train/                  |             |
|    approx_kl            | 0.016942218 |
|    clip_fraction        | 0.0906      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.04       |
|    explained_variance   | -1.91e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 15.9        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0128     |
|    value_loss           | 33.4        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 36          |
|    iterations           | 14          |
|    time_elapsed         | 49          |
|    total_timesteps      | 1792        |
| train/                  |             |
|    approx_kl            | 0.012975462 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.08       |
|    explained_variance   | -4.05e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 15.5        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00776    |
|    value_loss           | 32.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 35          |
|    iterations           | 15          |
|    time_elapsed         | 53          |
|    total_timesteps      | 1920        |
| train/                  |             |
|    approx_kl            | 0.010480434 |
|    clip_fraction        | 0.068       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 4.17e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 15          |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.00925    |
|    value_loss           | 32          |
-----------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 2000
Best mean reward: -805.61 - Last mean reward per episode: -798.33
Saving new best model at 114000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 16           |
|    time_elapsed         | 58           |
|    total_timesteps      | 2048         |
| train/                  |              |
|    approx_kl            | 0.0031340858 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -3.22e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 14.8         |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.0027      |
|    value_loss           | 31.3         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 34          |
|    iterations           | 17          |
|    time_elapsed         | 63          |
|    total_timesteps      | 2176        |
| train/                  |             |
|    approx_kl            | 0.019109601 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.08       |
|    explained_variance   | -7.83e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 11.5        |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.00887    |
|    value_loss           | 24.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 18           |
|    time_elapsed         | 67           |
|    total_timesteps      | 2304         |
| train/                  |              |
|    approx_kl            | 0.0031698556 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.06        |
|    explained_variance   | 7.27e-06     |
|    learning_rate        | 0.0003       |
|    loss                 | 13.8         |
|    n_updates            | 170          |
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 33          |
|    iterations           | 19          |
|    time_elapsed         | 72          |
|    total_timesteps      | 2432        |
| train/                  |             |
|    approx_kl            | 0.014550358 |
|    clip_fraction        | 0.0977      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.02       |
|    explained_variance   | -4.89e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 14.1        |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 29.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 33           |
|    iterations           | 20           |
|    time_elapsed         | 77           |
|    total_timesteps      | 2560         |
| train/                  |              |
|    approx_kl            | 0.0028649853 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.01        |
|    explained_variance   | 1.73e-06     |
|    learning_rate        | 0.0003       |
|    loss                 | 14           |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.00108     |
|    value_loss           | 28.6         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 32          |
|    iterations           | 21          |
|    time_elapsed         | 81          |
|    total_timesteps      | 2688        |
| train/                  |             |
|    approx_kl            | 0.007105691 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -1          |
|    explained_variance   | -9.54e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 13.3        |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00433    |
|    value_loss           | 28          |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 32          |
|    iterations           | 22          |
|    time_elapsed         | 85          |
|    total_timesteps      | 2816        |
| train/                  |             |
|    approx_kl            | 0.005413984 |
|    clip_fraction        | 0.0102      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.977      |
|    explained_variance   | 8.94e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 12.7        |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.00549    |
|    value_loss           | 27.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 32           |
|    iterations           | 23           |
|    time_elapsed         | 90           |
|    total_timesteps      | 2944         |
| train/                  |              |
|    approx_kl            | 0.0005023866 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.955       |
|    explained_variance   | -7.15e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 12.5         |
|    n_updates            | 220          |
|    policy_gradient_loss | 0.000662     |
|    value_loss           | 26.7         |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 3000
Best mean reward: -798.33 - Last mean reward per episode: -791.40
Saving new best model at 115000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 32          |
|    iterations           | 24          |
|    time_elapsed         | 95          |
|    total_timesteps      | 3072        |
| train/                  |             |
|    approx_kl            | 0.020254124 |
|    clip_fraction        | 0.068       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.939      |
|    explained_variance   | -5.96e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 11.3        |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0108     |
|    value_loss           | 26.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 32          |
|    iterations           | 25          |
|    time_elapsed         | 98          |
|    total_timesteps      | 3200        |
| train/                  |             |
|    approx_kl            | 0.014599133 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.995      |
|    explained_variance   | -0.0487     |
|    learning_rate        | 0.0003      |
|    loss                 | 14.5        |
|    n_updates            | 240         |
|    policy_gradient_loss | 0.0166      |
|    value_loss           | 23.8        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 32           |
|    iterations           | 26           |
|    time_elapsed         | 101          |
|    total_timesteps      | 3328         |
| train/                  |              |
|    approx_kl            | 0.0070616584 |
|    clip_fraction        | 0.018        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.02        |
|    explained_variance   | 0.000242     |
|    learning_rate        | 0.0003       |
|    loss                 | 11.5         |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.00712     |
|    value_loss           | 25           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 33            |
|    iterations           | 27            |
|    time_elapsed         | 104           |
|    total_timesteps      | 3456          |
| train/                  |               |
|    approx_kl            | 0.00032123085 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.989        |
|    explained_variance   | -2.86e-06     |
|    learning_rate        | 0.0003        |
|    loss                 | 11.1          |
|    n_updates            | 260           |
|    policy_gradient_loss | 0.00134       |
|    value_loss           | 24.3          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 33          |
|    iterations           | 28          |
|    time_elapsed         | 107         |
|    total_timesteps      | 3584        |
| train/                  |             |
|    approx_kl            | 0.005925579 |
|    clip_fraction        | 0.0367      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -7.63e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 11.1        |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0042     |
|    value_loss           | 23.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 33          |
|    iterations           | 29          |
|    time_elapsed         | 109         |
|    total_timesteps      | 3712        |
| train/                  |             |
|    approx_kl            | 0.036093973 |
|    clip_fraction        | 0.423       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.936      |
|    explained_variance   | -1.43e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 10.3        |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0316     |
|    value_loss           | 23.1        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 30           |
|    time_elapsed         | 112          |
|    total_timesteps      | 3840         |
| train/                  |              |
|    approx_kl            | 0.0052258503 |
|    clip_fraction        | 0.0172       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.863       |
|    explained_variance   | -5.36e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 10.2         |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.00393     |
|    value_loss           | 22.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 31           |
|    time_elapsed         | 115          |
|    total_timesteps      | 3968         |
| train/                  |              |
|    approx_kl            | 0.0032999385 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.802       |
|    explained_variance   | 8.94e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 10.2         |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.00223     |
|    value_loss           | 22           |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 4000
Best mean reward: -791.40 - Last mean reward per episode: -784.77
Saving new best model at 116000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 32           |
|    time_elapsed         | 118          |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0015778379 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.789       |
|    explained_variance   | -9.54e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 9.78         |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.00113     |
|    value_loss           | 21.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 33           |
|    time_elapsed         | 121          |
|    total_timesteps      | 4224         |
| train/                  |              |
|    approx_kl            | 0.0036919918 |
|    clip_fraction        | 0.0156       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.763       |
|    explained_variance   | -0.000266    |
|    learning_rate        | 0.0003       |
|    loss                 | 16.9         |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00127     |
|    value_loss           | 30.4         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 34          |
|    iterations           | 34          |
|    time_elapsed         | 125         |
|    total_timesteps      | 4352        |
| train/                  |             |
|    approx_kl            | 0.004624564 |
|    clip_fraction        | 0.0227      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.831      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 9.37        |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.00265    |
|    value_loss           | 20.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 34          |
|    iterations           | 35          |
|    time_elapsed         | 128         |
|    total_timesteps      | 4480        |
| train/                  |             |
|    approx_kl            | 0.034396015 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.778      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 8.93        |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.0233     |
|    value_loss           | 19.8        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 36           |
|    time_elapsed         | 131          |
|    total_timesteps      | 4608         |
| train/                  |              |
|    approx_kl            | 0.0045622857 |
|    clip_fraction        | 0.0266       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.615       |
|    explained_variance   | 1.79e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 9.2          |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.00352     |
|    value_loss           | 19.3         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 35          |
|    iterations           | 37          |
|    time_elapsed         | 135         |
|    total_timesteps      | 4736        |
| train/                  |             |
|    approx_kl            | 0.010924997 |
|    clip_fraction        | 0.0469      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.639      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 8.31        |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0122     |
|    value_loss           | 18.7        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 38           |
|    time_elapsed         | 138          |
|    total_timesteps      | 4864         |
| train/                  |              |
|    approx_kl            | 0.0003604982 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.726       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 8.7          |
|    n_updates            | 370          |
|    policy_gradient_loss | 0.000394     |
|    value_loss           | 18.2         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 35          |
|    iterations           | 39          |
|    time_elapsed         | 141         |
|    total_timesteps      | 4992        |
| train/                  |             |
|    approx_kl            | 0.009736953 |
|    clip_fraction        | 0.0312      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.686      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 8.17        |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.00699    |
|    value_loss           | 17.7        |
-----------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 5000
Best mean reward: -784.77 - Last mean reward per episode: -778.44
Saving new best model at 117000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
Eval num_timesteps=5000, episode_reward=-500.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 1e+03        |
|    mean_reward          | -500         |
| time/                   |              |
|    total_timesteps      | 5000         |
| train/                  |              |
|    approx_kl            | 6.957445e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.599       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 8.11         |
|    n_updates            | 390          |
|    policy_gradient_loss | 2.04e-05     |
|    value_loss           | 17.2         |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -500     |
| time/              |          |
|    fps             | 30       |
|    iterations      | 40       |
|    time_elapsed    | 169      |
|    total_timesteps | 5120     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 41           |
|    time_elapsed         | 172          |
|    total_timesteps      | 5248         |
| train/                  |              |
|    approx_kl            | 0.0020786393 |
|    clip_fraction        | 0.0156       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.625       |
|    explained_variance   | -4.65e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 16           |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00178     |
|    value_loss           | 33.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 42           |
|    time_elapsed         | 176          |
|    total_timesteps      | 5376         |
| train/                  |              |
|    approx_kl            | 0.0021874714 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.627       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 7.61         |
|    n_updates            | 410          |
|    policy_gradient_loss | -0.0019      |
|    value_loss           | 16.2         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 43          |
|    time_elapsed         | 180         |
|    total_timesteps      | 5504        |
| train/                  |             |
|    approx_kl            | 0.003924306 |
|    clip_fraction        | 0.0164      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.606      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 6.78        |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.0022     |
|    value_loss           | 15.8        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 44          |
|    time_elapsed         | 183         |
|    total_timesteps      | 5632        |
| train/                  |             |
|    approx_kl            | 0.000177335 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.667      |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 6.84        |
|    n_updates            | 430         |
|    policy_gradient_loss | 0.000151    |
|    value_loss           | 15.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 45           |
|    time_elapsed         | 186          |
|    total_timesteps      | 5760         |
| train/                  |              |
|    approx_kl            | 0.0027067163 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.629       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 6.56         |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00245     |
|    value_loss           | 14.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 46           |
|    time_elapsed         | 190          |
|    total_timesteps      | 5888         |
| train/                  |              |
|    approx_kl            | 0.0046964753 |
|    clip_fraction        | 0.0336       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.62        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 6.62         |
|    n_updates            | 450          |
|    policy_gradient_loss | -0.00506     |
|    value_loss           | 14.4         |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 6000
Best mean reward: -778.44 - Last mean reward per episode: -745.69
Saving new best model at 123000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 47          |
|    time_elapsed         | 194         |
|    total_timesteps      | 6016        |
| train/                  |             |
|    approx_kl            | 0.003401048 |
|    clip_fraction        | 0.00469     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.633      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 6.22        |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00353    |
|    value_loss           | 13.9        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 48          |
|    time_elapsed         | 198         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.002217397 |
|    clip_fraction        | 0.0281      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.522      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 23          |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00301    |
|    value_loss           | 39          |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 49           |
|    time_elapsed         | 202          |
|    total_timesteps      | 6272         |
| train/                  |              |
|    approx_kl            | 0.0002932879 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.507       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 6.46         |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.000635    |
|    value_loss           | 13.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 50           |
|    time_elapsed         | 207          |
|    total_timesteps      | 6400         |
| train/                  |              |
|    approx_kl            | 0.0028086263 |
|    clip_fraction        | 0.00937      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.552       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 5.87         |
|    n_updates            | 490          |
|    policy_gradient_loss | -0.00266     |
|    value_loss           | 13           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 30            |
|    iterations           | 51            |
|    time_elapsed         | 212           |
|    total_timesteps      | 6528          |
| train/                  |               |
|    approx_kl            | 0.00014245929 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.606        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 5.74          |
|    n_updates            | 500           |
|    policy_gradient_loss | 0.000594      |
|    value_loss           | 12.6          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 52          |
|    time_elapsed         | 217         |
|    total_timesteps      | 6656        |
| train/                  |             |
|    approx_kl            | 0.004495841 |
|    clip_fraction        | 0.00781     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.577      |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.43        |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.00519    |
|    value_loss           | 12.1        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 30            |
|    iterations           | 53            |
|    time_elapsed         | 221           |
|    total_timesteps      | 6784          |
| train/                  |               |
|    approx_kl            | 0.00011324976 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.523        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 5.2           |
|    n_updates            | 520           |
|    policy_gradient_loss | 0.000717      |
|    value_loss           | 11.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 30            |
|    iterations           | 54            |
|    time_elapsed         | 226           |
|    total_timesteps      | 6912          |
| train/                  |               |
|    approx_kl            | 0.00084830634 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.543        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 5.1           |
|    n_updates            | 530           |
|    policy_gradient_loss | -0.000909     |
|    value_loss           | 11.3          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 7000
Best mean reward: -745.69 - Last mean reward per episode: -740.96
Saving new best model at 124000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 55          |
|    time_elapsed         | 231         |
|    total_timesteps      | 7040        |
| train/                  |             |
|    approx_kl            | 0.001961843 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.549      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 4.93        |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.00286    |
|    value_loss           | 10.9        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 56           |
|    time_elapsed         | 235          |
|    total_timesteps      | 7168         |
| train/                  |              |
|    approx_kl            | 0.0057091615 |
|    clip_fraction        | 0.025        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.497       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 20.2         |
|    n_updates            | 550          |
|    policy_gradient_loss | -0.000409    |
|    value_loss           | 45.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 57           |
|    time_elapsed         | 239          |
|    total_timesteps      | 7296         |
| train/                  |              |
|    approx_kl            | 0.0027465126 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.448       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 5.76         |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.000588    |
|    value_loss           | 11.7         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 58           |
|    time_elapsed         | 242          |
|    total_timesteps      | 7424         |
| train/                  |              |
|    approx_kl            | 0.0003337129 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.41        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 4.8          |
|    n_updates            | 570          |
|    policy_gradient_loss | -0.00115     |
|    value_loss           | 10.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 59           |
|    time_elapsed         | 246          |
|    total_timesteps      | 7552         |
| train/                  |              |
|    approx_kl            | 0.0008267863 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.384       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 4.54         |
|    n_updates            | 580          |
|    policy_gradient_loss | -0.00228     |
|    value_loss           | 10.1         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 30            |
|    iterations           | 60            |
|    time_elapsed         | 250           |
|    total_timesteps      | 7680          |
| train/                  |               |
|    approx_kl            | 0.00052219816 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.343        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 4.35          |
|    n_updates            | 590           |
|    policy_gradient_loss | -0.000999     |
|    value_loss           | 9.74          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 61           |
|    time_elapsed         | 253          |
|    total_timesteps      | 7808         |
| train/                  |              |
|    approx_kl            | 7.874798e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.322       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 4.32         |
|    n_updates            | 600          |
|    policy_gradient_loss | -0.000149    |
|    value_loss           | 9.37         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 30            |
|    iterations           | 62            |
|    time_elapsed         | 256           |
|    total_timesteps      | 7936          |
| train/                  |               |
|    approx_kl            | 0.00012692623 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.311        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 3.83          |
|    n_updates            | 610           |
|    policy_gradient_loss | -0.000455     |
|    value_loss           | 9.01          |
-------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 8000
Best mean reward: -740.96 - Last mean reward per episode: -736.42
Saving new best model at 125000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 63           |
|    time_elapsed         | 260          |
|    total_timesteps      | 8064         |
| train/                  |              |
|    approx_kl            | 0.0024519735 |
|    clip_fraction        | 0.00781      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.279       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 3.86         |
|    n_updates            | 620          |
|    policy_gradient_loss | -0.00508     |
|    value_loss           | 8.66         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 64          |
|    time_elapsed         | 263         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.001801183 |
|    clip_fraction        | 0.00859     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.285      |
|    explained_variance   | -2.38e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 38.5        |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.00313    |
|    value_loss           | 53.2        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 31           |
|    iterations           | 65           |
|    time_elapsed         | 266          |
|    total_timesteps      | 8320         |
| train/                  |              |
|    approx_kl            | 0.0026602955 |
|    clip_fraction        | 0.0773       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.411       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 4.15         |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.00407     |
|    value_loss           | 9.27         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 31           |
|    iterations           | 66           |
|    time_elapsed         | 269          |
|    total_timesteps      | 8448         |
| train/                  |              |
|    approx_kl            | 0.0031341258 |
|    clip_fraction        | 0.0266       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.363       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 3.86         |
|    n_updates            | 650          |
|    policy_gradient_loss | -0.00373     |
|    value_loss           | 8.35         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 67          |
|    time_elapsed         | 272         |
|    total_timesteps      | 8576        |
| train/                  |             |
|    approx_kl            | 0.000492807 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.338      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 3.41        |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.000899   |
|    value_loss           | 7.95        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 68          |
|    time_elapsed         | 275         |
|    total_timesteps      | 8704        |
| train/                  |             |
|    approx_kl            | 0.007822897 |
|    clip_fraction        | 0.043       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.431      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 3.21        |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0111     |
|    value_loss           | 7.61        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 31           |
|    iterations           | 69           |
|    time_elapsed         | 278          |
|    total_timesteps      | 8832         |
| train/                  |              |
|    approx_kl            | 0.0009879894 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.473       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 3.13         |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.00121     |
|    value_loss           | 7.28         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 31           |
|    iterations           | 70           |
|    time_elapsed         | 281          |
|    total_timesteps      | 8960         |
| train/                  |              |
|    approx_kl            | 0.0025051828 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.463       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 3.15         |
|    n_updates            | 690          |
|    policy_gradient_loss | -0.00405     |
|    value_loss           | 6.97         |
------------------------------------------
Num timesteps: 9000
Best mean reward: -736.42 - Last mean reward per episode: -732.04
Saving new best model at 126000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -500       |
| time/                   |            |
|    fps                  | 31         |
|    iterations           | 71         |
|    time_elapsed         | 284        |
|    total_timesteps      | 9088       |
| train/                  |            |
|    approx_kl            | 0.00929874 |
|    clip_fraction        | 0.0555     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.546     |
|    explained_variance   | -1.19e-07  |
|    learning_rate        | 0.0003     |
|    loss                 | 2.77       |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.00756   |
|    value_loss           | 6.66       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 31           |
|    iterations           | 72           |
|    time_elapsed         | 288          |
|    total_timesteps      | 9216         |
| train/                  |              |
|    approx_kl            | 0.0030726646 |
|    clip_fraction        | 0.0148       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.55        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 39.1         |
|    n_updates            | 710          |
|    policy_gradient_loss | -0.00131     |
|    value_loss           | 63.2         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 32          |
|    iterations           | 73          |
|    time_elapsed         | 291         |
|    total_timesteps      | 9344        |
| train/                  |             |
|    approx_kl            | 4.70425e-05 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.575      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 3.5         |
|    n_updates            | 720         |
|    policy_gradient_loss | 0.000336    |
|    value_loss           | 7.23        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 32          |
|    iterations           | 74          |
|    time_elapsed         | 295         |
|    total_timesteps      | 9472        |
| train/                  |             |
|    approx_kl            | 0.004909315 |
|    clip_fraction        | 0.0297      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.59       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 2.75        |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.00273    |
|    value_loss           | 6.39        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 32          |
|    iterations           | 75          |
|    time_elapsed         | 298         |
|    total_timesteps      | 9600        |
| train/                  |             |
|    approx_kl            | 0.005076651 |
|    clip_fraction        | 0.0281      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.658      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 2.54        |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.00294    |
|    value_loss           | 6.04        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 32           |
|    iterations           | 76           |
|    time_elapsed         | 301          |
|    total_timesteps      | 9728         |
| train/                  |              |
|    approx_kl            | 0.0033574752 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.676       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 2.41         |
|    n_updates            | 750          |
|    policy_gradient_loss | -0.0028      |
|    value_loss           | 5.74         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 32          |
|    iterations           | 77          |
|    time_elapsed         | 305         |
|    total_timesteps      | 9856        |
| train/                  |             |
|    approx_kl            | 0.008803891 |
|    clip_fraction        | 0.0664      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.572      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 2.37        |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00424    |
|    value_loss           | 5.46        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 32           |
|    iterations           | 78           |
|    time_elapsed         | 309          |
|    total_timesteps      | 9984         |
| train/                  |              |
|    approx_kl            | 0.0003151619 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.527       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 2.28         |
|    n_updates            | 770          |
|    policy_gradient_loss | -0.000238    |
|    value_loss           | 5.19         |
------------------------------------------
Num timesteps: 10000
Best mean reward: -732.04 - Last mean reward per episode: -727.82
Saving new best model at 127000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=10000, episode_reward=-500.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 1e+03        |
|    mean_reward          | -500         |
| time/                   |              |
|    total_timesteps      | 10000        |
| train/                  |              |
|    approx_kl            | 0.0029541953 |
|    clip_fraction        | 0.0102       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.532       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 2            |
|    n_updates            | 780          |
|    policy_gradient_loss | -0.00167     |
|    value_loss           | 4.92         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -500     |
| time/              |          |
|    fps             | 29       |
|    iterations      | 79       |
|    time_elapsed    | 340      |
|    total_timesteps | 10112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 29          |
|    iterations           | 80          |
|    time_elapsed         | 344         |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.018321782 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.471      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 24.6        |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.013      |
|    value_loss           | 68.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 29          |
|    iterations           | 81          |
|    time_elapsed         | 347         |
|    total_timesteps      | 10368       |
| train/                  |             |
|    approx_kl            | 0.003703867 |
|    clip_fraction        | 0.0492      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.427      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 2.36        |
|    n_updates            | 800         |
|    policy_gradient_loss | 0.00202     |
|    value_loss           | 5.19        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 29            |
|    iterations           | 82            |
|    time_elapsed         | 350           |
|    total_timesteps      | 10496         |
| train/                  |               |
|    approx_kl            | 0.00037275068 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.363        |
|    explained_variance   | 1.79e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 1.96          |
|    n_updates            | 810           |
|    policy_gradient_loss | -2.58e-05     |
|    value_loss           | 4.61          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 83           |
|    time_elapsed         | 354          |
|    total_timesteps      | 10624        |
| train/                  |              |
|    approx_kl            | 0.0015255669 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.378       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 1.76         |
|    n_updates            | 820          |
|    policy_gradient_loss | -0.00147     |
|    value_loss           | 4.32         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 84           |
|    time_elapsed         | 358          |
|    total_timesteps      | 10752        |
| train/                  |              |
|    approx_kl            | 0.0022139167 |
|    clip_fraction        | 0.0148       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.316       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 1.69         |
|    n_updates            | 830          |
|    policy_gradient_loss | -0.00129     |
|    value_loss           | 4.07         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 85           |
|    time_elapsed         | 361          |
|    total_timesteps      | 10880        |
| train/                  |              |
|    approx_kl            | 0.0009199893 |
|    clip_fraction        | 0.00703      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.307       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 1.57         |
|    n_updates            | 840          |
|    policy_gradient_loss | -0.00306     |
|    value_loss           | 3.84         |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 11000
Best mean reward: -727.82 - Last mean reward per episode: -705.41
Saving new best model at 133000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 86          |
|    time_elapsed         | 365         |
|    total_timesteps      | 11008       |
| train/                  |             |
|    approx_kl            | 0.006506403 |
|    clip_fraction        | 0.0586      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.38       |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.45        |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.00772    |
|    value_loss           | 3.61        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 30            |
|    iterations           | 87            |
|    time_elapsed         | 369           |
|    total_timesteps      | 11136         |
| train/                  |               |
|    approx_kl            | 0.00035478966 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.417        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 28.6          |
|    n_updates            | 860           |
|    policy_gradient_loss | -0.000229     |
|    value_loss           | 82.1          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 88          |
|    time_elapsed         | 372         |
|    total_timesteps      | 11264       |
| train/                  |             |
|    approx_kl            | 0.002834741 |
|    clip_fraction        | 0.0195      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.475      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 1.95        |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.00142    |
|    value_loss           | 4.07        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 89          |
|    time_elapsed         | 375         |
|    total_timesteps      | 11392       |
| train/                  |             |
|    approx_kl            | 0.003531904 |
|    clip_fraction        | 0.0133      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.481      |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.46        |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.00349    |
|    value_loss           | 3.44        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 90           |
|    time_elapsed         | 379          |
|    total_timesteps      | 11520        |
| train/                  |              |
|    approx_kl            | 0.0010992992 |
|    clip_fraction        | 0.00937      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.465       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 1.27         |
|    n_updates            | 890          |
|    policy_gradient_loss | -0.00174     |
|    value_loss           | 3.18         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 91          |
|    time_elapsed         | 382         |
|    total_timesteps      | 11648       |
| train/                  |             |
|    approx_kl            | 0.014601188 |
|    clip_fraction        | 0.0836      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.581      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.17        |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.0109     |
|    value_loss           | 2.96        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 92           |
|    time_elapsed         | 386          |
|    total_timesteps      | 11776        |
| train/                  |              |
|    approx_kl            | 0.0036628041 |
|    clip_fraction        | 0.0273       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.655       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 1.09         |
|    n_updates            | 910          |
|    policy_gradient_loss | -0.00285     |
|    value_loss           | 2.76         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 93           |
|    time_elapsed         | 389          |
|    total_timesteps      | 11904        |
| train/                  |              |
|    approx_kl            | 0.0044517396 |
|    clip_fraction        | 0.0328       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.705       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.978        |
|    n_updates            | 920          |
|    policy_gradient_loss | -0.00147     |
|    value_loss           | 2.57         |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 12000
Best mean reward: -705.41 - Last mean reward per episode: -702.10
Saving new best model at 134000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 94          |
|    time_elapsed         | 394         |
|    total_timesteps      | 12032       |
| train/                  |             |
|    approx_kl            | 0.006208144 |
|    clip_fraction        | 0.0688      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.773      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.913       |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.00353    |
|    value_loss           | 2.38        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -500       |
| time/                   |            |
|    fps                  | 30         |
|    iterations           | 95         |
|    time_elapsed         | 399        |
|    total_timesteps      | 12160      |
| train/                  |            |
|    approx_kl            | 0.00939085 |
|    clip_fraction        | 0.0586     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.754     |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 48.5       |
|    n_updates            | 940        |
|    policy_gradient_loss | -0.00944   |
|    value_loss           | 93.8       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 96           |
|    time_elapsed         | 404          |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0080456855 |
|    clip_fraction        | 0.0516       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.754       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 1.23         |
|    n_updates            | 950          |
|    policy_gradient_loss | -0.00427     |
|    value_loss           | 2.76         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 97           |
|    time_elapsed         | 409          |
|    total_timesteps      | 12416        |
| train/                  |              |
|    approx_kl            | 0.0061086277 |
|    clip_fraction        | 0.043        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.829       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.799        |
|    n_updates            | 960          |
|    policy_gradient_loss | -0.00431     |
|    value_loss           | 2.25         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 98          |
|    time_elapsed         | 414         |
|    total_timesteps      | 12544       |
| train/                  |             |
|    approx_kl            | 0.004941313 |
|    clip_fraction        | 0.0203      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.837      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.729       |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.00243    |
|    value_loss           | 2.04        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 99          |
|    time_elapsed         | 419         |
|    total_timesteps      | 12672       |
| train/                  |             |
|    approx_kl            | 0.028939253 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.894      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.721       |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.0154     |
|    value_loss           | 1.87        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 100          |
|    time_elapsed         | 424          |
|    total_timesteps      | 12800        |
| train/                  |              |
|    approx_kl            | 0.0024255728 |
|    clip_fraction        | 0.00625      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.951       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 0.634        |
|    n_updates            | 990          |
|    policy_gradient_loss | -0.000384    |
|    value_loss           | 1.71         |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -500       |
| time/                   |            |
|    fps                  | 29         |
|    iterations           | 101        |
|    time_elapsed         | 431        |
|    total_timesteps      | 12928      |
| train/                  |            |
|    approx_kl            | 0.02363471 |
|    clip_fraction        | 0.0523     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.924     |
|    explained_variance   | -1.19e-07  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.556      |
|    n_updates            | 1000       |
|    policy_gradient_loss | -0.00826   |
|    value_loss           | 1.56       |
----------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 13000
Best mean reward: -702.10 - Last mean reward per episode: -698.89
Saving new best model at 135000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 29          |
|    iterations           | 102         |
|    time_elapsed         | 435         |
|    total_timesteps      | 13056       |
| train/                  |             |
|    approx_kl            | 0.012256715 |
|    clip_fraction        | 0.0898      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.792      |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.486       |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.00463    |
|    value_loss           | 1.42        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 103          |
|    time_elapsed         | 439          |
|    total_timesteps      | 13184        |
| train/                  |              |
|    approx_kl            | 0.0048046485 |
|    clip_fraction        | 0.00313      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.716       |
|    explained_variance   | -4.65e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 41.8         |
|    n_updates            | 1020         |
|    policy_gradient_loss | -0.00354     |
|    value_loss           | 107          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 104          |
|    time_elapsed         | 442          |
|    total_timesteps      | 13312        |
| train/                  |              |
|    approx_kl            | 0.0060822666 |
|    clip_fraction        | 0.0781       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.549       |
|    explained_variance   | -1.9e-05     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.673        |
|    n_updates            | 1030         |
|    policy_gradient_loss | -0.00567     |
|    value_loss           | 1.71         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 105         |
|    time_elapsed         | 445         |
|    total_timesteps      | 13440       |
| train/                  |             |
|    approx_kl            | 0.006089509 |
|    clip_fraction        | 0.0797      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.621      |
|    explained_variance   | -1.69e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.438       |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.0141     |
|    value_loss           | 1.31        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 106         |
|    time_elapsed         | 448         |
|    total_timesteps      | 13568       |
| train/                  |             |
|    approx_kl            | 0.010899398 |
|    clip_fraction        | 0.0703      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.579      |
|    explained_variance   | 3.16e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.37        |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.00523    |
|    value_loss           | 1.15        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 107         |
|    time_elapsed         | 451         |
|    total_timesteps      | 13696       |
| train/                  |             |
|    approx_kl            | 0.013909482 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.456      |
|    explained_variance   | 1.37e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.314       |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.00786    |
|    value_loss           | 1.03        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 108         |
|    time_elapsed         | 454         |
|    total_timesteps      | 13824       |
| train/                  |             |
|    approx_kl            | 0.002391058 |
|    clip_fraction        | 0.025       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.42       |
|    explained_variance   | 6.08e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.279       |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.00383    |
|    value_loss           | 0.912       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 109          |
|    time_elapsed         | 457          |
|    total_timesteps      | 13952        |
| train/                  |              |
|    approx_kl            | 0.0063546207 |
|    clip_fraction        | 0.0281       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.416       |
|    explained_variance   | -2.03e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 0.264        |
|    n_updates            | 1080         |
|    policy_gradient_loss | -0.00176     |
|    value_loss           | 0.803        |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 14000
Best mean reward: -698.89 - Last mean reward per episode: -695.78
Saving new best model at 136000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 110          |
|    time_elapsed         | 460          |
|    total_timesteps      | 14080        |
| train/                  |              |
|    approx_kl            | 0.0019002929 |
|    clip_fraction        | 0.0594       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.537       |
|    explained_variance   | -3.7e-06     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.193        |
|    n_updates            | 1090         |
|    policy_gradient_loss | -0.00314     |
|    value_loss           | 0.702        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 111          |
|    time_elapsed         | 464          |
|    total_timesteps      | 14208        |
| train/                  |              |
|    approx_kl            | 0.0006040768 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.526       |
|    explained_variance   | 1.79e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 55.4         |
|    n_updates            | 1100         |
|    policy_gradient_loss | -0.000223    |
|    value_loss           | 122          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 112         |
|    time_elapsed         | 469         |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.013329842 |
|    clip_fraction        | 0.0727      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.47       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.321       |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.00664    |
|    value_loss           | 0.906       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 113          |
|    time_elapsed         | 474          |
|    total_timesteps      | 14464        |
| train/                  |              |
|    approx_kl            | 0.0047938037 |
|    clip_fraction        | 0.0297       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.463       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.191        |
|    n_updates            | 1120         |
|    policy_gradient_loss | -0.00406     |
|    value_loss           | 0.628        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 114          |
|    time_elapsed         | 479          |
|    total_timesteps      | 14592        |
| train/                  |              |
|    approx_kl            | 0.0038521234 |
|    clip_fraction        | 0.0219       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.486       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 0.127        |
|    n_updates            | 1130         |
|    policy_gradient_loss | -0.00442     |
|    value_loss           | 0.522        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 115         |
|    time_elapsed         | 484         |
|    total_timesteps      | 14720       |
| train/                  |             |
|    approx_kl            | 0.006023012 |
|    clip_fraction        | 0.0492      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.428      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.106       |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.00299    |
|    value_loss           | 0.439       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 116         |
|    time_elapsed         | 489         |
|    total_timesteps      | 14848       |
| train/                  |             |
|    approx_kl            | 0.003422256 |
|    clip_fraction        | 0.0164      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.36       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0798      |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.0023     |
|    value_loss           | 0.366       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 117          |
|    time_elapsed         | 494          |
|    total_timesteps      | 14976        |
| train/                  |              |
|    approx_kl            | 0.0008310578 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.306       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0633       |
|    n_updates            | 1160         |
|    policy_gradient_loss | -0.000372    |
|    value_loss           | 0.299        |
------------------------------------------
Num timesteps: 15000
Best mean reward: -695.78 - Last mean reward per episode: -692.77
Saving new best model at 137000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Eval num_timesteps=15000, episode_reward=-500.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 1e+03        |
|    mean_reward          | -500         |
| time/                   |              |
|    total_timesteps      | 15000        |
| train/                  |              |
|    approx_kl            | 0.0022182954 |
|    clip_fraction        | 0.0133       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.293       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0434       |
|    n_updates            | 1170         |
|    policy_gradient_loss | -0.00128     |
|    value_loss           | 0.24         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -500     |
| time/              |          |
|    fps             | 28       |
|    iterations      | 118      |
|    time_elapsed    | 524      |
|    total_timesteps | 15104    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 119          |
|    time_elapsed         | 528          |
|    total_timesteps      | 15232        |
| train/                  |              |
|    approx_kl            | 5.480228e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.311       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 63.5         |
|    n_updates            | 1180         |
|    policy_gradient_loss | -0.000189    |
|    value_loss           | 131          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 120          |
|    time_elapsed         | 533          |
|    total_timesteps      | 15360        |
| train/                  |              |
|    approx_kl            | 0.0026156548 |
|    clip_fraction        | 0.0141       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.294       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.119        |
|    n_updates            | 1190         |
|    policy_gradient_loss | -0.00178     |
|    value_loss           | 0.357        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 121          |
|    time_elapsed         | 539          |
|    total_timesteps      | 15488        |
| train/                  |              |
|    approx_kl            | 0.0041543096 |
|    clip_fraction        | 0.0234       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.293       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0324       |
|    n_updates            | 1200         |
|    policy_gradient_loss | -0.00317     |
|    value_loss           | 0.197        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 28            |
|    iterations           | 122           |
|    time_elapsed         | 544           |
|    total_timesteps      | 15616         |
| train/                  |               |
|    approx_kl            | 0.00078260386 |
|    clip_fraction        | 0.0406        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.388        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0102        |
|    n_updates            | 1210          |
|    policy_gradient_loss | -0.0022       |
|    value_loss           | 0.142         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 123          |
|    time_elapsed         | 550          |
|    total_timesteps      | 15744        |
| train/                  |              |
|    approx_kl            | 0.0025714738 |
|    clip_fraction        | 0.0141       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.362       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000728    |
|    n_updates            | 1220         |
|    policy_gradient_loss | -0.00242     |
|    value_loss           | 0.103        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 124          |
|    time_elapsed         | 554          |
|    total_timesteps      | 15872        |
| train/                  |              |
|    approx_kl            | 0.0033659548 |
|    clip_fraction        | 0.032        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.312       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000776    |
|    n_updates            | 1230         |
|    policy_gradient_loss | -0.00285     |
|    value_loss           | 0.0714       |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 16000
Best mean reward: -692.77 - Last mean reward per episode: -676.48
Saving new best model at 143000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 28          |
|    iterations           | 125         |
|    time_elapsed         | 559         |
|    total_timesteps      | 16000       |
| train/                  |             |
|    approx_kl            | 0.006018175 |
|    clip_fraction        | 0.0234      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.246      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00773    |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.00355    |
|    value_loss           | 0.0478      |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 126          |
|    time_elapsed         | 563          |
|    total_timesteps      | 16128        |
| train/                  |              |
|    approx_kl            | 0.0004927586 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.18        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 92.2         |
|    n_updates            | 1250         |
|    policy_gradient_loss | 0.000244     |
|    value_loss           | 151          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 127          |
|    time_elapsed         | 567          |
|    total_timesteps      | 16256        |
| train/                  |              |
|    approx_kl            | 0.0034929882 |
|    clip_fraction        | 0.0273       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.17        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0102       |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.00484     |
|    value_loss           | 0.0998       |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 28            |
|    iterations           | 128           |
|    time_elapsed         | 571           |
|    total_timesteps      | 16384         |
| train/                  |               |
|    approx_kl            | 0.00016944483 |
|    clip_fraction        | 0.00469       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.166        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | -0.00156      |
|    n_updates            | 1270          |
|    policy_gradient_loss | -0.00038      |
|    value_loss           | 0.0331        |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 129          |
|    time_elapsed         | 575          |
|    total_timesteps      | 16512        |
| train/                  |              |
|    approx_kl            | 0.0004749624 |
|    clip_fraction        | 0.00937      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.187       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00682     |
|    n_updates            | 1280         |
|    policy_gradient_loss | -0.00143     |
|    value_loss           | 0.0235       |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 28          |
|    iterations           | 130         |
|    time_elapsed         | 579         |
|    total_timesteps      | 16640       |
| train/                  |             |
|    approx_kl            | 0.002748841 |
|    clip_fraction        | 0.0234      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.166      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0129     |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.00338    |
|    value_loss           | 0.0154      |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 131          |
|    time_elapsed         | 583          |
|    total_timesteps      | 16768        |
| train/                  |              |
|    approx_kl            | 0.0005489937 |
|    clip_fraction        | 0.0141       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.155       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.000657    |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.00141     |
|    value_loss           | 0.0103       |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 28            |
|    iterations           | 132           |
|    time_elapsed         | 587           |
|    total_timesteps      | 16896         |
| train/                  |               |
|    approx_kl            | 0.00015073083 |
|    clip_fraction        | 0.00937       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.155        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.000431      |
|    n_updates            | 1310          |
|    policy_gradient_loss | 0.000378      |
|    value_loss           | 0.00692       |
-------------------------------------------
Num timesteps: 17000
Best mean reward: -676.48 - Last mean reward per episode: -674.03
Saving new best model at 144000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 133          |
|    time_elapsed         | 591          |
|    total_timesteps      | 17024        |
| train/                  |              |
|    approx_kl            | 0.0011444329 |
|    clip_fraction        | 0.0203       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.13        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00107      |
|    n_updates            | 1320         |
|    policy_gradient_loss | -0.000938    |
|    value_loss           | 0.00445      |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 28            |
|    iterations           | 134           |
|    time_elapsed         | 595           |
|    total_timesteps      | 17152         |
| train/                  |               |
|    approx_kl            | 6.4373016e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.138        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 83            |
|    n_updates            | 1330          |
|    policy_gradient_loss | 0             |
|    value_loss           | 160           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 135          |
|    time_elapsed         | 598          |
|    total_timesteps      | 17280        |
| train/                  |              |
|    approx_kl            | 9.570317e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.142       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00018     |
|    n_updates            | 1340         |
|    policy_gradient_loss | -0.000228    |
|    value_loss           | 0.0179       |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 136          |
|    time_elapsed         | 601          |
|    total_timesteps      | 17408        |
| train/                  |              |
|    approx_kl            | 0.0008671973 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.117       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00177     |
|    n_updates            | 1350         |
|    policy_gradient_loss | -0.000754    |
|    value_loss           | 0.00347      |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 137          |
|    time_elapsed         | 605          |
|    total_timesteps      | 17536        |
| train/                  |              |
|    approx_kl            | 0.0014042761 |
|    clip_fraction        | 0.00937      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.12        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00702     |
|    n_updates            | 1360         |
|    policy_gradient_loss | -0.00247     |
|    value_loss           | 0.00428      |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 28            |
|    iterations           | 138           |
|    time_elapsed         | 609           |
|    total_timesteps      | 17664         |
| train/                  |               |
|    approx_kl            | 0.00051945634 |
|    clip_fraction        | 0.00781       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.149        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | -0.00245      |
|    n_updates            | 1370          |
|    policy_gradient_loss | -0.000429     |
|    value_loss           | 0.0016        |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 29          |
|    iterations           | 139         |
|    time_elapsed         | 612         |
|    total_timesteps      | 17792       |
| train/                  |             |
|    approx_kl            | 0.006127768 |
|    clip_fraction        | 0.0125      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.216      |
|    explained_variance   | 1.79e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00243    |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.00866    |
|    value_loss           | 0.00149     |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 29           |
|    iterations           | 140          |
|    time_elapsed         | 616          |
|    total_timesteps      | 17920        |
| train/                  |              |
|    approx_kl            | 0.0026454772 |
|    clip_fraction        | 0.0219       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.258       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00187      |
|    n_updates            | 1390         |
|    policy_gradient_loss | -0.00139     |
|    value_loss           | 0.000739     |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 18000
Best mean reward: -674.03 - Last mean reward per episode: -671.64
Saving new best model at 145000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 29          |
|    iterations           | 141         |
|    time_elapsed         | 620         |
|    total_timesteps      | 18048       |
| train/                  |             |
|    approx_kl            | 0.001173581 |
|    clip_fraction        | 0.0164      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.261      |
|    explained_variance   | 1.19e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00562    |
|    n_updates            | 1400        |
|    policy_gradient_loss | -0.000623   |
|    value_loss           | 0.000515    |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 29            |
|    iterations           | 142           |
|    time_elapsed         | 624           |
|    total_timesteps      | 18176         |
| train/                  |               |
|    approx_kl            | 0.00057688914 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.255        |
|    explained_variance   | -3.58e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 100           |
|    n_updates            | 1410          |
|    policy_gradient_loss | 0.000573      |
|    value_loss           | 163           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 29           |
|    iterations           | 143          |
|    time_elapsed         | 627          |
|    total_timesteps      | 18304        |
| train/                  |              |
|    approx_kl            | 0.0015135417 |
|    clip_fraction        | 0.00234      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.231       |
|    explained_variance   | -0.000144    |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00707     |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.000833    |
|    value_loss           | 0.00661      |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 29          |
|    iterations           | 144         |
|    time_elapsed         | 631         |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.002314658 |
|    clip_fraction        | 0.0234      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.225      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00362    |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.00125    |
|    value_loss           | 0.000988    |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 29            |
|    iterations           | 145           |
|    time_elapsed         | 634           |
|    total_timesteps      | 18560         |
| train/                  |               |
|    approx_kl            | 0.00040044961 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.208        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | -0.00194      |
|    n_updates            | 1440          |
|    policy_gradient_loss | -8.6e-05      |
|    value_loss           | 0.000986      |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 29           |
|    iterations           | 146          |
|    time_elapsed         | 638          |
|    total_timesteps      | 18688        |
| train/                  |              |
|    approx_kl            | 0.0028133593 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.179       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00456     |
|    n_updates            | 1450         |
|    policy_gradient_loss | -0.00143     |
|    value_loss           | 0.000453     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 29           |
|    iterations           | 147          |
|    time_elapsed         | 641          |
|    total_timesteps      | 18816        |
| train/                  |              |
|    approx_kl            | 0.0064907162 |
|    clip_fraction        | 0.0242       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.137       |
|    explained_variance   | 2.38e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00634     |
|    n_updates            | 1460         |
|    policy_gradient_loss | -0.0034      |
|    value_loss           | 0.00032      |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 29           |
|    iterations           | 148          |
|    time_elapsed         | 645          |
|    total_timesteps      | 18944        |
| train/                  |              |
|    approx_kl            | 0.0008000829 |
|    clip_fraction        | 0.00313      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.121       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00143     |
|    n_updates            | 1470         |
|    policy_gradient_loss | -0.00152     |
|    value_loss           | 0.000199     |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 19000
Best mean reward: -671.64 - Last mean reward per episode: -669.32
Saving new best model at 146000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 29           |
|    iterations           | 149          |
|    time_elapsed         | 648          |
|    total_timesteps      | 19072        |
| train/                  |              |
|    approx_kl            | 0.0011134623 |
|    clip_fraction        | 0.0156       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.167       |
|    explained_variance   | 2.98e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00618      |
|    n_updates            | 1480         |
|    policy_gradient_loss | -0.000146    |
|    value_loss           | 0.00013      |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 29            |
|    iterations           | 150           |
|    time_elapsed         | 652           |
|    total_timesteps      | 19200         |
| train/                  |               |
|    approx_kl            | 0.00026674196 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.16         |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 83.4          |
|    n_updates            | 1490          |
|    policy_gradient_loss | -0.000655     |
|    value_loss           | 164           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 29           |
|    iterations           | 151          |
|    time_elapsed         | 657          |
|    total_timesteps      | 19328        |
| train/                  |              |
|    approx_kl            | 4.172325e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.153       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00122     |
|    n_updates            | 1500         |
|    policy_gradient_loss | -7.65e-06    |
|    value_loss           | 0.00499      |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 29            |
|    iterations           | 152           |
|    time_elapsed         | 662           |
|    total_timesteps      | 19456         |
| train/                  |               |
|    approx_kl            | 0.00091942167 |
|    clip_fraction        | 0.018         |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.169        |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 0.000166      |
|    n_updates            | 1510          |
|    policy_gradient_loss | -0.000993     |
|    value_loss           | 0.000599      |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 29            |
|    iterations           | 153           |
|    time_elapsed         | 667           |
|    total_timesteps      | 19584         |
| train/                  |               |
|    approx_kl            | 0.00079489406 |
|    clip_fraction        | 0.00625       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.155        |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | -0.00124      |
|    n_updates            | 1520          |
|    policy_gradient_loss | -0.00125      |
|    value_loss           | 0.000606      |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 29          |
|    iterations           | 154         |
|    time_elapsed         | 673         |
|    total_timesteps      | 19712       |
| train/                  |             |
|    approx_kl            | 0.003036621 |
|    clip_fraction        | 0.0258      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.158      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00326    |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.00283    |
|    value_loss           | 0.000289    |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 29           |
|    iterations           | 155          |
|    time_elapsed         | 677          |
|    total_timesteps      | 19840        |
| train/                  |              |
|    approx_kl            | 0.0025560544 |
|    clip_fraction        | 0.0148       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.187       |
|    explained_variance   | 4.17e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00591     |
|    n_updates            | 1540         |
|    policy_gradient_loss | -0.00132     |
|    value_loss           | 0.000199     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 29           |
|    iterations           | 156          |
|    time_elapsed         | 682          |
|    total_timesteps      | 19968        |
| train/                  |              |
|    approx_kl            | 0.0050299093 |
|    clip_fraction        | 0.0281       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.255       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00288     |
|    n_updates            | 1550         |
|    policy_gradient_loss | -0.00226     |
|    value_loss           | 0.000128     |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 20000
Best mean reward: -669.32 - Last mean reward per episode: -667.07
Saving new best model at 147000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
Eval num_timesteps=20000, episode_reward=-500.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | -500       |
| time/                   |            |
|    total_timesteps      | 20000      |
| train/                  |            |
|    approx_kl            | 0.00646175 |
|    clip_fraction        | 0.032      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.357     |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00905   |
|    n_updates            | 1560       |
|    policy_gradient_loss | -0.00383   |
|    value_loss           | 8.01e-05   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -500     |
| time/              |          |
|    fps             | 28       |
|    iterations      | 157      |
|    time_elapsed    | 713      |
|    total_timesteps | 20096    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 158          |
|    time_elapsed         | 718          |
|    total_timesteps      | 20224        |
| train/                  |              |
|    approx_kl            | 9.909272e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.416       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 51.3         |
|    n_updates            | 1570         |
|    policy_gradient_loss | 0.000472     |
|    value_loss           | 161          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 159          |
|    time_elapsed         | 724          |
|    total_timesteps      | 20352        |
| train/                  |              |
|    approx_kl            | 0.0023283008 |
|    clip_fraction        | 0.0117       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.418       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00598     |
|    n_updates            | 1580         |
|    policy_gradient_loss | -0.00144     |
|    value_loss           | 0.00547      |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 160          |
|    time_elapsed         | 730          |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 0.0040943827 |
|    clip_fraction        | 0.0492       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.403       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00694     |
|    n_updates            | 1590         |
|    policy_gradient_loss | -0.00213     |
|    value_loss           | 0.000613     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 161          |
|    time_elapsed         | 735          |
|    total_timesteps      | 20608        |
| train/                  |              |
|    approx_kl            | 0.0010285927 |
|    clip_fraction        | 0.00313      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.379       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00116     |
|    n_updates            | 1600         |
|    policy_gradient_loss | -0.000276    |
|    value_loss           | 0.000612     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 28          |
|    iterations           | 162         |
|    time_elapsed         | 740         |
|    total_timesteps      | 20736       |
| train/                  |             |
|    approx_kl            | 0.003402548 |
|    clip_fraction        | 0.0391      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.303      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00217     |
|    n_updates            | 1610        |
|    policy_gradient_loss | -0.00238    |
|    value_loss           | 0.00029     |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 27            |
|    iterations           | 163           |
|    time_elapsed         | 745           |
|    total_timesteps      | 20864         |
| train/                  |               |
|    approx_kl            | 5.2885152e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.299        |
|    explained_variance   | 2.38e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | -0.00269      |
|    n_updates            | 1620          |
|    policy_gradient_loss | 0.000101      |
|    value_loss           | 0.000201      |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 27           |
|    iterations           | 164          |
|    time_elapsed         | 750          |
|    total_timesteps      | 20992        |
| train/                  |              |
|    approx_kl            | 0.0062524304 |
|    clip_fraction        | 0.0367       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.274       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0141      |
|    n_updates            | 1630         |
|    policy_gradient_loss | -0.00567     |
|    value_loss           | 0.000128     |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 21000
Best mean reward: -667.07 - Last mean reward per episode: -654.69
Saving new best model at 153000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 27           |
|    iterations           | 165          |
|    time_elapsed         | 755          |
|    total_timesteps      | 21120        |
| train/                  |              |
|    approx_kl            | 0.0052670767 |
|    clip_fraction        | 0.0398       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.222       |
|    explained_variance   | 8.94e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00565     |
|    n_updates            | 1640         |
|    policy_gradient_loss | -0.00612     |
|    value_loss           | 8.23e-05     |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 27            |
|    iterations           | 166           |
|    time_elapsed         | 759           |
|    total_timesteps      | 21248         |
| train/                  |               |
|    approx_kl            | 4.2941887e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.198        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 70.5          |
|    n_updates            | 1650          |
|    policy_gradient_loss | 0.00116       |
|    value_loss           | 103           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 167          |
|    time_elapsed         | 762          |
|    total_timesteps      | 21376        |
| train/                  |              |
|    approx_kl            | 0.0024133655 |
|    clip_fraction        | 0.0156       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.223       |
|    explained_variance   | -4.47e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00778     |
|    n_updates            | 1660         |
|    policy_gradient_loss | -0.0027      |
|    value_loss           | 0.00592      |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 168          |
|    time_elapsed         | 765          |
|    total_timesteps      | 21504        |
| train/                  |              |
|    approx_kl            | 0.0035999436 |
|    clip_fraction        | 0.0328       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.292       |
|    explained_variance   | -3.25e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0146      |
|    n_updates            | 1670         |
|    policy_gradient_loss | -0.0066      |
|    value_loss           | 0.000601     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 169          |
|    time_elapsed         | 769          |
|    total_timesteps      | 21632        |
| train/                  |              |
|    approx_kl            | 0.0013911868 |
|    clip_fraction        | 0.00625      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.286       |
|    explained_variance   | 3.26e-05     |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00377     |
|    n_updates            | 1680         |
|    policy_gradient_loss | -0.000789    |
|    value_loss           | 0.000639     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 170          |
|    time_elapsed         | 772          |
|    total_timesteps      | 21760        |
| train/                  |              |
|    approx_kl            | 0.0010156399 |
|    clip_fraction        | 0.00937      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.286       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00779     |
|    n_updates            | 1690         |
|    policy_gradient_loss | -0.00152     |
|    value_loss           | 0.000329     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 28          |
|    iterations           | 171         |
|    time_elapsed         | 776         |
|    total_timesteps      | 21888       |
| train/                  |             |
|    approx_kl            | 0.002907265 |
|    clip_fraction        | 0.0164      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.304      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000209    |
|    n_updates            | 1700        |
|    policy_gradient_loss | -0.00508    |
|    value_loss           | 0.000224    |
-----------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 22000
Best mean reward: -654.69 - Last mean reward per episode: -652.80
Saving new best model at 154000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 28          |
|    iterations           | 172         |
|    time_elapsed         | 779         |
|    total_timesteps      | 22016       |
| train/                  |             |
|    approx_kl            | 0.001114767 |
|    clip_fraction        | 0.00625     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.267      |
|    explained_variance   | 1.79e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00288    |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.00103    |
|    value_loss           | 0.000142    |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 28            |
|    iterations           | 173           |
|    time_elapsed         | 783           |
|    total_timesteps      | 22144         |
| train/                  |               |
|    approx_kl            | 2.4260487e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.243        |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 63.7          |
|    n_updates            | 1720          |
|    policy_gradient_loss | -0.000294     |
|    value_loss           | 163           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 174          |
|    time_elapsed         | 788          |
|    total_timesteps      | 22272        |
| train/                  |              |
|    approx_kl            | 0.0014311643 |
|    clip_fraction        | 0.0117       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.26        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0129      |
|    n_updates            | 1730         |
|    policy_gradient_loss | -0.00122     |
|    value_loss           | 0.00657      |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 175          |
|    time_elapsed         | 793          |
|    total_timesteps      | 22400        |
| train/                  |              |
|    approx_kl            | 0.0005616499 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.271       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00173     |
|    n_updates            | 1740         |
|    policy_gradient_loss | -0.000464    |
|    value_loss           | 0.00076      |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 28          |
|    iterations           | 176         |
|    time_elapsed         | 797         |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.002624067 |
|    clip_fraction        | 0.025       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.257      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0107     |
|    n_updates            | 1750        |
|    policy_gradient_loss | -0.00416    |
|    value_loss           | 0.000819    |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 177          |
|    time_elapsed         | 802          |
|    total_timesteps      | 22656        |
| train/                  |              |
|    approx_kl            | 0.0040020314 |
|    clip_fraction        | 0.0281       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.287       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0107      |
|    n_updates            | 1760         |
|    policy_gradient_loss | -0.00386     |
|    value_loss           | 0.000423     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 178          |
|    time_elapsed         | 808          |
|    total_timesteps      | 22784        |
| train/                  |              |
|    approx_kl            | 0.0015102862 |
|    clip_fraction        | 0.0453       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.357       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00895     |
|    n_updates            | 1770         |
|    policy_gradient_loss | -0.00698     |
|    value_loss           | 0.000275     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 179          |
|    time_elapsed         | 812          |
|    total_timesteps      | 22912        |
| train/                  |              |
|    approx_kl            | 0.0035901442 |
|    clip_fraction        | 0.025        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.298       |
|    explained_variance   | 4.77e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00388      |
|    n_updates            | 1780         |
|    policy_gradient_loss | -0.00172     |
|    value_loss           | 0.00017      |
------------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 23000
Best mean reward: -652.80 - Last mean reward per episode: -650.96
Saving new best model at 155000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 180          |
|    time_elapsed         | 817          |
|    total_timesteps      | 23040        |
| train/                  |              |
|    approx_kl            | 0.0039170566 |
|    clip_fraction        | 0.0328       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.312       |
|    explained_variance   | 3.58e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0139      |
|    n_updates            | 1790         |
|    policy_gradient_loss | -0.00319     |
|    value_loss           | 0.000116     |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 28            |
|    iterations           | 181           |
|    time_elapsed         | 821           |
|    total_timesteps      | 23168         |
| train/                  |               |
|    approx_kl            | 1.8566381e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.335        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 107           |
|    n_updates            | 1800          |
|    policy_gradient_loss | -0.000322     |
|    value_loss           | 164           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 182          |
|    time_elapsed         | 825          |
|    total_timesteps      | 23296        |
| train/                  |              |
|    approx_kl            | 0.0016881493 |
|    clip_fraction        | 0.0156       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.356       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00257     |
|    n_updates            | 1810         |
|    policy_gradient_loss | -0.00406     |
|    value_loss           | 0.0075       |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 183          |
|    time_elapsed         | 829          |
|    total_timesteps      | 23424        |
| train/                  |              |
|    approx_kl            | 0.0040643946 |
|    clip_fraction        | 0.0531       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.414       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0148      |
|    n_updates            | 1820         |
|    policy_gradient_loss | -0.00507     |
|    value_loss           | 0.000854     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 184          |
|    time_elapsed         | 833          |
|    total_timesteps      | 23552        |
| train/                  |              |
|    approx_kl            | 9.215996e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.434       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00287     |
|    n_updates            | 1830         |
|    policy_gradient_loss | 0.000419     |
|    value_loss           | 0.000876     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 185          |
|    time_elapsed         | 838          |
|    total_timesteps      | 23680        |
| train/                  |              |
|    approx_kl            | 0.0003237147 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.467       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00755     |
|    n_updates            | 1840         |
|    policy_gradient_loss | -0.000175    |
|    value_loss           | 0.000429     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 186          |
|    time_elapsed         | 844          |
|    total_timesteps      | 23808        |
| train/                  |              |
|    approx_kl            | 0.0008064499 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.455       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00769     |
|    n_updates            | 1850         |
|    policy_gradient_loss | -0.000152    |
|    value_loss           | 0.000307     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 27          |
|    iterations           | 187         |
|    time_elapsed         | 856         |
|    total_timesteps      | 23936       |
| train/                  |             |
|    approx_kl            | 0.006489021 |
|    clip_fraction        | 0.0375      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.463      |
|    explained_variance   | 2.98e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00242    |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.00417    |
|    value_loss           | 0.000183    |
-----------------------------------------
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Num timesteps: 24000
Best mean reward: -650.96 - Last mean reward per episode: -649.17
Saving new best model at 156000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 27           |
|    iterations           | 188          |
|    time_elapsed         | 866          |
|    total_timesteps      | 24064        |
| train/                  |              |
|    approx_kl            | 0.0008440921 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.415       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0122      |
|    n_updates            | 1870         |
|    policy_gradient_loss | -0.00123     |
|    value_loss           | 0.000121     |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 27            |
|    iterations           | 189           |
|    time_elapsed         | 870           |
|    total_timesteps      | 24192         |
| train/                  |               |
|    approx_kl            | 0.00014682766 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.422        |
|    explained_variance   | -2.38e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 106           |
|    n_updates            | 1880          |
|    policy_gradient_loss | -0.000841     |
|    value_loss           | 163           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 27           |
|    iterations           | 190          |
|    time_elapsed         | 873          |
|    total_timesteps      | 24320        |
| train/                  |              |
|    approx_kl            | 0.0034966236 |
|    clip_fraction        | 0.0125       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.385       |
|    explained_variance   | 1.73e-06     |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00336     |
|    n_updates            | 1890         |
|    policy_gradient_loss | -0.00332     |
|    value_loss           | 0.00744      |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 27           |
|    iterations           | 191          |
|    time_elapsed         | 876          |
|    total_timesteps      | 24448        |
| train/                  |              |
|    approx_kl            | 0.0008514328 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.314       |
|    explained_variance   | -7.38e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00755     |
|    n_updates            | 1900         |
|    policy_gradient_loss | -0.00179     |
|    value_loss           | 0.000825     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 27          |
|    iterations           | 192         |
|    time_elapsed         | 879         |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.001934065 |
|    clip_fraction        | 0.0563      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.346      |
|    explained_variance   | 0.000131    |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0161     |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.00332    |
|    value_loss           | 0.000853    |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -500          |
| time/                   |               |
|    fps                  | 27            |
|    iterations           | 193           |
|    time_elapsed         | 882           |
|    total_timesteps      | 24704         |
| train/                  |               |
|    approx_kl            | 0.00093688164 |
|    clip_fraction        | 0.00469       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.341        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | -0.0139       |
|    n_updates            | 1920          |
|    policy_gradient_loss | -0.00199      |
|    value_loss           | 0.000454      |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 28          |
|    iterations           | 194         |
|    time_elapsed         | 885         |
|    total_timesteps      | 24832       |
| train/                  |             |
|    approx_kl            | 0.008763311 |
|    clip_fraction        | 0.0539      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.417      |
|    explained_variance   | 0.000329    |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0178     |
|    n_updates            | 1930        |
|    policy_gradient_loss | -0.00947    |
|    value_loss           | 0.000375    |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 195          |
|    time_elapsed         | 889          |
|    total_timesteps      | 24960        |
| train/                  |              |
|    approx_kl            | 0.0016539507 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.446       |
|    explained_variance   | 0.000272     |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00996     |
|    n_updates            | 1940         |
|    policy_gradient_loss | -0.00203     |
|    value_loss           | 0.000172     |
------------------------------------------
Num timesteps: 25000
Best mean reward: -649.17 - Last mean reward per episode: -647.41
Saving new best model at 157000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  data_frame = pandas.concat(data_frames)
Traceback (most recent call last):
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/freeway/run_supervised_gnn.py", line 118, in <module>
    main()
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/freeway/run_supervised_gnn.py", line 112, in main
    model.learn(total_timesteps=1000000, callback=[WandbCallback(), save_best_callback, eval_callback])
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 315, in learn
    return super().learn(
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 201, in collect_rollouts
    if not callback.on_step():
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py", line 114, in on_step
    return self._on_step()
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py", line 219, in _on_step
    continue_training = callback.on_step() and continue_training
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py", line 114, in on_step
    return self._on_step()
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py", line 460, in _on_step
    episode_rewards, episode_lengths = evaluate_policy(
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py", line 88, in evaluate_policy
    actions, states = model.predict(
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/base_class.py", line 556, in predict
    return self.policy.predict(observation, state, episode_start, deterministic)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/policies.py", line 368, in predict
    actions = self._predict(obs_tensor, deterministic=deterministic)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/policies.py", line 717, in _predict
    return self.get_distribution(observation).get_actions(deterministic=deterministic)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/policies.py", line 750, in get_distribution
    features = super().extract_features(obs, self.pi_features_extractor)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/policies.py", line 131, in extract_features
    return features_extractor(preprocessed_obs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/model/policy.py", line 46, in forward
    obj_emb = self.model(pyg_data.x_dict, pyg_data.edge_index_dict, pyg_data.batch_dict)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/model/hetero_gnn.py", line 109, in forward
    x_dict = self.encoding_layers(x_dict, device)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/model/hetero_gnn.py", line 81, in encoding_layers
    x_dict[k] = self.encoding_mlps[k](v.to(device))
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch_geometric/nn/models/mlp.py", line 245, in forward
    x = self.lins[-1](x)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch_geometric/nn/dense/linear.py", line 147, in forward
    return F.linear(x, self.weight, self.bias)
KeyboardInterrupt