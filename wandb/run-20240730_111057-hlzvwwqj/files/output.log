
Using cpu device
-----------------------------
| time/              |      |
|    fps             | 242  |
|    iterations      | 1    |
|    time_elapsed    | 8    |
|    total_timesteps | 2048 |
-----------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 95           |
|    iterations           | 2            |
|    time_elapsed         | 43           |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0035215898 |
|    clip_fraction        | 0.0512       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.09        |
|    explained_variance   | -0.021       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.319        |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00173     |
|    value_loss           | 3.96         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -2.03e+03   |
| time/                   |             |
|    fps                  | 83          |
|    iterations           | 3           |
|    time_elapsed         | 73          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.010534329 |
|    clip_fraction        | 0.0211      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 0.029       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.928       |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00267    |
|    value_loss           | 12.9        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -2.03e+03  |
| time/                   |            |
|    fps                  | 77         |
|    iterations           | 4          |
|    time_elapsed         | 105        |
|    total_timesteps      | 8192       |
| train/                  |            |
|    approx_kl            | 0.01278777 |
|    clip_fraction        | 0.0738     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.05      |
|    explained_variance   | 0.00159    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.8        |
|    n_updates            | 30         |
|    policy_gradient_loss | -0.00572   |
|    value_loss           | 13.9       |
----------------------------------------
Num timesteps: 10000
Best mean reward: -inf - Last mean reward per episode: -1898.25
Saving new best model at 8193 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -1.9e+03    |
| time/                   |             |
|    fps                  | 74          |
|    iterations           | 5           |
|    time_elapsed         | 138         |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.011594087 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | 0.435       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0191     |
|    value_loss           | 7.98        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -1.9e+03   |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 6          |
|    time_elapsed         | 170        |
|    total_timesteps      | 12288      |
| train/                  |            |
|    approx_kl            | 0.01752686 |
|    clip_fraction        | 0.181      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.929     |
|    explained_variance   | 0.737      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.32       |
|    n_updates            | 50         |
|    policy_gradient_loss | -0.0201    |
|    value_loss           | 5.31       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -1.67e+03   |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 7           |
|    time_elapsed         | 202         |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.022203322 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.805      |
|    explained_variance   | 0.808       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.889       |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0163     |
|    value_loss           | 3.31        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -1.67e+03   |
| time/                   |             |
|    fps                  | 69          |
|    iterations           | 8           |
|    time_elapsed         | 235         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.016762398 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.644      |
|    explained_variance   | 0.823       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.406       |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.018      |
|    value_loss           | 2.77        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -1.36e+03   |
| time/                   |             |
|    fps                  | 68          |
|    iterations           | 9           |
|    time_elapsed         | 268         |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.011836613 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.516      |
|    explained_variance   | 0.888       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.484       |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0104     |
|    value_loss           | 1.89        |
-----------------------------------------
Num timesteps: 20000
Best mean reward: -1898.25 - Last mean reward per episode: -1358.12
Saving new best model at 16385 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -1.36e+03   |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 10          |
|    time_elapsed         | 302         |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.008749699 |
|    clip_fraction        | 0.069       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.426      |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.276       |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00495    |
|    value_loss           | 1.97        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -1.14e+03    |
| time/                   |              |
|    fps                  | 67           |
|    iterations           | 11           |
|    time_elapsed         | 334          |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0052015083 |
|    clip_fraction        | 0.0616       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.352       |
|    explained_variance   | 0.887        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.389        |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00664     |
|    value_loss           | 1.68         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -1.14e+03    |
| time/                   |              |
|    fps                  | 66           |
|    iterations           | 12           |
|    time_elapsed         | 367          |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0021273596 |
|    clip_fraction        | 0.0272       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.295       |
|    explained_variance   | 0.877        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.216        |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00409     |
|    value_loss           | 1.42         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -938         |
| time/                   |              |
|    fps                  | 66           |
|    iterations           | 13           |
|    time_elapsed         | 400          |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0028592495 |
|    clip_fraction        | 0.041        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.249       |
|    explained_variance   | 0.88         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.13         |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00519     |
|    value_loss           | 1.42         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -938         |
| time/                   |              |
|    fps                  | 66           |
|    iterations           | 14           |
|    time_elapsed         | 431          |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 0.0020308127 |
|    clip_fraction        | 0.0236       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.203       |
|    explained_variance   | 0.92         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.12         |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00316     |
|    value_loss           | 0.972        |
------------------------------------------
Num timesteps: 30000
Best mean reward: -1358.12 - Last mean reward per episode: -779.50
Saving new best model at 28673 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -780         |
| time/                   |              |
|    fps                  | 66           |
|    iterations           | 15           |
|    time_elapsed         | 464          |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 0.0025023199 |
|    clip_fraction        | 0.0292       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.175       |
|    explained_variance   | 0.938        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.264        |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00293     |
|    value_loss           | 0.937        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -780         |
| time/                   |              |
|    fps                  | 65           |
|    iterations           | 16           |
|    time_elapsed         | 498          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0026946696 |
|    clip_fraction        | 0.0233       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.15        |
|    explained_variance   | 0.805        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.134        |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00467     |
|    value_loss           | 1.13         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -671         |
| time/                   |              |
|    fps                  | 65           |
|    iterations           | 17           |
|    time_elapsed         | 534          |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0022471831 |
|    clip_fraction        | 0.0301       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.141       |
|    explained_variance   | 0.888        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.18         |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00411     |
|    value_loss           | 0.909        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -671         |
| time/                   |              |
|    fps                  | 64           |
|    iterations           | 18           |
|    time_elapsed         | 568          |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0051066307 |
|    clip_fraction        | 0.0197       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.141       |
|    explained_variance   | 0.921        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.123        |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00323     |
|    value_loss           | 0.905        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -579        |
| time/                   |             |
|    fps                  | 64          |
|    iterations           | 19          |
|    time_elapsed         | 604         |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.006262635 |
|    clip_fraction        | 0.0342      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.177      |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0421      |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0143     |
|    value_loss           | 0.684       |
-----------------------------------------
Num timesteps: 40000
Best mean reward: -779.50 - Last mean reward per episode: -579.17
Saving new best model at 36865 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -579         |
| time/                   |              |
|    fps                  | 64           |
|    iterations           | 20           |
|    time_elapsed         | 638          |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 0.0069857044 |
|    clip_fraction        | 0.0463       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.176       |
|    explained_variance   | 0.913        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.253        |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.00591     |
|    value_loss           | 1.02         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -504        |
| time/                   |             |
|    fps                  | 64          |
|    iterations           | 21          |
|    time_elapsed         | 671         |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.009728542 |
|    clip_fraction        | 0.061       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.181      |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.126       |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00253    |
|    value_loss           | 0.851       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -504        |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 22          |
|    time_elapsed         | 707         |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.006554533 |
|    clip_fraction        | 0.0488      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.187      |
|    explained_variance   | 0.904       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.31        |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.00131    |
|    value_loss           | 1.55        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -448        |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 23          |
|    time_elapsed         | 742         |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.005821964 |
|    clip_fraction        | 0.0381      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.151      |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0717      |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00432    |
|    value_loss           | 1.01        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -448         |
| time/                   |              |
|    fps                  | 62           |
|    iterations           | 24           |
|    time_elapsed         | 780          |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0044802083 |
|    clip_fraction        | 0.0406       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.129       |
|    explained_variance   | 0.894        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0437       |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.00959     |
|    value_loss           | 0.595        |
------------------------------------------
Num timesteps: 50000
Best mean reward: -579.17 - Last mean reward per episode: -401.38
Saving new best model at 49153 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -401         |
| time/                   |              |
|    fps                  | 62           |
|    iterations           | 25           |
|    time_elapsed         | 816          |
|    total_timesteps      | 51200        |
| train/                  |              |
|    approx_kl            | 0.0066950107 |
|    clip_fraction        | 0.051        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.168       |
|    explained_variance   | 0.915        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0759       |
|    n_updates            | 240          |
|    policy_gradient_loss | 0.000958     |
|    value_loss           | 0.935        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -401        |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 26          |
|    time_elapsed         | 849         |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.017343558 |
|    clip_fraction        | 0.061       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.125      |
|    explained_variance   | 0.928       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0711      |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00518    |
|    value_loss           | 0.56        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -356         |
| time/                   |              |
|    fps                  | 62           |
|    iterations           | 27           |
|    time_elapsed         | 882          |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 0.0077526034 |
|    clip_fraction        | 0.047        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.166       |
|    explained_variance   | 0.948        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0865       |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.00748     |
|    value_loss           | 0.44         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -356        |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 28          |
|    time_elapsed         | 916         |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.011589741 |
|    clip_fraction        | 0.082       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.228      |
|    explained_variance   | 0.921       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.049       |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.00694    |
|    value_loss           | 0.754       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -331        |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 29          |
|    time_elapsed         | 949         |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.014395408 |
|    clip_fraction        | 0.0711      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.219      |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.204       |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00241    |
|    value_loss           | 0.663       |
-----------------------------------------
Num timesteps: 60000
Best mean reward: -401.38 - Last mean reward per episode: -330.89
Saving new best model at 57345 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -331        |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 30          |
|    time_elapsed         | 982         |
|    total_timesteps      | 61440       |
| train/                  |             |
|    approx_kl            | 0.007029278 |
|    clip_fraction        | 0.0607      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.283      |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00632     |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.00257    |
|    value_loss           | 0.446       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -312        |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 31          |
|    time_elapsed         | 1015        |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.013210394 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.267      |
|    explained_variance   | 0.93        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0642      |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00259    |
|    value_loss           | 0.796       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -312        |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 32          |
|    time_elapsed         | 1050        |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.008269754 |
|    clip_fraction        | 0.0853      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.295      |
|    explained_variance   | 0.941       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.042       |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.00444    |
|    value_loss           | 0.594       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -289        |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 33          |
|    time_elapsed         | 1084        |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.014495559 |
|    clip_fraction        | 0.0931      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.238      |
|    explained_variance   | 0.932       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.523       |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.00601    |
|    value_loss           | 0.628       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -289        |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 34          |
|    time_elapsed         | 1120        |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.009515242 |
|    clip_fraction        | 0.0547      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.149      |
|    explained_variance   | 0.914       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0697      |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.00288    |
|    value_loss           | 0.664       |
-----------------------------------------
Num timesteps: 70000
Best mean reward: -330.89 - Last mean reward per episode: -259.79
Saving new best model at 69633 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 4.1e+03   |
|    ep_rew_mean          | -260      |
| time/                   |           |
|    fps                  | 62        |
|    iterations           | 35        |
|    time_elapsed         | 1155      |
|    total_timesteps      | 71680     |
| train/                  |           |
|    approx_kl            | 0.0129303 |
|    clip_fraction        | 0.0627    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.202    |
|    explained_variance   | 0.942     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.1       |
|    n_updates            | 340       |
|    policy_gradient_loss | -0.00203  |
|    value_loss           | 0.471     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 36          |
|    time_elapsed         | 1190        |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.009753509 |
|    clip_fraction        | 0.0572      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.179      |
|    explained_variance   | 0.932       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.143       |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00901    |
|    value_loss           | 0.635       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -229        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 37          |
|    time_elapsed         | 1225        |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.010790054 |
|    clip_fraction        | 0.0631      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.188      |
|    explained_variance   | 0.929       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0595      |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.00678    |
|    value_loss           | 0.594       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -229        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 38          |
|    time_elapsed         | 1258        |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.013086243 |
|    clip_fraction        | 0.074       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.182      |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0701      |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.00917    |
|    value_loss           | 0.511       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -206        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 39          |
|    time_elapsed         | 1291        |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.014057229 |
|    clip_fraction        | 0.0666      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.154      |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.116       |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.00991    |
|    value_loss           | 0.652       |
-----------------------------------------
Num timesteps: 80000
Best mean reward: -259.79 - Last mean reward per episode: -205.92
Saving new best model at 77825 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -206        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 40          |
|    time_elapsed         | 1324        |
|    total_timesteps      | 81920       |
| train/                  |             |
|    approx_kl            | 0.015049752 |
|    clip_fraction        | 0.0783      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.168      |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0604      |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.00969    |
|    value_loss           | 0.852       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -190        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 41          |
|    time_elapsed         | 1359        |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.016340636 |
|    clip_fraction        | 0.0902      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.168      |
|    explained_variance   | 0.93        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0279      |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00558    |
|    value_loss           | 0.514       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -190        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 42          |
|    time_elapsed         | 1395        |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.007938912 |
|    clip_fraction        | 0.0555      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.182      |
|    explained_variance   | 0.921       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0221      |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.00574    |
|    value_loss           | 0.662       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -173         |
| time/                   |              |
|    fps                  | 61           |
|    iterations           | 43           |
|    time_elapsed         | 1427         |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 0.0069424184 |
|    clip_fraction        | 0.0475       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.165       |
|    explained_variance   | 0.949        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0544       |
|    n_updates            | 420          |
|    policy_gradient_loss | -0.0049      |
|    value_loss           | 0.522        |
------------------------------------------
Num timesteps: 90000
Best mean reward: -205.92 - Last mean reward per episode: -172.79
Saving new best model at 86017 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -173        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 44          |
|    time_elapsed         | 1461        |
|    total_timesteps      | 90112       |
| train/                  |             |
|    approx_kl            | 0.010446516 |
|    clip_fraction        | 0.0497      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.172      |
|    explained_variance   | 0.919       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0743      |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00639    |
|    value_loss           | 0.588       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -158        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 45          |
|    time_elapsed         | 1494        |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.011503947 |
|    clip_fraction        | 0.0416      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.136      |
|    explained_variance   | 0.955       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.11        |
|    n_updates            | 440         |
|    policy_gradient_loss | 0.00342     |
|    value_loss           | 0.661       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -158        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 46          |
|    time_elapsed         | 1527        |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.012388095 |
|    clip_fraction        | 0.0552      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.139      |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.128       |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.00526    |
|    value_loss           | 0.599       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -144       |
| time/                   |            |
|    fps                  | 61         |
|    iterations           | 47         |
|    time_elapsed         | 1560       |
|    total_timesteps      | 96256      |
| train/                  |            |
|    approx_kl            | 0.00838181 |
|    clip_fraction        | 0.0468     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.133     |
|    explained_variance   | 0.952      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0612     |
|    n_updates            | 460        |
|    policy_gradient_loss | 0.00214    |
|    value_loss           | 0.588      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -144        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 48          |
|    time_elapsed         | 1592        |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.010265048 |
|    clip_fraction        | 0.0655      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.18       |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.114       |
|    n_updates            | 470         |
|    policy_gradient_loss | 0.000737    |
|    value_loss           | 0.542       |
-----------------------------------------
Num timesteps: 100000
Best mean reward: -172.79 - Last mean reward per episode: -130.52
Saving new best model at 98305 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -131        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 49          |
|    time_elapsed         | 1624        |
|    total_timesteps      | 100352      |
| train/                  |             |
|    approx_kl            | 0.009216108 |
|    clip_fraction        | 0.0809      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.22       |
|    explained_variance   | 0.96        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0647      |
|    n_updates            | 480         |
|    policy_gradient_loss | 0.000895    |
|    value_loss           | 0.53        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -131        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 50          |
|    time_elapsed         | 1657        |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.008078594 |
|    clip_fraction        | 0.0585      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.194      |
|    explained_variance   | 0.944       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0695      |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.0071     |
|    value_loss           | 0.56        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -120         |
| time/                   |              |
|    fps                  | 61           |
|    iterations           | 51           |
|    time_elapsed         | 1690         |
|    total_timesteps      | 104448       |
| train/                  |              |
|    approx_kl            | 0.0066455286 |
|    clip_fraction        | 0.0592       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.173       |
|    explained_variance   | 0.958        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.143        |
|    n_updates            | 500          |
|    policy_gradient_loss | -0.00152     |
|    value_loss           | 0.48         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 4.1e+03   |
|    ep_rew_mean          | -120      |
| time/                   |           |
|    fps                  | 61        |
|    iterations           | 52        |
|    time_elapsed         | 1722      |
|    total_timesteps      | 106496    |
| train/                  |           |
|    approx_kl            | 0.0165958 |
|    clip_fraction        | 0.0994    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.225    |
|    explained_variance   | 0.887     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.104     |
|    n_updates            | 510       |
|    policy_gradient_loss | -0.0217   |
|    value_loss           | 1.32      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -113        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 53          |
|    time_elapsed         | 1754        |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.033246696 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.265      |
|    explained_variance   | 0.947       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.114       |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0073     |
|    value_loss           | 1.09        |
-----------------------------------------
Num timesteps: 110000
Best mean reward: -130.52 - Last mean reward per episode: -113.40
Saving new best model at 106497 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -113        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 54          |
|    time_elapsed         | 1786        |
|    total_timesteps      | 110592      |
| train/                  |             |
|    approx_kl            | 0.037678733 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.199      |
|    explained_variance   | 0.87        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.026       |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0203     |
|    value_loss           | 0.477       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -106        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 55          |
|    time_elapsed         | 1819        |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.050573718 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.284      |
|    explained_variance   | 0.872       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.12        |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.014      |
|    value_loss           | 0.931       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -106       |
| time/                   |            |
|    fps                  | 61         |
|    iterations           | 56         |
|    time_elapsed         | 1851       |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.02177241 |
|    clip_fraction        | 0.086      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.201     |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0538     |
|    n_updates            | 550        |
|    policy_gradient_loss | -0.00756   |
|    value_loss           | 0.64       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -100        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 57          |
|    time_elapsed         | 1885        |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.020023936 |
|    clip_fraction        | 0.0792      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.17       |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0604      |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.00741    |
|    value_loss           | 0.689       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -100        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 58          |
|    time_elapsed         | 1917        |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.013844392 |
|    clip_fraction        | 0.0682      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.129      |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.155       |
|    n_updates            | 570         |
|    policy_gradient_loss | 0.00852     |
|    value_loss           | 0.7         |
-----------------------------------------
Num timesteps: 120000
Best mean reward: -113.40 - Last mean reward per episode: -90.09
Saving new best model at 118785 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -90.1       |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 59          |
|    time_elapsed         | 1949        |
|    total_timesteps      | 120832      |
| train/                  |             |
|    approx_kl            | 0.011938273 |
|    clip_fraction        | 0.0632      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.127      |
|    explained_variance   | 0.928       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0869      |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00492    |
|    value_loss           | 0.55        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -90.1        |
| time/                   |              |
|    fps                  | 61           |
|    iterations           | 60           |
|    time_elapsed         | 1982         |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 0.0130641395 |
|    clip_fraction        | 0.0638       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.131       |
|    explained_variance   | 0.961        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0265       |
|    n_updates            | 590          |
|    policy_gradient_loss | -0.00968     |
|    value_loss           | 0.353        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -80         |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 61          |
|    time_elapsed         | 2015        |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.008116549 |
|    clip_fraction        | 0.0501      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.159      |
|    explained_variance   | 0.971       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0717      |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.000108   |
|    value_loss           | 0.462       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -80         |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 62          |
|    time_elapsed         | 2047        |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.012284392 |
|    clip_fraction        | 0.07        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.172      |
|    explained_variance   | 0.97        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.152       |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.00549    |
|    value_loss           | 0.466       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -73.8       |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 63          |
|    time_elapsed         | 2080        |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.026389565 |
|    clip_fraction        | 0.0989      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.176      |
|    explained_variance   | 0.928       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0718      |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.00121    |
|    value_loss           | 0.734       |
-----------------------------------------
Num timesteps: 130000
Best mean reward: -90.09 - Last mean reward per episode: -73.82
Saving new best model at 126977 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -73.8      |
| time/                   |            |
|    fps                  | 62         |
|    iterations           | 64         |
|    time_elapsed         | 2112       |
|    total_timesteps      | 131072     |
| train/                  |            |
|    approx_kl            | 0.01608538 |
|    clip_fraction        | 0.0891     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.132     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0507     |
|    n_updates            | 630        |
|    policy_gradient_loss | -0.00701   |
|    value_loss           | 0.62       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -66.8       |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 65          |
|    time_elapsed         | 2144        |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.012890213 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.194      |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0756      |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.0233     |
|    value_loss           | 0.792       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -66.8       |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 66          |
|    time_elapsed         | 2176        |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.058566924 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.205      |
|    explained_variance   | 0.929       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.129       |
|    n_updates            | 650         |
|    policy_gradient_loss | 0.00157     |
|    value_loss           | 0.74        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -62.6       |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 67          |
|    time_elapsed         | 2208        |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.018751238 |
|    clip_fraction        | 0.0656      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.143      |
|    explained_variance   | 0.914       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.104       |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.00274    |
|    value_loss           | 0.797       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -62.6       |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 68          |
|    time_elapsed         | 2241        |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.013359668 |
|    clip_fraction        | 0.0594      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.146      |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0483      |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0106     |
|    value_loss           | 0.617       |
-----------------------------------------
Num timesteps: 140000
Best mean reward: -73.82 - Last mean reward per episode: -54.49
Saving new best model at 139265 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -54.5       |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 69          |
|    time_elapsed         | 2387        |
|    total_timesteps      | 141312      |
| train/                  |             |
|    approx_kl            | 0.006230848 |
|    clip_fraction        | 0.0575      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.162      |
|    explained_variance   | 0.95        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0714      |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.0185     |
|    value_loss           | 0.411       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.09e+03    |
|    ep_rew_mean          | -43.9       |
| time/                   |             |
|    fps                  | 51          |
|    iterations           | 70          |
|    time_elapsed         | 2770        |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.006598019 |
|    clip_fraction        | 0.053       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.12       |
|    explained_variance   | 0.955       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0229      |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.0136     |
|    value_loss           | 0.368       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.09e+03    |
|    ep_rew_mean          | -43.9       |
| time/                   |             |
|    fps                  | 50          |
|    iterations           | 71          |
|    time_elapsed         | 2884        |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.011300834 |
|    clip_fraction        | 0.0481      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0999     |
|    explained_variance   | 0.921       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0328      |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.0053     |
|    value_loss           | 0.584       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.04e+03    |
|    ep_rew_mean          | -39         |
| time/                   |             |
|    fps                  | 49          |
|    iterations           | 72          |
|    time_elapsed         | 2981        |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.017641721 |
|    clip_fraction        | 0.0783      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.177      |
|    explained_variance   | 0.966       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.043       |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.011      |
|    value_loss           | 0.257       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.04e+03    |
|    ep_rew_mean          | -39         |
| time/                   |             |
|    fps                  | 49          |
|    iterations           | 73          |
|    time_elapsed         | 3017        |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.007917685 |
|    clip_fraction        | 0.0442      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.126      |
|    explained_variance   | 0.957       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0264      |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0107     |
|    value_loss           | 0.346       |
-----------------------------------------
Num timesteps: 150000
Best mean reward: -54.49 - Last mean reward per episode: -30.61
Saving new best model at 149505 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.04e+03    |
|    ep_rew_mean          | -30.6       |
| time/                   |             |
|    fps                  | 49          |
|    iterations           | 74          |
|    time_elapsed         | 3077        |
|    total_timesteps      | 151552      |
| train/                  |             |
|    approx_kl            | 0.015125017 |
|    clip_fraction        | 0.0748      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.156      |
|    explained_variance   | 0.932       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0556      |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.00361    |
|    value_loss           | 0.442       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.04e+03    |
|    ep_rew_mean          | -30.6       |
| time/                   |             |
|    fps                  | 26          |
|    iterations           | 75          |
|    time_elapsed         | 5750        |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.011283368 |
|    clip_fraction        | 0.0814      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.169      |
|    explained_variance   | 0.939       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0923      |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.0181     |
|    value_loss           | 0.523       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.04e+03    |
|    ep_rew_mean          | -24.2       |
| time/                   |             |
|    fps                  | 26          |
|    iterations           | 76          |
|    time_elapsed         | 5791        |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.009371189 |
|    clip_fraction        | 0.0649      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.2        |
|    explained_variance   | 0.958       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0315      |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0104     |
|    value_loss           | 0.341       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.04e+03    |
|    ep_rew_mean          | -24.2       |
| time/                   |             |
|    fps                  | 27          |
|    iterations           | 77          |
|    time_elapsed         | 5829        |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.009393291 |
|    clip_fraction        | 0.0439      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.223      |
|    explained_variance   | 0.965       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0384      |
|    n_updates            | 760         |
|    policy_gradient_loss | 9.24e-05    |
|    value_loss           | 0.336       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.04e+03    |
|    ep_rew_mean          | -18.2       |
| time/                   |             |
|    fps                  | 27          |
|    iterations           | 78          |
|    time_elapsed         | 5865        |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.040687528 |
|    clip_fraction        | 0.0919      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.17       |
|    explained_variance   | 0.942       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0159      |
|    n_updates            | 770         |
|    policy_gradient_loss | 0.025       |
|    value_loss           | 0.468       |
-----------------------------------------
Num timesteps: 160000
Best mean reward: -30.61 - Last mean reward per episode: -18.17
Saving new best model at 157697 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.04e+03    |
|    ep_rew_mean          | -18.2       |
| time/                   |             |
|    fps                  | 27          |
|    iterations           | 79          |
|    time_elapsed         | 5901        |
|    total_timesteps      | 161792      |
| train/                  |             |
|    approx_kl            | 0.018187204 |
|    clip_fraction        | 0.0817      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.207      |
|    explained_variance   | 0.951       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.197       |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.013      |
|    value_loss           | 0.657       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.04e+03    |
|    ep_rew_mean          | -12.9       |
| time/                   |             |
|    fps                  | 27          |
|    iterations           | 80          |
|    time_elapsed         | 5935        |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.017701369 |
|    clip_fraction        | 0.0963      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.241      |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0504      |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.0125     |
|    value_loss           | 0.533       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.04e+03    |
|    ep_rew_mean          | -12.9       |
| time/                   |             |
|    fps                  | 27          |
|    iterations           | 81          |
|    time_elapsed         | 5973        |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.025472052 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.287      |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0559      |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.00947    |
|    value_loss           | 0.845       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.05e+03   |
|    ep_rew_mean          | -9.87      |
| time/                   |            |
|    fps                  | 27         |
|    iterations           | 82         |
|    time_elapsed         | 6017       |
|    total_timesteps      | 167936     |
| train/                  |            |
|    approx_kl            | 0.02534353 |
|    clip_fraction        | 0.113      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.23      |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0219     |
|    n_updates            | 810        |
|    policy_gradient_loss | -0.0141    |
|    value_loss           | 0.676      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.05e+03    |
|    ep_rew_mean          | -9.87       |
| time/                   |             |
|    fps                  | 28          |
|    iterations           | 83          |
|    time_elapsed         | 6057        |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.019723054 |
|    clip_fraction        | 0.0915      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.268      |
|    explained_variance   | 0.938       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.11        |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.0083     |
|    value_loss           | 0.719       |
-----------------------------------------
Num timesteps: 170000
Best mean reward: -18.17 - Last mean reward per episode: -7.92
Saving new best model at 169985 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.05e+03    |
|    ep_rew_mean          | -7.92       |
| time/                   |             |
|    fps                  | 28          |
|    iterations           | 84          |
|    time_elapsed         | 6096        |
|    total_timesteps      | 172032      |
| train/                  |             |
|    approx_kl            | 0.028432552 |
|    clip_fraction        | 0.092       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.245      |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.116       |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.0084     |
|    value_loss           | 0.814       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.05e+03    |
|    ep_rew_mean          | -7.92       |
| time/                   |             |
|    fps                  | 28          |
|    iterations           | 85          |
|    time_elapsed         | 6133        |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.011781138 |
|    clip_fraction        | 0.0897      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.241      |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0439      |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.00885    |
|    value_loss           | 0.656       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.05e+03    |
|    ep_rew_mean          | -4.2        |
| time/                   |             |
|    fps                  | 28          |
|    iterations           | 86          |
|    time_elapsed         | 6170        |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.020177856 |
|    clip_fraction        | 0.0746      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.197      |
|    explained_variance   | 0.957       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0445      |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.00754    |
|    value_loss           | 0.374       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.05e+03    |
|    ep_rew_mean          | -4.2        |
| time/                   |             |
|    fps                  | 28          |
|    iterations           | 87          |
|    time_elapsed         | 6206        |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.015060258 |
|    clip_fraction        | 0.0612      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.21       |
|    explained_variance   | 0.939       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.14        |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.00338    |
|    value_loss           | 0.597       |
-----------------------------------------
Num timesteps: 180000
Best mean reward: -7.92 - Last mean reward per episode: -1.10
Saving new best model at 178177 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.05e+03    |
|    ep_rew_mean          | -1.1        |
| time/                   |             |
|    fps                  | 28          |
|    iterations           | 88          |
|    time_elapsed         | 6243        |
|    total_timesteps      | 180224      |
| train/                  |             |
|    approx_kl            | 0.011486551 |
|    clip_fraction        | 0.0877      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.245      |
|    explained_variance   | 0.948       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0163     |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.00667    |
|    value_loss           | 0.426       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.05e+03    |
|    ep_rew_mean          | -1.1        |
| time/                   |             |
|    fps                  | 29          |
|    iterations           | 89          |
|    time_elapsed         | 6279        |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.018681336 |
|    clip_fraction        | 0.0955      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.291      |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0358      |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.014      |
|    value_loss           | 0.367       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.05e+03    |
|    ep_rew_mean          | -1.7        |
| time/                   |             |
|    fps                  | 29          |
|    iterations           | 90          |
|    time_elapsed         | 6315        |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.020753114 |
|    clip_fraction        | 0.0699      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.294      |
|    explained_variance   | 0.943       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0457      |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.0105     |
|    value_loss           | 0.453       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.05e+03     |
|    ep_rew_mean          | -1.7         |
| time/                   |              |
|    fps                  | 29           |
|    iterations           | 91           |
|    time_elapsed         | 6349         |
|    total_timesteps      | 186368       |
| train/                  |              |
|    approx_kl            | 0.0095348675 |
|    clip_fraction        | 0.0588       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.275       |
|    explained_variance   | 0.941        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.042        |
|    n_updates            | 900          |
|    policy_gradient_loss | -0.00816     |
|    value_loss           | 0.449        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.05e+03    |
|    ep_rew_mean          | -2.71       |
| time/                   |             |
|    fps                  | 29          |
|    iterations           | 92          |
|    time_elapsed         | 6385        |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.013643086 |
|    clip_fraction        | 0.0972      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.339      |
|    explained_variance   | 0.937       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00207     |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.0138     |
|    value_loss           | 0.48        |
-----------------------------------------
Num timesteps: 190000
Best mean reward: -1.10 - Last mean reward per episode: -2.71
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.05e+03    |
|    ep_rew_mean          | -2.71       |
| time/                   |             |
|    fps                  | 29          |
|    iterations           | 93          |
|    time_elapsed         | 6425        |
|    total_timesteps      | 190464      |
| train/                  |             |
|    approx_kl            | 0.023267724 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.391      |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.126       |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.00806    |
|    value_loss           | 0.878       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.05e+03    |
|    ep_rew_mean          | -6.65       |
| time/                   |             |
|    fps                  | 29          |
|    iterations           | 94          |
|    time_elapsed         | 6459        |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.023689907 |
|    clip_fraction        | 0.0753      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.344      |
|    explained_variance   | 0.919       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0504      |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.00941    |
|    value_loss           | 0.585       |
-----------------------------------------
Traceback (most recent call last):
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/freeway/run_supervised_gnn.py", line 287, in <module>
    model.learn(total_timesteps=1000000, callback=[WandbCallback(), save_callback])
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 315, in learn
    return super().learn(
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 313, in learn
    self.train()
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 217, in train
    values, log_prob, entropy = self.policy.evaluate_actions(rollout_data.observations, actions)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/policies.py", line 730, in evaluate_actions
    features = self.extract_features(obs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/policies.py", line 672, in extract_features
    return super().extract_features(obs, self.features_extractor if features_extractor is None else features_extractor)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/policies.py", line 131, in extract_features
    return features_extractor(preprocessed_obs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/model/policy.py", line 40, in forward
    pyg_data = self.encoder.encode(observations)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/encoder/GraphEncoder.py", line 460, in encode
    return Batch.from_data_list(self.to_pyg_data(batch_data))
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/encoder/GraphEncoder.py", line 496, in to_pyg_data
    data[node_type].x = torch.cat(features_list)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch_geometric/data/hetero_data.py", line 178, in __getitem__
    key = self._to_canonical(*args)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch_geometric/data/hetero_data.py", line 492, in _to_canonical
    edge_types = [key for key in self.edge_types if key[1] == args]
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch_geometric/data/hetero_data.py", line 267, in edge_types
    return list(self._edge_store_dict.keys())
KeyboardInterrupt