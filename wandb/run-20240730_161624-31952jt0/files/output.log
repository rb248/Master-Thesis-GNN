
Using cpu device
-----------------------------
| time/              |      |
|    fps             | 296  |
|    iterations      | 1    |
|    time_elapsed    | 6    |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3e+03       |
|    ep_rew_mean          | -1.44e+03   |
| time/                   |             |
|    fps                  | 106         |
|    iterations           | 2           |
|    time_elapsed         | 38          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.008634815 |
|    clip_fraction        | 0.0739      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 0.0921      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.329       |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00289    |
|    value_loss           | 3.37        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3e+03       |
|    ep_rew_mean          | -1.39e+03   |
| time/                   |             |
|    fps                  | 89          |
|    iterations           | 3           |
|    time_elapsed         | 68          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.007814754 |
|    clip_fraction        | 0.0424      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | 0.00365     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.32        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00399    |
|    value_loss           | 15.9        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3e+03       |
|    ep_rew_mean          | -1.39e+03   |
| time/                   |             |
|    fps                  | 82          |
|    iterations           | 4           |
|    time_elapsed         | 99          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.015916152 |
|    clip_fraction        | 0.0803      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.03       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 6.81        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00732    |
|    value_loss           | 18          |
-----------------------------------------
Num timesteps: 10000
Best mean reward: -inf - Last mean reward per episode: -1240.00
Saving new best model at 9000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3e+03       |
|    ep_rew_mean          | -1.24e+03   |
| time/                   |             |
|    fps                  | 78          |
|    iterations           | 5           |
|    time_elapsed         | 130         |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.017490935 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.943      |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 9.16        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0106     |
|    value_loss           | 22.9        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3e+03       |
|    ep_rew_mean          | -1.08e+03   |
| time/                   |             |
|    fps                  | 76          |
|    iterations           | 6           |
|    time_elapsed         | 160         |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.011565594 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.838      |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 14.8        |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0104     |
|    value_loss           | 28.4        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3e+03      |
|    ep_rew_mean          | -1.08e+03  |
| time/                   |            |
|    fps                  | 75         |
|    iterations           | 7          |
|    time_elapsed         | 189        |
|    total_timesteps      | 14336      |
| train/                  |            |
|    approx_kl            | 0.00933883 |
|    clip_fraction        | 0.0911     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.737     |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 15.4       |
|    n_updates            | 60         |
|    policy_gradient_loss | -0.00751   |
|    value_loss           | 35.6       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3e+03       |
|    ep_rew_mean          | -948        |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 8           |
|    time_elapsed         | 221         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.005209702 |
|    clip_fraction        | 0.0863      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.648      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 15.2        |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00596    |
|    value_loss           | 33          |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3e+03        |
|    ep_rew_mean          | -830         |
| time/                   |              |
|    fps                  | 73           |
|    iterations           | 9            |
|    time_elapsed         | 251          |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0055078943 |
|    clip_fraction        | 0.0568       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.576       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 16.1         |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00418     |
|    value_loss           | 34.7         |
------------------------------------------
Num timesteps: 20000
Best mean reward: -1240.00 - Last mean reward per episode: -830.00
Saving new best model at 18000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3e+03        |
|    ep_rew_mean          | -830         |
| time/                   |              |
|    fps                  | 72           |
|    iterations           | 10           |
|    time_elapsed         | 284          |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 0.0027504868 |
|    clip_fraction        | 0.0388       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.503       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 17.8         |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00244     |
|    value_loss           | 37.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3e+03        |
|    ep_rew_mean          | -729         |
| time/                   |              |
|    fps                  | 71           |
|    iterations           | 11           |
|    time_elapsed         | 314          |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0033022445 |
|    clip_fraction        | 0.0396       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.443       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 16.7         |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00266     |
|    value_loss           | 35.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3e+03        |
|    ep_rew_mean          | -638         |
| time/                   |              |
|    fps                  | 70           |
|    iterations           | 12           |
|    time_elapsed         | 348          |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0022087684 |
|    clip_fraction        | 0.0237       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.39        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 18.7         |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00112     |
|    value_loss           | 36.1         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3e+03        |
|    ep_rew_mean          | -638         |
| time/                   |              |
|    fps                  | 69           |
|    iterations           | 13           |
|    time_elapsed         | 380          |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0005297674 |
|    clip_fraction        | 0.00601      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.359       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 17.5         |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.000412    |
|    value_loss           | 35.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3e+03        |
|    ep_rew_mean          | -580         |
| time/                   |              |
|    fps                  | 69           |
|    iterations           | 14           |
|    time_elapsed         | 412          |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 0.0010212483 |
|    clip_fraction        | 0.00854      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.379       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 15.4         |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.000554    |
|    value_loss           | 36.8         |
------------------------------------------
Num timesteps: 30000
Best mean reward: -830.00 - Last mean reward per episode: -526.00
Saving new best model at 30000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3e+03        |
|    ep_rew_mean          | -526         |
| time/                   |              |
|    fps                  | 69           |
|    iterations           | 15           |
|    time_elapsed         | 444          |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 0.0024121557 |
|    clip_fraction        | 0.0317       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.335       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 15.7         |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00273     |
|    value_loss           | 37.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3e+03        |
|    ep_rew_mean          | -526         |
| time/                   |              |
|    fps                  | 68           |
|    iterations           | 16           |
|    time_elapsed         | 478          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0017368905 |
|    clip_fraction        | 0.0126       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.297       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 19.2         |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.000761    |
|    value_loss           | 36.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.98e+03     |
|    ep_rew_mean          | -466         |
| time/                   |              |
|    fps                  | 67           |
|    iterations           | 17           |
|    time_elapsed         | 512          |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0019416182 |
|    clip_fraction        | 0.0243       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.238       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 19.6         |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00228     |
|    value_loss           | 36.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.98e+03     |
|    ep_rew_mean          | -420         |
| time/                   |              |
|    fps                  | 67           |
|    iterations           | 18           |
|    time_elapsed         | 544          |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0014567641 |
|    clip_fraction        | 0.0336       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.183       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 20.8         |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00259     |
|    value_loss           | 37.1         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.98e+03     |
|    ep_rew_mean          | -377         |
| time/                   |              |
|    fps                  | 67           |
|    iterations           | 19           |
|    time_elapsed         | 575          |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0010525703 |
|    clip_fraction        | 0.0145       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.163       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 16.2         |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.000917    |
|    value_loss           | 37.4         |
------------------------------------------
Num timesteps: 40000
Best mean reward: -526.00 - Last mean reward per episode: -377.27
Saving new best model at 38769 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.98e+03      |
|    ep_rew_mean          | -377          |
| time/                   |               |
|    fps                  | 67            |
|    iterations           | 20            |
|    time_elapsed         | 607           |
|    total_timesteps      | 40960         |
| train/                  |               |
|    approx_kl            | 0.00049470994 |
|    clip_fraction        | 0.00884       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.166        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 20.2          |
|    n_updates            | 190           |
|    policy_gradient_loss | -0.000254     |
|    value_loss           | 37.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.98e+03      |
|    ep_rew_mean          | -342          |
| time/                   |               |
|    fps                  | 67            |
|    iterations           | 21            |
|    time_elapsed         | 638           |
|    total_timesteps      | 43008         |
| train/                  |               |
|    approx_kl            | 0.00042432133 |
|    clip_fraction        | 0.0114        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.162        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 22.5          |
|    n_updates            | 200           |
|    policy_gradient_loss | -0.000872     |
|    value_loss           | 38.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.98e+03     |
|    ep_rew_mean          | -310         |
| time/                   |              |
|    fps                  | 66           |
|    iterations           | 22           |
|    time_elapsed         | 676          |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0006046281 |
|    clip_fraction        | 0.00737      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.147       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 17.9         |
|    n_updates            | 210          |
|    policy_gradient_loss | -4.61e-05    |
|    value_loss           | 36           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.98e+03      |
|    ep_rew_mean          | -310          |
| time/                   |               |
|    fps                  | 66            |
|    iterations           | 23            |
|    time_elapsed         | 710           |
|    total_timesteps      | 47104         |
| train/                  |               |
|    approx_kl            | 0.00084159675 |
|    clip_fraction        | 0.00527       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.132        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 15.7          |
|    n_updates            | 220           |
|    policy_gradient_loss | -1.82e-05     |
|    value_loss           | 37.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.94e+03      |
|    ep_rew_mean          | -286          |
| time/                   |               |
|    fps                  | 66            |
|    iterations           | 24            |
|    time_elapsed         | 743           |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 0.00060746365 |
|    clip_fraction        | 0.00728       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.119        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 24.5          |
|    n_updates            | 230           |
|    policy_gradient_loss | -0.00063      |
|    value_loss           | 38.9          |
-------------------------------------------
Num timesteps: 50000
Best mean reward: -377.27 - Last mean reward per episode: -285.78
Saving new best model at 47105 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.95e+03      |
|    ep_rew_mean          | -257          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 25            |
|    time_elapsed         | 777           |
|    total_timesteps      | 51200         |
| train/                  |               |
|    approx_kl            | 0.00062471273 |
|    clip_fraction        | 0.0126        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.103        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 18.8          |
|    n_updates            | 240           |
|    policy_gradient_loss | -0.00107      |
|    value_loss           | 37            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.95e+03     |
|    ep_rew_mean          | -232         |
| time/                   |              |
|    fps                  | 65           |
|    iterations           | 26           |
|    time_elapsed         | 813          |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0002049905 |
|    clip_fraction        | 0.00522      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0928      |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 22.2         |
|    n_updates            | 250          |
|    policy_gradient_loss | 2.18e-05     |
|    value_loss           | 37.3         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.95e+03      |
|    ep_rew_mean          | -232          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 27            |
|    time_elapsed         | 847           |
|    total_timesteps      | 55296         |
| train/                  |               |
|    approx_kl            | 0.00012490398 |
|    clip_fraction        | 0.0021        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0984       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 18.8          |
|    n_updates            | 260           |
|    policy_gradient_loss | 0.000199      |
|    value_loss           | 36.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.91e+03     |
|    ep_rew_mean          | -216         |
| time/                   |              |
|    fps                  | 65           |
|    iterations           | 28           |
|    time_elapsed         | 880          |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0003823777 |
|    clip_fraction        | 0.00703      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0984      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 19.1         |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.000239    |
|    value_loss           | 40.1         |
