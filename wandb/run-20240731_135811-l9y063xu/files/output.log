
Using cpu device
-----------------------------
| time/              |      |
|    fps             | 234  |
|    iterations      | 1    |
|    time_elapsed    | 8    |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.22e+03    |
|    ep_rew_mean          | -1.61e+03   |
| time/                   |             |
|    fps                  | 64          |
|    iterations           | 2           |
|    time_elapsed         | 63          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.011302709 |
|    clip_fraction        | 0.0925      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 0.0642      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.385       |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00335    |
|    value_loss           | 3.82        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.22e+03    |
|    ep_rew_mean          | -1.61e+03   |
| time/                   |             |
|    fps                  | 51          |
|    iterations           | 3           |
|    time_elapsed         | 118         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.008239541 |
|    clip_fraction        | 0.0287      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 5.36e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.161       |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00172    |
|    value_loss           | 13.9        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.07e+03    |
|    ep_rew_mean          | -1.52e+03   |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 4           |
|    time_elapsed         | 171         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.015126434 |
|    clip_fraction        | 0.0159      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.121       |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00196    |
|    value_loss           | 12.7        |
-----------------------------------------
Num timesteps: 10000
Best mean reward: -inf - Last mean reward per episode: -1521.25
Saving new best model at 6145 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -1.62e+03   |
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 5           |
|    time_elapsed         | 223         |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.008936375 |
|    clip_fraction        | 0.0127      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0205     |
|    n_updates            | 40          |
|    policy_gradient_loss | 0.000263    |
|    value_loss           | 6.59        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -1.62e+03   |
| time/                   |             |
|    fps                  | 44          |
|    iterations           | 6           |
|    time_elapsed         | 276         |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.009928912 |
|    clip_fraction        | 0.0754      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 9.47        |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00345    |
|    value_loss           | 18.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.07e+03    |
|    ep_rew_mean          | -1.42e+03   |
| time/                   |             |
|    fps                  | 43          |
|    iterations           | 7           |
|    time_elapsed         | 331         |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.013452966 |
|    clip_fraction        | 0.0613      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | 1.19e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 25.2        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00299    |
|    value_loss           | 32.4        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.03e+03    |
|    ep_rew_mean          | -1.26e+03   |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 8           |
|    time_elapsed         | 388         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.014057187 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.927      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 31.4        |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0108     |
|    value_loss           | 50.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.9e+03     |
|    ep_rew_mean          | -1.11e+03   |
| time/                   |             |
|    fps                  | 41          |
|    iterations           | 9           |
|    time_elapsed         | 447         |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.011974137 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.821      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 33          |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00689    |
|    value_loss           | 62.7        |
-----------------------------------------
Num timesteps: 20000
Best mean reward: -1521.25 - Last mean reward per episode: -984.36
Saving new best model at 19781 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.83e+03    |
|    ep_rew_mean          | -984        |
| time/                   |             |
|    fps                  | 40          |
|    iterations           | 10          |
|    time_elapsed         | 505         |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.006648792 |
|    clip_fraction        | 0.0767      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.731      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 33.3        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00388    |
|    value_loss           | 71.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.83e+03     |
|    ep_rew_mean          | -984         |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 11           |
|    time_elapsed         | 559          |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0037366347 |
|    clip_fraction        | 0.0417       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.645       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 50           |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00196     |
|    value_loss           | 75.4         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.82e+03    |
|    ep_rew_mean          | -853        |
| time/                   |             |
|    fps                  | 40          |
|    iterations           | 12          |
|    time_elapsed         | 614         |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.006278879 |
|    clip_fraction        | 0.0691      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.559      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 49          |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00455    |
|    value_loss           | 77.4        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.85e+03     |
|    ep_rew_mean          | -740         |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 13           |
|    time_elapsed         | 670          |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0055805272 |
|    clip_fraction        | 0.0635       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.474       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 44.8         |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00288     |
|    value_loss           | 77.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.85e+03     |
|    ep_rew_mean          | -740         |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 14           |
|    time_elapsed         | 724          |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 0.0016134181 |
|    clip_fraction        | 0.0191       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.497       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 34.9         |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.000409    |
|    value_loss           | 80.9         |
------------------------------------------
Num timesteps: 30000
Best mean reward: -984.36 - Last mean reward per episode: -653.65
Saving new best model at 28673 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.87e+03    |
|    ep_rew_mean          | -654        |
| time/                   |             |
|    fps                  | 39          |
|    iterations           | 15          |
|    time_elapsed         | 778         |
|    total_timesteps      | 30720       |
| train/                  |             |
|    approx_kl            | 0.003632741 |
|    clip_fraction        | 0.0274      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.426      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 32.4        |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0015     |
|    value_loss           | 79.5        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.87e+03     |
|    ep_rew_mean          | -654         |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 16           |
|    time_elapsed         | 828          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0014592445 |
|    clip_fraction        | 0.0285       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.357       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 44.4         |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00192     |
|    value_loss           | 81.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.98e+03     |
|    ep_rew_mean          | -565         |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 17           |
|    time_elapsed         | 880          |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0029905052 |
|    clip_fraction        | 0.0415       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.302       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 43.5         |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00265     |
|    value_loss           | 81.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.91e+03     |
|    ep_rew_mean          | -496         |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 18           |
|    time_elapsed         | 939          |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0020169886 |
|    clip_fraction        | 0.0289       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.259       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 36.2         |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00236     |
|    value_loss           | 81.3         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.96e+03      |
|    ep_rew_mean          | -407          |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 19            |
|    time_elapsed         | 993           |
|    total_timesteps      | 38912         |
| train/                  |               |
|    approx_kl            | 0.00022627355 |
|    clip_fraction        | 0.0214        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.217        |
|    explained_variance   | -2.38e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 48.4          |
|    n_updates            | 180           |
|    policy_gradient_loss | -0.000353     |
|    value_loss           | 82.9          |
-------------------------------------------
Num timesteps: 40000
Best mean reward: -653.65 - Last mean reward per episode: -406.65
Saving new best model at 38533 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.96e+03     |
|    ep_rew_mean          | -407         |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 20           |
|    time_elapsed         | 1044         |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 0.0016169249 |
|    clip_fraction        | 0.0123       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.242       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 41.7         |
|    n_updates            | 190          |
|    policy_gradient_loss | 0.000129     |
|    value_loss           | 81.8         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.93e+03    |
|    ep_rew_mean          | -353        |
| time/                   |             |
|    fps                  | 39          |
|    iterations           | 21          |
|    time_elapsed         | 1102        |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.001681883 |
|    clip_fraction        | 0.0235      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.189      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 40          |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00141    |
|    value_loss           | 87.4        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.97e+03     |
|    ep_rew_mean          | -272         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 22           |
|    time_elapsed         | 1157         |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0006702763 |
|    clip_fraction        | 0.0119       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.153       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 33.3         |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.000829    |
|    value_loss           | 88.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.97e+03     |
|    ep_rew_mean          | -272         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 23           |
|    time_elapsed         | 1210         |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 0.0008327816 |
|    clip_fraction        | 0.0175       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.124       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 40.2         |
|    n_updates            | 220          |
|    policy_gradient_loss | -0.000986    |
|    value_loss           | 89.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.94e+03      |
|    ep_rew_mean          | -231          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 24            |
|    time_elapsed         | 1268          |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 0.00029962938 |
|    clip_fraction        | 0.00498       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.112        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 41.4          |
|    n_updates            | 230           |
|    policy_gradient_loss | -0.00053      |
|    value_loss           | 85.2          |
-------------------------------------------
Num timesteps: 50000
Best mean reward: -406.65 - Last mean reward per episode: -193.50
Saving new best model at 49719 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.92e+03      |
|    ep_rew_mean          | -194          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 25            |
|    time_elapsed         | 1325          |
|    total_timesteps      | 51200         |
| train/                  |               |
|    approx_kl            | 0.00022965134 |
|    clip_fraction        | 0.000244      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.113        |
|    explained_variance   | 1.79e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 49            |
|    n_updates            | 240           |
|    policy_gradient_loss | 0.000102      |
|    value_loss           | 87.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.92e+03      |
|    ep_rew_mean          | -194          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 26            |
|    time_elapsed         | 1378          |
|    total_timesteps      | 53248         |
| train/                  |               |
|    approx_kl            | 0.00093746453 |
|    clip_fraction        | 0.015         |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.119        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 42.6          |
|    n_updates            | 250           |
|    policy_gradient_loss | -0.00153      |
|    value_loss           | 90.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.96e+03     |
|    ep_rew_mean          | -151         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 27           |
|    time_elapsed         | 1429         |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 0.0003261242 |
|    clip_fraction        | 0.00684      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.112       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 44.4         |
|    n_updates            | 260          |
|    policy_gradient_loss | 0.00011      |
|    value_loss           | 88.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.96e+03     |
|    ep_rew_mean          | -151         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 28           |
|    time_elapsed         | 1480         |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0002542977 |
|    clip_fraction        | 0.00986      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.124       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 49.7         |
|    n_updates            | 270          |
|    policy_gradient_loss | 0.000132     |
|    value_loss           | 83.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.02e+03      |
|    ep_rew_mean          | -110          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 29            |
|    time_elapsed         | 1533          |
|    total_timesteps      | 59392         |
| train/                  |               |
|    approx_kl            | 0.00056609814 |
|    clip_fraction        | 0.0112        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.108        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 55.3          |
|    n_updates            | 280           |
|    policy_gradient_loss | -0.000614     |
|    value_loss           | 90.4          |
-------------------------------------------
Num timesteps: 60000
Best mean reward: -193.50 - Last mean reward per episode: -110.13
Saving new best model at 57345 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.05e+03     |
|    ep_rew_mean          | -73.8        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 30           |
|    time_elapsed         | 1586         |
|    total_timesteps      | 61440        |
| train/                  |              |
|    approx_kl            | 0.0007955838 |
|    clip_fraction        | 0.0082       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.11        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 39.9         |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.000706    |
|    value_loss           | 86.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.05e+03     |
|    ep_rew_mean          | -73.8        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 31           |
|    time_elapsed         | 1638         |
|    total_timesteps      | 63488        |
| train/                  |              |
|    approx_kl            | 0.0001474706 |
|    clip_fraction        | 0.00347      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.101       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 29.9         |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.000106    |
|    value_loss           | 87.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.02e+03      |
|    ep_rew_mean          | -48.8         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 32            |
|    time_elapsed         | 1690          |
|    total_timesteps      | 65536         |
| train/                  |               |
|    approx_kl            | 0.00051680196 |
|    clip_fraction        | 0.0122        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0906       |
|    explained_variance   | 1.79e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 46.2          |
|    n_updates            | 310           |
|    policy_gradient_loss | -0.000935     |
|    value_loss           | 87            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.06e+03     |
|    ep_rew_mean          | -17          |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 33           |
|    time_elapsed         | 1742         |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 0.0003028848 |
|    clip_fraction        | 0.00342      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0886      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 49.2         |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.000329    |
|    value_loss           | 87.8         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.06e+03      |
|    ep_rew_mean          | -17           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 34            |
|    time_elapsed         | 1794          |
|    total_timesteps      | 69632         |
| train/                  |               |
|    approx_kl            | 0.00034543333 |
|    clip_fraction        | 0.0083        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0636       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 50            |
|    n_updates            | 330           |
|    policy_gradient_loss | -0.000605     |
|    value_loss           | 90.6          |
-------------------------------------------
Num timesteps: 70000
Best mean reward: -110.13 - Last mean reward per episode: -3.33
Saving new best model at 69633 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.03e+03      |
|    ep_rew_mean          | -3.33         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 35            |
|    time_elapsed         | 1844          |
|    total_timesteps      | 71680         |
| train/                  |               |
|    approx_kl            | 1.2032688e-05 |
|    clip_fraction        | 0.00498       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0577       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 45.3          |
|    n_updates            | 340           |
|    policy_gradient_loss | -0.000215     |
|    value_loss           | 84.9          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.03e+03    |
|    ep_rew_mean          | -3.33       |
| time/                   |             |
|    fps                  | 38          |
|    iterations           | 36          |
|    time_elapsed         | 1894        |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 9.95732e-05 |
|    clip_fraction        | 0.00225     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0683     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 40.5        |
|    n_updates            | 350         |
|    policy_gradient_loss | 4.56e-05    |
|    value_loss           | 89          |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.07e+03      |
|    ep_rew_mean          | 26.5          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 37            |
|    time_elapsed         | 1946          |
|    total_timesteps      | 75776         |
| train/                  |               |
|    approx_kl            | 0.00022458486 |
|    clip_fraction        | 0.00552       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0587       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 42            |
|    n_updates            | 360           |
|    policy_gradient_loss | 2.59e-05      |
|    value_loss           | 88.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.1e+03      |
|    ep_rew_mean          | 54.4         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 38           |
|    time_elapsed         | 1999         |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 0.0002405832 |
|    clip_fraction        | 0.00649      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.05        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 43.3         |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.00073     |
|    value_loss           | 90.3         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.1e+03       |
|    ep_rew_mean          | 54.4          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 39            |
|    time_elapsed         | 2051          |
|    total_timesteps      | 79872         |
| train/                  |               |
|    approx_kl            | 0.00013587851 |
|    clip_fraction        | 0.00142       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.047        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 51.6          |
|    n_updates            | 380           |
|    policy_gradient_loss | -0.000121     |
|    value_loss           | 88.4          |
-------------------------------------------
Num timesteps: 80000
Best mean reward: -3.33 - Last mean reward per episode: 67.83
Saving new best model at 79873 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.07e+03     |
|    ep_rew_mean          | 67.8         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 40           |
|    time_elapsed         | 2105         |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 1.852584e-05 |
|    clip_fraction        | 0.00225      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0501      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 54.8         |
|    n_updates            | 390          |
|    policy_gradient_loss | 0.000142     |
|    value_loss           | 90           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.09e+03      |
|    ep_rew_mean          | 91.2          |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 41            |
|    time_elapsed         | 2158          |
|    total_timesteps      | 83968         |
| train/                  |               |
|    approx_kl            | 0.00012735653 |
|    clip_fraction        | 0.0043        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0342       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 57.6          |
|    n_updates            | 400           |
|    policy_gradient_loss | -0.000138     |
|    value_loss           | 86.5          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.09e+03     |
|    ep_rew_mean          | 91.2         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 42           |
|    time_elapsed         | 2211         |
|    total_timesteps      | 86016        |
| train/                  |              |
|    approx_kl            | 0.0003968129 |
|    clip_fraction        | 0.00283      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0399      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 44.6         |
|    n_updates            | 410          |
|    policy_gradient_loss | 9.86e-05     |
|    value_loss           | 84.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.07e+03      |
|    ep_rew_mean          | 104           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 43            |
|    time_elapsed         | 2262          |
|    total_timesteps      | 88064         |
| train/                  |               |
|    approx_kl            | 0.00092789397 |
|    clip_fraction        | 0.00469       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0414       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 65            |
|    n_updates            | 420           |
|    policy_gradient_loss | 0.000121      |
|    value_loss           | 91.4          |
-------------------------------------------
Num timesteps: 90000
Best mean reward: 67.83 - Last mean reward per episode: 104.34
Saving new best model at 86017 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.11e+03      |
|    ep_rew_mean          | 121           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 44            |
|    time_elapsed         | 2314          |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 0.00083379843 |
|    clip_fraction        | 0.00889       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0638       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 46.6          |
|    n_updates            | 430           |
|    policy_gradient_loss | -0.000236     |
|    value_loss           | 84.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.11e+03      |
|    ep_rew_mean          | 121           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 45            |
|    time_elapsed         | 2365          |
|    total_timesteps      | 92160         |
| train/                  |               |
|    approx_kl            | 0.00041536381 |
|    clip_fraction        | 0.0019        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0502       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 57.1          |
|    n_updates            | 440           |
|    policy_gradient_loss | 0.000195      |
|    value_loss           | 93            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.07e+03      |
|    ep_rew_mean          | 128           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 46            |
|    time_elapsed         | 2419          |
|    total_timesteps      | 94208         |
| train/                  |               |
|    approx_kl            | 0.00014974811 |
|    clip_fraction        | 0.00142       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.043        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 51.1          |
|    n_updates            | 450           |
|    policy_gradient_loss | -4.15e-05     |
|    value_loss           | 88.5          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.1e+03      |
|    ep_rew_mean          | 146          |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 47           |
|    time_elapsed         | 2471         |
|    total_timesteps      | 96256        |
| train/                  |              |
|    approx_kl            | 5.762832e-05 |
|    clip_fraction        | 0.00195      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0328      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 45.4         |
|    n_updates            | 460          |
|    policy_gradient_loss | -7.73e-05    |
|    value_loss           | 85           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.1e+03       |
|    ep_rew_mean          | 146           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 48            |
|    time_elapsed         | 2523          |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 0.00017007397 |
|    clip_fraction        | 0.00186       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0313       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 38.6          |
|    n_updates            | 470           |
|    policy_gradient_loss | -0.000366     |
|    value_loss           | 91.3          |
-------------------------------------------
Num timesteps: 100000
Best mean reward: 104.34 - Last mean reward per episode: 155.23
Saving new best model at 98305 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.07e+03      |
|    ep_rew_mean          | 155           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 49            |
|    time_elapsed         | 2579          |
|    total_timesteps      | 100352        |
| train/                  |               |
|    approx_kl            | 0.00014241142 |
|    clip_fraction        | 0.00225       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.027        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 31.5          |
|    n_updates            | 480           |
|    policy_gradient_loss | -0.000376     |
|    value_loss           | 89.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.07e+03      |
|    ep_rew_mean          | 168           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 50            |
|    time_elapsed         | 2632          |
|    total_timesteps      | 102400        |
| train/                  |               |
|    approx_kl            | 0.00010139827 |
|    clip_fraction        | 0.00195       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0261       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 52.7          |
|    n_updates            | 490           |
|    policy_gradient_loss | -0.000269     |
|    value_loss           | 87.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.07e+03      |
|    ep_rew_mean          | 168           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 51            |
|    time_elapsed         | 2686          |
|    total_timesteps      | 104448        |
| train/                  |               |
|    approx_kl            | 0.00018365687 |
|    clip_fraction        | 0.00356       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0219       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 46.1          |
|    n_updates            | 500           |
|    policy_gradient_loss | -4.37e-05     |
|    value_loss           | 92            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.07e+03      |
|    ep_rew_mean          | 185           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 52            |
|    time_elapsed         | 2738          |
|    total_timesteps      | 106496        |
| train/                  |               |
|    approx_kl            | 5.5976125e-05 |
|    clip_fraction        | 0.000732      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0184       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 30.6          |
|    n_updates            | 510           |
|    policy_gradient_loss | -0.000208     |
|    value_loss           | 85.1          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.09e+03     |
|    ep_rew_mean          | 203          |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 53           |
|    time_elapsed         | 2791         |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 6.115588e-05 |
|    clip_fraction        | 0.000195     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.016       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 45.3         |
|    n_updates            | 520          |
|    policy_gradient_loss | -1.83e-05    |
|    value_loss           | 85.5         |
------------------------------------------
Num timesteps: 110000
Best mean reward: 155.23 - Last mean reward per episode: 202.86
Saving new best model at 108320 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.09e+03      |
|    ep_rew_mean          | 203           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 54            |
|    time_elapsed         | 2843          |
|    total_timesteps      | 110592        |
| train/                  |               |
|    approx_kl            | 6.4497755e-05 |
|    clip_fraction        | 0.000879      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0121       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 45.5          |
|    n_updates            | 530           |
|    policy_gradient_loss | -7.22e-05     |
|    value_loss           | 90.3          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.07e+03     |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 55           |
|    time_elapsed         | 2895         |
|    total_timesteps      | 112640       |
| train/                  |              |
|    approx_kl            | 9.590018e-05 |
|    clip_fraction        | 0.00181      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0116      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 31.6         |
|    n_updates            | 540          |
|    policy_gradient_loss | -0.000315    |
|    value_loss           | 89.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.07e+03     |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 56           |
|    time_elapsed         | 2946         |
|    total_timesteps      | 114688       |
| train/                  |              |
|    approx_kl            | 0.0001736529 |
|    clip_fraction        | 0.000928     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00798     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 40.8         |
|    n_updates            | 550          |
|    policy_gradient_loss | -0.00021     |
|    value_loss           | 88.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.1e+03      |
|    ep_rew_mean          | 227          |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 57           |
|    time_elapsed         | 2998         |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 5.994842e-05 |
|    clip_fraction        | 0.000684     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0061      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 34           |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.000103    |
|    value_loss           | 87.8         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.11e+03      |
|    ep_rew_mean          | 236           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 58            |
|    time_elapsed         | 3052          |
|    total_timesteps      | 118784        |
| train/                  |               |
|    approx_kl            | 2.7617207e-05 |
|    clip_fraction        | 0.000879      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0064       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 45.8          |
|    n_updates            | 570           |
|    policy_gradient_loss | -6.27e-05     |
|    value_loss           | 86            |
-------------------------------------------
Num timesteps: 120000
Best mean reward: 202.86 - Last mean reward per episode: 235.72
Saving new best model at 118345 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.11e+03 |
|    ep_rew_mean          | 236      |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 59       |
|    time_elapsed         | 3103     |
|    total_timesteps      | 120832   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00614 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 40.8     |
|    n_updates            | 580      |
|    policy_gradient_loss | 2.14e-10 |
|    value_loss           | 92.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.1e+03   |
|    ep_rew_mean          | 239       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 60        |
|    time_elapsed         | 3156      |
|    total_timesteps      | 122880    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00614  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 64.2      |
|    n_updates            | 590       |
|    policy_gradient_loss | -3.08e-10 |
|    value_loss           | 87.8      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.11e+03      |
|    ep_rew_mean          | 249           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 61            |
|    time_elapsed         | 3210          |
|    total_timesteps      | 124928        |
| train/                  |               |
|    approx_kl            | 1.3838697e-05 |
|    clip_fraction        | 0.000146      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00558      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 46.4          |
|    n_updates            | 600           |
|    policy_gradient_loss | -1.57e-05     |
|    value_loss           | 87.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.11e+03     |
|    ep_rew_mean          | 249          |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 62           |
|    time_elapsed         | 3263         |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 8.643957e-05 |
|    clip_fraction        | 0.00132      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00418     |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 58.2         |
|    n_updates            | 610          |
|    policy_gradient_loss | -0.000307    |
|    value_loss           | 89.1         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.1e+03      |
|    ep_rew_mean          | 252          |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 63           |
|    time_elapsed         | 3318         |
|    total_timesteps      | 129024       |
| train/                  |              |
|    approx_kl            | 0.0002588437 |
|    clip_fraction        | 0.000391     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00687     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 36           |
|    n_updates            | 620          |
|    policy_gradient_loss | -3.89e-05    |
|    value_loss           | 86.4         |
------------------------------------------
Num timesteps: 130000
Best mean reward: 235.72 - Last mean reward per episode: 251.50
Saving new best model at 126977 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.11e+03     |
|    ep_rew_mean          | 265          |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 64           |
|    time_elapsed         | 3372         |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 4.168623e-05 |
|    clip_fraction        | 0.000781     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00628     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 36.4         |
|    n_updates            | 630          |
|    policy_gradient_loss | -0.000117    |
|    value_loss           | 86.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.09e+03      |
|    ep_rew_mean          | 268           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 65            |
|    time_elapsed         | 3432          |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 1.3106735e-05 |
|    clip_fraction        | 0.000293      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00524      |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 48.1          |
|    n_updates            | 640           |
|    policy_gradient_loss | -3.69e-05     |
|    value_loss           | 88.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.07e+03     |
|    ep_rew_mean          | 269          |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 66           |
|    time_elapsed         | 3490         |
|    total_timesteps      | 135168       |
| train/                  |              |
|    approx_kl            | 0.0004930957 |
|    clip_fraction        | 0.00186      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00357     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 38.4         |
|    n_updates            | 650          |
|    policy_gradient_loss | -0.00022     |
|    value_loss           | 86.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.04e+03      |
|    ep_rew_mean          | 269           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 67            |
|    time_elapsed         | 3552          |
|    total_timesteps      | 137216        |
| train/                  |               |
|    approx_kl            | 2.6171678e-05 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00227      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 37.8          |
|    n_updates            | 660           |
|    policy_gradient_loss | 2.06e-05      |
|    value_loss           | 86            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.04e+03      |
|    ep_rew_mean          | 269           |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 68            |
|    time_elapsed         | 3609          |
|    total_timesteps      | 139264        |
| train/                  |               |
|    approx_kl            | 1.4136196e-05 |
|    clip_fraction        | 0.000391      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00278      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 33.7          |
|    n_updates            | 670           |
|    policy_gradient_loss | -3.97e-05     |
|    value_loss           | 88.6          |
-------------------------------------------
Num timesteps: 140000
Best mean reward: 251.50 - Last mean reward per episode: 275.16
Saving new best model at 139265 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.03e+03  |
|    ep_rew_mean          | 275       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 69        |
|    time_elapsed         | 3668      |
|    total_timesteps      | 141312    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00253  |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.1      |
|    n_updates            | 680       |
|    policy_gradient_loss | -7.38e-10 |
|    value_loss           | 89.7      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.01e+03 |
|    ep_rew_mean          | 278      |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 70       |
|    time_elapsed         | 3730     |
|    total_timesteps      | 143360   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00253 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 45       |
|    n_updates            | 690      |
|    policy_gradient_loss | 7.87e-10 |
|    value_loss           | 90.5     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.01e+03 |
|    ep_rew_mean          | 282      |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 71       |
|    time_elapsed         | 3785     |
|    total_timesteps      | 145408   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00253 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 52       |
|    n_updates            | 700      |
|    policy_gradient_loss | 5.97e-10 |
|    value_loss           | 91       |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.01e+03     |
|    ep_rew_mean          | 282          |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 72           |
|    time_elapsed         | 3836         |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 0.0002089162 |
|    clip_fraction        | 0.000439     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00132     |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 43.7         |
|    n_updates            | 710          |
|    policy_gradient_loss | -8.03e-05    |
|    value_loss           | 88.9         |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.01e+03 |
|    ep_rew_mean          | 287      |
| time/                   |          |
|    fps                  | 38       |
|    iterations           | 73       |
|    time_elapsed         | 3887     |
|    total_timesteps      | 149504   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00122 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 46.5     |
|    n_updates            | 720      |
|    policy_gradient_loss | 2.12e-10 |
|    value_loss           | 90.1     |
--------------------------------------
Num timesteps: 150000
Best mean reward: 275.16 - Last mean reward per episode: 287.38
Saving new best model at 147457 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.01e+03     |
|    ep_rew_mean          | 287          |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 74           |
|    time_elapsed         | 3937         |
|    total_timesteps      | 151552       |
| train/                  |              |
|    approx_kl            | 7.895724e-05 |
|    clip_fraction        | 0.000439     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.000853    |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 51.6         |
|    n_updates            | 730          |
|    policy_gradient_loss | -2.47e-05    |
|    value_loss           | 89.8         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.03e+03  |
|    ep_rew_mean          | 298       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 75        |
|    time_elapsed         | 3988      |
|    total_timesteps      | 153600    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000835 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.1      |
|    n_updates            | 740       |
|    policy_gradient_loss | 1.29e-09  |
|    value_loss           | 88.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.03e+03  |
|    ep_rew_mean          | 298       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 76        |
|    time_elapsed         | 4037      |
|    total_timesteps      | 155648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000835 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 45.1      |
|    n_updates            | 750       |
|    policy_gradient_loss | -8.59e-11 |
|    value_loss           | 87.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.05e+03  |
|    ep_rew_mean          | 304       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 77        |
|    time_elapsed         | 4086      |
|    total_timesteps      | 157696    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000835 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 49.9      |
|    n_updates            | 760       |
|    policy_gradient_loss | 2.1e-10   |
|    value_loss           | 87.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.05e+03  |
|    ep_rew_mean          | 304       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 78        |
|    time_elapsed         | 4137      |
|    total_timesteps      | 159744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000835 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.3      |
|    n_updates            | 770       |
|    policy_gradient_loss | 3.96e-10  |
|    value_loss           | 88.7      |
---------------------------------------
Num timesteps: 160000
Best mean reward: 287.38 - Last mean reward per episode: 308.99
Saving new best model at 159745 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.07e+03  |
|    ep_rew_mean          | 309       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 79        |
|    time_elapsed         | 4187      |
|    total_timesteps      | 161792    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000835 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 38.6      |
|    n_updates            | 780       |
|    policy_gradient_loss | -3.11e-10 |
|    value_loss           | 88.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.07e+03  |
|    ep_rew_mean          | 309       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 80        |
|    time_elapsed         | 4235      |
|    total_timesteps      | 163840    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000835 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 51.9      |
|    n_updates            | 790       |
|    policy_gradient_loss | 9.55e-10  |
|    value_loss           | 84.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.09e+03  |
|    ep_rew_mean          | 318       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 81        |
|    time_elapsed         | 4285      |
|    total_timesteps      | 165888    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000835 |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 34.8      |
|    n_updates            | 800       |
|    policy_gradient_loss | 3.64e-11  |
|    value_loss           | 90.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.09e+03  |
|    ep_rew_mean          | 318       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 82        |
|    time_elapsed         | 4335      |
|    total_timesteps      | 167936    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000835 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 43.1      |
|    n_updates            | 810       |
|    policy_gradient_loss | -5.43e-10 |
|    value_loss           | 84.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.11e+03  |
|    ep_rew_mean          | 327       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 83        |
|    time_elapsed         | 4385      |
|    total_timesteps      | 169984    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000835 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 36.9      |
|    n_updates            | 820       |
|    policy_gradient_loss | 9.74e-10  |
|    value_loss           | 89.2      |
---------------------------------------
Num timesteps: 170000
Best mean reward: 308.99 - Last mean reward per episode: 327.25
Saving new best model at 167937 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.11e+03  |
|    ep_rew_mean          | 327       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 84        |
|    time_elapsed         | 4437      |
|    total_timesteps      | 172032    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000835 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 46.9      |
|    n_updates            | 830       |
|    policy_gradient_loss | 6.42e-10  |
|    value_loss           | 88.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.13e+03  |
|    ep_rew_mean          | 338       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 85        |
|    time_elapsed         | 4490      |
|    total_timesteps      | 174080    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000835 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 48.2      |
|    n_updates            | 840       |
|    policy_gradient_loss | -4.31e-10 |
|    value_loss           | 86.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.12e+03  |
|    ep_rew_mean          | 340       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 86        |
|    time_elapsed         | 4547      |
|    total_timesteps      | 176128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000835 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 52.5      |
|    n_updates            | 850       |
|    policy_gradient_loss | 1.01e-09  |
|    value_loss           | 91.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.11e+03  |
|    ep_rew_mean          | 343       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 87        |
|    time_elapsed         | 4604      |
|    total_timesteps      | 178176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000835 |
|    explained_variance   | 0         |
|    learning_rate        | 0.0003    |
|    loss                 | 42.8      |
|    n_updates            | 860       |
|    policy_gradient_loss | -1.27e-09 |
|    value_loss           | 87.8      |
---------------------------------------
Num timesteps: 180000
Best mean reward: 327.25 - Last mean reward per episode: 345.54
Saving new best model at 179937 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.1e+03   |
|    ep_rew_mean          | 346       |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 88        |
|    time_elapsed         | 4662      |
|    total_timesteps      | 180224    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000835 |
|    explained_variance   | 5.96e-08  |
|    learning_rate        | 0.0003    |
|    loss                 | 36.6      |
|    n_updates            | 870       |
|    policy_gradient_loss | 2.56e-10  |
|    value_loss           | 89.3      |
---------------------------------------
Traceback (most recent call last):
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/freeway/run_supervised_gnn.py", line 290, in <module>
    model.learn(total_timesteps=160000, callback=[WandbCallback(), save_callback])
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 315, in learn
    return super().learn(
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 313, in learn
    self.train()
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 217, in train
    values, log_prob, entropy = self.policy.evaluate_actions(rollout_data.observations, actions)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/policies.py", line 730, in evaluate_actions
    features = self.extract_features(obs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/policies.py", line 672, in extract_features
    return super().extract_features(obs, self.features_extractor if features_extractor is None else features_extractor)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/policies.py", line 131, in extract_features
    return features_extractor(preprocessed_obs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/model/policy.py", line 40, in forward
    pyg_data = self.encoder.encode(observations)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/encoder/GraphEncoder.py", line 443, in encode
    if abs(node_features[i, 1] - node_features[j, 1]) <= proximity_threshold:
KeyboardInterrupt