
Using cpu device
-----------------------------
| time/              |      |
|    fps             | 284  |
|    iterations      | 1    |
|    time_elapsed    | 7    |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 93          |
|    iterations           | 2           |
|    time_elapsed         | 43          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.007834582 |
|    clip_fraction        | 0.0708      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | -0.0347     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.31        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00532    |
|    value_loss           | 3.44        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -2.05e+03   |
| time/                   |             |
|    fps                  | 79          |
|    iterations           | 3           |
|    time_elapsed         | 77          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.005182937 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.08       |
|    explained_variance   | 0.0286      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00264    |
|    n_updates            | 20          |
|    policy_gradient_loss | 3.19e-05    |
|    value_loss           | 13.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -2.05e+03   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 4           |
|    time_elapsed         | 115         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.011646495 |
|    clip_fraction        | 0.0323      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | -0.00145    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.913       |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00239    |
|    value_loss           | 11.2        |
-----------------------------------------
Num timesteps: 10000
Best mean reward: -inf - Last mean reward per episode: -1948.25
Saving new best model at 8193 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -1.95e+03   |
| time/                   |             |
|    fps                  | 65          |
|    iterations           | 5           |
|    time_elapsed         | 156         |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.015351605 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.02       |
|    explained_variance   | -9.54e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 7.58        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0118     |
|    value_loss           | 15.4        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -1.95e+03  |
| time/                   |            |
|    fps                  | 64         |
|    iterations           | 6          |
|    time_elapsed         | 189        |
|    total_timesteps      | 12288      |
| train/                  |            |
|    approx_kl            | 0.01665141 |
|    clip_fraction        | 0.0775     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.945     |
|    explained_variance   | 5.96e-08   |
|    learning_rate        | 0.0003     |
|    loss                 | 16.4       |
|    n_updates            | 50         |
|    policy_gradient_loss | -0.00495   |
|    value_loss           | 21.8       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -1.69e+03  |
| time/                   |            |
|    fps                  | 64         |
|    iterations           | 7          |
|    time_elapsed         | 223        |
|    total_timesteps      | 14336      |
| train/                  |            |
|    approx_kl            | 0.00617035 |
|    clip_fraction        | 0.0664     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.86      |
|    explained_variance   | -1.19e-07  |
|    learning_rate        | 0.0003     |
|    loss                 | 3.82       |
|    n_updates            | 60         |
|    policy_gradient_loss | -0.00542   |
|    value_loss           | 21.1       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -1.69e+03   |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 8           |
|    time_elapsed         | 256         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.010364147 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.809      |
|    explained_variance   | 0.541       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.71        |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0134     |
|    value_loss           | 7.03        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -1.48e+03   |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 9           |
|    time_elapsed         | 288         |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.018097278 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.72       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.39        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0142     |
|    value_loss           | 5.46        |
-----------------------------------------
Num timesteps: 20000
Best mean reward: -1948.25 - Last mean reward per episode: -1478.12
Saving new best model at 16385 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -1.48e+03   |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 10          |
|    time_elapsed         | 322         |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.015505055 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.628      |
|    explained_variance   | 0.801       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.78        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0125     |
|    value_loss           | 5.63        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -1.29e+03   |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 11          |
|    time_elapsed         | 355         |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.012785558 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.537      |
|    explained_variance   | 0.869       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.55        |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00831    |
|    value_loss           | 3.67        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -1.29e+03   |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 12          |
|    time_elapsed         | 392         |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.009277137 |
|    clip_fraction        | 0.0814      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.444      |
|    explained_variance   | 0.87        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.482       |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00701    |
|    value_loss           | 2.99        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -1.11e+03    |
| time/                   |              |
|    fps                  | 62           |
|    iterations           | 13           |
|    time_elapsed         | 425          |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0105674025 |
|    clip_fraction        | 0.078        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.378       |
|    explained_variance   | 0.878        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.418        |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00806     |
|    value_loss           | 2.14         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -1.11e+03    |
| time/                   |              |
|    fps                  | 62           |
|    iterations           | 14           |
|    time_elapsed         | 461          |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 0.0027333396 |
|    clip_fraction        | 0.0365       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.25        |
|    explained_variance   | 0.894        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.32         |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00411     |
|    value_loss           | 1.93         |
------------------------------------------
Num timesteps: 30000
Best mean reward: -1478.12 - Last mean reward per episode: -936.64
Saving new best model at 28673 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -937         |
| time/                   |              |
|    fps                  | 61           |
|    iterations           | 15           |
|    time_elapsed         | 495          |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 0.0026529417 |
|    clip_fraction        | 0.0292       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.215       |
|    explained_variance   | 0.929        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.402        |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00442     |
|    value_loss           | 1.48         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -937        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 16          |
|    time_elapsed         | 529         |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.005891146 |
|    clip_fraction        | 0.0571      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.298      |
|    explained_variance   | 0.854       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.266       |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00348    |
|    value_loss           | 2.23        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -831       |
| time/                   |            |
|    fps                  | 61         |
|    iterations           | 17         |
|    time_elapsed         | 562        |
|    total_timesteps      | 34816      |
| train/                  |            |
|    approx_kl            | 0.00506273 |
|    clip_fraction        | 0.0525     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.318     |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.33       |
|    n_updates            | 160        |
|    policy_gradient_loss | -0.00513   |
|    value_loss           | 1.41       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -831         |
| time/                   |              |
|    fps                  | 61           |
|    iterations           | 18           |
|    time_elapsed         | 597          |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0078551145 |
|    clip_fraction        | 0.0337       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.247       |
|    explained_variance   | 0.903        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.358        |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00536     |
|    value_loss           | 1.23         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -741         |
| time/                   |              |
|    fps                  | 61           |
|    iterations           | 19           |
|    time_elapsed         | 636          |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0047505675 |
|    clip_fraction        | 0.0396       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.27        |
|    explained_variance   | 0.876        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.179        |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.000592    |
|    value_loss           | 1.2          |
------------------------------------------
Num timesteps: 40000
Best mean reward: -936.64 - Last mean reward per episode: -741.39
Saving new best model at 36865 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -741         |
| time/                   |              |
|    fps                  | 61           |
|    iterations           | 20           |
|    time_elapsed         | 670          |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 0.0054850224 |
|    clip_fraction        | 0.0427       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.263       |
|    explained_variance   | 0.926        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.334        |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.0041      |
|    value_loss           | 1.27         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -664        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 21          |
|    time_elapsed         | 703         |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.008462819 |
|    clip_fraction        | 0.0366      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.231      |
|    explained_variance   | 0.899       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.16        |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00431    |
|    value_loss           | 1.01        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -664        |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 22          |
|    time_elapsed         | 737         |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.008981897 |
|    clip_fraction        | 0.0626      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.285      |
|    explained_variance   | 0.891       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.191       |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.00839    |
|    value_loss           | 1.52        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -608       |
| time/                   |            |
|    fps                  | 60         |
|    iterations           | 23         |
|    time_elapsed         | 773        |
|    total_timesteps      | 47104      |
| train/                  |            |
|    approx_kl            | 0.00826646 |
|    clip_fraction        | 0.0591     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.255     |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.177      |
|    n_updates            | 220        |
|    policy_gradient_loss | -0.00624   |
|    value_loss           | 1.36       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -608         |
| time/                   |              |
|    fps                  | 60           |
|    iterations           | 24           |
|    time_elapsed         | 809          |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0072114347 |
|    clip_fraction        | 0.0615       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.214       |
|    explained_variance   | 0.909        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.119        |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.00107     |
|    value_loss           | 0.821        |
------------------------------------------
Num timesteps: 50000
Best mean reward: -741.39 - Last mean reward per episode: -556.38
Saving new best model at 49153 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -556       |
| time/                   |            |
|    fps                  | 60         |
|    iterations           | 25         |
|    time_elapsed         | 845        |
|    total_timesteps      | 51200      |
| train/                  |            |
|    approx_kl            | 0.01072013 |
|    clip_fraction        | 0.054      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.242     |
|    explained_variance   | 0.913      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0773     |
|    n_updates            | 240        |
|    policy_gradient_loss | -0.00359   |
|    value_loss           | 0.958      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -556        |
| time/                   |             |
|    fps                  | 60          |
|    iterations           | 26          |
|    time_elapsed         | 882         |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.009692588 |
|    clip_fraction        | 0.0445      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.179      |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.14        |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00569    |
|    value_loss           | 0.992       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -496        |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 27          |
|    time_elapsed         | 923         |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.008223455 |
|    clip_fraction        | 0.0382      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.214      |
|    explained_variance   | 0.928       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0672      |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0033     |
|    value_loss           | 0.682       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -496         |
| time/                   |              |
|    fps                  | 59           |
|    iterations           | 28           |
|    time_elapsed         | 967          |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0074078823 |
|    clip_fraction        | 0.0439       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.182       |
|    explained_variance   | 0.934        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0957       |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.00405     |
|    value_loss           | 0.664        |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -452       |
| time/                   |            |
|    fps                  | 59         |
|    iterations           | 29         |
|    time_elapsed         | 1002       |
|    total_timesteps      | 59392      |
| train/                  |            |
|    approx_kl            | 0.00878552 |
|    clip_fraction        | 0.0438     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.165     |
|    explained_variance   | 0.938      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0972     |
|    n_updates            | 280        |
|    policy_gradient_loss | -0.00459   |
|    value_loss           | 0.713      |
----------------------------------------
Num timesteps: 60000
Best mean reward: -556.38 - Last mean reward per episode: -452.32
Saving new best model at 57345 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -452         |
| time/                   |              |
|    fps                  | 58           |
|    iterations           | 30           |
|    time_elapsed         | 1042         |
|    total_timesteps      | 61440        |
| train/                  |              |
|    approx_kl            | 0.0060178293 |
|    clip_fraction        | 0.051        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.186       |
|    explained_variance   | 0.944        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0568       |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.00571     |
|    value_loss           | 0.541        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -416        |
| time/                   |             |
|    fps                  | 58          |
|    iterations           | 31          |
|    time_elapsed         | 1076        |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.008203935 |
|    clip_fraction        | 0.0499      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.175      |
|    explained_variance   | 0.905       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.076       |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00737    |
|    value_loss           | 0.691       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -416         |
| time/                   |              |
|    fps                  | 58           |
|    iterations           | 32           |
|    time_elapsed         | 1111         |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0046610455 |
|    clip_fraction        | 0.0385       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.129       |
|    explained_variance   | 0.931        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.135        |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.00397     |
|    value_loss           | 0.518        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -376        |
| time/                   |             |
|    fps                  | 58          |
|    iterations           | 33          |
|    time_elapsed         | 1151        |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.007698769 |
|    clip_fraction        | 0.0456      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.168      |
|    explained_variance   | 0.943       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0369      |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.00435    |
|    value_loss           | 0.554       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -376         |
| time/                   |              |
|    fps                  | 58           |
|    iterations           | 34           |
|    time_elapsed         | 1191         |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 0.0043696337 |
|    clip_fraction        | 0.0299       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0973      |
|    explained_variance   | 0.909        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0528       |
|    n_updates            | 330          |
|    policy_gradient_loss | -0.0037      |
|    value_loss           | 0.667        |
------------------------------------------
Num timesteps: 70000
Best mean reward: -452.32 - Last mean reward per episode: -339.79
Saving new best model at 69633 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -340        |
| time/                   |             |
|    fps                  | 58          |
|    iterations           | 35          |
|    time_elapsed         | 1231        |
|    total_timesteps      | 71680       |
| train/                  |             |
|    approx_kl            | 0.009185256 |
|    clip_fraction        | 0.05        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.118      |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0448      |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00647    |
|    value_loss           | 0.585       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -340         |
| time/                   |              |
|    fps                  | 58           |
|    iterations           | 36           |
|    time_elapsed         | 1268         |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0054802597 |
|    clip_fraction        | 0.0524       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.146       |
|    explained_variance   | 0.92         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0235       |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.00328     |
|    value_loss           | 0.586        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -304        |
| time/                   |             |
|    fps                  | 57          |
|    iterations           | 37          |
|    time_elapsed         | 1309        |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.008650374 |
|    clip_fraction        | 0.0551      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.178      |
|    explained_variance   | 0.939       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0864      |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0055     |
|    value_loss           | 0.63        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -304        |
| time/                   |             |
|    fps                  | 57          |
|    iterations           | 38          |
|    time_elapsed         | 1349        |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.011547871 |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.182      |
|    explained_variance   | 0.938       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0265      |
|    n_updates            | 370         |
|    policy_gradient_loss | 0.00179     |
|    value_loss           | 0.398       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -279         |
| time/                   |              |
|    fps                  | 57           |
|    iterations           | 39           |
|    time_elapsed         | 1389         |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 0.0074722096 |
|    clip_fraction        | 0.0545       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.175       |
|    explained_variance   | 0.924        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0995       |
|    n_updates            | 380          |
|    policy_gradient_loss | 0.00397      |
|    value_loss           | 0.89         |
------------------------------------------
Num timesteps: 80000
Best mean reward: -339.79 - Last mean reward per episode: -278.55
Saving new best model at 77825 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -279         |
| time/                   |              |
|    fps                  | 57           |
|    iterations           | 40           |
|    time_elapsed         | 1429         |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 0.0076186024 |
|    clip_fraction        | 0.0441       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.149       |
|    explained_variance   | 0.894        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0497       |
|    n_updates            | 390          |
|    policy_gradient_loss | -0.00455     |
|    value_loss           | 0.884        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -257         |
| time/                   |              |
|    fps                  | 57           |
|    iterations           | 41           |
|    time_elapsed         | 1466         |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0062815505 |
|    clip_fraction        | 0.057        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.173       |
|    explained_variance   | 0.929        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.025        |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00753     |
|    value_loss           | 0.482        |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -257       |
| time/                   |            |
|    fps                  | 57         |
|    iterations           | 42         |
|    time_elapsed         | 1502       |
|    total_timesteps      | 86016      |
| train/                  |            |
|    approx_kl            | 0.02232706 |
|    clip_fraction        | 0.0964     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.154     |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.24       |
|    n_updates            | 410        |
|    policy_gradient_loss | 0.000988   |
|    value_loss           | 0.907      |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -234         |
| time/                   |              |
|    fps                  | 57           |
|    iterations           | 43           |
|    time_elapsed         | 1537         |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 0.0070426306 |
|    clip_fraction        | 0.0489       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.131       |
|    explained_variance   | 0.936        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0425       |
|    n_updates            | 420          |
|    policy_gradient_loss | -0.000853    |
|    value_loss           | 0.529        |
------------------------------------------
Num timesteps: 90000
Best mean reward: -278.55 - Last mean reward per episode: -233.74
Saving new best model at 86017 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -234        |
| time/                   |             |
|    fps                  | 57          |
|    iterations           | 44          |
|    time_elapsed         | 1571        |
|    total_timesteps      | 90112       |
| train/                  |             |
|    approx_kl            | 0.009506974 |
|    clip_fraction        | 0.0473      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.138      |
|    explained_variance   | 0.88        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.067       |
|    n_updates            | 430         |
|    policy_gradient_loss | 0.000884    |
|    value_loss           | 0.983       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -214        |
| time/                   |             |
|    fps                  | 57          |
|    iterations           | 45          |
|    time_elapsed         | 1611        |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.006955244 |
|    clip_fraction        | 0.0348      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.107      |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.235       |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00343    |
|    value_loss           | 0.811       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -214        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 46          |
|    time_elapsed         | 1653        |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.014206754 |
|    clip_fraction        | 0.056       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.127      |
|    explained_variance   | 0.915       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0619      |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0165     |
|    value_loss           | 0.625       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -200        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 47          |
|    time_elapsed         | 1698        |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.014992067 |
|    clip_fraction        | 0.0701      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.176      |
|    explained_variance   | 0.944       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.039       |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00538    |
|    value_loss           | 0.519       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -200        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 48          |
|    time_elapsed         | 1740        |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.016158018 |
|    clip_fraction        | 0.0825      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.208      |
|    explained_variance   | 0.939       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0487      |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00672    |
|    value_loss           | 0.524       |
-----------------------------------------
Num timesteps: 100000
Best mean reward: -233.74 - Last mean reward per episode: -192.19
Saving new best model at 98305 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -192        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 49          |
|    time_elapsed         | 1779        |
|    total_timesteps      | 100352      |
| train/                  |             |
|    approx_kl            | 0.011109095 |
|    clip_fraction        | 0.0779      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.229      |
|    explained_variance   | 0.933       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.124       |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.0111     |
|    value_loss           | 0.971       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -192        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 50          |
|    time_elapsed         | 1818        |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.015176557 |
|    clip_fraction        | 0.0743      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.223      |
|    explained_variance   | 0.936       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0902      |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.0113     |
|    value_loss           | 0.872       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -183        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 51          |
|    time_elapsed         | 1859        |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.012024345 |
|    clip_fraction        | 0.0552      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.174      |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0838      |
|    n_updates            | 500         |
|    policy_gradient_loss | 0.00154     |
|    value_loss           | 0.469       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -183         |
| time/                   |              |
|    fps                  | 56           |
|    iterations           | 52           |
|    time_elapsed         | 1896         |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 0.0135711655 |
|    clip_fraction        | 0.107        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.359       |
|    explained_variance   | 0.92         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.134        |
|    n_updates            | 510          |
|    policy_gradient_loss | -0.0116      |
|    value_loss           | 1.4          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -188        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 53          |
|    time_elapsed         | 1929        |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.007768004 |
|    clip_fraction        | 0.0871      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.32       |
|    explained_variance   | 0.951       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0438      |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.00177    |
|    value_loss           | 0.854       |
-----------------------------------------
Num timesteps: 110000
Best mean reward: -192.19 - Last mean reward per episode: -188.02
Saving new best model at 106497 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -188        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 54          |
|    time_elapsed         | 1966        |
|    total_timesteps      | 110592      |
| train/                  |             |
|    approx_kl            | 0.014298963 |
|    clip_fraction        | 0.0797      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.208      |
|    explained_variance   | 0.907       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.144       |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.00879    |
|    value_loss           | 0.834       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -175        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 55          |
|    time_elapsed         | 2000        |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.020427521 |
|    clip_fraction        | 0.0927      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.177      |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.126       |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.00781    |
|    value_loss           | 0.572       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -175        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 56          |
|    time_elapsed         | 2035        |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.018419486 |
|    clip_fraction        | 0.0625      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.207      |
|    explained_variance   | 0.937       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0621      |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.00639    |
|    value_loss           | 0.583       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -161        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 57          |
|    time_elapsed         | 2073        |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.015018359 |
|    clip_fraction        | 0.0842      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.182      |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0646      |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.00227    |
|    value_loss           | 0.661       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -161        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 58          |
|    time_elapsed         | 2109        |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.012451928 |
|    clip_fraction        | 0.0768      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.173      |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000101    |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.0143     |
|    value_loss           | 0.417       |
-----------------------------------------
Num timesteps: 120000
Best mean reward: -188.02 - Last mean reward per episode: -148.71
Saving new best model at 118785 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -149        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 59          |
|    time_elapsed         | 2148        |
|    total_timesteps      | 120832      |
| train/                  |             |
|    approx_kl            | 0.010376122 |
|    clip_fraction        | 0.0829      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.198      |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0407      |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0165     |
|    value_loss           | 0.651       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -149       |
| time/                   |            |
|    fps                  | 56         |
|    iterations           | 60         |
|    time_elapsed         | 2189       |
|    total_timesteps      | 122880     |
| train/                  |            |
|    approx_kl            | 0.01132662 |
|    clip_fraction        | 0.0785     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.219     |
|    explained_variance   | 0.949      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0532     |
|    n_updates            | 590        |
|    policy_gradient_loss | -0.00684   |
|    value_loss           | 0.458      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -135        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 61          |
|    time_elapsed         | 2227        |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.010864215 |
|    clip_fraction        | 0.0571      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.177      |
|    explained_variance   | 0.949       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0683      |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.00641    |
|    value_loss           | 0.413       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -135        |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 62          |
|    time_elapsed         | 2267        |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.013122543 |
|    clip_fraction        | 0.0862      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.218      |
|    explained_variance   | 0.957       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.15        |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0126     |
|    value_loss           | 0.478       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -129        |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 63          |
|    time_elapsed         | 2308        |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.011873742 |
|    clip_fraction        | 0.0864      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.283      |
|    explained_variance   | 0.93        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0175      |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.000757   |
|    value_loss           | 0.628       |
-----------------------------------------
Num timesteps: 130000
Best mean reward: -148.71 - Last mean reward per episode: -128.66
Saving new best model at 126977 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -129        |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 64          |
|    time_elapsed         | 2349        |
|    total_timesteps      | 131072      |
| train/                  |             |
|    approx_kl            | 0.023108158 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.337      |
|    explained_variance   | 0.925       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0208      |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.014      |
|    value_loss           | 0.629       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -122        |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 65          |
|    time_elapsed         | 2388        |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.030490873 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.341      |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.038       |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.0076     |
|    value_loss           | 0.614       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -122       |
| time/                   |            |
|    fps                  | 55         |
|    iterations           | 66         |
|    time_elapsed         | 2428       |
|    total_timesteps      | 135168     |
| train/                  |            |
|    approx_kl            | 0.01332732 |
|    clip_fraction        | 0.0646     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.206     |
|    explained_variance   | 0.956      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0223     |
|    n_updates            | 650        |
|    policy_gradient_loss | -0.0103    |
|    value_loss           | 0.474      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -114        |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 67          |
|    time_elapsed         | 2465        |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.012767777 |
|    clip_fraction        | 0.0778      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.211      |
|    explained_variance   | 0.949       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.026       |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.00254    |
|    value_loss           | 0.491       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -114        |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 68          |
|    time_elapsed         | 2502        |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.024041655 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.29       |
|    explained_variance   | 0.946       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0811      |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0095     |
|    value_loss           | 0.617       |
-----------------------------------------
Num timesteps: 140000
Best mean reward: -128.66 - Last mean reward per episode: -107.43
Saving new best model at 139265 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -107       |
| time/                   |            |
|    fps                  | 55         |
|    iterations           | 69         |
|    time_elapsed         | 2543       |
|    total_timesteps      | 141312     |
| train/                  |            |
|    approx_kl            | 0.01148556 |
|    clip_fraction        | 0.0843     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.207     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0128     |
|    n_updates            | 680        |
|    policy_gradient_loss | -0.0126    |
|    value_loss           | 0.526      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -107        |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 70          |
|    time_elapsed         | 2582        |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.011074621 |
|    clip_fraction        | 0.0616      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.17       |
|    explained_variance   | 0.949       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.156       |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00362    |
|    value_loss           | 0.376       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -97.2       |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 71          |
|    time_elapsed         | 2622        |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.011776904 |
|    clip_fraction        | 0.0499      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.182      |
|    explained_variance   | 0.946       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0516      |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.00566    |
|    value_loss           | 0.511       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -97.2       |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 72          |
|    time_elapsed         | 2667        |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.014539598 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.33       |
|    explained_variance   | 0.936       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.101       |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.00821    |
|    value_loss           | 0.561       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -91.3      |
| time/                   |            |
|    fps                  | 55         |
|    iterations           | 73         |
|    time_elapsed         | 2704       |
|    total_timesteps      | 149504     |
| train/                  |            |
|    approx_kl            | 0.01986932 |
|    clip_fraction        | 0.131      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.293     |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0402     |
|    n_updates            | 720        |
|    policy_gradient_loss | -0.0182    |
|    value_loss           | 0.545      |
----------------------------------------
Num timesteps: 150000
Best mean reward: -107.43 - Last mean reward per episode: -91.35
Saving new best model at 147457 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -91.3       |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 74          |
|    time_elapsed         | 2740        |
|    total_timesteps      | 151552      |
| train/                  |             |
|    approx_kl            | 0.027534217 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.257      |
|    explained_variance   | 0.935       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00911    |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.0128     |
|    value_loss           | 0.669       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -85.3       |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 75          |
|    time_elapsed         | 2779        |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.010912128 |
|    clip_fraction        | 0.0621      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.216      |
|    explained_variance   | 0.939       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0092      |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.00666    |
|    value_loss           | 0.559       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -85.3       |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 76          |
|    time_elapsed         | 2814        |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.018775346 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.277      |
|    explained_variance   | 0.939       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.045       |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0107     |
|    value_loss           | 0.424       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -80.6       |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 77          |
|    time_elapsed         | 2848        |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.019018523 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.275      |
|    explained_variance   | 0.913       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0826      |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00406    |
|    value_loss           | 0.613       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -80.6       |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 78          |
|    time_elapsed         | 2887        |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.017106827 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.282      |
|    explained_variance   | 0.955       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0244      |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.00709    |
|    value_loss           | 0.345       |
-----------------------------------------
Num timesteps: 160000
Best mean reward: -91.35 - Last mean reward per episode: -77.24
Saving new best model at 159745 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -77.2       |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 79          |
|    time_elapsed         | 2927        |
|    total_timesteps      | 161792      |
| train/                  |             |
|    approx_kl            | 0.024996964 |
|    clip_fraction        | 0.0843      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.245      |
|    explained_variance   | 0.937       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0296      |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00944    |
|    value_loss           | 0.43        |
-----------------------------------------