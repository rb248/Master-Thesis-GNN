
Using cpu device
-----------------------------
| time/              |      |
|    fps             | 242  |
|    iterations      | 1    |
|    time_elapsed    | 8    |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.06e+03    |
|    ep_rew_mean          | -1.03e+03   |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 2           |
|    time_elapsed         | 68          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.010874428 |
|    clip_fraction        | 0.0575      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 0.02        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.396       |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00196    |
|    value_loss           | 5.67        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.38e+03    |
|    ep_rew_mean          | -1.18e+03   |
| time/                   |             |
|    fps                  | 48          |
|    iterations           | 3           |
|    time_elapsed         | 125         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.010746479 |
|    clip_fraction        | 0.0307      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.08       |
|    explained_variance   | 1.19e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0155      |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00177    |
|    value_loss           | 14.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.38e+03    |
|    ep_rew_mean          | -1.18e+03   |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 4           |
|    time_elapsed         | 175         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.015769381 |
|    clip_fraction        | 0.0727      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.02       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 2.26        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00444    |
|    value_loss           | 23.5        |
-----------------------------------------
Num timesteps: 10000
Best mean reward: -inf - Last mean reward per episode: -1255.50
Saving new best model at 8193 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.73e+03    |
|    ep_rew_mean          | -1.26e+03   |
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 5           |
|    time_elapsed         | 227         |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.015963852 |
|    clip_fraction        | 0.0739      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.978      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.54        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00137    |
|    value_loss           | 23.3        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.86e+03   |
|    ep_rew_mean          | -1.18e+03  |
| time/                   |            |
|    fps                  | 43         |
|    iterations           | 6          |
|    time_elapsed         | 282        |
|    total_timesteps      | 12288      |
| train/                  |            |
|    approx_kl            | 0.01399924 |
|    clip_fraction        | 0.154      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.842     |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 22.6       |
|    n_updates            | 50         |
|    policy_gradient_loss | -0.00782   |
|    value_loss           | 41.7       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.8e+03      |
|    ep_rew_mean          | -1.09e+03    |
| time/                   |              |
|    fps                  | 42           |
|    iterations           | 7            |
|    time_elapsed         | 339          |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 0.0065596728 |
|    clip_fraction        | 0.0827       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.773       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 25.6         |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.0031      |
|    value_loss           | 41.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.8e+03      |
|    ep_rew_mean          | -1.09e+03    |
| time/                   |              |
|    fps                  | 41           |
|    iterations           | 8            |
|    time_elapsed         | 390          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0027130048 |
|    clip_fraction        | 0.0125       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.751       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 37.9         |
|    n_updates            | 70           |
|    policy_gradient_loss | 0.00026      |
|    value_loss           | 50           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.73e+03     |
|    ep_rew_mean          | -1.01e+03    |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 9            |
|    time_elapsed         | 457          |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0029811792 |
|    clip_fraction        | 0.041        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.71        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 19.5         |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00147     |
|    value_loss           | 48.9         |
------------------------------------------
Num timesteps: 20000
Best mean reward: -1255.50 - Last mean reward per episode: -961.21
Saving new best model at 18797 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.69e+03     |
|    ep_rew_mean          | -961         |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 10           |
|    time_elapsed         | 515          |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 0.0066795778 |
|    clip_fraction        | 0.0427       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.666       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 35.6         |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00197     |
|    value_loss           | 45.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.77e+03     |
|    ep_rew_mean          | -926         |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 11           |
|    time_elapsed         | 569          |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0054561533 |
|    clip_fraction        | 0.0348       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.583       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 19.7         |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.0017      |
|    value_loss           | 49.1         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.77e+03     |
|    ep_rew_mean          | -926         |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 12           |
|    time_elapsed         | 624          |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0037627933 |
|    clip_fraction        | 0.0289       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.492       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 27.9         |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00158     |
|    value_loss           | 65.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.73e+03     |
|    ep_rew_mean          | -862         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 13           |
|    time_elapsed         | 687          |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0014221119 |
|    clip_fraction        | 0.0179       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.479       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 38           |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.000191    |
|    value_loss           | 64.2         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.66e+03     |
|    ep_rew_mean          | -773         |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 14           |
|    time_elapsed         | 750          |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 0.0044414448 |
|    clip_fraction        | 0.0533       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.439       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 37.6         |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00254     |
|    value_loss           | 72.3         |
------------------------------------------
Num timesteps: 30000
Best mean reward: -961.21 - Last mean reward per episode: -725.14
Saving new best model at 28673 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.61e+03     |
|    ep_rew_mean          | -725         |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 15           |
|    time_elapsed         | 813          |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 0.0015323586 |
|    clip_fraction        | 0.021        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.384       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 50           |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00159     |
|    value_loss           | 68.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.56e+03     |
|    ep_rew_mean          | -670         |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 16           |
|    time_elapsed         | 879          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0013297986 |
|    clip_fraction        | 0.00967      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.344       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 36.7         |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.000162    |
|    value_loss           | 73.3         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.56e+03      |
|    ep_rew_mean          | -641          |
| time/                   |               |
|    fps                  | 37            |
|    iterations           | 17            |
|    time_elapsed         | 936           |
|    total_timesteps      | 34816         |
| train/                  |               |
|    approx_kl            | 0.00081368786 |
|    clip_fraction        | 0.0102        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.32         |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 32.6          |
|    n_updates            | 160           |
|    policy_gradient_loss | 1.32e-06      |
|    value_loss           | 69.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.56e+03      |
|    ep_rew_mean          | -602          |
| time/                   |               |
|    fps                  | 37            |
|    iterations           | 18            |
|    time_elapsed         | 994           |
|    total_timesteps      | 36864         |
| train/                  |               |
|    approx_kl            | 0.00082319416 |
|    clip_fraction        | 0.00435       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.334        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 35.1          |
|    n_updates            | 170           |
|    policy_gradient_loss | -0.000406     |
|    value_loss           | 71.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.58e+03     |
|    ep_rew_mean          | -572         |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 19           |
|    time_elapsed         | 1051         |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0018779916 |
|    clip_fraction        | 0.0117       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.271       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 27.1         |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.000771    |
|    value_loss           | 70.1         |
------------------------------------------
Num timesteps: 40000
Best mean reward: -725.14 - Last mean reward per episode: -548.28
Saving new best model at 39805 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.49e+03     |
|    ep_rew_mean          | -548         |
| time/                   |              |
|    fps                  | 36           |
|    iterations           | 20           |
|    time_elapsed         | 1117         |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 0.0011173923 |
|    clip_fraction        | 0.0174       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.234       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 27.8         |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.000686    |
|    value_loss           | 73.3         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.41e+03      |
|    ep_rew_mean          | -524          |
| time/                   |               |
|    fps                  | 36            |
|    iterations           | 21            |
|    time_elapsed         | 1188          |
|    total_timesteps      | 43008         |
| train/                  |               |
|    approx_kl            | 0.00022455645 |
|    clip_fraction        | 0.00264       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.233        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 36.3          |
|    n_updates            | 200           |
|    policy_gradient_loss | 7.69e-05      |
|    value_loss           | 66.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.39e+03      |
|    ep_rew_mean          | -515          |
| time/                   |               |
|    fps                  | 36            |
|    iterations           | 22            |
|    time_elapsed         | 1247          |
|    total_timesteps      | 45056         |
| train/                  |               |
|    approx_kl            | 0.00059796404 |
|    clip_fraction        | 0.0112        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.215        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 25.7          |
|    n_updates            | 210           |
|    policy_gradient_loss | -0.000565     |
|    value_loss           | 61            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.43e+03     |
|    ep_rew_mean          | -497         |
| time/                   |              |
|    fps                  | 36           |
|    iterations           | 23           |
|    time_elapsed         | 1303         |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 0.0012647767 |
|    clip_fraction        | 0.0172       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.164       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 33.1         |
|    n_updates            | 220          |
|    policy_gradient_loss | -0.000767    |
|    value_loss           | 72.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.45e+03      |
|    ep_rew_mean          | -485          |
| time/                   |               |
|    fps                  | 36            |
|    iterations           | 24            |
|    time_elapsed         | 1359          |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 0.00026081185 |
|    clip_fraction        | 0.00361       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.169        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 31.5          |
|    n_updates            | 230           |
|    policy_gradient_loss | -0.000218     |
|    value_loss           | 69.1          |
-------------------------------------------
Num timesteps: 50000
Best mean reward: -548.28 - Last mean reward per episode: -484.77
Saving new best model at 49091 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.45e+03      |
|    ep_rew_mean          | -485          |
| time/                   |               |
|    fps                  | 36            |
|    iterations           | 25            |
|    time_elapsed         | 1414          |
|    total_timesteps      | 51200         |
| train/                  |               |
|    approx_kl            | 0.00035937864 |
|    clip_fraction        | 0.00962       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.159        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 35.1          |
|    n_updates            | 240           |
|    policy_gradient_loss | -0.000463     |
|    value_loss           | 73.3          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.44e+03     |
|    ep_rew_mean          | -480         |
| time/                   |              |
|    fps                  | 36           |
|    iterations           | 26           |
|    time_elapsed         | 1472         |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0007594428 |
|    clip_fraction        | 0.00747      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.152       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 24.7         |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.000301    |
|    value_loss           | 58.1         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.42e+03     |
|    ep_rew_mean          | -456         |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 27           |
|    time_elapsed         | 1546         |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 7.548358e-05 |
|    clip_fraction        | 0.00229      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.149       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 31.6         |
|    n_updates            | 260          |
|    policy_gradient_loss | 0.000138     |
|    value_loss           | 75.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.4e+03      |
|    ep_rew_mean          | -436         |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 28           |
|    time_elapsed         | 1611         |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0007806318 |
|    clip_fraction        | 0.00835      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.124       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 36.8         |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.000357    |
|    value_loss           | 71.9         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.39e+03      |
|    ep_rew_mean          | -432          |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 29            |
|    time_elapsed         | 1674          |
|    total_timesteps      | 59392         |
| train/                  |               |
|    approx_kl            | 0.00013077998 |
|    clip_fraction        | 0.00527       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.114        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 18.7          |
|    n_updates            | 280           |
|    policy_gradient_loss | 0.000326      |
|    value_loss           | 62.1          |
-------------------------------------------
Num timesteps: 60000
Best mean reward: -484.77 - Last mean reward per episode: -423.46
Saving new best model at 59393 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.38e+03      |
|    ep_rew_mean          | -423          |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 30            |
|    time_elapsed         | 1740          |
|    total_timesteps      | 61440         |
| train/                  |               |
|    approx_kl            | 0.00067276316 |
|    clip_fraction        | 0.0083        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.093        |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 34.4          |
|    n_updates            | 290           |
|    policy_gradient_loss | -0.000392     |
|    value_loss           | 71.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.36e+03      |
|    ep_rew_mean          | -414          |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 31            |
|    time_elapsed         | 1806          |
|    total_timesteps      | 63488         |
| train/                  |               |
|    approx_kl            | 0.00031603075 |
|    clip_fraction        | 0.00288       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0818       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 34.9          |
|    n_updates            | 300           |
|    policy_gradient_loss | -6.55e-05     |
|    value_loss           | 71.7          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.35e+03     |
|    ep_rew_mean          | -404         |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 32           |
|    time_elapsed         | 1867         |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0004044343 |
|    clip_fraction        | 0.00845      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0642      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 36.7         |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.0004      |
|    value_loss           | 72           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.34e+03      |
|    ep_rew_mean          | -394          |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 33            |
|    time_elapsed         | 1935          |
|    total_timesteps      | 67584         |
| train/                  |               |
|    approx_kl            | 0.00014975583 |
|    clip_fraction        | 0.00298       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0541       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 30.2          |
|    n_updates            | 320           |
|    policy_gradient_loss | -0.000178     |
|    value_loss           | 70.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.37e+03      |
|    ep_rew_mean          | -393          |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 34            |
|    time_elapsed         | 1990          |
|    total_timesteps      | 69632         |
| train/                  |               |
|    approx_kl            | 3.2513548e-05 |
|    clip_fraction        | 0.00376       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0599       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 22.5          |
|    n_updates            | 330           |
|    policy_gradient_loss | -0.000345     |
|    value_loss           | 71.3          |
-------------------------------------------
Num timesteps: 70000
Best mean reward: -423.46 - Last mean reward per episode: -392.74
Saving new best model at 68619 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.37e+03      |
|    ep_rew_mean          | -393          |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 35            |
|    time_elapsed         | 2046          |
|    total_timesteps      | 71680         |
| train/                  |               |
|    approx_kl            | 0.00015365463 |
|    clip_fraction        | 0.00107       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0579       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 31.6          |
|    n_updates            | 340           |
|    policy_gradient_loss | -3.64e-06     |
|    value_loss           | 71.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.39e+03     |
|    ep_rew_mean          | -388         |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 36           |
|    time_elapsed         | 2106         |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 9.469065e-05 |
|    clip_fraction        | 0.00244      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0605      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 31.7         |
|    n_updates            | 350          |
|    policy_gradient_loss | -3.31e-05    |
|    value_loss           | 70.2         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.42e+03     |
|    ep_rew_mean          | -384         |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 37           |
|    time_elapsed         | 2161         |
|    total_timesteps      | 75776        |
| train/                  |              |
|    approx_kl            | 0.0001589912 |
|    clip_fraction        | 0.00122      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0477      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 27.9         |
|    n_updates            | 360          |
|    policy_gradient_loss | 5.93e-07     |
|    value_loss           | 71.1         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.42e+03      |
|    ep_rew_mean          | -384          |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 38            |
|    time_elapsed         | 2215          |
|    total_timesteps      | 77824         |
| train/                  |               |
|    approx_kl            | 8.6620916e-05 |
|    clip_fraction        | 0.00283       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0513       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 28.2          |
|    n_updates            | 370           |
|    policy_gradient_loss | -0.000114     |
|    value_loss           | 68.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.43e+03     |
|    ep_rew_mean          | -380         |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 39           |
|    time_elapsed         | 2268         |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 9.583315e-05 |
|    clip_fraction        | 0.00239      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0543      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 34.3         |
|    n_updates            | 380          |
|    policy_gradient_loss | 0.000107     |
|    value_loss           | 70.9         |
------------------------------------------
Num timesteps: 80000
Best mean reward: -392.74 - Last mean reward per episode: -379.77
Saving new best model at 77825 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.42e+03    |
|    ep_rew_mean          | -378        |
| time/                   |             |
|    fps                  | 35          |
|    iterations           | 40          |
|    time_elapsed         | 2329        |
|    total_timesteps      | 81920       |
| train/                  |             |
|    approx_kl            | 0.000294767 |
|    clip_fraction        | 0.00288     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0439     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 37.4        |
|    n_updates            | 390         |
|    policy_gradient_loss | -8.18e-05   |
|    value_loss           | 63.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.41e+03     |
|    ep_rew_mean          | -367         |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 41           |
|    time_elapsed         | 2394         |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0001716461 |
|    clip_fraction        | 0.000391     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0413      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 33.3         |
|    n_updates            | 400          |
|    policy_gradient_loss | -4.38e-05    |
|    value_loss           | 76           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.4e+03       |
|    ep_rew_mean          | -363          |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 42            |
|    time_elapsed         | 2460          |
|    total_timesteps      | 86016         |
| train/                  |               |
|    approx_kl            | 0.00012865351 |
|    clip_fraction        | 0.00176       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.035        |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 39.2          |
|    n_updates            | 410           |
|    policy_gradient_loss | -0.000239     |
|    value_loss           | 69.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.44e+03      |
|    ep_rew_mean          | -349          |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 43            |
|    time_elapsed         | 2513          |
|    total_timesteps      | 88064         |
| train/                  |               |
|    approx_kl            | 0.00011776542 |
|    clip_fraction        | 0.00161       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0315       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 38.3          |
|    n_updates            | 420           |
|    policy_gradient_loss | -9.86e-05     |
|    value_loss           | 75.9          |
-------------------------------------------
Num timesteps: 90000
Best mean reward: -379.77 - Last mean reward per episode: -351.78
Saving new best model at 89872 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.43e+03      |
|    ep_rew_mean          | -352          |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 44            |
|    time_elapsed         | 2573          |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 0.00023786939 |
|    clip_fraction        | 0.00146       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0229       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 40.7          |
|    n_updates            | 430           |
|    policy_gradient_loss | -0.000162     |
|    value_loss           | 69.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.43e+03     |
|    ep_rew_mean          | -352         |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 45           |
|    time_elapsed         | 2629         |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 8.585569e-05 |
|    clip_fraction        | 0.00283      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0162      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 31.2         |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.000282    |
|    value_loss           | 56.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.43e+03      |
|    ep_rew_mean          | -348          |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 46            |
|    time_elapsed         | 2699          |
|    total_timesteps      | 94208         |
| train/                  |               |
|    approx_kl            | 0.00024940015 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0161       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 29.3          |
|    n_updates            | 450           |
|    policy_gradient_loss | 9.87e-05      |
|    value_loss           | 73.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.42e+03      |
|    ep_rew_mean          | -339          |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 47            |
|    time_elapsed         | 2773          |
|    total_timesteps      | 96256         |
| train/                  |               |
|    approx_kl            | 5.4495526e-05 |
|    clip_fraction        | 0.000928      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0175       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 44.9          |
|    n_updates            | 460           |
|    policy_gradient_loss | -0.000207     |
|    value_loss           | 82.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.41e+03      |
|    ep_rew_mean          | -335          |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 48            |
|    time_elapsed         | 2851          |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 0.00011361265 |
|    clip_fraction        | 0.00234       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0134       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 40.8          |
|    n_updates            | 470           |
|    policy_gradient_loss | -0.000358     |
|    value_loss           | 69.6          |
-------------------------------------------
Num timesteps: 100000
Best mean reward: -351.78 - Last mean reward per episode: -333.23
Saving new best model at 98305 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.4e+03       |
|    ep_rew_mean          | -333          |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 49            |
|    time_elapsed         | 2937          |
|    total_timesteps      | 100352        |
| train/                  |               |
|    approx_kl            | 3.8032944e-05 |
|    clip_fraction        | 0.00112       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0113       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 40.2          |
|    n_updates            | 480           |
|    policy_gradient_loss | -0.000116     |
|    value_loss           | 69.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.39e+03      |
|    ep_rew_mean          | -330          |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 50            |
|    time_elapsed         | 3004          |
|    total_timesteps      | 102400        |
| train/                  |               |
|    approx_kl            | 1.2794335e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0119       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 27.2          |
|    n_updates            | 490           |
|    policy_gradient_loss | -7.45e-06     |
|    value_loss           | 67.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.38e+03     |
|    ep_rew_mean          | -326         |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 51           |
|    time_elapsed         | 3067         |
|    total_timesteps      | 104448       |
| train/                  |              |
|    approx_kl            | 1.437086e-05 |
|    clip_fraction        | 0.000293     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0121      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 30.5         |
|    n_updates            | 500          |
|    policy_gradient_loss | -5.59e-05    |
|    value_loss           | 67.5         |
------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 2.37e+03       |
|    ep_rew_mean          | -326           |
| time/                   |                |
|    fps                  | 33             |
|    iterations           | 52             |
|    time_elapsed         | 3132           |
|    total_timesteps      | 106496         |
| train/                  |                |
|    approx_kl            | 0.000118442666 |
|    clip_fraction        | 0.000977       |
|    clip_range           | 0.2            |
|    entropy_loss         | -0.00957       |
|    explained_variance   | 0              |
|    learning_rate        | 0.0003         |
|    loss                 | 37.4           |
|    n_updates            | 510            |
|    policy_gradient_loss | -2.09e-05      |
|    value_loss           | 61.3           |
--------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.37e+03     |
|    ep_rew_mean          | -325         |
| time/                   |              |
|    fps                  | 33           |
|    iterations           | 53           |
|    time_elapsed         | 3193         |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 2.628757e-05 |
|    clip_fraction        | 0.000391     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00774     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 32           |
|    n_updates            | 520          |
|    policy_gradient_loss | -6.04e-05    |
|    value_loss           | 66.7         |
------------------------------------------
Num timesteps: 110000
Best mean reward: -333.23 - Last mean reward per episode: -319.62
Saving new best model at 108545 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.36e+03      |
|    ep_rew_mean          | -320          |
| time/                   |               |
|    fps                  | 33            |
|    iterations           | 54            |
|    time_elapsed         | 3256          |
|    total_timesteps      | 110592        |
| train/                  |               |
|    approx_kl            | 0.00026531046 |
|    clip_fraction        | 0.00142       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00597      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 31.7          |
|    n_updates            | 530           |
|    policy_gradient_loss | -3.55e-05     |
|    value_loss           | 73.5          |
-------------------------------------------
Traceback (most recent call last):
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/freeway/run_supervised_gnn.py", line 290, in <module>
    model.learn(total_timesteps=160000, callback=[WandbCallback(), save_callback])
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 315, in learn
    return super().learn(
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 179, in collect_rollouts
    actions, values, log_probs = self.policy(obs_tensor)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/policies.py", line 645, in forward
    features = self.extract_features(obs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/policies.py", line 672, in extract_features
    return super().extract_features(obs, self.features_extractor if features_extractor is None else features_extractor)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/policies.py", line 131, in extract_features
    return features_extractor(preprocessed_obs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/model/policy.py", line 40, in forward
    pyg_data = self.encoder.encode(observations)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/encoder/GraphEncoder.py", line 460, in encode
    return Batch.from_data_list(self.to_pyg_data(batch_data))
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch_geometric/data/batch.py", line 97, in from_data_list
    batch, slice_dict, inc_dict = collate(
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch_geometric/data/collate.py", line 61, in collate
    out.stores_as(data_list[0])  # type: ignore
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch_geometric/data/hetero_data.py", line 245, in stores_as
    self.get_edge_store(*edge_type)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch_geometric/data/hetero_data.py", line 606, in get_edge_store
    out = EdgeStorage(_parent=self, _key=key)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch_geometric/data/storage.py", line 66, in __init__
    def __init__(
KeyboardInterrupt