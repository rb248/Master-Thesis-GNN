
Using cpu device
-----------------------------
| time/              |      |
|    fps             | 280  |
|    iterations      | 1    |
|    time_elapsed    | 7    |
|    total_timesteps | 2048 |
-----------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.92e+03     |
|    ep_rew_mean          | -930         |
| time/                   |              |
|    fps                  | 81           |
|    iterations           | 2            |
|    time_elapsed         | 50           |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0074489624 |
|    clip_fraction        | 0.0249       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.09        |
|    explained_variance   | 0.0128       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.365        |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.000266    |
|    value_loss           | 5.1          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.15e+03    |
|    ep_rew_mean          | -546        |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 3           |
|    time_elapsed         | 91          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.003807295 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 1.59        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.000288   |
|    value_loss           | 27          |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 542         |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 60          |
|    iterations           | 4           |
|    time_elapsed         | 134         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.011363452 |
|    clip_fraction        | 0.0271      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 7.36        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00274    |
|    value_loss           | 35.7        |
-----------------------------------------
Num timesteps: 10000
Best mean reward: -inf - Last mean reward per episode: -169.96
Saving new best model at 9998 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 376         |
|    ep_rew_mean          | -158        |
| time/                   |             |
|    fps                  | 57          |
|    iterations           | 5           |
|    time_elapsed         | 177         |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.014920052 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.988      |
|    explained_variance   | 0.000165    |
|    learning_rate        | 0.0003      |
|    loss                 | 21.1        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00657    |
|    value_loss           | 103         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 267          |
|    ep_rew_mean          | -104         |
| time/                   |              |
|    fps                  | 55           |
|    iterations           | 6            |
|    time_elapsed         | 222          |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0061627408 |
|    clip_fraction        | 0.0416       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.938       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 90.3         |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.000844    |
|    value_loss           | 122          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 229         |
|    ep_rew_mean          | -84.7       |
| time/                   |             |
|    fps                  | 54          |
|    iterations           | 7           |
|    time_elapsed         | 263         |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.013059776 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.894      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 80.9        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0106     |
|    value_loss           | 167         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 194          |
|    ep_rew_mean          | -67.1        |
| time/                   |              |
|    fps                  | 53           |
|    iterations           | 8            |
|    time_elapsed         | 308          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0106947515 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.809       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 56.1         |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00974     |
|    value_loss           | 135          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 118          |
|    ep_rew_mean          | -28.8        |
| time/                   |              |
|    fps                  | 52           |
|    iterations           | 9            |
|    time_elapsed         | 351          |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0037549813 |
|    clip_fraction        | 0.0354       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.78        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 67           |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00279     |
|    value_loss           | 155          |
------------------------------------------
Num timesteps: 20000
Best mean reward: -169.96 - Last mean reward per episode: -19.47
Saving new best model at 19970 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 96.7         |
|    ep_rew_mean          | -18.3        |
| time/                   |              |
|    fps                  | 52           |
|    iterations           | 10           |
|    time_elapsed         | 392          |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 0.0035650681 |
|    clip_fraction        | 0.0188       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.764       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 67.8         |
|    n_updates            | 90           |
|    policy_gradient_loss | -8.23e-05    |
|    value_loss           | 147          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 85.2         |
|    ep_rew_mean          | -12.6        |
| time/                   |              |
|    fps                  | 52           |
|    iterations           | 11           |
|    time_elapsed         | 433          |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0024908902 |
|    clip_fraction        | 0.0352       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.634       |
|    explained_variance   | 1.31e-06     |
|    learning_rate        | 0.0003       |
|    loss                 | 86.2         |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00177     |
|    value_loss           | 139          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 83.2        |
|    ep_rew_mean          | -11.6       |
| time/                   |             |
|    fps                  | 51          |
|    iterations           | 12          |
|    time_elapsed         | 473         |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.002042282 |
|    clip_fraction        | 0.0284      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.575      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 53.5        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00201    |
|    value_loss           | 130         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 79.1         |
|    ep_rew_mean          | -9.57        |
| time/                   |              |
|    fps                  | 51           |
|    iterations           | 13           |
|    time_elapsed         | 513          |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0049255104 |
|    clip_fraction        | 0.0166       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.603       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 59.2         |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.000273    |
|    value_loss           | 111          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 78.9         |
|    ep_rew_mean          | -9.43        |
| time/                   |              |
|    fps                  | 51           |
|    iterations           | 14           |
|    time_elapsed         | 556          |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 0.0034354867 |
|    clip_fraction        | 0.0397       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.498       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 55.9         |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.003       |
|    value_loss           | 115          |
------------------------------------------
Num timesteps: 30000
Best mean reward: -19.47 - Last mean reward per episode: -9.79
Saving new best model at 29956 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 79           |
|    ep_rew_mean          | -9.51        |
| time/                   |              |
|    fps                  | 51           |
|    iterations           | 15           |
|    time_elapsed         | 599          |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 0.0013364162 |
|    clip_fraction        | 0.0135       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.472       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 38.8         |
|    n_updates            | 140          |
|    policy_gradient_loss | 5.15e-05     |
|    value_loss           | 103          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 78           |
|    ep_rew_mean          | -8.97        |
| time/                   |              |
|    fps                  | 51           |
|    iterations           | 16           |
|    time_elapsed         | 641          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0015808921 |
|    clip_fraction        | 0.0226       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.429       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 74.9         |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.000914    |
|    value_loss           | 105          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 78.3         |
|    ep_rew_mean          | -9.18        |
| time/                   |              |
|    fps                  | 50           |
|    iterations           | 17           |
|    time_elapsed         | 684          |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0012209993 |
|    clip_fraction        | 0.00962      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.433       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 31.4         |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.000461    |
|    value_loss           | 105          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.1         |
|    ep_rew_mean          | -8.54        |
| time/                   |              |
|    fps                  | 50           |
|    iterations           | 18           |
|    time_elapsed         | 728          |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0007981109 |
|    clip_fraction        | 0.00186      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.427       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 55           |
|    n_updates            | 170          |
|    policy_gradient_loss | 0.000111     |
|    value_loss           | 100          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.4          |
|    ep_rew_mean          | -8.7          |
| time/                   |               |
|    fps                  | 50            |
|    iterations           | 19            |
|    time_elapsed         | 774           |
|    total_timesteps      | 38912         |
| train/                  |               |
|    approx_kl            | 0.00028852362 |
|    clip_fraction        | 0.0191        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.475        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 48.6          |
|    n_updates            | 180           |
|    policy_gradient_loss | -0.000118     |
|    value_loss           | 103           |
-------------------------------------------
Num timesteps: 40000
Best mean reward: -9.79 - Last mean reward per episode: -8.48
Saving new best model at 39970 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.2         |
|    ep_rew_mean          | -8.62        |
| time/                   |              |
|    fps                  | 49           |
|    iterations           | 20           |
|    time_elapsed         | 830          |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 0.0033342387 |
|    clip_fraction        | 0.0262       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.426       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 41           |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.00124     |
|    value_loss           | 98.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 77.6          |
|    ep_rew_mean          | -9.08         |
| time/                   |               |
|    fps                  | 47            |
|    iterations           | 21            |
|    time_elapsed         | 900           |
|    total_timesteps      | 43008         |
| train/                  |               |
|    approx_kl            | 0.00088220474 |
|    clip_fraction        | 0.0174        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.423        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 34.6          |
|    n_updates            | 200           |
|    policy_gradient_loss | 5.66e-05      |
|    value_loss           | 97.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.8         |
|    ep_rew_mean          | -9.21        |
| time/                   |              |
|    fps                  | 46           |
|    iterations           | 22           |
|    time_elapsed         | 962          |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0009768198 |
|    clip_fraction        | 0.0203       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.328       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 43.5         |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.00156     |
|    value_loss           | 96.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 77.8         |
|    ep_rew_mean          | -9.2         |
| time/                   |              |
|    fps                  | 45           |
|    iterations           | 23           |
|    time_elapsed         | 1025         |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 0.0005892667 |
|    clip_fraction        | 0.0022       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.332       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 51.8         |
|    n_updates            | 220          |
|    policy_gradient_loss | -0.000172    |
|    value_loss           | 99.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 75.4         |
|    ep_rew_mean          | -8           |
| time/                   |              |
|    fps                  | 44           |
|    iterations           | 24           |
|    time_elapsed         | 1103         |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0003430575 |
|    clip_fraction        | 0.0179       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.314       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 47.2         |
|    n_updates            | 230          |
|    policy_gradient_loss | 5.12e-05     |
|    value_loss           | 104          |
------------------------------------------
Num timesteps: 50000
Best mean reward: -8.48 - Last mean reward per episode: -7.89
Saving new best model at 49939 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 74.8         |
|    ep_rew_mean          | -7.71        |
| time/                   |              |
|    fps                  | 43           |
|    iterations           | 25           |
|    time_elapsed         | 1172         |
|    total_timesteps      | 51200        |
| train/                  |              |
|    approx_kl            | 0.0020037387 |
|    clip_fraction        | 0.0152       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.301       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 41.3         |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00015     |
|    value_loss           | 101          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 73.2         |
|    ep_rew_mean          | -7.18        |
| time/                   |              |
|    fps                  | 42           |
|    iterations           | 26           |
|    time_elapsed         | 1247         |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0014219184 |
|    clip_fraction        | 0.0153       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.261       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 62.8         |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.000785    |
|    value_loss           | 99.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 74.5         |
|    ep_rew_mean          | -7.88        |
| time/                   |              |
|    fps                  | 41           |
|    iterations           | 27           |
|    time_elapsed         | 1319         |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 0.0013507497 |
|    clip_fraction        | 0.0163       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.246       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 43           |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.000755    |
|    value_loss           | 93.3         |
