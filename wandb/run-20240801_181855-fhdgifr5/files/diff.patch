diff --git a/.DS_Store b/.DS_Store
index c01bf45..6d7b227 100644
Binary files a/.DS_Store and b/.DS_Store differ
diff --git a/.gitignore b/.gitignore
new file mode 100644
index 0000000..f3f2746
--- /dev/null
+++ b/.gitignore
@@ -0,0 +1,11 @@
+# don't include out files and directories
+# don't include .DS_Store files
+# don't include .idea files
+# don't include .gradle files
+# dont include .pyc files
+*.out
+*.DS_Store
+.idea/
+.gradle/
+*.pyc
+*.zip 
\ No newline at end of file
diff --git a/games/__pycache__/__init__.cpython-310.pyc b/games/__pycache__/__init__.cpython-310.pyc
index 1b00a1b..347bbb7 100644
Binary files a/games/__pycache__/__init__.cpython-310.pyc and b/games/__pycache__/__init__.cpython-310.pyc differ
diff --git a/games/encoder/GraphEncoder.py b/games/encoder/GraphEncoder.py
index 7e34464..a0dbe69 100644
--- a/games/encoder/GraphEncoder.py
+++ b/games/encoder/GraphEncoder.py
@@ -286,51 +286,171 @@ class HeteroGNNEncoderPongProximity:
 #         return data_list 
 
 
+# class GraphEncoderFreeway:
+#     def __init__(self, obj_type_id: str = "obj"):
+#         self.obj_type_id = obj_type_id
+
+#     def encode(self, batch_node_features: torch.Tensor, proximity_threshold: float = 50) -> Batch:
+#         batch_size, num_nodes, object_feature_length = batch_node_features.shape
+#         batch_data = []
+
+#         # Precompute node types for all batches
+#         chicken_mask = batch_node_features[:, :, -3] == 1
+#         lane_mask = batch_node_features[:, :, -2] == 1
+#         car_mask = batch_node_features[:, :, -1] == 1
+
+#         for b in range(batch_size):
+#             node_features = batch_node_features[b]
+#             graph = nx.Graph()
+
+#             # Add object nodes (vectorized)
+#             graph.add_nodes_from([(i, {"type": self.obj_type_id, "features": node_features[i]}) for i in range(num_nodes)])
+
+#             chicken_indices = chicken_mask[b].nonzero(as_tuple=True)[0].tolist()
+#             lane_indices = lane_mask[b].nonzero(as_tuple=True)[0].tolist()
+#             car_indices = car_mask[b].nonzero(as_tuple=True)[0].tolist()
+
+#             # Convert to sets for faster lookups
+#             chicken_set = set(chicken_indices)
+#             lane_set = set(lane_indices)
+#             car_set = set(car_indices)
+
+#             atom_index = num_nodes
+
+#             # Add atoms and edges (can be further optimized with matrix operations)
+#             for i in range(num_nodes):
+#                 if i in chicken_set or i in car_set:
+#                     for j in lane_set:
+#                         if abs(node_features[i, 1] - node_features[j, 1]) <= proximity_threshold:
+#                             atom_type = "ChickenOnLane" if i in chicken_set else "CarOnLane"
+#                             graph.add_node(atom_index, type=atom_type, features=torch.zeros((2, object_feature_length)))
+#                             graph.add_edge(i, atom_index, position=0)
+#                             graph.add_edge(j, atom_index, position=1)
+#                             atom_index += 1
+
+#             # Add LaneNextToLane atoms and edges
+#             for i in range(len(lane_indices) - 1):
+#                 graph.add_node(atom_index, type="LaneNextToLane", features=torch.zeros((2, object_feature_length)))
+#                 graph.add_edge(lane_indices[i], atom_index, position=0)
+#                 graph.add_edge(lane_indices[i + 1], atom_index, position=1)
+#                 atom_index += 1
+
+#             batch_data.append(graph)
+
+#         return Batch.from_data_list(self.to_pyg_data(batch_data))
+
+#     def to_pyg_data(self, batch_graphs: List[nx.Graph]) -> List[HeteroData]:
+#         data_list = []
+
+#         for graph in batch_graphs:
+#             data = HeteroData()
+#             node_index_mapping = defaultdict(dict)
+#             obj_features = []
+#             atom_features_dict = defaultdict(list)
+#             edge_dict = defaultdict(list)
+
+#             current_obj_features = []
+#             current_atom_features_dict = defaultdict(list)
+
+#             for node, attrs in graph.nodes(data=True):
+#                 node_type = attrs['type']
+#                 features = attrs['features']
+#                 if node_type == self.obj_type_id:
+#                     node_index_mapping[node_type][node] = len(current_obj_features)
+#                     current_obj_features.append(features)
+#                 else:
+#                     node_index_mapping[node_type][node] = len(current_atom_features_dict[node_type])
+#                     current_atom_features_dict[node_type].append(features)
+
+#             if current_obj_features:
+#                 obj_features.append(torch.stack(current_obj_features))
+
+#             for node_type, features_list in current_atom_features_dict.items():
+#                 if features_list:
+#                     # Flatten the features if necessary
+#                     flattened_features = [f.view(-1) for f in features_list]
+#                     atom_features_dict[node_type].append(torch.stack(flattened_features))
+
+#             if obj_features:
+#                 data[self.obj_type_id].x = torch.cat(obj_features, dim=0)
+
+#             for node_type, features_list in atom_features_dict.items():
+#                 if features_list:
+#                     data[node_type].x = torch.cat(features_list, dim=0)
+
+#             for src, dst, attr in graph.edges(data=True):
+#                 src_type = graph.nodes[src]['type']
+#                 dst_type = graph.nodes[dst]['type']
+#                 pos = str(attr['position'])
+#                 edge_type = (src_type, pos, dst_type)
+
+#                 src_idx = node_index_mapping[src_type][src]
+#                 dst_idx = node_index_mapping[dst_type][dst]
+#                 edge_dict[edge_type].append((src_idx, dst_idx))
+#                 # Add reverse edges for bidirectionality
+#                 reverse_edge_type = (dst_type, pos, src_type)
+#                 edge_dict[reverse_edge_type].append((dst_idx, src_idx))
+
+#             for edge_type, edges in edge_dict.items():
+#                 edge_tensor = torch.tensor(edges, dtype=torch.long).t().contiguous()
+#                 data[edge_type].edge_index = edge_tensor
+
+#             data_list.append(data)
+
+#         return data_list
+
 class GraphEncoderFreeway:
     def __init__(self, obj_type_id: str = "obj"):
         self.obj_type_id = obj_type_id
 
     def encode(self, batch_node_features: torch.Tensor, proximity_threshold: float = 50) -> Batch:
-        batch_size, num_nodes, object_feature_length = batch_node_features.shape
+        # remove the values from batch_node_features that have all zeros in the vector
+        # batch_node_features = batch_node_features[~torch.all(batch_node_features == 0, dim=1)]
         batch_data = []
-
-        # Precompute node types for all batches
-        chicken_mask = batch_node_features[:, :, -3] == 1
-        lane_mask = batch_node_features[:, :, -2] == 1
-        car_mask = batch_node_features[:, :, -1] == 1
+        batch_size = batch_node_features.size(0)
 
         for b in range(batch_size):
             node_features = batch_node_features[b]
+            num_nodes = node_features.size(0)
             graph = nx.Graph()
 
-            # Add object nodes (vectorized)
-            graph.add_nodes_from([(i, {"type": self.obj_type_id, "features": node_features[i]}) for i in range(num_nodes)])
-
-            chicken_indices = chicken_mask[b].nonzero(as_tuple=True)[0].tolist()
-            lane_indices = lane_mask[b].nonzero(as_tuple=True)[0].tolist()
-            car_indices = car_mask[b].nonzero(as_tuple=True)[0].tolist()
+            object_feature_length = node_features.size(1)
 
-            # Convert to sets for faster lookups
-            chicken_set = set(chicken_indices)
-            lane_set = set(lane_indices)
-            car_set = set(car_indices)
+            # Add object nodes
+            for i in range(num_nodes):
+                graph.add_node(i, type=self.obj_type_id, features=node_features[i].tolist())
 
             atom_index = num_nodes
 
-            # Add atoms and edges (can be further optimized with matrix operations)
-            for i in range(num_nodes):
-                if i in chicken_set or i in car_set:
-                    for j in lane_set:
-                        if abs(node_features[i, 1] - node_features[j, 1]) <= proximity_threshold:
-                            atom_type = "ChickenOnLane" if i in chicken_set else "CarOnLane"
-                            graph.add_node(atom_index, type=atom_type, features=torch.zeros((2, object_feature_length)))
-                            graph.add_edge(i, atom_index, position=0)
-                            graph.add_edge(j, atom_index, position=1)
-                            atom_index += 1
+            # Add ChickenOnLane atoms and edges
+            chicken_indices = [i for i in range(num_nodes) if node_features[i, -3] == 1]
+            lane_indices = [i for i in range(num_nodes) if node_features[i, -2] == 1]
+
+            for i in chicken_indices:
+                for j in lane_indices:
+                    if abs(node_features[i, 1] - node_features[j, 1]) <= proximity_threshold:
+                        atom_features = torch.zeros((2, object_feature_length)).tolist()
+                        graph.add_node(atom_index, type="ChickenOnLane", features=atom_features)
+                        graph.add_edge(i, atom_index, position=0)
+                        graph.add_edge(j, atom_index, position=1)
+                        atom_index += 1
+
+            # Add CarOnLane atoms and edges
+            car_indices = [i for i in range(num_nodes) if node_features[i, -1] == 1]
+
+            for i in car_indices:
+                for j in lane_indices:
+                    if abs(node_features[i, 1] - node_features[j, 1]) <= proximity_threshold:
+                        atom_features = torch.zeros((2, object_feature_length)).tolist()
+                        graph.add_node(atom_index, type="CarOnLane", features=atom_features)
+                        graph.add_edge(i, atom_index, position=0)
+                        graph.add_edge(j, atom_index, position=1)
+                        atom_index += 1
 
             # Add LaneNextToLane atoms and edges
             for i in range(len(lane_indices) - 1):
-                graph.add_node(atom_index, type="LaneNextToLane", features=torch.zeros((2, object_feature_length)))
+                atom_features = torch.zeros((2, object_feature_length)).tolist()
+                graph.add_node(atom_index, type="LaneNextToLane", features=atom_features)
                 graph.add_edge(lane_indices[i], atom_index, position=0)
                 graph.add_edge(lane_indices[i + 1], atom_index, position=1)
                 atom_index += 1
@@ -354,7 +474,7 @@ class GraphEncoderFreeway:
 
             for node, attrs in graph.nodes(data=True):
                 node_type = attrs['type']
-                features = attrs['features']
+                features = torch.tensor(attrs['features'])
                 if node_type == self.obj_type_id:
                     node_index_mapping[node_type][node] = len(current_obj_features)
                     current_obj_features.append(features)
@@ -364,19 +484,16 @@ class GraphEncoderFreeway:
 
             if current_obj_features:
                 obj_features.append(torch.stack(current_obj_features))
-
             for node_type, features_list in current_atom_features_dict.items():
                 if features_list:
-                    # Flatten the features if necessary
                     flattened_features = [f.view(-1) for f in features_list]
                     atom_features_dict[node_type].append(torch.stack(flattened_features))
 
             if obj_features:
-                data[self.obj_type_id].x = torch.cat(obj_features, dim=0)
-
+                data[self.obj_type_id].x = torch.cat(obj_features)
             for node_type, features_list in atom_features_dict.items():
                 if features_list:
-                    data[node_type].x = torch.cat(features_list, dim=0)
+                    data[node_type].x = torch.cat(features_list)
 
             for src, dst, attr in graph.edges(data=True):
                 src_type = graph.nodes[src]['type']
@@ -398,8 +515,6 @@ class GraphEncoderFreeway:
             data_list.append(data)
 
         return data_list
-
-    
 class GraphEncoderFreewayProximity:
     def __init__(self, obj_type_id: str = "obj"):
         self.obj_type_id = obj_type_id
diff --git a/games/encoder/__pycache__/GraphEncoder.cpython-310.pyc b/games/encoder/__pycache__/GraphEncoder.cpython-310.pyc
index 7f7cf70..b9ee24e 100644
Binary files a/games/encoder/__pycache__/GraphEncoder.cpython-310.pyc and b/games/encoder/__pycache__/GraphEncoder.cpython-310.pyc differ
diff --git a/games/encoder/__pycache__/__init__.cpython-310.pyc b/games/encoder/__pycache__/__init__.cpython-310.pyc
index e4059e9..7335618 100644
Binary files a/games/encoder/__pycache__/__init__.cpython-310.pyc and b/games/encoder/__pycache__/__init__.cpython-310.pyc differ
diff --git a/games/freeway/__pycache__/__init__.cpython-310.pyc b/games/freeway/__pycache__/__init__.cpython-310.pyc
index 8f6a241..ee44eda 100644
Binary files a/games/freeway/__pycache__/__init__.cpython-310.pyc and b/games/freeway/__pycache__/__init__.cpython-310.pyc differ
diff --git a/games/freeway/__pycache__/run_supervised_gnn.cpython-310.pyc b/games/freeway/__pycache__/run_supervised_gnn.cpython-310.pyc
index b518fb6..da89774 100644
Binary files a/games/freeway/__pycache__/run_supervised_gnn.cpython-310.pyc and b/games/freeway/__pycache__/run_supervised_gnn.cpython-310.pyc differ
diff --git a/games/freeway/freeway_envs/__pycache__/freeway_env.cpython-310.pyc b/games/freeway/freeway_envs/__pycache__/freeway_env.cpython-310.pyc
index 5560abe..52b5ca4 100644
Binary files a/games/freeway/freeway_envs/__pycache__/freeway_env.cpython-310.pyc and b/games/freeway/freeway_envs/__pycache__/freeway_env.cpython-310.pyc differ
diff --git a/games/freeway/freeway_envs/freeway_env.py b/games/freeway/freeway_envs/freeway_env.py
index 9bed93d..a14c291 100644
--- a/games/freeway/freeway_envs/freeway_env.py
+++ b/games/freeway/freeway_envs/freeway_env.py
@@ -198,6 +198,7 @@ import torch
 from collections import deque
 from skimage.color import rgb2gray
 from skimage.transform import resize
+from stable_baselines3 import PPO
 
 class FreewayEnv(gym.Env):
     metadata = {'render_modes': ['human', 'rgb_array']}
@@ -287,28 +288,29 @@ class FreewayEnv(gym.Env):
         ]
         # lane_combinations = [[60, 90], [60, 90, 120], [60, 120]]
         # # 
-        lane_combinations =[[50,80,120],[50,80],[80,120],[50,120]]
-
-        number_cars = [5,10, 15]
+        lane_combinations =[[50,80,120],[50,80],[80,120]]
+        #lane_combinations = [[50,80,120]]
+        number_cars = [10,12, 15]
         car_speeds = [3,4]
 
         self.car_speed = random.choice(car_speeds)
         self.player_speed = 0
         #self.lanes = random.choices(lane_combinations, weights=lane_weights, k=1)[0]
-        #self.lanes = random.choice(lane_combinations)
+        self.lanes = random.choice(lane_combinations)
         self.max_cars = random.choice(number_cars)
         
-        lane_speeds = {30: self.car_speed - 2, 60: self.car_speed - 1, 90: self.car_speed, 120: self.car_speed - 1, 150: self.car_speed - 2}
-        #lane_speeds = {50: self.car_speed - 2, 80: self.car_speed, 120: self.car_speed-1}
+        #lane_speeds = {30: self.car_speed - 2, 60: self.car_speed - 1, 90: self.car_speed, 120: self.car_speed - 1, 150: self.car_speed - 2}
+        lane_speeds = {50: self.car_speed - 2, 80: self.car_speed, 120: self.car_speed-1}
         self.cars = []
         lane_car_count = {lane: 0 for lane in self.lanes}
 
         for _ in range(self.max_cars):
-            lane = random.choice(self.lanes)
-            if lane_car_count[lane] < 5:
-                car = {'x': random.randint(0, self.window_width - self.car_width), 'lane': lane, 'speed': random.randint(2, 4)}
-                self.cars.append(car)
-                lane_car_count[lane] += 1
+                lane = random.choice(self.lanes)
+                
+                if lane_car_count[lane] < 5:
+                    car = {'x': random.randint(0, self.window_width - self.car_width), 'lane': lane, 'speed': lane_speeds[lane]}
+                    self.cars.append(car)
+                    lane_car_count[lane] += 1
 
         self.done = False
         self.episode_start_time = pygame.time.get_ticks()
@@ -323,7 +325,7 @@ class FreewayEnv(gym.Env):
         reward = 0
         reward = -0.5
         self.episode_step += 1
-        if self.episode_step % 1000 == 0:
+        if self.episode_step % 3000 == 0:
             self.done = True
         previous_y = self.player_rect.y
         current_time = pygame.time.get_ticks()
@@ -337,7 +339,7 @@ class FreewayEnv(gym.Env):
             if car['x'] > self.window_width:
                 # car['x'] = -random.randint(100, 300)
                 car['x'] = 0
-                car['speed'] = random.randint(2, 4)
+                #car['speed'] = self.car_speed
                 #car['speed'] = self.car_speed 
                 # print(f"Car speed: {car['speed']}")
                 # print(f"Car lane: {car['lane']}")
@@ -349,8 +351,8 @@ class FreewayEnv(gym.Env):
             #reward -= 3
         
             self.last_time = current_time
-        # if current_time - self.episode_start_time >= 60000:  # 60000 milliseconds = 1 minute
-        #     self.done = True
+        if current_time - self.episode_start_time >= 60000:  # 60000 milliseconds = 1 minute
+             self.done = True
             
         if self.player_rect.y <= 0:  # Reached top
             self.score +=1  
@@ -417,297 +419,10 @@ class FreewayEnv(gym.Env):
     def close(self):
         pygame.quit()
 
-# class FreewayEnvConstant(gym.Env):
-#     metadata = {'render_modes': ['human', 'rgb_array']}
-
-#     def __init__(self, render_mode='human', observation_type='pixel', frame_stack=4, lanes = [30, 60, 90, 120, 150], max_cars=10, car_speed=1):
-#         super(FreewayEnvConstant, self).__init__()
-#         pygame.init()
-#         self.last_time = pygame.time.get_ticks()
-#         self.render_mode = render_mode
-#         self.observation_type = observation_type
-#         #self.window_width = 800
-#         self.window_width = 210
-#         #self.window_height = 600
-#         self.window_height = 160
-#         self.player_width = 5
-#         self.player_height = 5
-#         self.car_width = 20
-#         self.car_height = 20
-#         self.frame_stack = frame_stack
-
-#         self.lanes = lanes
-#         self.max_cars = max_cars
-#         self.car_speed = car_speed
-#         # Define action and observation space
-#         # Actions: 0 - Stay, 1 - Move Up, 2 - Move Down
-#         self.action_space = spaces.Discrete(3)
-
-#         if observation_type == "pixel":
-#             self.observation_space = spaces.Box(low=0, high=255, shape=(self.frame_stack, 84, 84), dtype=np.uint8)
-#         else:
-#             self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(24, 7), dtype=np.float32)
-
-#         self.window = pygame.display.set_mode((self.window_width, self.window_height))
-#         self.background_image = pygame.image.load("games/images/Atari - background.png")
-#         self.background_image = pygame.transform.scale(self.background_image, (self.window_width, self.window_height))
-#         self.player_image = pygame.image.load("games/images/chicken.png").convert_alpha()
-#         self.player_image = pygame.transform.scale(self.player_image, (self.player_width, self.player_height))
-#         self.car_image = pygame.image.load("games/images/car.png").convert_alpha()
-#         self.car_image = pygame.transform.scale(self.car_image, (self.car_width, self.car_height))
-#         self.frame_buffer = np.zeros((self.frame_stack, 84, 84), dtype=np.uint8)
-
-#         self.clock = pygame.time.Clock()
-#         self.reset()
-#     def seed(self, seed=None):
-#         self.np_random, seed = gym.utils.seeding.np_random(seed)
-#         random.seed(seed)
-#         np.random.seed(seed)
-#         return [seed]
-
-#     def reset(self, seed=None, options=None):
-#         super().reset(seed=seed, options=options)
-#         if seed is not None:
-#             self.seed(seed)
-#         self.episode_step = 0
-#         self.player_rect = pygame.Rect(self.window_width // 2 - self.player_width // 2,
-#                                     self.window_height - self.player_height - 10,
-#                                     self.player_width, self.player_height)
-#         self.score = 0
-
-#         # Define lane combinations and their weights
-#         lane_combinations = [
-#             [30, 60, 90, 120, 150],  # 5-lane setup
-#             [30, 60, 90, 120],       # 4-lane setup
-#             [30, 60, 150],           # 3-lane setup
-#             [30, 90, 120],           # Middle lane setup
-#             [30, 90, 150],           # 3-lane setup
-#             [30, 120, 150],          # 3-lane setup
-#             [60, 90, 120, 150],      # 4-lane setup
-#             [60, 90, 120],           # 3-lane setup
-#             [60, 90, 150],           # 3-lane setup
-#             [60, 120, 150],          # 3-lane setup
-#             [90, 120, 150]           # Middle lane setup
-#         ]
-#         lane_weights = [
-#             30,  # Higher probability for 5-lane setup
-#             10,  # Moderate probability for 4-lane setup
-#             5,   # Lower probability for 3-lane setup
-#             5,  # Higher probability for middle lane setup
-#             5,   # Lower probability for 3-lane setup
-#             5,   # Lower probability for 3-lane setup
-#             10,  # Moderate probability for 4-lane setup
-#             5,   # Lower probability for 3-lane setup
-#             5,   # Lower probability for 3-lane setup
-#             5,   # Lower probability for 3-lane setup
-#             10   # Higher probability for middle lane setup
-#         ]
-#         # lane_combinations = [[60, 90], [60, 90, 120], [60, 120]]
-#         # # 
-#         #lane_combinations =[[50,80,120],[50,80],[80,120],[50,120]]
-#         #lane_combinations = [[30, 60, 90, 120, 150]]
-#         lane_combinations = [[50, 120]]
-#         number_cars = [10]
-#         car_speeds = [3]
-
-#         self.car_speed = random.choice(car_speeds)
-#         self.player_speed = 0
-#         #self.lanes = random.choices(lane_combinations, weights=lane_weights, k=1)[0]
-#         self.lanes = random.choice(lane_combinations)
-#         self.max_cars = random.choice(number_cars)
-        
-#         lane_speeds = {30: self.car_speed - 2, 60: self.car_speed - 1, 90: self.car_speed, 120: self.car_speed - 1, 150: self.car_speed - 2}
-#         #lane_speeds = {50: self.car_speed - 2, 80: self.car_speed, 120: self.car_speed-1}
-#         self.cars = []
-#         lane_car_count = {lane: 0 for lane in self.lanes}
-
-#         for _ in range(self.max_cars):
-#             while True:
-#                 lane = random.choice(self.lanes)
-#                 if lane_car_count[lane] < 5:
-#                     car = {
-#                         'x': random.randint(0, self.window_width - self.car_width),
-#                         'lane': lane,
-#                         'speed': random.randint(1, 2)
-#                     }
-#                     self.cars.append(car)
-#                     lane_car_count[lane] += 1
-#                     break  # Exit the while loop once a valid lane is found
-
-#         self.done = False
-#         self.episode_start_time = pygame.time.get_ticks()
-#         self.frame_buffer = np.zeros((self.frame_stack, 84, 84), dtype=np.uint8)
-#         if self.observation_type == "pixel":
-#             for _ in range(self.frame_stack):
-#                 self.update_frame_buffer()
-#             return self.get_observation(), {}
-#         else:
-#             return self.get_object_data(), {}
-#     def step(self, action):
-#         reward = 0
-#         reward = -0.5
-#         self.episode_step += 1
-#         if self.episode_step % 1000 == 0:
-#             self.done = True
-#         previous_y = self.player_rect.y
-#         current_time = pygame.time.get_ticks()
-#         if action == 1 and self.episode_step>=30: # Up
-#             self.player_rect.y = max(0, self.player_rect.y - 5)
-#         elif action == 2 and self.episode_step>=30:  # Down
-#             self.player_rect.y = min(self.window_height - self.player_height, self.player_rect.y + 5)
-#         self.player_speed = self.player_rect.y - previous_y
-#         for car in self.cars:
-#             car['x'] += car['speed']
-#             if car['x'] > self.window_width:
-#                 # car['x'] = -random.randint(100, 300)
-#                 car['x'] = 0
-#                 car['speed'] = random.randint(1, 2)
-#                 #car['speed'] = self.car_speed 
-#                 # print(f"Car speed: {car['speed']}")
-#                 # print(f"Car lane: {car['lane']}")
-
-#         # Collision detection
-#         hit = any(self.player_rect.colliderect(pygame.Rect(car['x'], car['lane'], self.car_width, self.car_height)) for car in self.cars)
-#         if hit:
-#             self.player_rect.y = self.window_height - self.player_height - 10
-#             #reward -= 3
-        
-#             self.last_time = current_time
-#         # if current_time - self.episode_start_time >= 60000:  # 60000 milliseconds = 1 minute
-#         #     self.done = True
-            
-#         if self.player_rect.y <= 0:  # Reached top
-#             self.score +=1  
-#             reward += 10*(len(self.lanes))
-            
-
-
-#             self.player_rect.y = self.window_height - self.player_height - 10
-#             #self.done = True
-            
-
-
-#         if self.observation_type == "pixel":
-#             self.update_frame_buffer()
-#             observation = self.get_observation()
-#         else:
-#             observation = self.get_object_data()
-
-#         return observation, reward, self.done, False, {}
-
-#     def update_frame_buffer(self):
-#         frame = self.render_to_array()
-#         grayscale = np.dot(frame[..., :3], [0.2989, 0.5870, 0.1140]).astype(np.uint8)  # Convert to grayscale
-#         resized_frame = pygame.transform.scale(pygame.surfarray.make_surface(grayscale), (84, 84))
-#         frame_array = pygame.surfarray.array3d(resized_frame).transpose(1, 0, 2)[:, :, 0]
-
-#         self.frame_buffer = np.roll(self.frame_buffer, shift=-1, axis=0)
-#         self.frame_buffer[-1] = frame_array
-
-#     def render_to_array(self):
-#         self.window.blit(self.background_image, (0, 0))
-#         for car in self.cars:
-#             self.window.blit(self.car_image, (car['x'], car['lane']))
-#         self.window.blit(self.player_image, (self.player_rect.x, self.player_rect.y))
-#         return pygame.surfarray.array3d(self.window)
-
-#     def get_observation(self):
-#         return self.frame_buffer
-
-#     def get_object_data(self):
-#         objects = [
-#             [self.player_rect.x, self.player_rect.y, self.player_speed, 0, 1, 0, 0],  # Player
-            
-#         ] 
-#         # add lanes
-#         for lane in self.lanes:
-#             objects.append([self.window_width//2, lane, 0, 0, 0, 1, 0])
-
-#         for i, car in enumerate(self.cars):
-#             objects.append([car['x'], car['lane'], car['speed'], 0, 0, 0, 1])
-
-#         while len(objects) < 24:  # Ensure the list has a constant length
-#              objects.append([0, 0, 0, 0, 0, 0, 0])
-
-#         return torch.tensor(objects, dtype=torch.float32)
-
-#     def render(self, mode='human'):
-#         self.window.blit(self.background_image, (0, 0))
-#         for car in self.cars:
-#             self.window.blit(self.car_image, (car['x'], car['lane']))
-#         self.window.blit(self.player_image, (self.player_rect.x, self.player_rect.y))
-#         pygame.display.update()
-
-#     def close(self):
-#         pygame.quit()
-
-
-# if __name__=="__main__":
-#     env = FreewayEnvConstant(render_mode='human', observation_type='graph')
-#     #env = FreewayEnv(render_mode='human', observation_type='pixel')
-#     #model = PPO.load("freeway_ppo_pixel_test")
-#     #model = PPO.load("ppo_freeway_pixel")
-#     model = PPO.load("logs/Freeway-GNN-training/best-1.zip")
-#     #model = PPO.load("logs/Freeway-GNN-training/best_model.zip")
-#     #model = PPO.load("freeway_cnn_training")
-#     #model = PPO.load("logs/Freeway-GNN-eval/best_model.zip")
-#     #model = PPO.load("freeway-gnn-eval.zip")
-
-#     #model = PPO.load("freeway_CNN_training_128.zip")
-#     #model = PPO.load("freeway_cnn_training.zip")
-#     #model = PPO.load("freeway_GNN_training.zip")
-
-#     #model = PPO.load("ppo_freeway_curriculum_1.zip")
-
-#     # # Evaluate the agent
-#     # mean_reward, std_reward = evaluate_policy(model, env, n_eval¸_episodes=1, render=True)
-#     # print(f"Mean reward: {mean_reward} ± {std_reward}")
-
-#     obs,_ = env.reset()
-#     done = False
-#     total_reward = 0
-#     n_episodes = 10
-#     for _ in range(n_episodes):
-#         obs,_ = env.reset()
-#         done = False
-#         while not done:
-#             action, _ = model.predict(obs)
-#             if action == 2 or action == 0:
-#                 print(f"Player speed: {env.player_speed}")
-#             #action = env.action_space.sample()
-#             obs, reward, done, _,_ = env.step(action)
-#             total_reward += reward
-#             pygame.time.delay(50)
-#             env.render()
-
-#         print(f"Total reward: {total_reward}")
-#     # while not done:
-#     #     action, _ = model.predict(obs)
-#     #     #action = env.action_space.sample()
-#     #     obs, reward, done, _,_ = env.step(action)
-#     #     total_reward += reward
-#     #     pygame.time.delay(50)
-#     #     env.render()
-
-#     # print(f"Total reward: {total_reward}")
-
-import random
-import pygame
-import numpy as np
-import gymnasium as gym
-from gymnasium import spaces
-import torch
-import networkx as nx
-from torch_geometric.data import HeteroData, Batch
-from collections import defaultdict
-from itertools import combinations
-from stable_baselines3 import PPO
-from stable_baselines3.common.evaluation import evaluate_policy
-
 class FreewayEnvConstant(gym.Env):
     metadata = {'render_modes': ['human', 'rgb_array']}
 
-    def __init__(self, render_mode='human', observation_type='pixel', frame_stack=4):
+    def __init__(self, render_mode='human', observation_type='pixel', frame_stack=4, lanes = [30, 60, 90, 120, 150], max_cars=10, car_speed=1):
         super(FreewayEnvConstant, self).__init__()
         pygame.init()
         self.last_time = pygame.time.get_ticks()
@@ -723,9 +438,9 @@ class FreewayEnvConstant(gym.Env):
         self.car_height = 20
         self.frame_stack = frame_stack
 
-        self.lanes = [100, 200, 300, 400, 500, 600, 700]
-        self.lanes = [50,80,120]
-        self.max_cars = 10
+        self.lanes = lanes
+        self.max_cars = max_cars
+        self.car_speed = car_speed
         # Define action and observation space
         # Actions: 0 - Stay, 1 - Move Up, 2 - Move Down
         self.action_space = spaces.Discrete(3)
@@ -733,21 +448,19 @@ class FreewayEnvConstant(gym.Env):
         if observation_type == "pixel":
             self.observation_space = spaces.Box(low=0, high=255, shape=(self.frame_stack, 84, 84), dtype=np.uint8)
         else:
-            self.max_objects = self.max_cars_init + 4
-            self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.max_objects, 7), dtype=np.float32)
+            self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(24, 7), dtype=np.float32)
 
         self.window = pygame.display.set_mode((self.window_width, self.window_height))
         self.background_image = pygame.image.load("games/images/Atari - background.png")
         self.background_image = pygame.transform.scale(self.background_image, (self.window_width, self.window_height))
         self.player_image = pygame.image.load("games/images/chicken.png").convert_alpha()
         self.player_image = pygame.transform.scale(self.player_image, (self.player_width, self.player_height))
-        self.car_image = pygame.image.load("games/images/car2.png").convert_alpha()
+        self.car_image = pygame.image.load("games/images/car.png").convert_alpha()
         self.car_image = pygame.transform.scale(self.car_image, (self.car_width, self.car_height))
         self.frame_buffer = np.zeros((self.frame_stack, 84, 84), dtype=np.uint8)
-        self.player_speed = 0
+
         self.clock = pygame.time.Clock()
         self.reset()
-
     def seed(self, seed=None):
         self.np_random, seed = gym.utils.seeding.np_random(seed)
         random.seed(seed)
@@ -758,81 +471,141 @@ class FreewayEnvConstant(gym.Env):
         super().reset(seed=seed, options=options)
         if seed is not None:
             self.seed(seed)
+        self.episode_step = 0
         self.player_rect = pygame.Rect(self.window_width // 2 - self.player_width // 2,
-                                       self.window_height - self.player_height - 10,
-                                       self.player_width, self.player_height)
+                                    self.window_height - self.player_height - 10,
+                                    self.player_width, self.player_height)
         self.score = 0
-        lane_combinations = [[50,80,120],[50,80],[50,120],[80,120]]
-        number_cars = [10,15,20]
-        car_speeds = [1,2,3]
-        self.lanes = random.choice(lane_combinations)
-        self.max_cars = random.choice(number_cars)
+
+        # Define lane combinations and their weights
+        lane_combinations = [
+            [30, 60, 90, 120, 150],  # 5-lane setup
+            [30, 60, 90, 120],       # 4-lane setup
+            [30, 60, 150],           # 3-lane setup
+            [30, 90, 120],           # Middle lane setup
+            [30, 90, 150],           # 3-lane setup
+            [30, 120, 150],          # 3-lane setup
+            [60, 90, 120, 150],      # 4-lane setup
+            [60, 90, 120],           # 3-lane setup
+            [60, 90, 150],           # 3-lane setup
+            [60, 120, 150],          # 3-lane setup
+            [90, 120, 150]           # Middle lane setup
+        ]
+        lane_weights = [
+            30,  # Higher probability for 5-lane setup
+            10,  # Moderate probability for 4-lane setup
+            5,   # Lower probability for 3-lane setup
+            5,  # Higher probability for middle lane setup
+            5,   # Lower probability for 3-lane setup
+            5,   # Lower probability for 3-lane setup
+            10,  # Moderate probability for 4-lane setup
+            5,   # Lower probability for 3-lane setup
+            5,   # Lower probability for 3-lane setup
+            5,   # Lower probability for 3-lane setup
+            10   # Higher probability for middle lane setup
+        ]
+        # lane_combinations = [[60, 90], [60, 90, 120], [60, 120]]
+        # # 
+        #lane_combinations =[[50,80,120],[50,80],[80,120],[50,120]]
+        #lane_combinations = [[30, 60, 90, 120, 150]]
+        lane_combinations = [[50, 80, 120]]
+        number_cars = [10,15]
+        car_speeds = [3]
+
         self.car_speed = random.choice(car_speeds)
-        self.cars = [{'x': random.randint(0, self.window_width - self.car_width),
-                      'lane': random.choice(self.lanes),
-                      'speed': self.car_speed} for car in range(self.max_cars)]
-        self.done = False
-        self.episode_start_time = pygame.time.get_ticks()
-        self.frame_buffer = np.zeros((self.frame_stack, 84, 84), dtype=np.uint8)
         self.player_speed = 0
-        if self.observation_type == "pixel":
-            for _ in range(self.frame_stack):
-                self.frame_buffer.append(self._get_obs())
-            return np.array(self.frame_buffer), {}
-        else:
-            return self.get_object_data(), {}
+        #self.lanes = random.choices(lane_combinations, weights=lane_weights, k=1)[0]
+        self.lanes = random.choice(lane_combinations)
+        self.max_cars = random.choice(number_cars)
+        
+        lane_speeds = {30: self.car_speed - 2, 60: self.car_speed - 1, 90: self.car_speed, 120: self.car_speed - 1, 150: self.car_speed - 2}
+        #lane_speeds = {50: self.car_speed - 2, 80: self.car_speed, 120: self.car_speed-1}
+        self.cars = []
+        lane_car_count = {lane: 0 for lane in self.lanes}
+
+        for _ in range(self.max_cars):
+            while True:
+                lane = random.choice(self.lanes)
+                if lane_car_count[lane] < 5:
+                    car = {
+                        'x': random.randint(0, self.window_width - self.car_width),
+                        'lane': lane,
+                        'speed': car_speeds[0]
+                    }
+                    self.cars.append(car)
+                    lane_car_count[lane] += 1
+                    break  # Exit the while loop once a valid lane is found
 
+        self.done = False
+        self.episode_start_time = pygame.time.get_ticks()
+        self.frame_buffer = np.zeros((self.frame_stack, 84, 84), dtype=np.uint8)
+        if self.observation_type == "pixel":
+            for _ in range(self.frame_stack):
+                self.update_frame_buffer()
+            return self.get_observation(), {}
+        else:
+            return self.get_object_data(), {}
     def step(self, action):
+        reward = 0
         reward = -0.5
-        current_time = pygame.time.get_ticks()
+        self.episode_step += 1
+        if self.episode_step % 1000 == 0:
+            self.done = True
         previous_y = self.player_rect.y
-
-        if action == 1:  # Up
+        current_time = pygame.time.get_ticks()
+        if action == 1 and self.episode_step>=30: # Up
             self.player_rect.y = max(0, self.player_rect.y - 5)
-        elif action == 2:  # Down
+        elif action == 2 and self.episode_step>=30:  # Down
             self.player_rect.y = min(self.window_height - self.player_height, self.player_rect.y + 5)
         self.player_speed = self.player_rect.y - previous_y
-
         for car in self.cars:
             car['x'] += car['speed']
             if car['x'] > self.window_width:
-                car['x'] = -random.randint(100, 300)
-                car['speed'] = random.randint(1,2)
+                # car['x'] = -random.randint(100, 300)
+                car['x'] = 0
+                #car['speed'] = 
+                #car['speed'] = self.car_speed 
+                # print(f"Car speed: {car['speed']}")
+                # print(f"Car lane: {car['lane']}")
 
+        # Collision detection
         hit = any(self.player_rect.colliderect(pygame.Rect(car['x'], car['lane'], self.car_width, self.car_height)) for car in self.cars)
         if hit:
             self.player_rect.y = self.window_height - self.player_height - 10
+            #reward -= 3
+        
             self.last_time = current_time
-        done = False
-       
-
+        # if current_time - self.episode_start_time >= 60000:  # 60000 milliseconds = 1 minute
+        #     self.done = True
+            
         if self.player_rect.y <= 0:  # Reached top
-            self.score += 1
-            reward += 10 * (len(self.lanes))
+            self.score +=1  
+            reward += 10*(len(self.lanes))
+            self.done = True
+
+            
+
+        
             self.player_rect.y = self.window_height - self.player_height - 10
-        truncated = False
-        info = {}  
+            
+
+
         if self.observation_type == "pixel":
+            self.update_frame_buffer()
             observation = self.get_observation()
-            return np.array(self.frame_buffer), reward, done, truncated, info
         else:
-            return self.get_object_data(), reward, done, truncated, info
-
+            observation = self.get_object_data()
 
+        return observation, reward, self.done, False, {}
 
-    def _get_obs(self):
+    def update_frame_buffer(self):
         frame = self.render_to_array()
-    
-        # Convert to grayscale
-        grayscale = rgb2gray(frame)
-        
-        # Normalize the grayscale image to enhance contrast
-        normalized_frame = (grayscale - grayscale.min()) / (grayscale.max() - grayscale.min())
-        
-        # Resize the frame
-        resized_frame = resize(normalized_frame, (84, 84), anti_aliasing=True, mode='reflect', preserve_range=True)
-        
-        return resized_frame
+        grayscale = np.dot(frame[..., :3], [0.2989, 0.5870, 0.1140]).astype(np.uint8)  # Convert to grayscale
+        resized_frame = pygame.transform.scale(pygame.surfarray.make_surface(grayscale), (84, 84))
+        frame_array = pygame.surfarray.array3d(resized_frame).transpose(1, 0, 2)[:, :, 0]
+
+        self.frame_buffer = np.roll(self.frame_buffer, shift=-1, axis=0)
+        self.frame_buffer[-1] = frame_array
 
     def render_to_array(self):
         self.window.blit(self.background_image, (0, 0))
@@ -850,14 +623,346 @@ class FreewayEnvConstant(gym.Env):
             
         ] 
         # add lanes
+        for lane in self.lanes:
+            objects.append([self.window_width//2, lane, 0, 0, 0, 1, 0])
+
+        for i, car in enumerate(self.cars):
+            objects.append([car['x'], car['lane'], car['speed'], 0, 0, 0, 1])
+
+        while len(objects) < 24:  # Ensure the list has a constant length
+             objects.append([0, 0, 0, 0, 0, 0, 0])
+
+        return torch.tensor(objects, dtype=torch.float32)
+
+    def render(self, mode='human'):
+        self.window.blit(self.background_image, (0, 0))
+        for car in self.cars:
+            self.window.blit(self.car_image, (car['x'], car['lane']))
+        self.window.blit(self.player_image, (self.player_rect.x, self.player_rect.y))
+        pygame.display.update()
+
+    def close(self):
+        pygame.quit()
+
+
+
+class FreewayEnvTest(gym.Env):
+    metadata = {'render_modes': ['human', 'rgb_array']}
+
+    def __init__(self, render_mode='human', observation_type='pixel', frame_stack=4):
+        super(FreewayEnvTest, self).__init__()
+        pygame.init()
+        self.last_time = pygame.time.get_ticks()
+        self.render_mode = render_mode
+        self.observation_type = observation_type
+        self.window_width = 210
+        self.window_height = 160
+        self.player_width = 5
+        self.player_height = 5
+        self.car_width = 20
+        self.car_height = 20
+        self.frame_stack = frame_stack
+
+        self.lanes = [50, 80, 120]
+        self.max_cars = 5
+        self.action_space = spaces.Discrete(3)
+
+        if observation_type == "pixel":
+            self.observation_space = spaces.Box(low=0, high=255, shape=(self.frame_stack, 84, 84), dtype=np.uint8)
+        else:
+            self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.max_cars + len(self.lanes) + 1, 7), dtype=np.float32)
+
+        self.window = pygame.display.set_mode((self.window_width, self.window_height))
+        self.background_image = pygame.image.load("games/images/Atari - background.png")
+        self.background_image = pygame.transform.scale(self.background_image, (self.window_width, self.window_height))
+        self.player_image = pygame.image.load("games/images/chicken.png").convert_alpha()
+        self.player_image = pygame.transform.scale(self.player_image, (self.player_width, self.player_height))
+        self.car_image = pygame.image.load("games/images/car2.png").convert_alpha()
+        self.car_image = pygame.transform.scale(self.car_image, (self.car_width, self.car_height))
+        self.frame_buffer = np.zeros((self.frame_stack, 84, 84), dtype=np.uint8)
+
+        self.clock = pygame.time.Clock()
+        self.reset()
+
+    def seed(self, seed=None):
+        self.np_random, seed = gym.utils.seeding.np_random(seed)
+        random.seed(seed)
+        np.random.seed(seed)
+        return [seed]
+
+    def reset(self, seed=None, options=None):
+        super().reset(seed=seed, options=options)
+        if seed is not None:
+            self.seed(seed)
+        self.player_rect = pygame.Rect(self.window_width // 2 - self.player_width // 2,
+                                       self.window_height - self.player_height - 10,
+                                       self.player_width, self.player_height)
+        self.score = 0
+        self.cars = [{'x': random.randint(0, self.window_width - self.car_width),
+                      'lane': random.choice(self.lanes),
+                      'speed': random.randint(1, 2)} for _ in range(self.max_cars)]
+        self.done = False
+        self.episode_start_time = pygame.time.get_ticks()
+        self.steps_since_collision = 0
+        self.frame_buffer = np.zeros((self.frame_stack, 84, 84), dtype=np.uint8)
+        if self.observation_type == "pixel":
+            for _ in range(self.frame_stack):
+                self.update_frame_buffer()
+            return self.get_observation(), {}
+        else:
+            return self.get_object_data(), {}
+
+    def step(self, action):
+        reward = -0.5
+        current_time = pygame.time.get_ticks()
+
+        if self.steps_since_collision < 30:  # Check the step counter
+            self.steps_since_collision += 1
+        else:
+            if action == 1:  # Up
+                self.player_rect.y = max(0, self.player_rect.y - 5)
+            elif action == 2:  # Down
+                self.player_rect.y = min(self.window_height - self.player_height, self.player_rect.y + 5)
+
+        for car in self.cars:
+            car['x'] += car['speed']
+            if car['x'] > self.window_width:
+                car['x'] = 0
+                car['speed'] = random.randint(1, 2)
+
+        # Collision detection
+        hit = any(self.player_rect.colliderect(pygame.Rect(car['x'], car['lane'], self.car_width, self.car_height)) for car in self.cars)
+        if hit:
+            self.player_rect.y = self.window_height - self.player_height - 10
+            self.steps_since_collision = 0  # Reset the counter on collision
+
+        if current_time - self.episode_start_time >= 60000:  # 60000 milliseconds = 1 minute
+            self.done = True
+
+        if self.player_rect.y <= 0:  # Reached top
+            self.score += 1
+            reward += 10 * len(self.lanes)
+            self.player_rect.y = self.window_height - self.player_height - 10
+
+        if self.observation_type == "pixel":
+            self.update_frame_buffer()
+            observation = self.get_observation()
+        else:
+            observation = self.get_object_data()
+
+        return observation, reward, self.done, False, {}
+
+    def update_frame_buffer(self):
+        frame = self.render_to_array()
+        grayscale = np.dot(frame[..., :3], [0.2989, 0.5870, 0.1140]).astype(np.uint8)  # Convert to grayscale
+        resized_frame = pygame.transform.scale(pygame.surfarray.make_surface(grayscale), (84, 84))
+        frame_array = pygame.surfarray.array3d(resized_frame).transpose(1, 0, 2)[:, :, 0]
+
+        self.frame_buffer = np.roll(self.frame_buffer, shift=-1, axis=0)
+        self.frame_buffer[-1] = frame_array
+
+    def render_to_array(self):
+        self.window.blit(self.background_image, (0, 0))
+        for car in self.cars:
+            self.window.blit(self.car_image, (car['x'], car['lane']))
+        self.window.blit(self.player_image, (self.player_rect.x, self.player_rect.y))
+        return pygame.surfarray.array3d(self.window)
+
+    def get_observation(self):
+        return self.frame_buffer
+
+    def get_object_data(self):
+        objects = [
+            [self.player_rect.x, self.player_rect.y, 0, 0, 1, 0, 0],  # Player
+        ]
+        # add lanes
         for lane in self.lanes:
             objects.append([self.window_width // 2, lane, 0, 0, 0, 1, 0])
 
+        for i, car in enumerate(self.cars):
+            objects.append([car['x'], car['lane'], car['speed'], 0, 0, 0, 1])
+
+        return torch.tensor(objects, dtype=torch.float32)
+
+    def render(self, mode='human'):
+        self.window.blit(self.background_image, (0, 0))
+        for car in self.cars:
+            self.window.blit(self.car_image, (car['x'], car['lane']))
+        self.window.blit(self.player_image, (self.player_rect.x, self.player_rect.y))
+        pygame.display.update()
+
+    def close(self):
+        pygame.quit()
+
+import random
+import pygame
+import numpy as np
+import gymnasium as gym
+from gymnasium import spaces
+import torch
+from stable_baselines3 import PPO
+
+class FreewayEnvDynamic(gym.Env):
+    metadata = {'render_modes': ['human', 'rgb_array']}
+
+    def __init__(self, render_mode='human', observation_type='pixel', frame_stack=4):
+        super(FreewayEnvDynamic, self).__init__()
+        pygame.init()
+        self.render_mode = render_mode
+        self.observation_type = observation_type
+        self.window_width = 210
+        self.window_height = 160
+        self.player_width = 5
+        self.player_height = 5
+        self.car_width = 20
+        self.car_height = 20
+        self.frame_stack = frame_stack
+        self.max_episode_length = 1000
+        self.steps_since_collision = 0
+        self.collision_wait_steps = 30
+
+        self.lanes = [50, 80, 120]
+        self.max_cars = 5
+        self.car_speed = 1
+        self.action_space = spaces.Discrete(3)
+
+        if observation_type == "pixel":
+            self.observation_space = spaces.Box(low=0, high=255, shape=(self.frame_stack, 84, 84), dtype=np.uint8)
+        else:
+            self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.max_cars + len(self.lanes) + 1, 7), dtype=np.float32)
+
+        self.window = pygame.display.set_mode((self.window_width, self.window_height))
+        self.background_image = pygame.image.load("games/images/Atari - background.png")
+        self.background_image = pygame.transform.scale(self.background_image, (self.window_width, self.window_height))
+        self.player_image = pygame.image.load("games/images/chicken.png").convert_alpha()
+        self.player_image = pygame.transform.scale(self.player_image, (self.player_width, self.player_height))
+        self.car_image = pygame.image.load("games/images/car2.png").convert_alpha()
+        self.car_image = pygame.transform.scale(self.car_image, (self.car_width, self.car_height))
+        self.frame_buffer = np.zeros((self.frame_stack, 84, 84), dtype=np.uint8)
+
+        self.clock = pygame.time.Clock()
+        self.reset()
+
+    def seed(self, seed=None):
+        self.np_random, seed = gym.utils.seeding.np_random(seed)
+        random.seed(seed)
+        np.random.seed(seed)
+        return [seed]
+
+    def reset(self, seed=None, options=None):
+        super().reset(seed=seed, options=options)
+        if seed is not None:
+            self.seed(seed)
+        self.player_rect = pygame.Rect(self.window_width // 2 - self.player_width // 2,
+                                       self.window_height - self.player_height - 10,
+                                       self.player_width, self.player_height)
+        self.player_speed = 0
+        self.score = 0
+        self.done = False
+        self.episode_step = 0
+        self.episode_start_time = pygame.time.get_ticks()
+        self.steps_since_collision = 0
+        self.frame_buffer = np.zeros((self.frame_stack, 84, 84), dtype=np.uint8)
+        self._update_environment()
+
+        if self.observation_type == "pixel":
+            for _ in range(self.frame_stack):
+                self.update_frame_buffer()
+            return self.get_observation(), {}
+        else:
+            return self.get_object_data(), {}
+
+    def _update_environment(self):
+        lane_combinations = [[50, 80, 120], [50, 80], [80, 120]]
+        number_cars = [5, 10, 12, 15]
+        car_speeds = [3, 4]
+
+        self.car_speed = random.choice(car_speeds)
+        self.lanes = random.choice(lane_combinations)
+        self.max_cars = random.choice(number_cars)
+
+        lane_speeds = {50: self.car_speed - 2, 80: self.car_speed-1, 120: self.car_speed}
+        self.cars = []
+        lane_car_count = {lane: 0 for lane in self.lanes}
+
+        for _ in range(self.max_cars):
+            lane = random.choice(self.lanes)
+            if lane_car_count[lane] < 5:
+                car = {'x': random.randint(0, self.window_width - self.car_width), 'lane': lane, 'speed': lane_speeds[lane]}
+                self.cars.append(car)
+                lane_car_count[lane] += 1
+
+    def step(self, action):
+        reward = -0.5
+        self.episode_step += 1
+        player_pos = self.player_rect.y
+        if self.steps_since_collision < self.collision_wait_steps:
+            self.steps_since_collision += 1
+        else:
+            if action == 1:  # Up
+                self.player_rect.y = max(0, self.player_rect.y - 5)
+            elif action == 2:  # Down
+                self.player_rect.y = min(self.window_height - self.player_height, self.player_rect.y + 5)
+            self.player_speed = self.player_rect.y - player_pos
         for car in self.cars:
+            car['x'] += car['speed']
+            if car['x'] > self.window_width:
+                car['x'] = 0
+                car['speed'] = random.randint(1, 2)
+
+        hit = any(self.player_rect.colliderect(pygame.Rect(car['x'], car['lane'], self.car_width, self.car_height)) for car in self.cars)
+        if hit:
+            self.player_rect.y = self.window_height - self.player_height - 10
+            self.steps_since_collision = 0  # Reset the counter on collision
+
+        if self.player_rect.y <= 0:  # Reached top
+            self.score += 1
+            reward += 10 * len(self.lanes)
+            self.player_rect.y = self.window_height - self.player_height - 10
+            self._update_environment()  # Update the environment after reaching the top
+
+        if self.episode_step >= self.max_episode_length:
+            self.done = True
+
+        if self.observation_type == "pixel":
+            self.update_frame_buffer()
+            observation = self.get_observation()
+        else:
+            observation = self.get_object_data()
+
+        return observation, reward, self.done, False, {}
+
+    def update_frame_buffer(self):
+        frame = self.render_to_array()
+        grayscale = np.dot(frame[..., :3], [0.2989, 0.5870, 0.1140]).astype(np.uint8)
+        resized_frame = pygame.transform.scale(pygame.surfarray.make_surface(grayscale), (84, 84))
+        frame_array = pygame.surfarray.array3d(resized_frame).transpose(1, 0, 2)[:, :, 0]
+
+        self.frame_buffer = np.roll(self.frame_buffer, shift=-1, axis=0)
+        self.frame_buffer[-1] = frame_array
+
+    def render_to_array(self):
+        self.window.blit(self.background_image, (0, 0))
+        for car in self.cars:
+            self.window.blit(self.car_image, (car['x'], car['lane']))
+        self.window.blit(self.player_image, (self.player_rect.x, self.player_rect.y))
+        return pygame.surfarray.array3d(self.window)
+
+    def get_observation(self):
+        return self.frame_buffer
+
+    def get_object_data(self):
+        objects = [
+            [self.player_rect.x, self.player_rect.y, self.player_speed , 0, 1, 0, 0],  # Player
+        ]
+        for lane in self.lanes:
+            objects.append([self.window_width // 2, lane, 0, 0, 0, 1, 0])
+
+        for i, car in enumerate(self.cars):
             objects.append([car['x'], car['lane'], car['speed'], 0, 0, 0, 1])
 
-        while len(objects) < self.max_objects:
-            objects.append([0, 0, 0, 0, 0, 0, 0])
+        while len(objects) < 24:  # Ensure the list has a constant length
+             objects.append([0, 0, 0, 0, 0, 0, 0])
 
         return torch.tensor(objects, dtype=torch.float32)
 
@@ -867,40 +972,118 @@ class FreewayEnvConstant(gym.Env):
             self.window.blit(self.car_image, (car['x'], car['lane']))
         self.window.blit(self.player_image, (self.player_rect.x, self.player_rect.y))
         pygame.display.update()
-        self.clock.tick(60)
 
     def close(self):
         pygame.quit()
 
 
-if __name__=="__main__":
-    env = FreewayEnvConstant(render_mode='human', observation_type='graph')
 
-    #model = PPO.load("best_model")
-    #model = PPO.load("ppo_freeway_pixel")
-    #model = PPO.load("logs/Freeway-GNN-training/best_model.zip")
-    model = PPO.load("ppo_custom_heterognn")
+if __name__ == "__main__":
+    env = FreewayEnvTest(render_mode='human', observation_type='pixel')
 
-    # # Evaluate the agent
-    # mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1, render=True)
-    # print(f"Mean reward: {mean_reward} ± {std_reward}")
+    model = PPO.load("ppo_freeway_pixel")
 
+    obs, _ = env.reset()
+    done = False
+    total_reward = 0
+    while not done:
+        action, _ = model.predict(obs)
+        obs, reward, done, _, _ = env.step(action)
+        total_reward += reward
+        pygame.time.delay(50)
+        env.render()
+
+    print(f"Total reward: {total_reward}")
+
+
+
+if __name__=="__main__":
+    env = FreewayEnvTest(render_mode='human', observation_type='graph')
+
+    #model = PPO.load("ppo_freeway_pixel")
+    model = PPO.load("logs/Freeway-GNN-training/best_model.zip")
+    #model = PPO.load("ppo_custom_heterognn")
     obs,_ = env.reset()
     done = False
     total_reward = 0
     n_episodes = 10
-    for i in range(n_episodes):
+    for _ in range(n_episodes):
+        obs,_ = env.reset()
+        done = False
         while not done:
             action, _ = model.predict(obs)
+            # if action == 2 or action == 0:
+            #     print(f"Player speed: {env.player_speed}")
             #action = env.action_space.sample()
             obs, reward, done, _,_ = env.step(action)
             total_reward += reward
             pygame.time.delay(50)
             env.render()
 
-        print(f"Episode {i+1}/{n_episodes}: Total reward = {total_reward}")
-        total_reward = 0
-        obs,_ = env.reset()
-        done = False
+        print(f"Total reward: {total_reward}")
+    # while not done:
+    #     action, _ = model.predict(obs)
+    #     #action = env.action_space.sample()
+    #     obs, reward, done, _,_ = env.step(action)
+    #     total_reward += reward
+    #     pygame.time.delay(50)
+    #     env.render()
+
+    # print(f"Total reward: {total_reward}")
+
+
+
+    # # Evaluate the agent
+    # mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1, render=True)
+    # print(f"Mean reward: {mean_reward} ± {std_reward}")
+
+    
+# if __name__=="__main__":
+#     #env = FreewayEnv(render_mode='human', observation_type='graph')
+#     env = FreewayEnv(render_mode='human', observation_type='pixel')
+#     model = PPO.load("ppo_freeway_pixel")
+#     #model = PPO.load("ppo_freeway_pixel_1.zip")
+#     #model = PPO.load("logs/Freeway-GNN-training/best-1.zip")
+#     #model = PPO.load("logs/Freeway-GNN-training/best_model.zip")
+#     #model = PPO.load("logs/Freeway-GNN-training/best-threelanes-constant-speed.zip")
+#     #model = PPO.load("logs/Freeway-GNN-eval/best_model.zip")
+#     #model = PPO.load("freeway-gnn-eval.zip")
+
+#     #model = PPO.load("freeway_GNN_training.zip")
+
+#     #model = PPO.load("ppo_freeway_curriculum_1.zip")
+
+#     #model = PPO.load("ppo_freeway_curriculum_2.zip")
+
+#     # # Evaluate the agent
+#     # mean_reward, std_reward = evaluate_policy(model, env, n_eval¸_episodes=1, render=True)
+#     # print(f"Mean reward: {mean_reward} ± {std_reward}")
+
+#     obs,_ = env.reset()
+#     done = False
+#     total_reward = 0
+#     n_episodes = 10
+#     for _ in range(n_episodes):
+#         obs,_ = env.reset()
+#         done = False
+#         while not done:
+#             action, _ = model.predict(obs)
+#             if action == 2 or action == 0:
+#                 print(f"Player speed: {env.player_speed}")
+#             #action = env.action_space.sample()
+#             obs, reward, done, _,_ = env.step(action)
+#             total_reward += reward
+#             pygame.time.delay(50)
+#             env.render()
+
+#         print(f"Total reward: {total_reward}")
+#     # while not done:
+#     #     action, _ = model.predict(obs)
+#     #     #action = env.action_space.sample()
+#     #     obs, reward, done, _,_ = env.step(action)
+#     #     total_reward += reward
+#     #     pygame.time.delay(50)
+#     #     env.render()
+
+#     # print(f"Total reward: {total_reward}")
 
-    print(f"Total reward: {total_reward}")
\ No newline at end of file
diff --git a/games/freeway/run_supervised_gnn.py b/games/freeway/run_supervised_gnn.py
index 2689c59..07b6d5d 100644
--- a/games/freeway/run_supervised_gnn.py
+++ b/games/freeway/run_supervised_gnn.py
@@ -157,7 +157,7 @@
 
 # # #env = FreewayEnv(render_mode='human', observation_type='graph')
 # # #env = make_vec_env(lambda: env, n_envs=8, vec_env_cls=SubprocVecEnv)
-# # envs = SubprocVecEnv([make_env([50, 80, 120], 10, 2, rank=i) for i in range(16)])
+# # 
 # # # policy_kwargs = dict(
 # # #     features_extractor_class=CustomCNN,
 # # #     features_extractor_kwargs=dict(features_dim=128),
@@ -186,10 +186,65 @@ from stable_baselines3 import PPO
 from stable_baselines3.common.env_util import make_vec_env
 from wandb.integration.sb3 import WandbCallback
 #from games.model.policy import CustomActorCriticPolicy
-from games.freeway.freeway_envs.freeway_env import FreewayEnvConstant
+from games.freeway.freeway_envs.freeway_env import FreewayEnvConstant, FreewayEnv, FreewayEnvTest, FreewayEnvDynamic
 from games.model.policy import CustomCNN, CustomHeteroGNN
 import pygame
-# #Initialize wandb
+from stable_baselines3.common.callbacks import BaseCallback
+import os
+import numpy as np
+from stable_baselines3.common.vec_env import DummyVecEnv
+from stable_baselines3.common.monitor import Monitor
+from stable_baselines3.common.callbacks import EvalCallback
+from stable_baselines3.common.monitor import load_results
+from stable_baselines3.common.results_plotter import ts2xy
+#Initialize wandb
+class SaveOnBestTrainingRewardCallback(BaseCallback):
+    def __init__(self, check_freq, log_dir, verbose=1):
+        super(SaveOnBestTrainingRewardCallback, self).__init__(verbose)
+        self.check_freq = check_freq
+        self.log_dir = log_dir
+        self.save_path = os.path.join(log_dir, "best_model")
+        self.best_mean_reward = -np.inf
+
+    def _init_callback(self) -> None:
+        if self.save_path is not None:
+            os.makedirs(self.save_path, exist_ok=True)
+
+    def _on_step(self) -> bool:
+        if self.n_calls % self.check_freq == 0:
+            x, y = ts2xy(load_results(self.log_dir), "timesteps")
+            if len(x) > 0:
+                mean_reward = np.mean(y[-100:])
+                if self.verbose > 0:
+                    print(f"Num timesteps: {self.num_timesteps}")
+                    print(f"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}")
+                if mean_reward > self.best_mean_reward:
+                    self.best_mean_reward = mean_reward
+                    if self.verbose > 0:
+                        print(f"Saving new best model at {x[-1]} timesteps")
+                        print(f"Saving new best model to {self.save_path}.zip")
+                    self.model.save(self.save_path)
+                #wandb.log({"mean_reward": mean_reward, "timesteps": self.num_timesteps})
+            else:
+                device = "cpu"
+                if self.verbose > 0:
+                    print("No data available for logging.")
+                #wandb.log({"timesteps": self.num_timesteps})
+        return True 
+log_dir = "./logs/Freeway-GNN-training/"
+
+def make_env(lanes, max_cars, car_speed, seed=0, rank=None):
+    def _init():
+        env = FreewayEnvDynamic( render_mode='human', observation_type='graph')
+        monitor_path = os.path.join(log_dir, f"monitor_{rank}.csv")
+        os.makedirs(log_dir, exist_ok=True)  # Create log directory if it doesn't exist
+        env = Monitor(env, filename=monitor_path, allow_early_resets=True)
+        env.seed(seed + rank)
+        return env
+    return _init 
+envs = DummyVecEnv([make_env([50, 80, 120], 10, 2, rank=i) for i in range(1)])
+
+
 wandb.init(
     project="gnn_atari_freeway",  # Replace with your project name
     sync_tensorboard=True,        # Automatically sync SB3 logs with wandb
@@ -206,18 +261,20 @@ wandb.init(
 
 # Wrap the environment 
 
-env = FreewayEnvConstant(render_mode='human', observation_type='graph')
+#env = FreewayEnv(render_mode='human', observation_type='graph')
 # policy_kwargs = dict(
 #     features_extractor_class=CustomCNN,
 #     features_extractor_kwargs=dict(features_dim=128),
-# )
+# ) 
+
+save_callback = SaveOnBestTrainingRewardCallback(check_freq=10000, log_dir=log_dir)
 
 policy_kwargs = dict(
     features_extractor_class=CustomHeteroGNN,
     features_extractor_kwargs=dict(
         features_dim=64,
         hidden_size=64,
-        num_layer=2,
+        num_layer=10,
         obj_type_id='obj',
         arity_dict={'ChickenOnLane':2, 'CarOnLane':2, 'LaneNextToLane':2},
         game = 'freeway'
@@ -225,8 +282,11 @@ policy_kwargs = dict(
 )
 
 # # Create the PPO model with the custom feature extractor
-model = PPO('MlpPolicy', env, policy_kwargs=policy_kwargs, verbose=2)
+model = PPO('MlpPolicy', envs, policy_kwargs=policy_kwargs, verbose=2)
+#model = PPO.load("logs/Freeway-GNN-training/best-threelanes-constant-speed.zip") 
+#model.set_env(envs)
+
 # # Train the model with WandbCallback
-model.learn(total_timesteps=100000, callback=WandbCallback() )
+model.learn(total_timesteps=1000000, callback=[WandbCallback(), save_callback]) 
 # # Save the model
 model.save("ppo_custom_heterognn")
diff --git a/games/model/__pycache__/cnn_model.cpython-310.pyc b/games/model/__pycache__/cnn_model.cpython-310.pyc
index aaea007..8ce27a0 100644
Binary files a/games/model/__pycache__/cnn_model.cpython-310.pyc and b/games/model/__pycache__/cnn_model.cpython-310.pyc differ
diff --git a/games/model/__pycache__/hetero_gnn.cpython-310.pyc b/games/model/__pycache__/hetero_gnn.cpython-310.pyc
index fae3973..212315f 100644
Binary files a/games/model/__pycache__/hetero_gnn.cpython-310.pyc and b/games/model/__pycache__/hetero_gnn.cpython-310.pyc differ
diff --git a/games/model/__pycache__/hetero_message_passing.cpython-310.pyc b/games/model/__pycache__/hetero_message_passing.cpython-310.pyc
index 8b8b9a9..8b90800 100644
Binary files a/games/model/__pycache__/hetero_message_passing.cpython-310.pyc and b/games/model/__pycache__/hetero_message_passing.cpython-310.pyc differ
diff --git a/games/model/__pycache__/policy.cpython-310.pyc b/games/model/__pycache__/policy.cpython-310.pyc
index 57471c6..9044bb9 100644
Binary files a/games/model/__pycache__/policy.cpython-310.pyc and b/games/model/__pycache__/policy.cpython-310.pyc differ
diff --git a/games/model/hetero_gnn.py b/games/model/hetero_gnn.py
index 141ee67..c1d824c 100644
--- a/games/model/hetero_gnn.py
+++ b/games/model/hetero_gnn.py
@@ -11,14 +11,6 @@ from torch_geometric.typing import Adj
 
 from games.model.hetero_message_passing import FanInMP, FanOutMP
 from torch_geometric.nn import GCNConv, GATConv
-import torch
-import torch_geometric as pyg
-from torch import Tensor
-from torch.nn import ModuleDict
-from typing import Dict, Optional, List, Tuple, Union
-from collections import defaultdict
-from torch_geometric.data import Batch, HeteroData
-from torch_geometric.nn import global_add_pool
 
 class HeteroGNN(torch.nn.Module):
     def __init__(
@@ -129,122 +121,22 @@ class HeteroGNN(torch.nn.Module):
         return pyg.nn.MLP([in_size, hidden_size, out_size], norm=None, dropout=0.0)
 
 
+class HeteroGCN(torch.nn.Module):
+    def __init__(self, in_channels_dict, out_channels):
+        super(HeteroGCN, self).__init__()
+        self.convs = torch.nn.ModuleDict()
+        for obj_type, in_channels in in_channels_dict.items():
+            self.convs[obj_type] = GCNConv(in_channels, out_channels)
 
+    def forward(self, data):
+        for obj_type in data.node_types:
+            x = data[obj_type].x
+            edge_index = data[obj_type, 'to', obj_type].edge_index
+            x = self.convs[obj_type](x, edge_index)
+            x = F.relu(x)
+            data[obj_type].x = x
 
-# class HeteroGNN(torch.nn.Module):
-#     def __init__(
-#         self,
-#         hidden_size: int,
-#         num_layer: int,
-#         obj_type_id: str,
-#         arity_dict: Dict[str, int],
-#         input_size: int = 7,  # Assuming initial input size is 7 for obj nodes
-#         aggr: Optional[Union[str, pyg.nn.aggr.Aggregation]] = "sum",
-#     ):
-#         """
-#         :param hidden_size: The size of object embeddings.
-#         :param num_layer: Total number of message exchange iterations.
-#         :param aggr: Aggregation function to be used for message passing.
-#         :param obj_type_id: The type identifier of objects in the x_dict.
-#         :param arity_dict: A dictionary mapping predicate names to their arity.
-#         Creates one MLP for each predicate.
-#         Note that predicates as well as goal-predicates are meant.
-#         """
-#         super().__init__()
-
-#         self.hidden_size: int = hidden_size
-#         self.num_layer: int = num_layer
-#         self.obj_type_id: str = obj_type_id
-
-#         # Initialize Linear layers for each node type based on arity
-#         self.linear_layers = torch.nn.ModuleDict()
-#         self.linear_layers[obj_type_id] = torch.nn.Linear(input_size, hidden_size)
-#         for pred, arity in arity_dict.items():
-#             if arity > 0:
-#                 self.linear_layers[pred] = torch.nn.Linear(input_size * arity, hidden_size * arity)
-
-#         # Initialize MLPs for each predicate
-#         mlp_dict = {
-#             pred: HeteroGNN.mlp(hidden_size * arity, hidden_size * arity, hidden_size * arity)
-#             for pred, arity in arity_dict.items()
-#             if arity > 0
-#         }
-
-#         self.obj_to_atom = FanOutMP(mlp_dict, src_name=obj_type_id)
-
-#         self.obj_update = HeteroGNN.mlp(
-#             in_size=(hidden_size + hidden_size), hidden_size=(hidden_size + hidden_size) * 2, out_size=hidden_size
-#         )
-
-#         self.atom_to_obj = FanInMP(
-#             hidden_size=hidden_size,
-#             dst_name=obj_type_id,
-#             aggr=aggr,
-#         )
-
-#         #self.readout = HeteroGNN.mlp(hidden_size, 2 * hidden_size, 1)
-
-#     def encode(self, x_dict: Dict[str, Tensor], device: torch.device) -> Dict[str, Tensor]:
-#         # Apply linear transformation to all node types based on their arity
-#         for k, v in x_dict.items():
-#             arity = 1 if k == self.obj_type_id else v.size(1) // self.hidden_size
-#             x_dict[k] = self.linear_layers[k](v.view(v.size(0), -1)).to(device)
-#         return x_dict
-
-#     def layer(self, x_dict, edge_index_dict):
-#         out = self.obj_to_atom(x_dict, edge_index_dict)
-#         x_dict.update(out)
-#         out = self.atom_to_obj(x_dict, edge_index_dict)
-#         obj_emb = torch.cat([x_dict[self.obj_type_id], out[self.obj_type_id]], dim=1)
-#         obj_emb = self.obj_update(obj_emb)
-#         x_dict[self.obj_type_id] = obj_emb
-        
-
-#     def forward(
-#         self,
-#         x_dict: Dict[str, Tensor],
-#         edge_index_dict: Dict[str, Adj],
-#         batch_dict: Optional[Dict[str, Tensor]] = None,
-#     ):
-#         device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-#         x_dict = {k: v.to(device) for k, v in x_dict.items() if v.numel() != 0}
-#         edge_index_dict = {k: v.to(device) for k, v in edge_index_dict.items() if v.numel() != 0}
-
-#         x_dict = self.encode(x_dict, device)  # Encode to hidden size
-
-#         for _ in range(self.num_layer):
-#             self.layer(x_dict, edge_index_dict)
-
-#         obj_emb = x_dict[self.obj_type_id]
-#         batch = (
-#             batch_dict[self.obj_type_id].to(device)
-#             if batch_dict is not None
-#             else torch.zeros(obj_emb.shape[0], dtype=torch.long, device=obj_emb.device)
-#         )
-#         aggr = pyg.nn.global_add_pool(obj_emb, batch)
-#         return aggr
-
-#     @staticmethod
-#     def mlp(in_size: int, hidden_size: int, out_size: int):
-#         return pyg.nn.MLP([in_size, hidden_size, out_size], norm=None, dropout=0.0)
-
-
-# class HeteroGCN(torch.nn.Module):
-#     def __init__(self, in_channels_dict, out_channels):
-#         super(HeteroGCN, self).__init__()
-#         self.convs = torch.nn.ModuleDict()
-#         for obj_type, in_channels in in_channels_dict.items():
-#             self.convs[obj_type] = GCNConv(in_channels, out_channels)
-
-#     def forward(self, data):
-#         for obj_type in data.node_types:
-#             x = data[obj_type].x
-#             edge_index = data[obj_type, 'to', obj_type].edge_index
-#             x = self.convs[obj_type](x, edge_index)
-#             x = F.relu(x)
-#             data[obj_type].x = x
-
-#         return data
+        return data
 
 class HeteroGAT(torch.nn.Module):
     def __init__(self, in_channels_dict, out_channels):
diff --git a/games/model/hetero_message_passing.py b/games/model/hetero_message_passing.py
index 0b4020c..230410f 100644
--- a/games/model/hetero_message_passing.py
+++ b/games/model/hetero_message_passing.py
@@ -1,183 +1,3 @@
-# import abc
-# from typing import Any, Dict, List, Optional, Union
-
-# import torch
-# import torch_geometric as pyg
-# from torch import Tensor
-# from torch_geometric.nn import Aggregation, SimpleConv
-# from torch_geometric.nn.conv.hetero_conv import group
-# from torch_geometric.nn.module_dict import ModuleDict
-# from torch_geometric.typing import Adj, EdgeType, OptPairTensor
-
-
-# class HeteroRouting(torch.nn.Module):
-#     """
-#     Handles heterogeneous message passing very similar to pyg.nn.HeteroConv.
-#     Instead of specifying a convolution for each EdgeType more generic rules can be used.
-#     """
-
-#     def __init__(self, aggr: Optional[str | Aggregation] = None) -> None:
-#         super().__init__()
-#         self.aggr = aggr
-
-#     @abc.abstractmethod
-#     def _accept_edge(self, src: str, rel: str, dst: str) -> bool:
-#         pass
-
-#     @abc.abstractmethod
-#     def _internal_forward(self, x, edges_index, edge_type: EdgeType):
-#         pass
-
-#     def _group_out(self, out_dict: Dict[str, List]) -> Dict[str, Tensor]:
-#         aggregated: Dict[str, Tensor] = {}
-#         for key, value in out_dict.items():
-#             # hetero_conv.group does not yet support Aggregation modules
-#             if isinstance(self.aggr, Aggregation):
-#                 out = torch.stack(value, dim=0)
-#                 out = self.aggr(out, dim=0)
-#                 if out.dim() == 3 and out.shape[0] == 1:
-#                     out = out[0]  # TODO Why does Softmax return one dim to much
-#             else:
-#                 out = group(value, self.aggr)
-#             aggregated[key] = out
-#         return aggregated
-
-#     def forward(self, x_dict, edge_index_dict):
-#         """
-#         Apply message passing to each edge_index key if the edge-type is accepted.
-#         Calls the internal forward with a normal homogenous signature of x, edge_index
-#         :param x_dict: Dictionary with a feature matrix for each node type
-#         :param edge_index_dict: One edge_index adjacency matrix for each edge type.
-#         :return: Dictionary with each processed dst as key and their updated embedding as value.
-#         """
-       
-#         out_dict: Dict[str, Any] = {}
-#         for edge_type in edge_index_dict.keys():
-#             src, rel, dst = edge_type
-
-#             if not self._accept_edge(src, rel, dst):
-#                 continue
-
-#             if src == dst and src in x_dict:
-#                 x = x_dict[src]
-#             elif src in x_dict or dst in x_dict:
-#                 x = (
-#                     x_dict.get(src, None),
-#                     x_dict.get(dst, None),
-#                 )
-#             else:
-#                 raise ValueError(
-#                     f"Neither src ({src}) nor destination ({dst})"
-#                     + f" found in x_dict ({x_dict})"
-#                 )
-
-#             out = self._internal_forward(x, edge_index_dict[edge_type], edge_type)
-#             if dst not in out_dict:
-#                 out_dict[dst] = [out]
-#             else:
-#                 out_dict[dst].append(out)
-
-#         return self._group_out(out_dict)
-
-
-# class FanOutMP(HeteroRouting):
-#     """
-#      Accepts EdgeTypes with the defined src_name.
-#     1. For each destination concatenate all embeddings of the source.
-#     2. Run the destination specific MLP on the concatenated embeddings.
-#     3. Save the new embedding under the destination key.
-#     FanOut should be aggregation free in theory.
-#     Every atom gets only as many messages as the arity of its predicate.
-#     :param update_mlp_by_dst: An MLP for each possible destination.
-#         Needs the degree of incoming edges as input and output dimension
-#     :param src_name: The node-type for which outgoing edges should be accepted.
-#     """
-
-#     def __init__(
-#         self,
-#         update_mlp_by_dst: Dict[str, torch.nn.Module],
-#         src_name: str,
-#     ) -> None:
-#         """ """
-#         super().__init__()
-#         self.update_mlp_by_dst = ModuleDict(update_mlp_by_dst)
-#         self.simple = SimpleConv()
-#         self.src_name = src_name
-
-#     def _accept_edge(self, src, rel, dst) -> bool:
-#         return src == self.src_name
-
-#     def _internal_forward(self, x, edge_index, edge_type: EdgeType):
-#         position = int(edge_type[1])
-        
-#         # Debug: Print edge index and node features
-
-#         # Ensure edge indices are within bounds
-#         max_index = x.shape[0] if isinstance(x, torch.Tensor) else max(x[0].shape[0], x[1].shape[0])
-#         if edge_index.max() >= max_index:
-#             raise ValueError(f"Invalid edge index: {edge_index.max()} is out of bounds for tensor with size {max_index}")
-        
-
-#         out = self.simple(x, edge_index)
-#         return position, out
-
-#     def _group_out(self, out_dict: Dict[str, List]) -> Dict[str, Tensor]:
-#         for dst, value in out_dict.items():
-#             sorted_out = sorted(value, key=lambda tpl: tpl[0])
-#             stacked = torch.cat([out for _, out in sorted_out], dim=1)
-#             out_dict[dst] = self.update_mlp_by_dst[dst](stacked)
-
-#         return out_dict
-
-
-# class FanInMP(HeteroRouting):
-
-#     def __init__(
-#         self,
-#         hidden_size: int,
-#         dst_name: str,
-#         aggr: Optional[Union[str, Aggregation]] = "sum",
-#     ) -> None:
-#         super().__init__(aggr)
-#         self.select = SelectMP(hidden_size)
-#         self.dst_name = dst_name
-
-#     def _accept_edge(self, src: str, rel: str, dst: str) -> bool:
-#         return dst == self.dst_name
-
-#     def _internal_forward(self, x, edges_index, edge_type):
-#         return self.select(x, edges_index, int(edge_type[1]))
-
-
-# class SelectMP(pyg.nn.MessagePassing):
-
-#     def __init__(
-#         self,
-#         hidden_size: int,
-#         aggr: Optional[str | List[str]] = "sum",
-#         aggr_kwargs: Optional[Dict[str, Any]] = None,
-#     ) -> None:
-#         super().__init__(
-#             aggr,
-#             aggr_kwargs=aggr_kwargs,
-#         )
-#         self.hidden = hidden_size
-
-#     def forward(
-#         self, x: Union[Tensor, OptPairTensor], edge_index: Adj, position: int
-#     ) -> Tensor:
-#         if isinstance(x, Tensor):
-#             x = (x, x)
-#         return self.propagate(edge_index, x=x, position=position)
-
-#     def message(self, x_j: Tensor, position: int) -> Tensor:
-#         # Take the i-th hidden-number of elements from the last dimension
-#         # e.g from [1, 2, 3, 4, 5, 6] with hidden=2 and position=1 -> [3, 4]
-#         # alternatively split = torch.split(x_j, self.hidden, dim=-1)
-#         #               split[self.position]
-#         sliced = x_j[:, position * self.hidden : (position + 1) * self.hidden]
-#         return sliced
-
 import abc
 from typing import Any, Dict, List, Optional, Union
 
@@ -230,6 +50,7 @@ class HeteroRouting(torch.nn.Module):
         :param edge_index_dict: One edge_index adjacency matrix for each edge type.
         :return: Dictionary with each processed dst as key and their updated embedding as value.
         """
+       
         out_dict: Dict[str, Any] = {}
         for edge_type in edge_index_dict.keys():
             src, rel, dst = edge_type
@@ -251,7 +72,6 @@ class HeteroRouting(torch.nn.Module):
                 )
 
             out = self._internal_forward(x, edge_index_dict[edge_type], edge_type)
-
             if dst not in out_dict:
                 out_dict[dst] = [out]
             else:
@@ -289,6 +109,15 @@ class FanOutMP(HeteroRouting):
 
     def _internal_forward(self, x, edge_index, edge_type: EdgeType):
         position = int(edge_type[1])
+        
+        # Debug: Print edge index and node features
+
+        # Ensure edge indices are within bounds
+        max_index = x.shape[0] if isinstance(x, torch.Tensor) else max(x[0].shape[0], x[1].shape[0])
+        if edge_index.max() >= max_index:
+            raise ValueError(f"Invalid edge index: {edge_index.max()} is out of bounds for tensor with size {max_index}")
+        
+
         out = self.simple(x, edge_index)
         return position, out
 
@@ -347,4 +176,4 @@ class SelectMP(pyg.nn.MessagePassing):
         # alternatively split = torch.split(x_j, self.hidden, dim=-1)
         #               split[self.position]
         sliced = x_j[:, position * self.hidden : (position + 1) * self.hidden]
-        return sliced
+        return sliced
\ No newline at end of file
diff --git a/games/model/policy.py b/games/model/policy.py
index 7119db4..2d9ea67 100644
--- a/games/model/policy.py
+++ b/games/model/policy.py
@@ -1,5 +1,3 @@
-import pstats
-import time
 import torch as th
 import torch.nn as nn
 import gymnasium as gym
@@ -7,53 +5,48 @@ from stable_baselines3.common.policies import ActorCriticPolicy
 from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
 from games.model.hetero_gnn import HeteroGNN
 from typing import Dict
-from games.encoder.GraphEncoder import HeteroGNNEncoderPong, GraphEncoderFreeway, GraphEncoderPacman, GraphEncoderBreakout
+from games.encoder.GraphEncoder import HeteroGNNEncoderPong
 from gymnasium import spaces
+import torch
+import torch.nn as nn
+from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
+from games.encoder.GraphEncoder import HeteroGNNEncoderPong, GraphEncoderFreeway, GraphEncoderPacman, GraphEncoderBreakout
+from games.model.hetero_gnn import HeteroGNN
 import torch_geometric as pyg
 from games.model.cnn_model import CNNgame
-
+import time
 class CustomHeteroGNN(BaseFeaturesExtractor):
     def __init__(self, observation_space, features_dim=64, hidden_size=64, num_layer=2, obj_type_id='obj', arity_dict={'atom': 2}, game = 'pong'):
         super().__init__(observation_space, features_dim=hidden_size)
         if game == 'pong':
             self.encoder = HeteroGNNEncoderPong()
         elif game == 'freeway':
-            self.encoder = GraphEncoderFreeway()
+            self.encoder = GraphEncoderFreeway() 
         elif game == 'pacman':
             self.encoder = GraphEncoderPacman()
             self.model = HeteroGNN(hidden_size, num_layer, obj_type_id, arity_dict, input_size=8)
         elif game == 'breakout':
             self.encoder = GraphEncoderBreakout()
         
-        self.counter = 0
-
         # set device to mps if available
-        # self.device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
+        #self.device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
         self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-        self.model = HeteroGNN(hidden_size, num_layer, obj_type_id, arity_dict).to(self.device)
+        self.model = HeteroGNN(hidden_size, num_layer, obj_type_id, arity_dict, input_size=7).to(self.device)
+
 
     def forward(self, observations):
         # Encode observations to a graph using the encoder
-        self.counter+=1
-        
         start = time.time()
         pyg_data = self.encoder.encode(observations)
-
         # if observations.shape[0] >1:
         #     print(f"Time to encode: {time.time() - start}")
 
-        #pyg_data = pyg_data.to(self.device) 
+        pyg_data = pyg_data.to(self.device) 
         obj_emb = self.model(pyg_data.x_dict, pyg_data.edge_index_dict, pyg_data.batch_dict)
         # Flatten or pool the embeddings if necessary to match the expected features_dim
-        #print(f"Time to encode: {time.time() - start}")
-        #total_time += 
-        if self.counter % 2048/64 == 0:
-            print(f"time to encode step size is: {time.time() - start}")
-
         return obj_emb
 
 
-# Additional classes for the rest of the code remain unchanged
 
 import torch
 import torch.nn as nn
@@ -101,5 +94,4 @@ class CustomCNN(BaseFeaturesExtractor):
         
         cnn_output = self.cnn(observations)
         final_output = self.adjust_to_features_dim(cnn_output)
-        return final_output
-
+        return final_output
\ No newline at end of file
diff --git a/games/pong/__pycache__/__init__.cpython-310.pyc b/games/pong/__pycache__/__init__.cpython-310.pyc
index 8ff616f..e5567cc 100644
Binary files a/games/pong/__pycache__/__init__.cpython-310.pyc and b/games/pong/__pycache__/__init__.cpython-310.pyc differ
diff --git a/games/pong/__pycache__/eval.cpython-310.pyc b/games/pong/__pycache__/eval.cpython-310.pyc
index c8f54b5..fb7cf0e 100644
Binary files a/games/pong/__pycache__/eval.cpython-310.pyc and b/games/pong/__pycache__/eval.cpython-310.pyc differ
diff --git a/games/pong/eval.py b/games/pong/eval.py
index 5ea5cdc..3c5d17a 100644
--- a/games/pong/eval.py
+++ b/games/pong/eval.py
@@ -1,6 +1,6 @@
 from stable_baselines3 import PPO
 from stable_baselines3.common.vec_env import DummyVecEnv
-from games.pong.pong_envs.pong_env import PongEnvNew
+from games.pong.pong_envs.pong_env import PongEnvTest
 from stable_baselines3.common.evaluation import evaluate_policy
 from stable_baselines3.common.env_util import make_vec_env
 import numpy as np
@@ -48,7 +48,7 @@ def evaluate_model_on_configs(model_path, env_configs, n_eval_episodes=10):
         print(f"Evaluating with config: {config}")
 
         # Create a single instance of the environment for evaluation with the given config
-        eval_env = PongEnvNew(**config)
+        eval_env = PongEnvTest(**config)
 
         # Evaluate the policy
         mean_reward, std_reward, _ = custom_evaluate_policy(model, eval_env, n_eval_episodes=n_eval_episodes)
@@ -96,31 +96,58 @@ if __name__ == "__main__":
     #     {"render_mode": None, "observation_type": "pixel", "paddle_width": 2, "ball_speed": 4}
 
     # ]
-    env_configs = [
+    # 
+    # env_configs = [
 
-        {"render_mode": None, "observation_type": "pixel", "paddle_width": 5, "ball_speed": 10},
-        {"render_mode": None, "observation_type": "pixel", "paddle_width": 5, "ball_speed": 9},
-        {"render_mode": None, "observation_type": "pixel", "paddle_width": 5, "ball_speed": 8},
-        {"render_mode": None, "observation_type": "pixel", "paddle_width": 5, "ball_speed": 7},
-        {"render_mode": None, "observation_type": "pixel", "paddle_width": 5, "ball_speed": 6},
-        {"render_mode": None, "observation_type": "pixel", "paddle_width": 5, "ball_speed": 5},
-        {"render_mode": None, "observation_type": "pixel", "paddle_width": 5, "ball_speed": 4},
-        {"render_mode": None, "observation_type": "pixel", "paddle_width": 5, "ball_speed":3},
-        {"render_mode": None, "observation_type": "pixel", "paddle_width": 5, "ball_speed": 2},
-        {"render_mode": None, "observation_type": "pixel", "paddle_width": 5, "ball_speed": 1}
-    ]
+    #     {"render_mode": None, "observation_type": "pixel", "paddle_width": 1, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "pixel", "paddle_width": 2, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "pixel", "paddle_width": 3, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "pixel", "paddle_width": 4, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "pixel", "paddle_width": 5, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "pixel", "paddle_width": 6, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "pixel", "paddle_width": 7, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "pixel", "paddle_width": 8, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "pixel", "paddle_width": 9, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "pixel", "paddle_width": 10, "ball_speed": 4}
+    # ] 
     # env_configs = [
 
-    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 10},
-    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 9},
-    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 8},
-    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 7},
-    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 6},
-    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 5},
+    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 1, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 2, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 3, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 4, "ball_speed": 4},
     #     {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 4},
-    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed":3},
-    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 2},
-    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 1}
+    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 6, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 7, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 8, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 9, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type": "graph", "paddle_width": 10, "ball_speed": 4}
+    # ]
+
+    env_configs = [
+
+        {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 10},
+        {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 9},
+        {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 8},
+        {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 7},
+        {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 6},
+        {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 5},
+        {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 4},
+        {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed":3},
+        {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 2},
+        {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 1}
+    ]
+    # env_configs = [
+    #     {"render_mode": None, "observation_type":"pixel", "paddle_width": 5, "ball_speed": 1},
+    #     {"render_mode": None, "observation_type":"pixel", "paddle_width": 5, "ball_speed": 2},
+    #     {"render_mode": None, "observation_type":"pixel", "paddle_width": 5, "ball_speed": 3},
+    #     {"render_mode": None, "observation_type":"pixel", "paddle_width": 5, "ball_speed": 4},
+    #     {"render_mode": None, "observation_type":"pixel", "paddle_width": 5, "ball_speed": 5},
+    #     {"render_mode": None, "observation_type":"pixel", "paddle_width": 5, "ball_speed": 6},
+    #     {"render_mode": None, "observation_type":"pixel", "paddle_width": 5, "ball_speed": 7},
+    #     {"render_mode": None, "observation_type":"pixel", "paddle_width": 5, "ball_speed": 8},
+    #     {"render_mode": None, "observation_type":"pixel", "paddle_width": 5, "ball_speed": 9},
+    #     {"render_mode": None, "observation_type":"pixel", "paddle_width": 5, "ball_speed": 10}
     # ]
     # env_configs = [
     #     {"render_mode": None, "observation_type": "graph", "paddle_width": 5, "ball_speed": 6},
@@ -132,8 +159,10 @@ if __name__ == "__main__":
     #