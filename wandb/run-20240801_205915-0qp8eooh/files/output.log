
Using cpu device
-----------------------------
| time/              |      |
|    fps             | 123  |
|    iterations      | 1    |
|    time_elapsed    | 16   |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.05e+03    |
|    ep_rew_mean          | -1.02e+03   |
| time/                   |             |
|    fps                  | 50          |
|    iterations           | 2           |
|    time_elapsed         | 80          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.011333322 |
|    clip_fraction        | 0.0723      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 0.000104    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.348       |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00199    |
|    value_loss           | 3.4         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.05e+03     |
|    ep_rew_mean          | -1.02e+03    |
| time/                   |              |
|    fps                  | 42           |
|    iterations           | 3            |
|    time_elapsed         | 143          |
|    total_timesteps      | 6144         |
| train/                  |              |
|    approx_kl            | 0.0035240916 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.09        |
|    explained_variance   | -0.000181    |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0178      |
|    n_updates            | 20           |
|    policy_gradient_loss | 0.000214     |
|    value_loss           | 14.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.07e+03     |
|    ep_rew_mean          | -1.04e+03    |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 4            |
|    time_elapsed         | 202          |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0018706234 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.06        |
|    explained_variance   | 4.87e-05     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.144        |
|    n_updates            | 30           |
|    policy_gradient_loss | 2.38e-05     |
|    value_loss           | 10.2         |
------------------------------------------
Num timesteps: 10000
Best mean reward: -inf - Last mean reward per episode: -1021.25
Saving new best model at 8230 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.06e+03   |
|    ep_rew_mean          | -1.02e+03  |
| time/                   |            |
|    fps                  | 38         |
|    iterations           | 5          |
|    time_elapsed         | 262        |
|    total_timesteps      | 10240      |
| train/                  |            |
|    approx_kl            | 0.01074004 |
|    clip_fraction        | 0.0159     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.07      |
|    explained_variance   | -3.22e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 3.06       |
|    n_updates            | 40         |
|    policy_gradient_loss | -0.000573  |
|    value_loss           | 10.8       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.05e+03     |
|    ep_rew_mean          | -1.01e+03    |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 6            |
|    time_elapsed         | 324          |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0053676404 |
|    clip_fraction        | 0.0368       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.08        |
|    explained_variance   | 0.00453      |
|    learning_rate        | 0.0003       |
|    loss                 | 7.74         |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00209     |
|    value_loss           | 9.19         |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.05e+03   |
|    ep_rew_mean          | -1.01e+03  |
| time/                   |            |
|    fps                  | 37         |
|    iterations           | 7          |
|    time_elapsed         | 384        |
|    total_timesteps      | 14336      |
| train/                  |            |
|    approx_kl            | 0.00852574 |
|    clip_fraction        | 0.0932     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.07      |
|    explained_variance   | 0.646      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.66       |
|    n_updates            | 60         |
|    policy_gradient_loss | -0.00359   |
|    value_loss           | 4.63       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.05e+03    |
|    ep_rew_mean          | -981        |
| time/                   |             |
|    fps                  | 36          |
|    iterations           | 8           |
|    time_elapsed         | 451         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.013715537 |
|    clip_fraction        | 0.0826      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.03       |
|    explained_variance   | 0.583       |
|    learning_rate        | 0.0003      |
|    loss                 | 11.7        |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00507    |
|    value_loss           | 17.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.05e+03    |
|    ep_rew_mean          | -960        |
| time/                   |             |
|    fps                  | 35          |
|    iterations           | 9           |
|    time_elapsed         | 518         |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.014401528 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.977      |
|    explained_variance   | 0.604       |
|    learning_rate        | 0.0003      |
|    loss                 | 7.66        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00952    |
|    value_loss           | 16.6        |
-----------------------------------------
Num timesteps: 20000
Best mean reward: -1021.25 - Last mean reward per episode: -920.72
Saving new best model at 18433 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.05e+03    |
|    ep_rew_mean          | -921        |
| time/                   |             |
|    fps                  | 35          |
|    iterations           | 10          |
|    time_elapsed         | 584         |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.016815374 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.883      |
|    explained_variance   | 0.529       |
|    learning_rate        | 0.0003      |
|    loss                 | 25.9        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00896    |
|    value_loss           | 33.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.05e+03     |
|    ep_rew_mean          | -883         |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 11           |
|    time_elapsed         | 652          |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0060469676 |
|    clip_fraction        | 0.0588       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.802       |
|    explained_variance   | 0.497        |
|    learning_rate        | 0.0003       |
|    loss                 | 26.9         |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00443     |
|    value_loss           | 37.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.05e+03     |
|    ep_rew_mean          | -833         |
| time/                   |              |
|    fps                  | 33           |
|    iterations           | 12           |
|    time_elapsed         | 723          |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0047004893 |
|    clip_fraction        | 0.0141       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.762       |
|    explained_variance   | 0.461        |
|    learning_rate        | 0.0003       |
|    loss                 | 24.5         |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.000363    |
|    value_loss           | 48.9         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.05e+03    |
|    ep_rew_mean          | -789        |
| time/                   |             |
|    fps                  | 33          |
|    iterations           | 13          |
|    time_elapsed         | 787         |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.009358337 |
|    clip_fraction        | 0.0697      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.698      |
|    explained_variance   | 0.512       |
|    learning_rate        | 0.0003      |
|    loss                 | 27.8        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00507    |
|    value_loss           | 47.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.05e+03    |
|    ep_rew_mean          | -745        |
| time/                   |             |
|    fps                  | 33          |
|    iterations           | 14          |
|    time_elapsed         | 851         |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.006944748 |
|    clip_fraction        | 0.0852      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.606      |
|    explained_variance   | 0.457       |
|    learning_rate        | 0.0003      |
|    loss                 | 25.3        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00626    |
|    value_loss           | 53          |
-----------------------------------------
Num timesteps: 30000
Best mean reward: -920.72 - Last mean reward per episode: -720.82
Saving new best model at 28703 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.05e+03     |
|    ep_rew_mean          | -721         |
| time/                   |              |
|    fps                  | 33           |
|    iterations           | 15           |
|    time_elapsed         | 911          |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 0.0023156102 |
|    clip_fraction        | 0.0201       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.603       |
|    explained_variance   | 0.463        |
|    learning_rate        | 0.0003       |
|    loss                 | 22.9         |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.000449    |
|    value_loss           | 45.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.05e+03      |
|    ep_rew_mean          | -690          |
| time/                   |               |
|    fps                  | 33            |
|    iterations           | 16            |
|    time_elapsed         | 972           |
|    total_timesteps      | 32768         |
| train/                  |               |
|    approx_kl            | 0.00095009606 |
|    clip_fraction        | 0.0118        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.568        |
|    explained_variance   | 0.435         |
|    learning_rate        | 0.0003        |
|    loss                 | 22.8          |
|    n_updates            | 150           |
|    policy_gradient_loss | -0.00157      |
|    value_loss           | 52.6          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.05e+03    |
|    ep_rew_mean          | -664        |
| time/                   |             |
|    fps                  | 33          |
|    iterations           | 17          |
|    time_elapsed         | 1033        |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.003551602 |
|    clip_fraction        | 0.032       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.534      |
|    explained_variance   | 0.458       |
|    learning_rate        | 0.0003      |
|    loss                 | 18.4        |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.00256    |
|    value_loss           | 49          |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.05e+03     |
|    ep_rew_mean          | -648         |
| time/                   |              |
|    fps                  | 33           |
|    iterations           | 18           |
|    time_elapsed         | 1092         |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0037137843 |
|    clip_fraction        | 0.0329       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.456       |
|    explained_variance   | 0.444        |
|    learning_rate        | 0.0003       |
|    loss                 | 24.6         |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00203     |
|    value_loss           | 51.2         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.05e+03     |
|    ep_rew_mean          | -624         |
| time/                   |              |
|    fps                  | 33           |
|    iterations           | 19           |
|    time_elapsed         | 1158         |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0018095174 |
|    clip_fraction        | 0.0385       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.389       |
|    explained_variance   | 0.415        |
|    learning_rate        | 0.0003       |
|    loss                 | 31.8         |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.00263     |
|    value_loss           | 55.1         |
------------------------------------------
Num timesteps: 40000
Best mean reward: -720.82 - Last mean reward per episode: -599.29
Saving new best model at 38913 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.05e+03     |
|    ep_rew_mean          | -599         |
| time/                   |              |
|    fps                  | 33           |
|    iterations           | 20           |
|    time_elapsed         | 1221         |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 0.0025958284 |
|    clip_fraction        | 0.0292       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.359       |
|    explained_variance   | 0.431        |
|    learning_rate        | 0.0003       |
|    loss                 | 31.8         |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.00206     |
|    value_loss           | 61.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.05e+03     |
|    ep_rew_mean          | -588         |
| time/                   |              |
|    fps                  | 33           |
|    iterations           | 21           |
|    time_elapsed         | 1283         |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0010615159 |
|    clip_fraction        | 0.00933      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.373       |
|    explained_variance   | 0.396        |
|    learning_rate        | 0.0003       |
|    loss                 | 31.9         |
|    n_updates            | 200          |
|    policy_gradient_loss | 0.000359     |
|    value_loss           | 53.2         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.05e+03     |
|    ep_rew_mean          | -571         |
| time/                   |              |
|    fps                  | 33           |
|    iterations           | 22           |
|    time_elapsed         | 1350         |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0015032549 |
|    clip_fraction        | 0.0313       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.306       |
|    explained_variance   | 0.417        |
|    learning_rate        | 0.0003       |
|    loss                 | 25.5         |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.0016      |
|    value_loss           | 57.1         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.05e+03     |
|    ep_rew_mean          | -556         |
| time/                   |              |
|    fps                  | 33           |
|    iterations           | 23           |
|    time_elapsed         | 1415         |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 0.0014619898 |
|    clip_fraction        | 0.0132       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.286       |
|    explained_variance   | 0.407        |
|    learning_rate        | 0.0003       |
|    loss                 | 27           |
|    n_updates            | 220          |
|    policy_gradient_loss | -0.000207    |
|    value_loss           | 56.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.05e+03     |
|    ep_rew_mean          | -535         |
| time/                   |              |
|    fps                  | 33           |
|    iterations           | 24           |
|    time_elapsed         | 1482         |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0005854127 |
|    clip_fraction        | 0.0165       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.231       |
|    explained_variance   | 0.405        |
|    learning_rate        | 0.0003       |
|    loss                 | 36.1         |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.00136     |
|    value_loss           | 65.8         |
------------------------------------------
Num timesteps: 50000
Best mean reward: -599.29 - Last mean reward per episode: -521.52
Saving new best model at 49153 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.05e+03     |
|    ep_rew_mean          | -522         |
| time/                   |              |
|    fps                  | 32           |
|    iterations           | 25           |
|    time_elapsed         | 1552         |
|    total_timesteps      | 51200        |
| train/                  |              |
|    approx_kl            | 0.0010940749 |
|    clip_fraction        | 0.0162       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.197       |
|    explained_variance   | 0.393        |
|    learning_rate        | 0.0003       |
|    loss                 | 28.6         |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.000853    |
|    value_loss           | 55.3         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.05e+03      |
|    ep_rew_mean          | -506          |
| time/                   |               |
|    fps                  | 32            |
|    iterations           | 26            |
|    time_elapsed         | 1617          |
|    total_timesteps      | 53248         |
| train/                  |               |
|    approx_kl            | 0.00019551103 |
|    clip_fraction        | 0.00649       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.184        |
|    explained_variance   | 0.405         |
|    learning_rate        | 0.0003        |
|    loss                 | 33.1          |
|    n_updates            | 250           |
|    policy_gradient_loss | 5.71e-05      |
|    value_loss           | 63.3          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.05e+03     |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 32           |
|    iterations           | 27           |
|    time_elapsed         | 1684         |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 0.0011746719 |
|    clip_fraction        | 0.0126       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.179       |
|    explained_variance   | 0.395        |
|    learning_rate        | 0.0003       |
|    loss                 | 26.1         |
|    n_updates            | 260          |
|    policy_gradient_loss | -2.69e-05    |
|    value_loss           | 52.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.05e+03      |
|    ep_rew_mean          | -486          |
| time/                   |               |
|    fps                  | 32            |
|    iterations           | 28            |
|    time_elapsed         | 1749          |
|    total_timesteps      | 57344         |
| train/                  |               |
|    approx_kl            | 0.00034807037 |
|    clip_fraction        | 0.00781       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.162        |
|    explained_variance   | 0.389         |
|    learning_rate        | 0.0003        |
|    loss                 | 26.4          |
|    n_updates            | 270           |
|    policy_gradient_loss | -0.000307     |
|    value_loss           | 68.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.05e+03      |
|    ep_rew_mean          | -479          |
| time/                   |               |
|    fps                  | 32            |
|    iterations           | 29            |
|    time_elapsed         | 1821          |
|    total_timesteps      | 59392         |
| train/                  |               |
|    approx_kl            | 0.00045297857 |
|    clip_fraction        | 0.00244       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.149        |
|    explained_variance   | 0.385         |
|    learning_rate        | 0.0003        |
|    loss                 | 39.9          |
|    n_updates            | 280           |
|    policy_gradient_loss | -0.000136     |
|    value_loss           | 60.5          |
-------------------------------------------
Num timesteps: 60000
Best mean reward: -521.52 - Last mean reward per episode: -472.64
Saving new best model at 59393 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.05e+03      |
|    ep_rew_mean          | -473          |
| time/                   |               |
|    fps                  | 32            |
|    iterations           | 30            |
|    time_elapsed         | 1887          |
|    total_timesteps      | 61440         |
| train/                  |               |
|    approx_kl            | 0.00042973465 |
|    clip_fraction        | 0.0136        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.132        |
|    explained_variance   | 0.387         |
|    learning_rate        | 0.0003        |
|    loss                 | 21            |
|    n_updates            | 290           |
|    policy_gradient_loss | -0.000678     |
|    value_loss           | 59.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.05e+03      |
|    ep_rew_mean          | -465          |
| time/                   |               |
|    fps                  | 32            |
|    iterations           | 31            |
|    time_elapsed         | 1955          |
|    total_timesteps      | 63488         |
| train/                  |               |
|    approx_kl            | 0.00024497297 |
|    clip_fraction        | 0.00532       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.132        |
|    explained_variance   | 0.392         |
|    learning_rate        | 0.0003        |
|    loss                 | 32.6          |
|    n_updates            | 300           |
|    policy_gradient_loss | 0.000184      |
|    value_loss           | 63.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 2.05e+03      |
|    ep_rew_mean          | -452          |
| time/                   |               |
|    fps                  | 32            |
|    iterations           | 32            |
|    time_elapsed         | 2021          |
|    total_timesteps      | 65536         |
| train/                  |               |
|    approx_kl            | 0.00075708004 |
|    clip_fraction        | 0.00542       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.116        |
|    explained_variance   | 0.392         |
|    learning_rate        | 0.0003        |
|    loss                 | 30.1          |
|    n_updates            | 310           |
|    policy_gradient_loss | -6.52e-05     |
|    value_loss           | 68.1          |
-------------------------------------------
Traceback (most recent call last):
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/freeway/run_supervised_gnn.py", line 290, in <module>
    model.learn(total_timesteps=1000000, callback=[WandbCallback(), save_callback])
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 315, in learn
    return super().learn(
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 313, in learn
    self.train()
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 279, in train
    loss.backward()
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt