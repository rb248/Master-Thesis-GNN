diff --git a/games/encoder/__pycache__/GraphEncoder.cpython-310.pyc b/games/encoder/__pycache__/GraphEncoder.cpython-310.pyc
index 3dc7f23..30515ae 100644
Binary files a/games/encoder/__pycache__/GraphEncoder.cpython-310.pyc and b/games/encoder/__pycache__/GraphEncoder.cpython-310.pyc differ
diff --git a/games/freeway/__pycache__/run_supervised_gnn.cpython-310.pyc b/games/freeway/__pycache__/run_supervised_gnn.cpython-310.pyc
index ef42b16..98ca389 100644
Binary files a/games/freeway/__pycache__/run_supervised_gnn.cpython-310.pyc and b/games/freeway/__pycache__/run_supervised_gnn.cpython-310.pyc differ
diff --git a/games/freeway/freeway_envs/__pycache__/freeway_env.cpython-310.pyc b/games/freeway/freeway_envs/__pycache__/freeway_env.cpython-310.pyc
index 2093cbd..919134b 100644
Binary files a/games/freeway/freeway_envs/__pycache__/freeway_env.cpython-310.pyc and b/games/freeway/freeway_envs/__pycache__/freeway_env.cpython-310.pyc differ
diff --git a/games/freeway/run_supervised_gnn.py b/games/freeway/run_supervised_gnn.py
index 3a19658..1a76bab 100644
--- a/games/freeway/run_supervised_gnn.py
+++ b/games/freeway/run_supervised_gnn.py
@@ -3,9 +3,62 @@ from stable_baselines3 import PPO
 from stable_baselines3.common.env_util import make_vec_env
 from wandb.integration.sb3 import WandbCallback
 #from games.model.policy import CustomActorCriticPolicy
-from games.freeway.freeway_envs.freeway_env import FreewayEnv
 from games.model.policy import CustomCNN, CustomHeteroGNN
+from games.freeway.freeway_envs.freeway_env import FreewayEnv
 import pygame
+from stable_baselines3.common.callbacks import BaseCallback
+import os
+import numpy as np
+from stable_baselines3.common.vec_env import DummyVecEnv
+from stable_baselines3.common.monitor import Monitor
+from stable_baselines3.common.callbacks import EvalCallback
+from stable_baselines3.common.monitor import load_results
+from stable_baselines3.common.results_plotter import ts2xy
+#Initialize wandb
+class SaveOnBestTrainingRewardCallback(BaseCallback):
+    def __init__(self, check_freq, log_dir, verbose=1):
+        super(SaveOnBestTrainingRewardCallback, self).__init__(verbose)
+        self.check_freq = check_freq
+        self.log_dir = log_dir
+        self.save_path = os.path.join(log_dir, "best_model")
+        self.best_mean_reward = -np.inf
+
+    def _init_callback(self) -> None:
+        if self.save_path is not None:
+            os.makedirs(self.save_path, exist_ok=True)
+
+    def _on_step(self) -> bool:
+        if self.n_calls % self.check_freq == 0:
+            x, y = ts2xy(load_results(self.log_dir), "timesteps")
+            if len(x) > 0:
+                mean_reward = np.mean(y[-100:])
+                if self.verbose > 0:
+                    print(f"Num timesteps: {self.num_timesteps}")
+                    print(f"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}")
+                if mean_reward > self.best_mean_reward:
+                    self.best_mean_reward = mean_reward
+                    if self.verbose > 0:
+                        print(f"Saving new best model at {x[-1]} timesteps")
+                        print(f"Saving new best model to {self.save_path}.zip")
+                    self.model.save(self.save_path)
+                #wandb.log({"mean_reward": mean_reward, "timesteps": self.num_timesteps})
+            else:
+                device = "cpu"
+                if self.verbose > 0:
+                    print("No data available for logging.")
+                #wandb.log({"timesteps": self.num_timesteps})
+        return True 
+log_dir = "./logs/Freeway-GNN-training/"
+
+def make_env(lanes, max_cars, car_speed, seed=0, rank=None):
+    def _init():
+        env = FreewayEnvTest( render_mode='human', observation_type='graph')
+        monitor_path = os.path.join(log_dir, f"monitor_{rank}.csv")
+        os.makedirs(log_dir, exist_ok=True)  # Create log directory if it doesn't exist
+        env = Monitor(env, filename=monitor_path, allow_early_resets=True)
+        env.seed(seed + rank)
+        return env
+    return _init 
 # #Initialize wandb
 wandb.init(
     project="gnn_atari_freeway",  # Replace with your project name
@@ -23,12 +76,12 @@ wandb.init(
 
 # Wrap the environment 
 
-env = FreewayEnv(render_mode='human', observation_type='graph')
+#env = FreewayEnv(render_mode='human', observation_type='graph')
 # policy_kwargs = dict(
 #     features_extractor_class=CustomCNN,
 #     features_extractor_kwargs=dict(features_dim=128),
 # )
-
+envs = DummyVecEnv([make_env(2, 2, 1, i) for i in range(1)])
 policy_kwargs = dict(
     features_extractor_class=CustomHeteroGNN,
     features_extractor_kwargs=dict(
@@ -42,9 +95,10 @@ policy_kwargs = dict(
 )
 
 # # Create the PPO model with the custom feature extractor
-model = PPO('MlpPolicy', env, policy_kwargs=policy_kwargs, verbose=2)
+model = PPO('MlpPolicy', envs, policy_kwargs=policy_kwargs, verbose=2)
 # # Train the model with WandbCallback
-model.learn(total_timesteps=1000000, callback=WandbCallback() )
+callback = SaveOnBestTrainingRewardCallback(check_freq=10000, log_dir=log_dir)
+model.learn(total_timesteps=160000, callback=[callback, WandbCallback()] )
 # # Save the model
 model.save("ppo_custom_heterognn")
 
diff --git a/games/model/__pycache__/hetero_gnn.cpython-310.pyc b/games/model/__pycache__/hetero_gnn.cpython-310.pyc
index 7853617..237d220 100644
Binary files a/games/model/__pycache__/hetero_gnn.cpython-310.pyc and b/games/model/__pycache__/hetero_gnn.cpython-310.pyc differ
diff --git a/games/model/__pycache__/hetero_message_passing.cpython-310.pyc b/games/model/__pycache__/hetero_message_passing.cpython-310.pyc
index 243e3b4..069cd92 100644
Binary files a/games/model/__pycache__/hetero_message_passing.cpython-310.pyc and b/games/model/__pycache__/hetero_message_passing.cpython-310.pyc differ
diff --git a/games/model/__pycache__/policy.cpython-310.pyc b/games/model/__pycache__/policy.cpython-310.pyc
index 18a2c62..9e8820c 100644
Binary files a/games/model/__pycache__/policy.cpython-310.pyc and b/games/model/__pycache__/policy.cpython-310.pyc differ
diff --git a/wandb/debug-internal.log b/wandb/debug-internal.log
index 0355c64..4ea026a 120000
--- a/wandb/debug-internal.log
+++ b/wandb/debug-internal.log
@@ -1 +1 @@
-run-20240626_173531-u9sj3nyk/logs/debug-internal.log
\ No newline at end of file
+run-20240801_232008-w35wst1r/logs/debug-internal.log
\ No newline at end of file
diff --git a/wandb/debug.log b/wandb/debug.log
index c7c35e9..43e13ca 120000
--- a/wandb/debug.log
+++ b/wandb/debug.log
@@ -1 +1 @@
-run-20240626_173531-u9sj3nyk/logs/debug.log
\ No newline at end of file
+run-20240801_232008-w35wst1r/logs/debug.log
\ No newline at end of file
diff --git a/wandb/latest-run b/wandb/latest-run
index ae14d51..a2996f6 120000
--- a/wandb/latest-run
+++ b/wandb/latest-run
@@ -1 +1 @@
-run-20240626_173531-u9sj3nyk
\ No newline at end of file
+run-20240801_232008-w35wst1r
\ No newline at end of file
