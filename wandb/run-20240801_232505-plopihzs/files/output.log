/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: [33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.
  logger.warn(
Using cpu device
-----------------------------
| time/              |      |
|    fps             | 322  |
|    iterations      | 1    |
|    time_elapsed    | 6    |
|    total_timesteps | 2048 |
-----------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 113          |
|    iterations           | 2            |
|    time_elapsed         | 36           |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0109983925 |
|    clip_fraction        | 0.0551       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.09        |
|    explained_variance   | 0.0407       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.365        |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00199     |
|    value_loss           | 4.75         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.41e+03     |
|    ep_rew_mean          | -2.15e+03    |
| time/                   |              |
|    fps                  | 93           |
|    iterations           | 3            |
|    time_elapsed         | 65           |
|    total_timesteps      | 6144         |
| train/                  |              |
|    approx_kl            | 0.0030524684 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.09        |
|    explained_variance   | 5.96e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 1.1          |
|    n_updates            | 20           |
|    policy_gradient_loss | 5.82e-05     |
|    value_loss           | 15.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.41e+03     |
|    ep_rew_mean          | -2.15e+03    |
| time/                   |              |
|    fps                  | 86           |
|    iterations           | 4            |
|    time_elapsed         | 95           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0018509155 |
|    clip_fraction        | 0.0324       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.06        |
|    explained_variance   | 3.58e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 3.74         |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00373     |
|    value_loss           | 16.4         |
------------------------------------------
Num timesteps: 10000
Best mean reward: -inf - Last mean reward per episode: -1905.75
Saving new best model at 8583 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.29e+03    |
|    ep_rew_mean          | -1.91e+03   |
| time/                   |             |
|    fps                  | 81          |
|    iterations           | 5           |
|    time_elapsed         | 125         |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.015719619 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.999      |
|    explained_variance   | -2.38e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 6.84        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0131     |
|    value_loss           | 18.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.29e+03    |
|    ep_rew_mean          | -1.91e+03   |
| time/                   |             |
|    fps                  | 79          |
|    iterations           | 6           |
|    time_elapsed         | 154         |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.017363751 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.893      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 9.34        |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0173     |
|    value_loss           | 28.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -1.58e+03   |
| time/                   |             |
|    fps                  | 76          |
|    iterations           | 7           |
|    time_elapsed         | 186         |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.011912195 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.791      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 15.4        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0123     |
|    value_loss           | 28.8        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -1.58e+03  |
| time/                   |            |
|    fps                  | 74         |
|    iterations           | 8          |
|    time_elapsed         | 218        |
|    total_timesteps      | 16384      |
| train/                  |            |
|    approx_kl            | 0.00884554 |
|    clip_fraction        | 0.0974     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.698     |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 37.6       |
|    n_updates            | 70         |
|    policy_gradient_loss | -0.00638   |
|    value_loss           | 35.7       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -1.35e+03    |
| time/                   |              |
|    fps                  | 73           |
|    iterations           | 9            |
|    time_elapsed         | 249          |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0032878541 |
|    clip_fraction        | 0.0135       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.698       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 11.3         |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.000631    |
|    value_loss           | 32.5         |
------------------------------------------
Num timesteps: 20000
Best mean reward: -1905.75 - Last mean reward per episode: -1353.12
Saving new best model at 16385 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -1.35e+03   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 10          |
|    time_elapsed         | 283         |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.006064442 |
|    clip_fraction        | 0.0927      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.631      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 16.8        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00543    |
|    value_loss           | 33          |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -1.17e+03   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 11          |
|    time_elapsed         | 314         |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.005773217 |
|    clip_fraction        | 0.0404      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.61       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 17.8        |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00214    |
|    value_loss           | 33.6        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -1.17e+03    |
| time/                   |              |
|    fps                  | 70           |
|    iterations           | 12           |
|    time_elapsed         | 347          |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0047076414 |
|    clip_fraction        | 0.0495       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.54        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 18.1         |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00106     |
|    value_loss           | 34.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -1.04e+03    |
| time/                   |              |
|    fps                  | 70           |
|    iterations           | 13           |
|    time_elapsed         | 379          |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0020770743 |
|    clip_fraction        | 0.0283       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.465       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 15.5         |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00199     |
|    value_loss           | 35.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -1.04e+03    |
| time/                   |              |
|    fps                  | 69           |
|    iterations           | 14           |
|    time_elapsed         | 412          |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 0.0031040753 |
|    clip_fraction        | 0.0205       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.497       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 18.1         |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00167     |
|    value_loss           | 35.2         |
------------------------------------------
Num timesteps: 30000
Best mean reward: -1353.12 - Last mean reward per episode: -922.36
Saving new best model at 28673 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -922         |
| time/                   |              |
|    fps                  | 69           |
|    iterations           | 15           |
|    time_elapsed         | 443          |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 0.0028849314 |
|    clip_fraction        | 0.0317       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.425       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 21.7         |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00201     |
|    value_loss           | 35.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -922         |
| time/                   |              |
|    fps                  | 69           |
|    iterations           | 16           |
|    time_elapsed         | 473          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0010256737 |
|    clip_fraction        | 0.0111       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.402       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 20.5         |
|    n_updates            | 150          |
|    policy_gradient_loss | 1.39e-05     |
|    value_loss           | 36.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -823         |
| time/                   |              |
|    fps                  | 68           |
|    iterations           | 17           |
|    time_elapsed         | 509          |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0030821005 |
|    clip_fraction        | 0.0286       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.392       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 16.5         |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00211     |
|    value_loss           | 36.1         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -823         |
| time/                   |              |
|    fps                  | 67           |
|    iterations           | 18           |
|    time_elapsed         | 544          |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0030085864 |
|    clip_fraction        | 0.0311       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.332       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 15.2         |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00153     |
|    value_loss           | 37.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -735          |
| time/                   |               |
|    fps                  | 67            |
|    iterations           | 19            |
|    time_elapsed         | 578           |
|    total_timesteps      | 38912         |
| train/                  |               |
|    approx_kl            | 0.00035733814 |
|    clip_fraction        | 0.0199        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.26         |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 21.2          |
|    n_updates            | 180           |
|    policy_gradient_loss | -0.000237     |
|    value_loss           | 36.7          |
-------------------------------------------
Num timesteps: 40000
Best mean reward: -922.36 - Last mean reward per episode: -734.72
Saving new best model at 36865 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -735         |
| time/                   |              |
|    fps                  | 67           |
|    iterations           | 20           |
|    time_elapsed         | 609          |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 0.0017155989 |
|    clip_fraction        | 0.0303       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.244       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 17.7         |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.00249     |
|    value_loss           | 37.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -650          |
| time/                   |               |
|    fps                  | 67            |
|    iterations           | 21            |
|    time_elapsed         | 640           |
|    total_timesteps      | 43008         |
| train/                  |               |
|    approx_kl            | 0.00057151855 |
|    clip_fraction        | 0.00435       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.241        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 15.5          |
|    n_updates            | 200           |
|    policy_gradient_loss | -0.000146     |
|    value_loss           | 37.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -650         |
| time/                   |              |
|    fps                  | 67           |
|    iterations           | 22           |
|    time_elapsed         | 671          |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0011110455 |
|    clip_fraction        | 0.0231       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.196       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 14.4         |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.00235     |
|    value_loss           | 38.2         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -586         |
| time/                   |              |
|    fps                  | 67           |
|    iterations           | 23           |
|    time_elapsed         | 702          |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 0.0008663712 |
|    clip_fraction        | 0.0179       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.186       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 24.2         |
|    n_updates            | 220          |
|    policy_gradient_loss | -0.00103     |
|    value_loss           | 37.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -586         |
| time/                   |              |
|    fps                  | 66           |
|    iterations           | 24           |
|    time_elapsed         | 734          |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0016351496 |
|    clip_fraction        | 0.0172       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.168       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 21.7         |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.000954    |
|    value_loss           | 37.2         |
------------------------------------------
Num timesteps: 50000
Best mean reward: -734.72 - Last mean reward per episode: -524.71
Saving new best model at 49153 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -525          |
| time/                   |               |
|    fps                  | 66            |
|    iterations           | 25            |
|    time_elapsed         | 766           |
|    total_timesteps      | 51200         |
| train/                  |               |
|    approx_kl            | 0.00037340593 |
|    clip_fraction        | 0.00781       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.155        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 19.8          |
|    n_updates            | 240           |
|    policy_gradient_loss | -0.000135     |
|    value_loss           | 37.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -525          |
| time/                   |               |
|    fps                  | 66            |
|    iterations           | 26            |
|    time_elapsed         | 799           |
|    total_timesteps      | 53248         |
| train/                  |               |
|    approx_kl            | 0.00072058407 |
|    clip_fraction        | 0.00884       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.139        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 19            |
|    n_updates            | 250           |
|    policy_gradient_loss | -0.000782     |
|    value_loss           | 37.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -465          |
| time/                   |               |
|    fps                  | 66            |
|    iterations           | 27            |
|    time_elapsed         | 829           |
|    total_timesteps      | 55296         |
| train/                  |               |
|    approx_kl            | 0.00043294666 |
|    clip_fraction        | 0.0101        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.133        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 25.5          |
|    n_updates            | 260           |
|    policy_gradient_loss | -0.000623     |
|    value_loss           | 36.5          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.1e+03     |
|    ep_rew_mean          | -465        |
| time/                   |             |
|    fps                  | 66          |
|    iterations           | 28          |
|    time_elapsed         | 862         |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.000534227 |
|    clip_fraction        | 0.00664     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.126      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 12.9        |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.000266   |
|    value_loss           | 37.7        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -418          |
| time/                   |               |
|    fps                  | 66            |
|    iterations           | 29            |
|    time_elapsed         | 894           |
|    total_timesteps      | 59392         |
| train/                  |               |
|    approx_kl            | 0.00012763709 |
|    clip_fraction        | 0.00674       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.119        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 21.8          |
|    n_updates            | 280           |
|    policy_gradient_loss | -0.000193     |
|    value_loss           | 38.9          |
-------------------------------------------
Num timesteps: 60000
Best mean reward: -524.71 - Last mean reward per episode: -418.04
Saving new best model at 57345 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -418          |
| time/                   |               |
|    fps                  | 66            |
|    iterations           | 30            |
|    time_elapsed         | 929           |
|    total_timesteps      | 61440         |
| train/                  |               |
|    approx_kl            | 0.00040866318 |
|    clip_fraction        | 0.0108        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.12         |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 19.8          |
|    n_updates            | 290           |
|    policy_gradient_loss | -0.000999     |
|    value_loss           | 38.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -377          |
| time/                   |               |
|    fps                  | 66            |
|    iterations           | 31            |
|    time_elapsed         | 959           |
|    total_timesteps      | 63488         |
| train/                  |               |
|    approx_kl            | 0.00043493498 |
|    clip_fraction        | 0.00991       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.105        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 20.6          |
|    n_updates            | 300           |
|    policy_gradient_loss | -0.000676     |
|    value_loss           | 38.2          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -377         |
| time/                   |              |
|    fps                  | 66           |
|    iterations           | 32           |
|    time_elapsed         | 990          |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0002861847 |
|    clip_fraction        | 0.00713      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.116       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 18           |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.000456    |
|    value_loss           | 38.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -343         |
| time/                   |              |
|    fps                  | 66           |
|    iterations           | 33           |
|    time_elapsed         | 1021         |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 0.0004992364 |
|    clip_fraction        | 0.00913      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0979      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 15.9         |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.000714    |
|    value_loss           | 38.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -343          |
| time/                   |               |
|    fps                  | 66            |
|    iterations           | 34            |
|    time_elapsed         | 1052          |
|    total_timesteps      | 69632         |
| train/                  |               |
|    approx_kl            | 0.00037816985 |
|    clip_fraction        | 0.00522       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0829       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 23.6          |
|    n_updates            | 330           |
|    policy_gradient_loss | 2.57e-05      |
|    value_loss           | 37.3          |
-------------------------------------------
Num timesteps: 70000
Best mean reward: -418.04 - Last mean reward per episode: -312.74
Saving new best model at 69633 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -313         |
| time/                   |              |
|    fps                  | 65           |
|    iterations           | 35           |
|    time_elapsed         | 1089         |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 3.723227e-05 |
|    clip_fraction        | 0.00313      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0812      |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 24.1         |
|    n_updates            | 340          |
|    policy_gradient_loss | 0.000148     |
|    value_loss           | 39.2         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -313         |
| time/                   |              |
|    fps                  | 65           |
|    iterations           | 36           |
|    time_elapsed         | 1123         |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 5.804212e-05 |
|    clip_fraction        | 0.00308      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0739      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 19           |
|    n_updates            | 350          |
|    policy_gradient_loss | 2.29e-06     |
|    value_loss           | 37.8         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -279          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 37            |
|    time_elapsed         | 1156          |
|    total_timesteps      | 75776         |
| train/                  |               |
|    approx_kl            | 0.00048260306 |
|    clip_fraction        | 0.00884       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0594       |
|    explained_variance   | 1.79e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 21            |
|    n_updates            | 360           |
|    policy_gradient_loss | -0.00084      |
|    value_loss           | 38.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -279          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 38            |
|    time_elapsed         | 1187          |
|    total_timesteps      | 77824         |
| train/                  |               |
|    approx_kl            | 3.7857244e-05 |
|    clip_fraction        | 0.00425       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0528       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 20.4          |
|    n_updates            | 370           |
|    policy_gradient_loss | -0.000108     |
|    value_loss           | 38.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -245         |
| time/                   |              |
|    fps                  | 65           |
|    iterations           | 39           |
|    time_elapsed         | 1217         |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 0.0002489469 |
|    clip_fraction        | 0.00659      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0749      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 15.1         |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.000493    |
|    value_loss           | 36.5         |
------------------------------------------
Num timesteps: 80000
Best mean reward: -312.74 - Last mean reward per episode: -244.87
Saving new best model at 77825 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -245          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 40            |
|    time_elapsed         | 1247          |
|    total_timesteps      | 81920         |
| train/                  |               |
|    approx_kl            | 0.00035814053 |
|    clip_fraction        | 0.00923       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0606       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 16.4          |
|    n_updates            | 390           |
|    policy_gradient_loss | -0.000626     |
|    value_loss           | 38            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.12e+03      |
|    ep_rew_mean          | -221          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 41            |
|    time_elapsed         | 1275          |
|    total_timesteps      | 83968         |
| train/                  |               |
|    approx_kl            | 0.00019385791 |
|    clip_fraction        | 0.00508       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.071        |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 24.7          |
|    n_updates            | 400           |
|    policy_gradient_loss | -0.00019      |
|    value_loss           | 37.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.12e+03      |
|    ep_rew_mean          | -221          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 42            |
|    time_elapsed         | 1307          |
|    total_timesteps      | 86016         |
| train/                  |               |
|    approx_kl            | 0.00015785045 |
|    clip_fraction        | 0.00239       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0684       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 18.5          |
|    n_updates            | 410           |
|    policy_gradient_loss | 0.000168      |
|    value_loss           | 38.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -205          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 43            |
|    time_elapsed         | 1343          |
|    total_timesteps      | 88064         |
| train/                  |               |
|    approx_kl            | 0.00013544955 |
|    clip_fraction        | 0.00376       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0638       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 15.6          |
|    n_updates            | 420           |
|    policy_gradient_loss | -7.76e-05     |
|    value_loss           | 38.6          |
-------------------------------------------
Num timesteps: 90000
Best mean reward: -244.87 - Last mean reward per episode: -205.17
Saving new best model at 86017 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -205          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 44            |
|    time_elapsed         | 1382          |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 0.00029353055 |
|    clip_fraction        | 0.004         |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0546       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 21.3          |
|    n_updates            | 430           |
|    policy_gradient_loss | -0.00036      |
|    value_loss           | 38.1          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -186         |
| time/                   |              |
|    fps                  | 65           |
|    iterations           | 45           |
|    time_elapsed         | 1416         |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0002975693 |
|    clip_fraction        | 0.00171      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0521      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 13.5         |
|    n_updates            | 440          |
|    policy_gradient_loss | 7.15e-05     |
|    value_loss           | 36.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -186          |
| time/                   |               |
|    fps                  | 64            |
|    iterations           | 46            |
|    time_elapsed         | 1450          |
|    total_timesteps      | 94208         |
| train/                  |               |
|    approx_kl            | 0.00080728857 |
|    clip_fraction        | 0.00825       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0328       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 20            |
|    n_updates            | 450           |
|    policy_gradient_loss | -0.000708     |
|    value_loss           | 37            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -166          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 47            |
|    time_elapsed         | 1479          |
|    total_timesteps      | 96256         |
| train/                  |               |
|    approx_kl            | 0.00035418026 |
|    clip_fraction        | 0.00264       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.027        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 20.5          |
|    n_updates            | 460           |
|    policy_gradient_loss | -0.000247     |
|    value_loss           | 39.4          |
-------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 4.1e+03        |
|    ep_rew_mean          | -166           |
| time/                   |                |
|    fps                  | 65             |
|    iterations           | 48             |
|    time_elapsed         | 1510           |
|    total_timesteps      | 98304          |
| train/                  |                |
|    approx_kl            | 0.000108003675 |
|    clip_fraction        | 0.00103        |
|    clip_range           | 0.2            |
|    entropy_loss         | -0.0228        |
|    explained_variance   | 1.19e-07       |
|    learning_rate        | 0.0003         |
|    loss                 | 19             |
|    n_updates            | 470            |
|    policy_gradient_loss | -5.44e-05      |
|    value_loss           | 37.3           |
--------------------------------------------
Num timesteps: 100000
Best mean reward: -205.17 - Last mean reward per episode: -149.69
Saving new best model at 98305 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -150          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 49            |
|    time_elapsed         | 1541          |
|    total_timesteps      | 100352        |
| train/                  |               |
|    approx_kl            | 5.0651288e-05 |
|    clip_fraction        | 0.000732      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0169       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 22.9          |
|    n_updates            | 480           |
|    policy_gradient_loss | -0.000187     |
|    value_loss           | 38.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -150          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 50            |
|    time_elapsed         | 1571          |
|    total_timesteps      | 102400        |
| train/                  |               |
|    approx_kl            | 4.9987633e-05 |
|    clip_fraction        | 0.00132       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0145       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 17.1          |
|    n_updates            | 490           |
|    policy_gradient_loss | -0.000231     |
|    value_loss           | 36            |
-------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 4.1e+03        |
|    ep_rew_mean          | -130           |
| time/                   |                |
|    fps                  | 65             |
|    iterations           | 51             |
|    time_elapsed         | 1601           |
|    total_timesteps      | 104448         |
| train/                  |                |
|    approx_kl            | 0.000117135845 |
|    clip_fraction        | 0.00215        |
|    clip_range           | 0.2            |
|    entropy_loss         | -0.0124        |
|    explained_variance   | 1.19e-07       |
|    learning_rate        | 0.0003         |
|    loss                 | 19.7           |
|    n_updates            | 500            |
|    policy_gradient_loss | -8.62e-05      |
|    value_loss           | 38.4           |
--------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -130          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 52            |
|    time_elapsed         | 1632          |
|    total_timesteps      | 106496        |
| train/                  |               |
|    approx_kl            | 0.00023865973 |
|    clip_fraction        | 0.00234       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0117       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 22.3          |
|    n_updates            | 510           |
|    policy_gradient_loss | -0.000271     |
|    value_loss           | 37.7          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.1e+03      |
|    ep_rew_mean          | -115         |
| time/                   |              |
|    fps                  | 65           |
|    iterations           | 53           |
|    time_elapsed         | 1663         |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 7.966196e-05 |
|    clip_fraction        | 0.000732     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00913     |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 17.7         |
|    n_updates            | 520          |
|    policy_gradient_loss | -0.000136    |
|    value_loss           | 37           |
------------------------------------------
Num timesteps: 110000
Best mean reward: -149.69 - Last mean reward per episode: -114.94
Saving new best model at 106497 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -115          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 54            |
|    time_elapsed         | 1694          |
|    total_timesteps      | 110592        |
| train/                  |               |
|    approx_kl            | 2.1561165e-05 |
|    clip_fraction        | 0.000391      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00953      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 26.3          |
|    n_updates            | 530           |
|    policy_gradient_loss | -3.17e-06     |
|    value_loss           | 38.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -104          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 55            |
|    time_elapsed         | 1724          |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 0.00012225128 |
|    clip_fraction        | 0.00117       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00834      |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 22            |
|    n_updates            | 540           |
|    policy_gradient_loss | 0.000141      |
|    value_loss           | 38.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -104          |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 56            |
|    time_elapsed         | 1753          |
|    total_timesteps      | 114688        |
| train/                  |               |
|    approx_kl            | 3.1600328e-05 |
|    clip_fraction        | 0.000391      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00848      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 15            |
|    n_updates            | 550           |
|    policy_gradient_loss | -6.61e-05     |
|    value_loss           | 37.9          |
-------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.1e+03    |
|    ep_rew_mean          | -92.6      |
| time/                   |            |
|    fps                  | 65         |
|    iterations           | 57         |
|    time_elapsed         | 1784       |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 9.9545e-06 |
|    clip_fraction        | 0.000293   |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00895   |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 18.2       |
|    n_updates            | 560        |
|    policy_gradient_loss | -1.15e-05  |
|    value_loss           | 37.7       |
----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -92.6         |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 58            |
|    time_elapsed         | 1814          |
|    total_timesteps      | 118784        |
| train/                  |               |
|    approx_kl            | 4.5270484e-05 |
|    clip_fraction        | 0.000879      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0078       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 18.7          |
|    n_updates            | 570           |
|    policy_gradient_loss | -0.000104     |
|    value_loss           | 38.2          |
-------------------------------------------
Num timesteps: 120000
Best mean reward: -114.94 - Last mean reward per episode: -85.14
Saving new best model at 119098 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.11e+03     |
|    ep_rew_mean          | -85.1        |
| time/                   |              |
|    fps                  | 65           |
|    iterations           | 59           |
|    time_elapsed         | 1843         |
|    total_timesteps      | 120832       |
| train/                  |              |
|    approx_kl            | 1.713523e-05 |
|    clip_fraction        | 0.000244     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00858     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 19.6         |
|    n_updates            | 580          |
|    policy_gradient_loss | -4.28e-05    |
|    value_loss           | 38.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.11e+03      |
|    ep_rew_mean          | -85.1         |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 60            |
|    time_elapsed         | 1872          |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 0.00013544146 |
|    clip_fraction        | 0.00171       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00886      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 20.9          |
|    n_updates            | 590           |
|    policy_gradient_loss | -0.000148     |
|    value_loss           | 38.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.12e+03      |
|    ep_rew_mean          | -75.1         |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 61            |
|    time_elapsed         | 1901          |
|    total_timesteps      | 124928        |
| train/                  |               |
|    approx_kl            | 4.1953666e-05 |
|    clip_fraction        | 0.00083       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00724      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 20.1          |
|    n_updates            | 600           |
|    policy_gradient_loss | -0.000106     |
|    value_loss           | 38.3          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 4.12e+03 |
|    ep_rew_mean          | -75.1    |
| time/                   |          |
|    fps                  | 65       |
|    iterations           | 62       |
|    time_elapsed         | 1930     |
|    total_timesteps      | 126976   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00704 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 18.5     |
|    n_updates            | 610      |
|    policy_gradient_loss | 4.37e-10 |
|    value_loss           | 39.6     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.12e+03      |
|    ep_rew_mean          | -62.5         |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 63            |
|    time_elapsed         | 1962          |
|    total_timesteps      | 129024        |
| train/                  |               |
|    approx_kl            | 7.7522214e-05 |
|    clip_fraction        | 0.000879      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00534      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 20.5          |
|    n_updates            | 620           |
|    policy_gradient_loss | -0.00014      |
|    value_loss           | 36.8          |
-------------------------------------------
Num timesteps: 130000
Best mean reward: -85.14 - Last mean reward per episode: -62.48
Saving new best model at 127634 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 4.12e+03 |
|    ep_rew_mean          | -62.5    |
| time/                   |          |
|    fps                  | 65       |
|    iterations           | 64       |
|    time_elapsed         | 1992     |
|    total_timesteps      | 131072   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00524 |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 18.1     |
|    n_updates            | 630      |
|    policy_gradient_loss | 6.02e-10 |
|    value_loss           | 38.3     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.11e+03      |
|    ep_rew_mean          | -51.4         |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 65            |
|    time_elapsed         | 2022          |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 1.4871417e-05 |
|    clip_fraction        | 0.000342      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00611      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 14.7          |
|    n_updates            | 640           |
|    policy_gradient_loss | -7.85e-05     |
|    value_loss           | 37.3          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.11e+03     |
|    ep_rew_mean          | -51.4        |
| time/                   |              |
|    fps                  | 65           |
|    iterations           | 66           |
|    time_elapsed         | 2055         |
|    total_timesteps      | 135168       |
| train/                  |              |
|    approx_kl            | 3.497611e-05 |
|    clip_fraction        | 0.00083      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00501     |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 23           |
|    n_updates            | 650          |
|    policy_gradient_loss | -9.57e-05    |
|    value_loss           | 38.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -45           |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 67            |
|    time_elapsed         | 2086          |
|    total_timesteps      | 137216        |
| train/                  |               |
|    approx_kl            | 0.00015247284 |
|    clip_fraction        | 0.000391      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00709      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 23.7          |
|    n_updates            | 660           |
|    policy_gradient_loss | -0.000163     |
|    value_loss           | 38.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -45           |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 68            |
|    time_elapsed         | 2117          |
|    total_timesteps      | 139264        |
| train/                  |               |
|    approx_kl            | 0.00041668097 |
|    clip_fraction        | 0.000391      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0153       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 17.2          |
|    n_updates            | 670           |
|    policy_gradient_loss | -8.92e-05     |
|    value_loss           | 38.9          |
-------------------------------------------
Num timesteps: 140000
Best mean reward: -62.48 - Last mean reward per episode: -35.07
Saving new best model at 139265 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 4.1e+03        |
|    ep_rew_mean          | -35.1          |
| time/                   |                |
|    fps                  | 65             |
|    iterations           | 69             |
|    time_elapsed         | 2148           |
|    total_timesteps      | 141312         |
| train/                  |                |
|    approx_kl            | 0.000108218315 |
|    clip_fraction        | 0.00303        |
|    clip_range           | 0.2            |
|    entropy_loss         | -0.0125        |
|    explained_variance   | 1.19e-07       |
|    learning_rate        | 0.0003         |
|    loss                 | 13.4           |
|    n_updates            | 680            |
|    policy_gradient_loss | 3.98e-05       |
|    value_loss           | 37.8           |
--------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.1e+03       |
|    ep_rew_mean          | -35.1         |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 70            |
|    time_elapsed         | 2177          |
|    total_timesteps      | 143360        |
| train/                  |               |
|    approx_kl            | 0.00017742769 |
|    clip_fraction        | 0.0019        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0115       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 17.9          |
|    n_updates            | 690           |
|    policy_gradient_loss | -8.73e-05     |
|    value_loss           | 36.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.12e+03      |
|    ep_rew_mean          | -21.9         |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 71            |
|    time_elapsed         | 2205          |
|    total_timesteps      | 145408        |
| train/                  |               |
|    approx_kl            | 2.3806933e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0109       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 17.6          |
|    n_updates            | 700           |
|    policy_gradient_loss | -6.39e-08     |
|    value_loss           | 36.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.12e+03      |
|    ep_rew_mean          | -21.9         |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 72            |
|    time_elapsed         | 2235          |
|    total_timesteps      | 147456        |
| train/                  |               |
|    approx_kl            | 2.7459435e-05 |
|    clip_fraction        | 0.000684      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0125       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 18.9          |
|    n_updates            | 710           |
|    policy_gradient_loss | -0.000128     |
|    value_loss           | 38.1          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 4.12e+03     |
|    ep_rew_mean          | -15.7        |
| time/                   |              |
|    fps                  | 65           |
|    iterations           | 73           |
|    time_elapsed         | 2266         |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 6.634422e-05 |
|    clip_fraction        | 0.000439     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0117      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 16.4         |
|    n_updates            | 720          |
|    policy_gradient_loss | 2.92e-05     |
|    value_loss           | 37           |
------------------------------------------
Num timesteps: 150000
Best mean reward: -35.07 - Last mean reward per episode: -15.67
Saving new best model at 148168 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.12e+03      |
|    ep_rew_mean          | -15.7         |
| time/                   |               |
|    fps                  | 65            |
|    iterations           | 74            |
|    time_elapsed         | 2296          |
|    total_timesteps      | 151552        |
| train/                  |               |
|    approx_kl            | 1.1166936e-05 |
|    clip_fraction        | 0.000244      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0114       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 15.2          |
|    n_updates            | 730           |
|    policy_gradient_loss | -4.97e-05     |
|    value_loss           | 38.3          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 4.11e+03 |
|    ep_rew_mean          | -10.1    |
| time/                   |          |
|    fps                  | 66       |
|    iterations           | 75       |
|    time_elapsed         | 2326     |
|    total_timesteps      | 153600   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.012   |
|    explained_variance   | 0        |
|    learning_rate        | 0.0003   |
|    loss                 | 22       |
|    n_updates            | 740      |
|    policy_gradient_loss | 1.03e-09 |
|    value_loss           | 38.9     |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.11e+03    |
|    ep_rew_mean          | -10.1       |
| time/                   |             |
|    fps                  | 66          |
|    iterations           | 76          |
|    time_elapsed         | 2356        |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 9.88695e-06 |
|    clip_fraction        | 0.000244    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0133     |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 20.5        |
|    n_updates            | 750         |
|    policy_gradient_loss | -5.77e-05   |
|    value_loss           | 38.5        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.12e+03      |
|    ep_rew_mean          | -3.78         |
| time/                   |               |
|    fps                  | 66            |
|    iterations           | 77            |
|    time_elapsed         | 2385          |
|    total_timesteps      | 157696        |
| train/                  |               |
|    approx_kl            | 1.2469885e-05 |
|    clip_fraction        | 9.77e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0124       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 18.4          |
|    n_updates            | 760           |
|    policy_gradient_loss | -9.53e-06     |
|    value_loss           | 38            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 4.12e+03      |
|    ep_rew_mean          | -3.78         |
| time/                   |               |
|    fps                  | 66            |
|    iterations           | 78            |
|    time_elapsed         | 2416          |
|    total_timesteps      | 159744        |
| train/                  |               |
|    approx_kl            | 6.7663495e-05 |
|    clip_fraction        | 0.00127       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00942      |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 19            |
|    n_updates            | 770           |
|    policy_gradient_loss | -0.000285     |
|    value_loss           | 39            |
-------------------------------------------
Num timesteps: 160000
Best mean reward: -15.67 - Last mean reward per episode: -3.78
Saving new best model at 156447 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.11e+03    |
|    ep_rew_mean          | 3.06        |
| time/                   |             |
|    fps                  | 66          |
|    iterations           | 79          |
|    time_elapsed         | 2445        |
|    total_timesteps      | 161792      |
| train/                  |             |
|    approx_kl            | 0.000146617 |
|    clip_fraction        | 0.00117     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00965    |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 18.9        |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.000189   |
|    value_loss           | 38          |
-----------------------------------------