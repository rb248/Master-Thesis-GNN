
Using cpu device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -500     |
| time/              |          |
|    fps             | 144      |
|    iterations      | 1        |
|    time_elapsed    | 14       |
|    total_timesteps | 2048     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 55          |
|    iterations           | 2           |
|    time_elapsed         | 74          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.006787274 |
|    clip_fraction        | 0.0306      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 6.23e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.675       |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.000504   |
|    value_loss           | 4.03        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 1e+03     |
|    ep_rew_mean          | -500      |
| time/                   |           |
|    fps                  | 42        |
|    iterations           | 3         |
|    time_elapsed         | 143       |
|    total_timesteps      | 6144      |
| train/                  |           |
|    approx_kl            | 0.0093782 |
|    clip_fraction        | 0.00625   |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.09     |
|    explained_variance   | -2.38e-06 |
|    learning_rate        | 0.0003    |
|    loss                 | 0.106     |
|    n_updates            | 20        |
|    policy_gradient_loss | -0.000416 |
|    value_loss           | 12        |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -500         |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 4            |
|    time_elapsed         | 206          |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0066327895 |
|    clip_fraction        | 0.0337       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.09        |
|    explained_variance   | 0.00091      |
|    learning_rate        | 0.0003       |
|    loss                 | 3.69         |
|    n_updates            | 30           |
|    policy_gradient_loss | 0.00244      |
|    value_loss           | 12.8         |
------------------------------------------
Num timesteps: 10000
Best mean reward: -inf - Last mean reward per episode: -500.00
Saving new best model at 10000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -500        |
| time/                   |             |
|    fps                  | 37          |
|    iterations           | 5           |
|    time_elapsed         | 270         |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.010850219 |
|    clip_fraction        | 0.046       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.08       |
|    explained_variance   | -5.25e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0774      |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00192    |
|    value_loss           | 10          |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -488         |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 6            |
|    time_elapsed         | 330          |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0073880656 |
|    clip_fraction        | 0.0424       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.05        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 5.74         |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00128     |
|    value_loss           | 9.72         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -478        |
| time/                   |             |
|    fps                  | 36          |
|    iterations           | 7           |
|    time_elapsed         | 394         |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.009348528 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.995      |
|    explained_variance   | -1.78e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.9         |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00683    |
|    value_loss           | 19.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -473        |
| time/                   |             |
|    fps                  | 35          |
|    iterations           | 8           |
|    time_elapsed         | 462         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.004526562 |
|    clip_fraction        | 0.046       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.961      |
|    explained_variance   | -9.54e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 7.56        |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00257    |
|    value_loss           | 21.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -467        |
| time/                   |             |
|    fps                  | 34          |
|    iterations           | 9           |
|    time_elapsed         | 531         |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.008217437 |
|    clip_fraction        | 0.0465      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.885      |
|    explained_variance   | -2.6e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 6.04        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00227    |
|    value_loss           | 22.6        |
-----------------------------------------
Num timesteps: 20000
Best mean reward: -500.00 - Last mean reward per episode: -460.00
Saving new best model at 20000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -460         |
| time/                   |              |
|    fps                  | 33           |
|    iterations           | 10           |
|    time_elapsed         | 608          |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 0.0057892483 |
|    clip_fraction        | 0.0626       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.834       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 14.5         |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.0017      |
|    value_loss           | 26.1         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -454         |
| time/                   |              |
|    fps                  | 33           |
|    iterations           | 11           |
|    time_elapsed         | 680          |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0034152323 |
|    clip_fraction        | 0.0475       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.849       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 17.1         |
|    n_updates            | 100          |
|    policy_gradient_loss | 0.000467     |
|    value_loss           | 25           |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -447        |
| time/                   |             |
|    fps                  | 32          |
|    iterations           | 12          |
|    time_elapsed         | 756         |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.011926176 |
|    clip_fraction        | 0.0314      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.842      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 15.1        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00106    |
|    value_loss           | 33.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -435        |
| time/                   |             |
|    fps                  | 32          |
|    iterations           | 13          |
|    time_elapsed         | 831         |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.009389303 |
|    clip_fraction        | 0.075       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.75       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 22.3        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00285    |
|    value_loss           | 39          |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -431         |
| time/                   |              |
|    fps                  | 31           |
|    iterations           | 14           |
|    time_elapsed         | 905          |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 0.0018700522 |
|    clip_fraction        | 0.01         |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.694       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 9.95         |
|    n_updates            | 130          |
|    policy_gradient_loss | 0.000207     |
|    value_loss           | 34           |
------------------------------------------
Num timesteps: 30000
Best mean reward: -460.00 - Last mean reward per episode: -426.67
Saving new best model at 30000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -427         |
| time/                   |              |
|    fps                  | 31           |
|    iterations           | 15           |
|    time_elapsed         | 973          |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 0.0075120153 |
|    clip_fraction        | 0.122        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.624       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 12.7         |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.0064      |
|    value_loss           | 23.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -420         |
| time/                   |              |
|    fps                  | 31           |
|    iterations           | 16           |
|    time_elapsed         | 1036         |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0029010582 |
|    clip_fraction        | 0.0451       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.55        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 18.1         |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00165     |
|    value_loss           | 34.1         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -422         |
| time/                   |              |
|    fps                  | 31           |
|    iterations           | 17           |
|    time_elapsed         | 1106         |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0023498933 |
|    clip_fraction        | 0.0251       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.524       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 16.6         |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.000918    |
|    value_loss           | 42           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -415         |
| time/                   |              |
|    fps                  | 31           |
|    iterations           | 18           |
|    time_elapsed         | 1180         |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0031029705 |
|    clip_fraction        | 0.0334       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.494       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 8.38         |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00104     |
|    value_loss           | 33.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -411         |
| time/                   |              |
|    fps                  | 31           |
|    iterations           | 19           |
|    time_elapsed         | 1251         |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0013776326 |
|    clip_fraction        | 0.0133       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.475       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 6.23         |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.000681    |
|    value_loss           | 42           |
------------------------------------------
Num timesteps: 40000
Best mean reward: -426.67 - Last mean reward per episode: -409.75
Saving new best model at 40000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -410         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 20           |
|    time_elapsed         | 1324         |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 0.0034775124 |
|    clip_fraction        | 0.0681       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.418       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 10.1         |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.0033      |
|    value_loss           | 34.7         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -399         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 21           |
|    time_elapsed         | 1404         |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0026345686 |
|    clip_fraction        | 0.0408       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.354       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 28.2         |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00278     |
|    value_loss           | 43           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -394          |
| time/                   |               |
|    fps                  | 30            |
|    iterations           | 22            |
|    time_elapsed         | 1467          |
|    total_timesteps      | 45056         |
| train/                  |               |
|    approx_kl            | 0.00088216807 |
|    clip_fraction        | 0.0116        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.347        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 19.6          |
|    n_updates            | 210           |
|    policy_gradient_loss | -0.000323     |
|    value_loss           | 45.4          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -393        |
| time/                   |             |
|    fps                  | 30          |
|    iterations           | 23          |
|    time_elapsed         | 1532        |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.001062354 |
|    clip_fraction        | 0.00806     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.335      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 22.4        |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.000119   |
|    value_loss           | 42.4        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -385         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 24           |
|    time_elapsed         | 1598         |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0012600892 |
|    clip_fraction        | 0.0183       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.327       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 30.4         |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.000582    |
|    value_loss           | 34.6         |
------------------------------------------
Num timesteps: 50000
Best mean reward: -409.75 - Last mean reward per episode: -384.20
Saving new best model at 50000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -384         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 25           |
|    time_elapsed         | 1672         |
|    total_timesteps      | 51200        |
| train/                  |              |
|    approx_kl            | 0.0012779746 |
|    clip_fraction        | 0.024        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.339       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 24.2         |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.000185    |
|    value_loss           | 57.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -378         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 26           |
|    time_elapsed         | 1752         |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0012460866 |
|    clip_fraction        | 0.0106       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.291       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 10.1         |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.000377    |
|    value_loss           | 29.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -375         |
| time/                   |              |
|    fps                  | 30           |
|    iterations           | 27           |
|    time_elapsed         | 1842         |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 0.0015238819 |
|    clip_fraction        | 0.0245       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.271       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 20.4         |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.00119     |
|    value_loss           | 47.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -374          |
| time/                   |               |
|    fps                  | 29            |
|    iterations           | 28            |
|    time_elapsed         | 1931          |
|    total_timesteps      | 57344         |
| train/                  |               |
|    approx_kl            | 0.00040732863 |
|    clip_fraction        | 0.0143        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.253        |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 15.5          |
|    n_updates            | 270           |
|    value_loss           | 37.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -370         |
| time/                   |              |
|    fps                  | 29           |
|    iterations           | 29           |
|    time_elapsed         | 2026         |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 0.0017415294 |
|    clip_fraction        | 0.0267       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.216       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 14.2         |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.00244     |
|    value_loss           | 38.2         |
------------------------------------------
Num timesteps: 60000
Best mean reward: -384.20 - Last mean reward per episode: -369.33
Saving new best model at 60000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -367         |
| time/                   |              |
|    fps                  | 29           |
|    iterations           | 30           |
|    time_elapsed         | 2110         |
|    total_timesteps      | 61440        |
| train/                  |              |
|    approx_kl            | 0.0003274009 |
|    clip_fraction        | 0.0106       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.183       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 18.3         |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.000266    |
|    value_loss           | 42.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -364         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 31           |
|    time_elapsed         | 2194         |
|    total_timesteps      | 63488        |
| train/                  |              |
|    approx_kl            | 0.0011036026 |
|    clip_fraction        | 0.00586      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.175       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 19.2         |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.0001      |
|    value_loss           | 40.9         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -362          |
| time/                   |               |
|    fps                  | 28            |
|    iterations           | 32            |
|    time_elapsed         | 2293          |
|    total_timesteps      | 65536         |
| train/                  |               |
|    approx_kl            | 0.00077685085 |
|    clip_fraction        | 0.0129        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.136        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 27.7          |
|    n_updates            | 310           |
|    policy_gradient_loss | -0.000561     |
|    value_loss           | 53.2          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -360        |
| time/                   |             |
|    fps                  | 28          |
|    iterations           | 33          |
|    time_elapsed         | 2395        |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.000307187 |
|    clip_fraction        | 0.00518     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.143      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 26          |
|    n_updates            | 320         |
|    policy_gradient_loss | 0.000211    |
|    value_loss           | 35.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -359         |
| time/                   |              |
|    fps                  | 28           |
|    iterations           | 34           |
|    time_elapsed         | 2483         |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 0.0004690481 |
|    clip_fraction        | 0.00747      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.152       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 27.3         |
|    n_updates            | 330          |
|    policy_gradient_loss | -0.000761    |
|    value_loss           | 35.7         |
------------------------------------------
Num timesteps: 70000
Best mean reward: -369.33 - Last mean reward per episode: -357.86
Saving new best model at 70000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -357          |
| time/                   |               |
|    fps                  | 27            |
|    iterations           | 35            |
|    time_elapsed         | 2607          |
|    total_timesteps      | 71680         |
| train/                  |               |
|    approx_kl            | 0.00046670943 |
|    clip_fraction        | 0.00508       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.156        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 39.6          |
|    n_updates            | 340           |
|    policy_gradient_loss | 0.000107      |
|    value_loss           | 50.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -353         |
| time/                   |              |
|    fps                  | 27           |
|    iterations           | 36           |
|    time_elapsed         | 2721         |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0012593328 |
|    clip_fraction        | 0.00898      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.162       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 13.6         |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.000422    |
|    value_loss           | 38           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -355         |
| time/                   |              |
|    fps                  | 26           |
|    iterations           | 37           |
|    time_elapsed         | 2879         |
|    total_timesteps      | 75776        |
| train/                  |              |
|    approx_kl            | 0.0006521441 |
|    clip_fraction        | 0.00962      |
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -356          |
| time/                   |               |
|    fps                  | 25            |
|    iterations           | 38            |
|    time_elapsed         | 3051          |
|    total_timesteps      | 77824         |
| train/                  |               |
|    approx_kl            | 0.00023890316 |
|    clip_fraction        | 0.00596       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.151        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 13.2          |
|    n_updates            | 370           |
|    policy_gradient_loss | -0.000253     |
|    value_loss           | 24.7          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -351         |
| time/                   |              |
|    fps                  | 24           |
|    iterations           | 39           |
|    time_elapsed         | 3205         |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 0.0004885493 |
|    clip_fraction        | 0.0116       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.15        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 22.8         |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.000716    |
|    value_loss           | 34.2         |
------------------------------------------
Num timesteps: 80000
Best mean reward: -357.86 - Last mean reward per episode: -351.50
Saving new best model at 80000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -351        |
| time/                   |             |
|    fps                  | 24          |
|    iterations           | 40          |
|    time_elapsed         | 3339        |
|    total_timesteps      | 81920       |
| train/                  |             |
|    approx_kl            | 0.000558373 |
|    clip_fraction        | 0.00815     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.143      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 16.3        |
|    n_updates            | 390         |
|    policy_gradient_loss | 2.73e-05    |
|    value_loss           | 49.6        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -348         |
| time/                   |              |
|    fps                  | 24           |
|    iterations           | 41           |
|    time_elapsed         | 3456         |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 3.727965e-05 |
|    clip_fraction        | 0.00249      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.13        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 22.6         |
|    n_updates            | 400          |
|    policy_gradient_loss | 5.47e-05     |
|    value_loss           | 44.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -344          |
| time/                   |               |
|    fps                  | 24            |
|    iterations           | 42            |
|    time_elapsed         | 3577          |
|    total_timesteps      | 86016         |
| train/                  |               |
|    approx_kl            | 0.00058101583 |
|    clip_fraction        | 0.00396       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.135        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 29.1          |
|    n_updates            | 410           |
|    policy_gradient_loss | 0.000113      |
|    value_loss           | 38            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -342         |
| time/                   |              |
|    fps                  | 23           |
|    iterations           | 43           |
|    time_elapsed         | 3711         |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 0.0006466054 |
|    clip_fraction        | 0.0161       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0937      |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 30.7         |
|    n_updates            | 420          |
|    policy_gradient_loss | -0.000954    |
|    value_loss           | 55.7         |
------------------------------------------
Num timesteps: 90000
Best mean reward: -351.50 - Last mean reward per episode: -341.22
Saving new best model at 90000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -341          |
| time/                   |               |
|    fps                  | 23            |
|    iterations           | 44            |
|    time_elapsed         | 3854          |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 0.00022620955 |
|    clip_fraction        | 0.00552       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.103        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 19.2          |
|    n_updates            | 430           |
|    policy_gradient_loss | -0.000118     |
|    value_loss           | 38.4          |
-------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -342       |
| time/                   |            |
|    fps                  | 23         |
|    iterations           | 45         |
|    time_elapsed         | 3980       |
|    total_timesteps      | 92160      |
| train/                  |            |
|    approx_kl            | 0.00041551 |
|    clip_fraction        | 0.0108     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.11      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 18.2       |
|    n_updates            | 440        |
|    policy_gradient_loss | -0.00103   |
|    value_loss           | 40         |
----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -340          |
| time/                   |               |
|    fps                  | 22            |
|    iterations           | 46            |
|    time_elapsed         | 4135          |
|    total_timesteps      | 94208         |
| train/                  |               |
|    approx_kl            | 0.00039796167 |
|    clip_fraction        | 0.00996       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0943       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 17.1          |
|    n_updates            | 450           |
|    policy_gradient_loss | -0.000615     |
|    value_loss           | 31.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -340          |
| time/                   |               |
|    fps                  | 22            |
|    iterations           | 47            |
|    time_elapsed         | 4254          |
|    total_timesteps      | 96256         |
| train/                  |               |
|    approx_kl            | 0.00056431745 |
|    clip_fraction        | 0.0125        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0709       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 14.5          |
|    n_updates            | 460           |
|    policy_gradient_loss | -0.00114      |
|    value_loss           | 42.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -340          |
| time/                   |               |
|    fps                  | 22            |
|    iterations           | 48            |
|    time_elapsed         | 4383          |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 0.00016617856 |
|    clip_fraction        | 0.00635       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0783       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 14.3          |
|    n_updates            | 470           |
|    policy_gradient_loss | -0.000482     |
|    value_loss           | 41.1          |
-------------------------------------------
Num timesteps: 100000
Best mean reward: -341.22 - Last mean reward per episode: -337.00
Saving new best model at 100000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -337          |
| time/                   |               |
|    fps                  | 22            |
|    iterations           | 49            |
|    time_elapsed         | 4491          |
|    total_timesteps      | 100352        |
| train/                  |               |
|    approx_kl            | 0.00046307192 |
|    clip_fraction        | 0.00596       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.077        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 18.6          |
|    n_updates            | 480           |
|    policy_gradient_loss | -7.66e-05     |
|    value_loss           | 41.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -332         |
| time/                   |              |
|    fps                  | 22           |
|    iterations           | 50           |
|    time_elapsed         | 4593         |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 8.721702e-05 |
|    clip_fraction        | 0.00215      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0738      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 32.5         |
|    n_updates            | 490          |
|    policy_gradient_loss | -4.62e-05    |
|    value_loss           | 48.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -326          |
| time/                   |               |
|    fps                  | 22            |
|    iterations           | 51            |
|    time_elapsed         | 4688          |
|    total_timesteps      | 104448        |
| train/                  |               |
|    approx_kl            | 0.00025635125 |
|    clip_fraction        | 0.00444       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0652       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 29.1          |
|    n_updates            | 500           |
|    policy_gradient_loss | -0.000245     |
|    value_loss           | 42.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -322          |
| time/                   |               |
|    fps                  | 22            |
|    iterations           | 52            |
|    time_elapsed         | 4784          |
|    total_timesteps      | 106496        |
| train/                  |               |
|    approx_kl            | 0.00014007554 |
|    clip_fraction        | 0.00234       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0586       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 33            |
|    n_updates            | 510           |
|    policy_gradient_loss | 0.000237      |
|    value_loss           | 49.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -316          |
| time/                   |               |
|    fps                  | 22            |
|    iterations           | 53            |
|    time_elapsed         | 4911          |
|    total_timesteps      | 108544        |
| train/                  |               |
|    approx_kl            | 4.6896574e-05 |
|    clip_fraction        | 0.000635      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0567       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 25            |
|    n_updates            | 520           |
|    policy_gradient_loss | 8.84e-05      |
|    value_loss           | 46.4          |
-------------------------------------------
Num timesteps: 110000
Best mean reward: -337.00 - Last mean reward per episode: -311.60
Saving new best model at 110000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -312          |
| time/                   |               |
|    fps                  | 22            |
|    iterations           | 54            |
|    time_elapsed         | 5007          |
|    total_timesteps      | 110592        |
| train/                  |               |
|    approx_kl            | 0.00011648302 |
|    clip_fraction        | 0.00327       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0555       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 14.9          |
|    n_updates            | 530           |
|    policy_gradient_loss | -0.000185     |
|    value_loss           | 54            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -309         |
| time/                   |              |
|    fps                  | 22           |
|    iterations           | 55           |
|    time_elapsed         | 5070         |
|    total_timesteps      | 112640       |
| train/                  |              |
|    approx_kl            | 0.0002525146 |
|    clip_fraction        | 0.0061       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.046       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 28.7         |
|    n_updates            | 540          |
|    policy_gradient_loss | -0.000462    |
|    value_loss           | 34.9         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -306          |
| time/                   |               |
|    fps                  | 22            |
|    iterations           | 56            |
|    time_elapsed         | 5137          |
|    total_timesteps      | 114688        |
| train/                  |               |
|    approx_kl            | 0.00019668567 |
|    clip_fraction        | 0.0022        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0402       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 22.4          |
|    n_updates            | 550           |
|    policy_gradient_loss | -0.000164     |
|    value_loss           | 42.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -301          |
| time/                   |               |
|    fps                  | 22            |
|    iterations           | 57            |
|    time_elapsed         | 5202          |
|    total_timesteps      | 116736        |
| train/                  |               |
|    approx_kl            | 0.00011940586 |
|    clip_fraction        | 0.00288       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0312       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 15.7          |
|    n_updates            | 560           |
|    policy_gradient_loss | -0.00017      |
|    value_loss           | 38.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -299          |
| time/                   |               |
|    fps                  | 22            |
|    iterations           | 58            |
|    time_elapsed         | 5268          |
|    total_timesteps      | 118784        |
| train/                  |               |
|    approx_kl            | 0.00010185168 |
|    clip_fraction        | 0.00308       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0373       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 40.5          |
|    n_updates            | 570           |
|    policy_gradient_loss | -0.00045      |
|    value_loss           | 57.1          |
-------------------------------------------
Num timesteps: 120000
Best mean reward: -311.60 - Last mean reward per episode: -296.80
Saving new best model at 120000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -297          |
| time/                   |               |
|    fps                  | 22            |
|    iterations           | 59            |
|    time_elapsed         | 5334          |
|    total_timesteps      | 120832        |
| train/                  |               |
|    approx_kl            | 0.00016666093 |
|    clip_fraction        | 0.00195       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0429       |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 15.3          |
|    n_updates            | 580           |
|    policy_gradient_loss | 1.13e-05      |
|    value_loss           | 32.2          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -295         |
| time/                   |              |
|    fps                  | 22           |
|    iterations           | 60           |
|    time_elapsed         | 5398         |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 0.0004353963 |
|    clip_fraction        | 0.00288      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0497      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 34.7         |
|    n_updates            | 590          |
|    policy_gradient_loss | -0.00019     |
|    value_loss           | 45.8         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -294          |
| time/                   |               |
|    fps                  | 22            |
|    iterations           | 61            |
|    time_elapsed         | 5465          |
|    total_timesteps      | 124928        |
| train/                  |               |
|    approx_kl            | 0.00013282182 |
|    clip_fraction        | 0.00439       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0658       |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 15.9          |
|    n_updates            | 600           |
|    policy_gradient_loss | -1.84e-05     |
|    value_loss           | 46.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -295          |
| time/                   |               |
|    fps                  | 22            |
|    iterations           | 62            |
|    time_elapsed         | 5528          |
|    total_timesteps      | 126976        |
| train/                  |               |
|    approx_kl            | 0.00023808086 |
|    clip_fraction        | 0.0041        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0635       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 12.6          |
|    n_updates            | 610           |
|    policy_gradient_loss | -0.000102     |
|    value_loss           | 35            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -288          |
| time/                   |               |
|    fps                  | 23            |
|    iterations           | 63            |
|    time_elapsed         | 5592          |
|    total_timesteps      | 129024        |
| train/                  |               |
|    approx_kl            | 0.00040219948 |
|    clip_fraction        | 0.00806       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.048        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 40.2          |
|    n_updates            | 620           |
|    policy_gradient_loss | -0.000775     |
|    value_loss           | 42.1          |
-------------------------------------------
Num timesteps: 130000
Best mean reward: -296.80 - Last mean reward per episode: -288.20
Saving new best model at 130000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -287       |
| time/                   |            |
|    fps                  | 23         |
|    iterations           | 64         |
|    time_elapsed         | 5656       |
|    total_timesteps      | 131072     |
| train/                  |            |
|    approx_kl            | 6.2109e-05 |
|    clip_fraction        | 0.00142    |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0425    |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 22.9       |
|    n_updates            | 630        |
|    policy_gradient_loss | -8.35e-07  |
|    value_loss           | 53.9       |
----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -286          |
| time/                   |               |
|    fps                  | 23            |
|    iterations           | 65            |
|    time_elapsed         | 5718          |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 7.7987206e-05 |
|    clip_fraction        | 0.00166       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0393       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 32.8          |
|    n_updates            | 640           |
|    policy_gradient_loss | -0.00017      |
|    value_loss           | 44.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -286          |
| time/                   |               |
|    fps                  | 23            |
|    iterations           | 66            |
|    time_elapsed         | 5781          |
|    total_timesteps      | 135168        |
| train/                  |               |
|    approx_kl            | 0.00030297102 |
|    clip_fraction        | 0.00283       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0394       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 19            |
|    n_updates            | 650           |
|    policy_gradient_loss | 9.4e-05       |
|    value_loss           | 39.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -284          |
| time/                   |               |
|    fps                  | 23            |
|    iterations           | 67            |
|    time_elapsed         | 5842          |
|    total_timesteps      | 137216        |
| train/                  |               |
|    approx_kl            | 2.5948073e-05 |
|    clip_fraction        | 0.000146      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0335       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 13.5          |
|    n_updates            | 660           |
|    policy_gradient_loss | -4.13e-05     |
|    value_loss           | 25.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -283          |
| time/                   |               |
|    fps                  | 23            |
|    iterations           | 68            |
|    time_elapsed         | 5907          |
|    total_timesteps      | 139264        |
| train/                  |               |
|    approx_kl            | 0.00020671875 |
|    clip_fraction        | 0.00474       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0304       |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 27.3          |
|    n_updates            | 670           |
|    policy_gradient_loss | 9.87e-05      |
|    value_loss           | 47.4          |
-------------------------------------------
Num timesteps: 140000
Best mean reward: -288.20 - Last mean reward per episode: -280.40
Saving new best model at 140000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -281          |
| time/                   |               |
|    fps                  | 23            |
|    iterations           | 69            |
|    time_elapsed         | 5970          |
|    total_timesteps      | 141312        |
| train/                  |               |
|    approx_kl            | 0.00024049816 |
|    clip_fraction        | 0.00273       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0362       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 38.5          |
|    n_updates            | 680           |
|    policy_gradient_loss | -0.000301     |
|    value_loss           | 47.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -280         |
| time/                   |              |
|    fps                  | 23           |
|    iterations           | 70           |
|    time_elapsed         | 6032         |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 0.0001756349 |
|    clip_fraction        | 0.00371      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0347      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 17.1         |
|    n_updates            | 690          |
|    policy_gradient_loss | -8.94e-05    |
|    value_loss           | 40.2         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -283          |
| time/                   |               |
|    fps                  | 23            |
|    iterations           | 71            |
|    time_elapsed         | 6097          |
|    total_timesteps      | 145408        |
| train/                  |               |
|    approx_kl            | 0.00021559541 |
|    clip_fraction        | 0.00513       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0291       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 39.5          |
|    n_updates            | 700           |
|    policy_gradient_loss | -0.000488     |
|    value_loss           | 47.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -281          |
| time/                   |               |
|    fps                  | 23            |
|    iterations           | 72            |
|    time_elapsed         | 6171          |
|    total_timesteps      | 147456        |
| train/                  |               |
|    approx_kl            | 0.00023806404 |
|    clip_fraction        | 0.00166       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.026        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 15.2          |
|    n_updates            | 710           |
|    policy_gradient_loss | -0.000116     |
|    value_loss           | 28.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -282          |
| time/                   |               |
|    fps                  | 23            |
|    iterations           | 73            |
|    time_elapsed         | 6236          |
|    total_timesteps      | 149504        |
| train/                  |               |
|    approx_kl            | 4.3358305e-05 |
|    clip_fraction        | 0.000293      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0225       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 13.8          |
|    n_updates            | 720           |
|    policy_gradient_loss | -1.53e-05     |
|    value_loss           | 51.3          |
-------------------------------------------
Num timesteps: 150000
Best mean reward: -280.40 - Last mean reward per episode: -280.70
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -279         |
| time/                   |              |
|    fps                  | 24           |
|    iterations           | 74           |
|    time_elapsed         | 6300         |
|    total_timesteps      | 151552       |
| train/                  |              |
|    approx_kl            | 9.787045e-05 |
|    clip_fraction        | 0.0022       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0159      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 16.6         |
|    n_updates            | 730          |
|    policy_gradient_loss | -0.000201    |
|    value_loss           | 44.2         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -279          |
| time/                   |               |
|    fps                  | 24            |
|    iterations           | 75            |
|    time_elapsed         | 6363          |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 0.00010033342 |
|    clip_fraction        | 0.000977      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0129       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 20.4          |
|    n_updates            | 740           |
|    policy_gradient_loss | -2.7e-05      |
|    value_loss           | 43.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -276         |
| time/                   |              |
|    fps                  | 24           |
|    iterations           | 76           |
|    time_elapsed         | 6428         |
|    total_timesteps      | 155648       |
| train/                  |              |
|    approx_kl            | 9.232201e-06 |
|    clip_fraction        | 0.000244     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0132      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 23.6         |
|    n_updates            | 750          |
|    policy_gradient_loss | 2.77e-05     |
|    value_loss           | 59.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -276          |
| time/                   |               |
|    fps                  | 24            |
|    iterations           | 77            |
|    time_elapsed         | 6490          |
|    total_timesteps      | 157696        |
| train/                  |               |
|    approx_kl            | 8.8533474e-05 |
|    clip_fraction        | 0.000928      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0162       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 28.1          |
|    n_updates            | 760           |
|    policy_gradient_loss | 4.18e-06      |
|    value_loss           | 49.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -276         |
| time/                   |              |
|    fps                  | 24           |
|    iterations           | 78           |
|    time_elapsed         | 6551         |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 4.946225e-05 |
|    clip_fraction        | 0.00151      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.013       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 26.2         |
|    n_updates            | 770          |
|    policy_gradient_loss | -4.52e-05    |
|    value_loss           | 38.5         |
------------------------------------------
Num timesteps: 160000
Best mean reward: -280.40 - Last mean reward per episode: -275.20
Saving new best model at 160000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -275          |
| time/                   |               |
|    fps                  | 24            |
|    iterations           | 79            |
|    time_elapsed         | 6613          |
|    total_timesteps      | 161792        |
| train/                  |               |
|    approx_kl            | 3.7938124e-05 |
|    clip_fraction        | 0.00146       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0162       |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.0003        |
|    loss                 | 36.5          |
|    n_updates            | 780           |
|    policy_gradient_loss | 8.14e-05      |
|    value_loss           | 50.7          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -276         |
| time/                   |              |
|    fps                  | 24           |
|    iterations           | 80           |
|    time_elapsed         | 6678         |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 7.103727e-05 |
|    clip_fraction        | 0.000635     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0137      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 17.2         |
|    n_updates            | 790          |
|    policy_gradient_loss | -7.93e-06    |
|    value_loss           | 37.9         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -275          |
| time/                   |               |
|    fps                  | 24            |
|    iterations           | 81            |
|    time_elapsed         | 6743          |
|    total_timesteps      | 165888        |
| train/                  |               |
|    approx_kl            | 0.00012005266 |
|    clip_fraction        | 0.00205       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0113       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 13            |
|    n_updates            | 800           |
|    policy_gradient_loss | -0.000233     |
|    value_loss           | 50.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -272          |
| time/                   |               |
|    fps                  | 24            |
|    iterations           | 82            |
|    time_elapsed         | 6813          |
|    total_timesteps      | 167936        |
| train/                  |               |
|    approx_kl            | 3.7213322e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.014        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 23.5          |
|    n_updates            | 810           |
|    policy_gradient_loss | 1.14e-05      |
|    value_loss           | 48.3          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -271         |
| time/                   |              |
|    fps                  | 24           |
|    iterations           | 83           |
|    time_elapsed         | 6883         |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 0.0001197301 |
|    clip_fraction        | 0.00117      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0133      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 35.6         |
|    n_updates            | 820          |
|    policy_gradient_loss | -7.11e-05    |
|    value_loss           | 50.3         |
------------------------------------------
Num timesteps: 170000
Best mean reward: -275.20 - Last mean reward per episode: -269.80
Saving new best model at 170000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -272         |
| time/                   |              |
|    fps                  | 24           |
|    iterations           | 84           |
|    time_elapsed         | 6963         |
|    total_timesteps      | 172032       |
| train/                  |              |
|    approx_kl            | 3.699871e-05 |
|    clip_fraction        | 0.000537     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0129      |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 16.3         |
|    n_updates            | 830          |
|    policy_gradient_loss | -3.55e-05    |
|    value_loss           | 45.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -270          |
| time/                   |               |
|    fps                  | 24            |
|    iterations           | 85            |
|    time_elapsed         | 7039          |
|    total_timesteps      | 174080        |
| train/                  |               |
|    approx_kl            | 5.3152326e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0122       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 13.8          |
|    n_updates            | 840           |
|    policy_gradient_loss | 1.33e-06      |
|    value_loss           | 36.5          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -268         |
| time/                   |              |
|    fps                  | 24           |
|    iterations           | 86           |
|    time_elapsed         | 7110         |
|    total_timesteps      | 176128       |
| train/                  |              |
|    approx_kl            | 4.192334e-05 |
|    clip_fraction        | 0.000684     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0129      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 34.5         |
|    n_updates            | 850          |
|    policy_gradient_loss | -0.000146    |
|    value_loss           | 45           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -267          |
| time/                   |               |
|    fps                  | 24            |
|    iterations           | 87            |
|    time_elapsed         | 7181          |
|    total_timesteps      | 178176        |
| train/                  |               |
|    approx_kl            | 6.0669874e-05 |
|    clip_fraction        | 0.00127       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0106       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 40.7          |
|    n_updates            | 860           |
|    policy_gradient_loss | -9.87e-05     |
|    value_loss           | 46.7          |
-------------------------------------------
Num timesteps: 180000
Best mean reward: -269.80 - Last mean reward per episode: -266.10
Saving new best model at 180000 timesteps
Saving new best model to ./logs/Freeway-GNN-training/best_model.zip
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -266          |
| time/                   |               |
|    fps                  | 24            |
|    iterations           | 88            |
|    time_elapsed         | 7255          |
|    total_timesteps      | 180224        |
| train/                  |               |
|    approx_kl            | 1.3432931e-05 |
|    clip_fraction        | 0.000781      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0123       |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 29.5          |
|    n_updates            | 870           |
|    policy_gradient_loss | -0.000187     |
|    value_loss           | 43            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -268         |
| time/                   |              |
|    fps                  | 24           |
|    iterations           | 89           |
|    time_elapsed         | 7334         |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 8.953808e-05 |
|    clip_fraction        | 0.00103      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0134      |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 19.4         |
|    n_updates            | 880          |
|    policy_gradient_loss | 0.000124     |
|    value_loss           | 44.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -267          |
| time/                   |               |
|    fps                  | 24            |
|    iterations           | 90            |
|    time_elapsed         | 7402          |
|    total_timesteps      | 184320        |
| train/                  |               |
|    approx_kl            | 1.4510006e-05 |
|    clip_fraction        | 0.000439      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0168       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 16.2          |
|    n_updates            | 890           |
|    policy_gradient_loss | -0.000249     |
|    value_loss           | 33.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 1e+03         |
|    ep_rew_mean          | -271          |
| time/                   |               |
|    fps                  | 24            |
|    iterations           | 91            |
|    time_elapsed         | 7476          |
|    total_timesteps      | 186368        |
| train/                  |               |
|    approx_kl            | 2.5159563e-05 |
|    clip_fraction        | 0.000293      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0141       |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 19.4          |
|    n_updates            | 900           |
|    policy_gradient_loss | -3.07e-05     |
|    value_loss           | 36.6          |
-------------------------------------------
Traceback (most recent call last):
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/Users/rishubbhatia/Documents/master thesis/Master-Thesis-GNN/games/freeway/run_supervised_gnn.py", line 290, in <module>
    model.learn(total_timesteps=1000000, callback=[WandbCallback(), save_callback])
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 315, in learn
    return super().learn(
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 313, in learn
    self.train()
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 282, in train
    self.policy.optimizer.step()
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/optim/optimizer.py", line 391, in wrapper
    out = func(*args, **kwargs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/optim/adam.py", line 168, in step
    adam(
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/optim/adam.py", line 318, in adam
    func(params,
  File "/Users/rishubbhatia/miniforge3/envs/games/lib/python3.10/site-packages/torch/optim/adam.py", line 443, in _single_tensor_adam
    param.addcdiv_(exp_avg, denom, value=-step_size)
KeyboardInterrupt